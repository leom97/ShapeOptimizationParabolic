If a package won't install, try https://stackoverflow.com/questions/59723500/cant-install-matplotlib-in-conda-env-w-python-3-8

I.e.:
conda (or mamba) install -c conda-forge name_of_package


Pipeline to set up a virtual environment
- download conda (https://www.anaconda.com/products/distribution)
- install using bash ***.sh
- run conda init
- run conda config --set auto_activate_base false
- create a conda virtual environment with python 3.7
- install mamba, as a substitute of conda install -c conda-forge ...: conda install -c conda-forge mamba
- (*)
- install fenics: mamba install --yes -c conda-forge fenics
- (*) install matplotlib: mamba install -c conda-forge matplotlib
- install dolfin-adjoint: pip install git+https://github.com/dolfin-adjoint/pyadjoint.git@2019.1.0 (@2019.1.0 can be added: do add it)
- install the meshing tools: mamba install -c conda-forge gmsh meshio, and pip install pygmsh (==4.0.6 for python 3.10, or nothing for older versions of python, e.g. 3.9 or 3.8)
- install mshr: mamba install -c conda-forge fenics mshr=2019.1.0=py38hf9f41d3_3 (not working and there is no need)
- fix 3D plotting: https://bitbucket.org/fenics-project/dolfin/commits/5e86e7e3409a8d9ec4b1f40aa2b361d5de84d2a0
- install scipy the usual way
- install tensorflow: mamba install -c conda-forge tensorflow
- /home/leonardo_mutti/anaconda3/envs/masters_thesis/venv_with_mshr/lib/python3.8/site-packages/pyadjoint/optimization/optimization.py:137 -> change to return m, res to return also the optimization result
- /home/leonardo_mutti/anaconda3/envs/masters_thesis/venv_with_mshr/lib/python3.8/site-packages/pyadjoint/optimization/optimization.py:252 -> change as well to
    opt, res = algorithm(rf_np, **kwargs)

    if len(opt) == 1:
        return opt[0], res
    else:
        return opt, res
- to have scipy.minimize output the history, /home/leonardo_mutti/anaconda3/envs/masters_thesis/venv_with_mshr/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py:351:
    energy_values = []
    gradient_infty_norms = []

    while 1:
        # x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \
        _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,
                       pgtol, wa, iwa, task, iprint, csave, lsave,
                       isave, dsave, maxls)
        task_str = task.tobytes()
        if task_str.startswith(b'FG'):
            # The minimization routine wants f and g at the current x.
            # Note that interruptions due to maxfun are postponed
            # until the completion of the current minimization iteration.
            # Overwrite f and g:
            f, g = func_and_grad(x)
            gv = np.max(np.abs(g))
            if not (np.isnan(f) or np.isnan(gv)):
                energy_values.append(f)
                gradient_infty_norms.append(gv)
        elif task_str.startswith(b'NEW_X'):
            # new iteration
            n_iterations += 1
            if callback is not None:
                callback(np.copy(x))

            if n_iterations >= maxiter:
                task[:] = 'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'
            elif sf.nfev > maxfun:
                task[:] = ('STOP: TOTAL NO. of f AND g EVALUATIONS '
                           'EXCEEDS LIMIT')
        else:
            break

    task_str = task.tobytes().strip(b'\x00').strip()
    if task_str.startswith(b'CONV'):
        warnflag = 0
    elif sf.nfev > maxfun or n_iterations >= maxiter:
        warnflag = 1
    else:
        warnflag = 2

    # These two portions of the workspace are described in the mainlb
    # subroutine in lbfgsb.f. See line 363.
    s = wa[0: m*n].reshape(m, n)
    y = wa[m*n: 2*m*n].reshape(m, n)

    # See lbfgsb.f line 160 for this portion of the workspace.
    # isave(31) = the total number of BFGS updates prior the current iteration;
    n_bfgs_updates = isave[30]

    n_corrs = min(n_bfgs_updates, maxcor)
    hess_inv = LbfgsInvHessProduct(s[:n_corrs], y[:n_corrs])

    task_str = task_str.decode()
    return OptimizeResult(fun=f, jac=g, nfev=sf.nfev,
                          njev=sf.ngev,
                          nit=n_iterations, status=warnflag, message=task_str,
                          x=x, success=(warnflag == 0), hess_inv=hess_inv, energy_hist = energy_values, gradient_infty_hist = gradient_infty_norms)
- to use scipy minize with bounds, go to /home/leonardo_mutti/anaconda3/envs/masters_thesis/venv_with_mshr/lib/python3.8/site-packages/pyadjoint/optimization/optimization.py:28 and change:
    # bound_len = len(rf_np.get_global(rf_np.controls[j]))
    const_bound = np.array([bound] * 1)
- pip install tensorflow==1.15.2 (note, this requires python 3.7 to work, and this is the only way in which graph visualization works)
- pip install protobuf==3.20.*
- fix some tensorflow things:
    - "/home/leonardo_mutti/anaconda3/envs/masters_thesis/lib/python3.10/site-packages/pyadjoint/tape.py", line 342, in visualise
    tf.reset_default_graph() -> must be changed into tf.compat.v1.*
    - same thing here and in the line below: /home/leonardo_mutti/anaconda3/envs/masters_thesis/lib/python3.10/site-packages/pyadjoint/tape.py:347
    - /home/leonardo_mutti/anaconda3/envs/masters_thesis/lib/python3.10/site-packages/pyadjoint/tape.py:280 -> see below

        # Block dependencies
        in_tensors = []
        for dep in block.get_dependencies():
            if id(dep) in self._tf_tensors:
                in_tensors.append(self._tf_tensors[id(dep)])
            else:
                with tf.name_scope(self._get_tf_scope_name(dep)):
                    tin = tf.numpy_function(lambda: None, [], [tf.float64],
                                     name=self._valid_tf_scope_name(str(dep)))
                    in_tensors.append(tin)
                    self._tf_tensors[id(dep)] = tin

        # Block node
        with tf.name_scope(self._get_tf_scope_name(block)):
            tensor = tf.numpy_function(lambda: None, [], [tf.float64],
                                name=self._valid_tf_scope_name(str(block)))
            self._tf_tensors[id(block)] = tensor

        # Block outputs
        for out in block.get_outputs():
            with tf.name_scope(self._get_tf_scope_name(out)):
                tout = tf.numpy_function(lambda: None, [], [tf.float64],
                                  name=self._valid_tf_scope_name(str(out)))
                self._tf_tensors[id(out)] = tout

    - /home/leonardo_mutti/anaconda3/envs/masters_thesis/lib/python3.10/site-packages/pyadjoint/tape.py:251-> name must be changed to a string, e.g. "no_name"