% Packages and bibliography
\documentclass[english,a4paper,9pt,oneside]{scrbook}	% it was 12 pt, remove me in case
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[english]{babel}
\usepackage{marvosym}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mathtools}
\usepackage{calrsfs}
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\usepackage[toc,page]{appendix}
\usepackage{xcolor}
\usepackage{cleveref}
\usepackage[backend=bibtex]{biblatex}
\usepackage[nottoc,notlot,notlof]{tocbibind}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage[many]{tcolorbox}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{geometry}	% remove me in case
 \geometry{
 a4paper,
 left=10mm,
 top=10mm,
 right=10mm,
 bottom=20mm,
 }
\addbibresource{Bibliography/bibliography.bib}

% Formatting options
\setlength{\parindent}{0em}
\parskip = .1cm \relax
%\renewcommand{\baselinestretch}{1.25}

% equations and theorems style
\counterwithin*{equation}{section}
\counterwithin*{equation}{subsection}
\renewcommand{\theequation}{%
  \thesection.%
  \ifnum\value{subsection}>0 \arabic{subsection}.\fi
  \arabic{equation}%
}
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\upshape}{}%
  {\bfseries}{}%
  {\newline}{}%
\theoremstyle{break}
\newtheorem{thm}[equation]{Theorem}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{lemma}[equation]{Lemma}
\newtheorem{defn}[equation]{Definition}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{ass}[equation]{Assumption}
\newtheorem{pb}[equation]{Problem}
\newenvironment{mproof}[1][\proofname]{%
  \begin{proof}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{proof}
}
\renewcommand*{\proofname}{Proof}
\theoremstyle{remark}
\newtheorem{obs}[equation]{Observation}
\newtheorem{es}[equation]{Example}


% Colors
\tcolorboxenvironment{thm}{colback=green!25!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{cor}{colback=green!5!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{lemma}{colback=green!5!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{defn}{colback=black!5!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{prop}{colback=green!15!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{ass}{colback=red!15!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{pb}{colback=blue!15!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{es}{colback=black!5!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}
\tcolorboxenvironment{obs}{colback=black!5!white,colframe=black!5!black, opacityframe=0, breakable, enhanced}

% Useful commands
\newcommand{\mR}{\mathbb{R}}
\newcommand{\mS}{\mathbb{S}^{n-1}}
\newcommand{\cV}{\pazocal{V}}
\newcommand{\ds}{\displaystyle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\HN}[1]{\norm{#1}_{H}}
\newcommand{\VN}[1]{\norm{#1}_{V}}
\newcommand{\VSN}[1]{\norm{#1}_{V^*}}
\newcommand{\tr}{\text{tr}}
\newcommand{\cc}{\subset\subset}
\newcommand{\emb}{\hookrightarrow}
\newcommand{\ind}[1]{\{\text{ #1 }\}}
\newcommand{\mind}[1]{$#1$}
\newcommand{\cT}{\pazocal{T}}
\newcommand{\id}{\text{Id}}
\newcommand{\te}{\theta}
\newcommand{\Te}{\Theta}
\newcommand{\tred}[1]{\textcolor{red}{#1}}
\newcommand{\dive}{\text{div}}
\newcommand{\weakc}{\rightharpoonup}
\newcommand{\xh}{\hat{x}}
\newcommand{\yh}{\hat{y}}
\newcommand{\eps}{\epsilon}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\newcommand{\tw}[1]{\texttt{#1}}

\begin{document}

% Titelseite
\pagestyle{empty}       % keine Seitennummer
%  \parbox{1.5cm}{\resizebox*{110pt}{!}{\includegraphics{Logos/blau/2015_Logo_TUM_CMYK.pdf}}}\hspace{310pt}%
%  \parbox{1.5cm}{\resizebox*{90pt}{!}{\includegraphics{Logos/08_Mathematik/MA_blau/FAK_MA_CMYK.pdf}}}%
\vspace*{3cm}
\begin{figure}[H]
\centering
\includegraphics[height=0.075\columnwidth]{Logos/blau/2015_Logo_TUM_CMYK.pdf}
\hspace{90pt}
\includegraphics[height=0.075\columnwidth]{Logos/08_Mathematik/MA_blau/FAK_MA_CMYK.pdf}
\end{figure}
\vspace*{1.5cm}
\begin{center}
{\Huge Technical University of Munich}
\\
\vspace*{1.5cm}
{\huge \textsc{Department of Mathematics}}
\\
\vspace*{3cm}
\font\myfont=cmr12 at 40pt
{\Huge \textbf{Finite element error in\\parabolic shape gradients\\}}
\title{Finite element error in parabolic shape gradients}
\vspace*{3cm}
{\Large Master's Thesis}\linebreak \\
{\Large von}\linebreak \\
{\Large Leonardo Mutti}\\
\vspace*{3cm}
{\Large 
\begin{tabular}{ll}
Supervisor: & Prof. Dr. Michael Ulbrich\\
Advisor: & Michael Ulbrich\\
Submission Date: & [Day. Month. Year]
\end{tabular}
}
\end{center}

\newpage    % Seitenwechsel

% Seite 2
\vspace*{18cm}
\noindent
I hereby declare that this thesis is my own work and that no other sources have been used except those clearly indicated and referenced.
\\[2cm]
Place, Date\\
original, hand-written signature
\newpage

% vertikaler Leerraum
\chapter*{Acknowledgements}

First and foremost, I would like to express my gratitude to my supervisor Michael Ulbrich. Apart from suggesting this fascinating topic and providing feedback and advice, he was encouraging, never pressuring me, which helped to put me in the right mindset.

No matter the outcome, conducting this thesis from start to finish was a personal success. Because parents and family play a substantial role in one's development, they must share the biggest part of my success today: they too should be proud of themselves. 

To my friends and to Anna, one way or another you helped shaping me into the person who made it to here: thank you.  

% Seite 3
\newpage
\section*{Abstract}
In the context of elliptic, PDE constrained shape optimization, it has already been noted that a distributed expression for the shape gradient is more accurate than the boundary counterpart, when finite elements are employed to discretize the arising PDEs. 

We extend such observations in two ways: first, we work in a parabolic setting and second, we explicitly address the fact that finite element solutions live on polygons/polyhedra, but they approximate functions defined on smooth domains. We therefore prove semidiscrete estimates in a spatially semidiscrete setting, and fully discrete estimates when the implicit Euler method is adopted for the time discretization.

We conduct numerical tests to support these observations, and we conjecture that our conclusions should apply as well to when the more accurate Crank-Nicolson method is employed.

Our analysis is based on a model shape optimization problem for the heat equation, where the goal is to determine the shape of a zero temperature inclusion given the temperature and heat flux at an external boundary. For such problem, the shape gradient is derived, a star-shaped ansatz is applied, and numerical results are presented and discussed.

\section*{Zusammenfassung}
Im Zusammenhang mit elliptischer, PDG-gebundener Formoptimierung wurde bereits festgestellt, dass ein verteilter Ausdruck für die Formableitung genauer ist als das Gegenstück am Rand, wenn finite Elemente zur Diskretisierung der entstehenden PDGs verwendet werden. 

Wir erweitern diese Beobachtungen in zweierlei Hinsicht: Erstens arbeiten wir in einem parabolischen Umfeld und zweitens berücksichtigen wir explizit die Tatsache, dass Finite-Elemente-Lösungen auf Polygonen/Polyedern leben, aber sie approximieren Funktionen, die auf glatten Gebieten definiert sind. Wir beweisen daher semidiskrete Schätzungen in einem räumlich semidiskreten Umfeld und vollständig diskrete Schätzungen, wenn die implizite Euler-Methode für die zeitliche Diskretisierung verwendet wird.

Wir führen numerische Tests durch, um diese Beobachtungen zu untermauern, und wir nehmen an, dass unsere Schlussfolgerungen auch gelten sollten, wenn die genauere Crank-Nicolson-Methode verwendet wird.

Unsere Analyse basiert auf einem modellhaften Formoptimierungsproblem für die Wärmeleitungsgleichung, bei dem das Ziel darin besteht, die Form eines Nulleinschlusses zu bestimmen, wenn die Temperatur und der Wärmestrom an einem äußeren Rand gegeben sind. Für ein solches Problem wird die Formableitung abgeleitet, ein sternförmiger Ansatz angewendet und numerische Ergebnisse werden vorgestellt und diskutiert.
%Seite 4



\newpage
\tableofcontents  


\chapter{Introduction}  \setcounter{page}{1}   % setzt Seitenzaehlung auf 1
\pagenumbering{arabic}  % Nummerierung der Seiten in 'arabisch' % neues Kapitel mit Namen "Introduction"

To obtain approximate estimates of solutions to PDE constrained shape optimization problems, a discretization of several "continuous" quantities has to be made. In particular, suitable numerical methods for the involved partial differential equations must be adopted, and then, an optimization routine has to be implemented, so as to obtain a hopefully reasonable estimate of the sought true solution.

The accuracy of the optimization procedure is influenced by many factors. In particular, when using gradient based optimization, one would like the discretized shape gradient to be as good of an approximation as possible to the continuous counterpart. There is actually one major design choice playing a role here, which is whether a boundary or distributed/volumetric approach is taken, when treating the shape optimization problem. There are of course advantages and disadvantages to both views (see e.g. \cite{avg_adj}), but there seems to be numerical evidence for a superior accuracy of the latter over the former, at least when the finite element method is adopted to approximate partial differential equations. Theoretical analysis backing up this observation was presented in the work \cite{paganini}. They analyzed a model elliptic problem, and showed that the discretized shape gradient can be expected to be a second order approximation to the continuous one in the volumetric case, but only a first order one in the boundary approach. Finite elements are employed, being a popular, widespread and general method that provides much flexibility for engineering applications.

Such conclusions are however only drawn in an elliptic setting, but parabolic shape optimization has important applications too, and deserves further analysis (see e.g. \cite{lindemann2}, \cite{harbrecht} to mention a few). With this in mind, we try to extend the observations of \cite{paganini} in two ways: 

\begin{itemize}
\item on one hand, we consider a time-dependent setting
\item on the other one we try to account for the fact that the continuous shape gradients are based on a smooth domain, whereas all discretized quantities naturally live on simplicial meshings of it
\end{itemize}

To this end, we borrow a model parabolic shape optimization problem from \cite{harbrecht} and center our arguments around it. In \cite{harbrecht}, boundary expressions for the shape gradients are derived, and PDEs are approximated using the boundary element method. While this choice provides computational efficiency, it sacrifices generality (more complicated PDEs need not to be easily converted to boundary integral equations). We take, in contrast, a distributed/volumetric approach and employ finite elements for the partial differential equations. As a by-product, we obtain a very easy implementation that is amenable to high-performance and already existing software packages, such as FEniCS (\cite{fenics}) and dolfin-adjoint (\cite{dolfin-adjoint_1}, \cite{dolfin-adjoint_2}, \cite{dolfin-adjoint_3}). 

This thesis is then structured as follows:

\begin{itemize}
	\item in \cref{chap:cts_shape_opt}, we introduce the model parabolic shape optimization problem, and proceed to compute the continuous shape gradient. We also discuss the star-shaped parametrization of the shapes that we adopted for simplicity in the implementation
	\item \cref{chap:discretization} is then about the finite element discretization of the problem and of the geometry. Estimates for the errors between discrete and continuous shape gradients are given, under the assumptions that the discrete domain interpolates the continuous domain. The analysis is satisfactory when the implicit Euler method is adopted in time, where we can even show that optimization and discretization commute. However, we only give some theoretical hints to some conjectures we made for the case where the Crank-Nicolson method is adopted
	\item in \cref{chap:num_exp} we discuss our implementation and conduct two sets of experiments are included: on one hand we illustrate results for the overall shape optimization algorithm for our model problem, and on the other hand we provide numerical evidence for the error estimates of \cref{chap:cts_shape_opt}
	\item \cref{chap:conclusion} contains a brief summary of the thesis and lists some future research directions
\end{itemize}

For exposition purposes, we delegated many technicalities to appendices:

\begin{itemize}
	\item some useful results from functional analysis are collected in \cref{chap:functional_spaces}
	\item all the details about parabolic equations that appear in the thesis can be found in \cref{chap:parab_eq}
	\item several facts about domains deformations are to be found in \cref{chap:domain_transformations}
	\item in \cref{chap:inh_fem}, the adopted finite element framework, in the context of smooth geometries, is explained
\end{itemize}

\chapter{Infinite dimensional setting}
\label{chap:cts_shape_opt}

This chapter is devoted to the analysis of the non-discretized shape optimization problem:

\begin{itemize}
	\item in \cref{sec:shid} we introduce the shape identification problem we are interested in
	\item in \cref{sec:shopt_treatment} we reformulate it as a shape optimization problem, and compute the shape gradient of the cost functional to be minimized
	\item in \cref{sec:star}, we discuss the ansatz that the sought domains are star-shaped, to give some justification for our computer implementation
	\item in \cref{sec:hilbert} we further justify our implementation, that is discussed in \cref{sec:implementation}, with respect to the scalar product in which shape optimization is performed
\end{itemize}

\section{Shape identification problem}
\label{sec:shid}

Let $D\subseteq\mR^n$ be a sufficiently smooth domain, and $\Omega \cc D$. We then call $\Gamma_f=\partial D$, $\Gamma_m = \partial \Omega$. We let $T>0$ and $I = (0,T)$, $\Sigma_f=I\times \Gamma_f$, $\Sigma_m=I\times \Gamma_m$.

\begin{figure}[H]
\centering
\includegraphics[width=0.25\columnwidth]{Images/Domains.pdf}
\caption{Space-time cylinder with labels}\label{fig:space_time}
\end{figure}

Let us interpret $D$ as a certain uniform and isotropic body, inside which a solid/liquid inclusion of zero temperature $\Omega$ is present. The temperature $u$ inside $D\setminus \Omega = U$ evolves over time according to the heat equation, at least approximately. What one might do, is to access the outer boundary $\partial D$ and measure its surface temperature and heat flux, and wonder about the actual shape of the inaccessible inclusion $\Omega$. We ask ourselves how to reconstruct such information from the knowledge of the boundary data only. This is a non-linear and ill-posed inverse problem (according to e.g. \cite{harbrecht}). 

Our problem is therefore, given the outer temperature and outer heat flux, how to reconstruct the shape of $\Omega$ that induced, through heat diffusion, those boundary quantities.

In a more mathematical language, let us consider a heat equation on $U\times I$, with zero initial condition and no volumetric forcing term. On $\Sigma_f$ are prescribed smooth enough Dirichlet and Neumann data, simultaneously, call them $f$ and $g$, whereas on $\Sigma_m$, homogeneous Dirichlet conditions are imposed.

\begin{pb}[Overdetermined heat equation]
\label{pb:pdes}
Call $U:=D\setminus \Omega$. We look for $u:U \times I \rightarrow \mR$ solving:
\begin{align*}
\left\{\begin{matrix}
u_t -\Delta u=0 & \text{on }U\times I \\ 
u(0)=0 & \\ 
u = f, \partial_\nu u=g & \text{on }\Sigma_f\\
u = 0 & \text{on }\Sigma_m\\
\end{matrix}\right.
\end{align*}

We introduce the splitting:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
v_t -\Delta v=0 & \text{on }U\times I \\ 
v(0)=0 & \\ 
v = f& \text{on }\Sigma_f\\
v = 0 & \text{on }\Sigma_m\\
\end{matrix}\right. &, \quad  \left\{\begin{matrix}
w_t -\Delta w=0 & \text{on }U\times I \\ 
w(0)=0 & \\ 
\partial_\nu w=g & \text{on }\Sigma_f\\
w = 0 & \text{on }\Sigma_m\\
\end{matrix}\right.
\end{matrix}
\end{align*}
\end{pb}

This overdetermined partial differential equation for $u$ need not to have a solution. It can be however shown that, for given $f,g$, there exists at most one $\Omega$ such that \cref{pb:pdes} is solvable (see \cite{chapko1}, \cite{chapko2}).

Our aim is to find a numerical approximation for such domain. We are therefore trying to solve a shape identification problem. In particular, the equations for $v,w$ are always uniquely solvable, and $u=v$, $u=w$, in case $u$ exists, i.e. when the shape identification problem admits a solution. One way to tackle it is therefore, given data $f,g$, a guess $\Omega$ of the sought domain, to simulate $v,w$, measure their discrepancy $\norm{v-w}$ and use this knowledge to improve the iterate $\Omega$.

%\begin{figure}[H]
%\centering
%\includegraphics[width=0.25\columnwidth]{Images/NormalDiscrepancy.pdf}
%\caption{Discrepancy between the Neumann data corresponding to the correct domain $\Omega$, and a guess of it, $\hat{\Omega}$}\label{fig:normal_discrepancy}
%\end{figure}

Summing up, the thesis is devoted to the analysis of the following problem.

\begin{pb}[Shape identification problem]
\label{pb:shid}
We aim at finding $\Omega$ such that $u$, defined in \cref{pb:pdes}, exists, i.e. such that $v=w$.
\end{pb}

This same problem was addressed in \cite{harbrecht} using a different approach than ours, involving boundary integral equations, boundary element methods and non-standard time stepping schemes. On the other hand our focus has a rather "volumetric" flavour, as we will make clear in the following chapters. 

As already mentioned, some uniqueness results are already available. We are not concerned with the problem of existence of $\Omega$, likewise this aspect is not addressed in the aforementioned work \cite{harbrecht}. Some advances in this direction are done in the case where $\Omega$ is allowed to evolve with time, this is addressed in \cite{brugger}.

In the following we will formalize assumptions, setting and notation, and we will tackle \cref{pb:shid} by shape optimization techniques.

\section{Treatment by shape optimization}
\label{sec:shopt_treatment}

\begin{ass}[Geometry assumptions for the shape optimization problem]
\label{ass:geo_sh}
Let $D\subseteq \mR^n$ be a bounded Lipschitz domain, and $\Omega_r \cc D$ also bounded Lipschitz. Call $U_r:=D\setminus \Omega_r$, another bounded Lipschitz domain.
\end{ass}

\begin{defn}[Admissible transformations]

Given $D$, we consider the set $\cT$ of bi-Lipschitz homeomorpshisms of $\mR^n$ that fix $D^c$, endowed the perturbation space $\Te$, i.e. Lipschitz deformation fields null on $D^c$. See also \cref{def:adm}.

We will consider transformations of $U$ that belong to $\cT_a:=\cT \cap \{ \tau \in W^{1,\infty}(\mR^n, \mR^n), \norm{\tau - \id}_{W^{1,\infty}(\mR^n, \mR^n)}<C(U_r)\}$, where the existence of $C(U_r)$ is guaranteed by \cref{thm:ptb_id_lip}. This is to ensure that $\tau(U_r)\cc D$ is also bounded Lipschitz.


\end{defn}

We remark that there exists a unique Lipschitz continuous representive $T$ of $\tau \in \cT_a$ (see \cref{prop:lip}), and that we denote it also by $\tau$, for simplicity. By $\tau(U_r)$ we precisely mean $T(U_r)$.

We recast \cref{pb:shid} in a new form, akin to shape optimization. To do so, we must at first analyze the well posedness of the equations for $v,w$ of \cref{pb:pdes}. This is done in detail in the appendix for the sake of presentation. What we remark is that such well-posedness holds, and that, given any extension $\bar{u}$ to $f$ onto $U\times I$, then $v = v_0+\bar{u}$, where $v_0$ solves the heat equation with homogeneous Dirichlet boundary conditions, but a non trivial source term. We write $v^\tau = v_0^\tau + \bar{u}$, and $v_0^\tau, w_\tau$ to emphasize the dependence on $\tau$, and refer to \cref{pb:joint_mov} and \cref{pb:diri_ext} for additional details. The adequate conditions for well-posedness are \cref{ass:diri}, \cref{ass:neu}.

\begin{pb}[Shape optimization problem]
\label{pb:shopt}
Suppose that \cref{ass:geo_sh}, \cref{ass:diri}, \cref{ass:neu} hold. We want to solve:

$$\inf_{\tau \in \cT_a}\frac{1}{2}\norm{v^\tau-w^\tau}_{L^2(I,H_\tau)}^2=:J(\tau)$$

The notation for the spaces also comes from  \cref{pb:joint_mov}: $\cdot_\tau$ means a space defined on the moving domain, $H=L^2, \tw{V}=H^1_0, \tw{W} = H^1_{0,m}=\{v \in H^1, v(\Gamma_m)=0\}$ (see also \cref{subs:inh_diri} for the last space).

\end{pb}

Therefore, we are now concerned with finding a function $\tau$, instead of a generic set $\Omega$: this way we can make use of functional analytic techniques and results from optimal control.

\begin{obs}[Well-posedness of $J$]
\mbox{}\\
We know from \cref{prop:diri_wp} that $v_0^\tau + \bar{u}$ doesn't depend on the particular choice of $\bar{u}$, therefore, for different $\tau$ yielding the same domain $U$, $J(\tau)$ doesn't change.

\end{obs}

\begin{obs}[Tracking type cost functional]
\mbox{}\\
We have chosen the $L^2(I,L^2)$ norm to measure the discrepancy $v\simeq w$. Apart from having favourable functional analytic properties (Fréchet differentiability, to mention one), such cost functional will also allow us to obtain "better behaved" adjoint states. In fact, contrary to \cite{harbrecht}, the heat equations for the adjoint states (see \cref{prop:gateaux_diff}) will have more compatibility between initial condition and boundary conditions. This potentially simplifies the numerical analysis of such equations.
\end{obs}


Now, let $U:=\tau(U_r)$, for $\tau \in \cT_a$ and let $\delta \te \in \Te$. To find a better (in the sense of the energy $J$) candidate $\tau$ for the solution of \cref{pb:shopt}, we can use gradient information, i.e. perturb our current guess $\tau$ in the direction of steepest descent for $J$. We are hence interested in finding the form $J'(\tau) \in \Te^*$ such that, for all $\delta \te_k \rightarrow 0$ in $\Te$, we have:


$$\lim_{k}\frac{|J(\tau+\delta \te_k)-J(\tau)-J'(\tau)(\delta \te_k)|}{\norm{\delta \te_k}_{\Te}}$$

We have set $\norm{\te}_\Te = \norm{\te}_{W^{1,\infty}(\mR^n;\mR^n)}=\norm{\te}_{W^{1,\infty}(D;\mR^n)}$.

Note, thanks to \cref{prop:ptb_id}, a small $\delta \te \in \Te$ perturbation of $\tau \in \cT_a$, small with respect to the $W^{1,\infty}(D;\mR^n)$ topology, yields an element $\tau +\delta  \te \in \cT_a$: it will be this the way in which an initial guess for the sought domain $\Omega = \tau(\Omega_r)$ will be refined, i.e. by iteratively adding to $\tau$, small perturbations $\delta \te$. We remark that for $k$ large enough, $\tau+\delta \te_k \in \cT_a$.

\begin{obs}
\mbox{}\\
To carry out all the reasonings with such a general form of tranformation $\tau$, an assumption of smallness (such as the one involving $C(U_r)$) is necessary. We will see a more transparent way of obtaining $\tau(U_r)\cc D$ Lipschitz, in \cref{sec:star}.
\mbox{}\\
Note, we need $\tau$ to have a Lipschitz inverse to conclude $\tau(U_r)\cc D$: for $x \in D$, we have $0<\delta = \inf_{d \in \partial D}|x-d|\leq \norm{\tau^{-1}}_{W^{1,\infty}(\mR^n,\mR^n)}\inf_{d \in \partial D}|\tau(x)-d|$.
\end{obs}

%Note, $\tau+\delta \te_k \in \cT_a$ for large enough $k$. In fact, $\tau+\delta \te_k \in \cT$ for large $k$ as in \cref{prop:ptb_id}, and the condition on $C(U_r)$ is satisfied too, because $\te :=\tau-\id$ was already in the $W^{1,\infty}$ open ball of radius $C(U_r)$ centered at the origin, and so will be $\te + \delta_k\te$, always for large $k$.

Now, $\tau+\delta \te_k  = (\id+\delta\te_k \circ \tau^{-1})\circ \tau$, and $\id+\delta\te_k \circ \tau^{-1}$ is in $\cT_a$ (it is in $\cT$ by \cref{prop:ptb_id} and the reasoning above shows it is also in $\cT_a$). We are then equivalently interested in:

$$\lim_{k}\frac{|J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau)-J'(\tau)[\delta \te_k]|}{\norm{\delta \te_k}_{\Te}}$$

This amounts to setting the reference domain to $\tau(U_r)$ instead of $U_r$ and perturbing the former, at least for the sake of computing derivatives.

We now introduce a Lagrangian functional, so as to derive the gradient expression of $J$. There are several ways to compute the so called "shape gradient" $dJ$, in the literature. We will adopt that contained in \cite{avg_adj}, but a valid alternative, at least formally, is the method of Cea, see \cite{cea}. The former requires the PDEs of $v=v^\tau$, $w=w^\tau$ to be reformulated on a non-moving domain, the reference domain $U_r$. We can perform such operation by considering the variational formulations of $v^\tau$ and $w^\tau$ and then applying a change of variables to the appearing integrals. This is precisely the content of \cref{thm:eq_pde}, whose applicability is ensured by \cref{ass:pull}, which holds by \cref{ass:geo_sh}.

Remembering that $k$ large, i.e. $k\geq K(\tau)$, we have $\tau_k:=\id+\delta\te_k \circ \tau^{-1} \in \cT_a$, as seen above, and  having \cref{thm:eq_pde} in mind we can set:

\begin{align*}
L_\tau(k,w,v_0,q,p) = \\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u} \circ \tau_k - w|^2|\det(D\tau_k)|+\\
\int_I ( w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla w, \nabla q)_{H_\tau} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)} +\\ \int_I (v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0, \nabla p)_{H_\tau}+\int_I((\bar{u}\circ \tau_k)',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla (\bar{u} \circ \tau_k), \nabla p)_{H_\tau}
\end{align*}

Here $w \in Q_0(I, \tw{W}_\tau), v_0 \in Q_0(I,\tw{V}_\tau), q \in Q^0(I, \tw{W}_\tau), p \in Q^0(I, \tw{V}_\tau)$, where the space $Q$ is thoroughly described after its introduction in \cref{def:Q}, which we recall: $Q(I,V)=H^{1,1}=L^2(I,V)\cap H^1(I,H)$, and $Q^0$ means the imposition of a zero terminal condition ($Q_0$ means zero initial condition). We have set $A_\tau:=  (D\tau)^{-1}(D\tau)^{-t}|\det(D\tau)|$.

$L_\tau$ is composed of three parts: the cost functional, the variational formulation of $v_0^\tau$ and that of $w^\tau$, all transported to the domain $\tau(U_r)$, which will remain fixed, for the sake of computing the shape gradient.

Note that to be precise, $\bar{u}$ is an extension (any extension in fact, satisfying the conditions of \cref{pb:diri_ext}) of the Dirichlet datum $f$, on the moving domain $\tau_k(\tau(U_r))$. Because of this, let's fix $\bar{u}_\tau$ with this property on $\tau(U_r)$. We show that $\bar{u}:=\bar{u}_\tau\circ \tau_k^{-1}$ satisfies the conditions stated in \cref{pb:diri_ext}. 

In particular:

\begin{itemize}
	\item composition with $\tau$ preserves the smoothness of the extension, as seen in \cref{lemma:bochner_Hk_map}, given that $\circ \tau_k^{-1}$ is a linear bounded operator between $\tw{W}_\tau$ and $\tw{W}_{\tau_k \circ \tau}$ (see \cref{thm:change})
	\item the initial value is preserved, as seen in the proof of \cref{prop:change_boch}
	\item the trace on $\Sigma_f$ is preserved, because the trace on $\Gamma_f=\partial D$ is preserved, see \cref{thm:change}
\end{itemize}

Therefore we can state the following definition.

\begin{defn}[Lagrangian]

For a fixed $\tau \in \cT_a$ and  $k\geq K(\tau)$, for $\tau_k:=\id+\delta\te_k \circ \tau^{-1} \in \cT_a$, we define:

\begin{align*}
L_\tau(k,w,v_0,q,p) = \\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|+\\
\int_I ( w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla w, \nabla q)_{H_\tau} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)} +\\ \int_I (v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0, \nabla p)_{H_\tau}+\int_I(\bar{u}_\tau',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla \bar{u}_\tau , \nabla p)_{H_\tau}
\end{align*}

$L_\tau$ is defined as a map $\{k\geq K(\tau)\}\times Q_0(I, \tw{W}_\tau)\times Q_0(I,\tw{V}_\tau)\times Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)\rightarrow \mR$.

We call $u = (w,v_0)$, $\pi = (q,p)$, $G(k,u,\pi) = L_\tau(k,w,v_0,q,p)$ to ease the notation.

We also call $b(k, u) = \frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|$ and $a(k, u,\pi) = G(k,u,\pi)-b(k, u)$, $E = Q_0(I, \tw{W}_\tau)\times Q_0(I,\tw{V}_\tau)$, $F=Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)$.

\end{defn}

The rest of this section is devoted to applying the averaged adjoint method \cite{avg_adj} to our problem, so as to identify the shape gradient. To this end we will have to understand which properties the Lagrangian $L_\tau $ enjoys.

\begin{prop}[Properties of the Lagrangian]
\label{prop:lagr}

$L_\tau$ satisfies the following properties:

\begin{enumerate}
	\item $\psi \mapsto a(k, \phi,\psi)$ is linear, no matter what $\phi,k$
	\item $G$ is Fréchet differentiable with respect to $\psi$ at $(k,\phi,0)$ for all $k, \phi$
	\item $d_\psi G(k,\phi,0)[\delta \psi]=0$ for all $\delta \psi \in F$ admits a unique solution $\phi = u^k$
	\item $[0,1]\ni s \mapsto G(k, su^k + (1-s)u^0,\psi)$ is $AC[0,1]$, no matter what $k, \psi$
	\item $G$ is Fréchet differentiable with respect to $\phi$ at $(k,\psi,\phi)$ for all $k, \psi, \phi$
	\item $[0,1]\ni s \mapsto d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]$ is $L^1(0,1)$, no matter what $k, \psi, \delta \phi$
	\item there exists a unique solution $\psi = \pi^k$ to $\ds \int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds =0$ for all $\delta \psi$ 
\end{enumerate}

In particular $\pi^k = (Q^k \circ \tau^k,P^k \circ \tau^k)$, where we introduced the averaged adjoint problems on the moving domain:

\begin{pb}[Averaged adjoint equations]
\label{pb:avg_adj_pb}
\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-Q^k_t-\Delta Q^k =\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} \\
Q^k(T)=0\\
\partial_\nu Q^k = 0 \text{ on } \Sigma_f\\
Q^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
, \quad &
\left\{\begin{matrix}
-P^k_t-\Delta P^k =-\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}-\bar{u}_\tau\circ \tau_k^{-1} \\
P^k(T)=0\\
P^k = 0 \text{ on } \Sigma_f\\
P^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}
\end{pb}

\end{prop}

\begin{mproof}

We give some comments on the non trivial points.

%\underline{Proof of 2}
%
%All the pieces are linear in $\psi$. We only check the boundedness of the various differentials. For simplicity, call $|\det(D\tau_k)|=d$, and note that   $\norm{qd}_{H_\tau}\leq C(d)\norm{q}_{H_\tau}$.
%
%And now, for instance:
%%\int_I \langle w_t , q |\det(DT_\e)|\rangle_{V^*_T,V_T}+ (A_{T_\e}\nabla w, \nabla q)_{H_T} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}
%\begin{align*}
%\int_I ( w_t , \delta q |\det(D\tau_k)|)_{H_\tau} = \int_I ( w_t , \delta q d )_{H_\tau}\leq\\ C(d) \int_I \norm{w_t}_{H_\tau}\norm{\delta q}_{H_\tau}\leq C(d) \norm{w_t}_{L^2(I,H_\tau)}\norm{\delta q}_{L^2(I,H_\tau)}\leq\\C(d) \norm{w}_{Q(I,\tw{W}_\tau)}\norm{\delta q}_{Q(I,\tw{W}_\tau)}\leq
%C(d) \norm{w}_{Q(I,\tw{W}_\tau)}(\norm{\delta q}_{Q(I,\tw{W}_\tau)}+\norm{\delta p}_{Q(I,\tw{W}_\tau)}) =\\ C(d) \norm{w}_{Q(I,\tw{W}_\tau)}\norm{\delta\psi}_F
%\end{align*}
%
%Or also:
%
%\begin{align*}
%\int_I(g,\tr_{U} \delta q)_{L^2(\Gamma_f)}\leq \int_I \norm{g}_{L^2(\Gamma_f)}\norm{\delta q}_{\tw{W}_\tau}\leq \norm{g}_{H^1(I,L^2(\Gamma_f))}\norm{\delta\psi}_F
%\end{align*}
%
%and:
%
%\begin{align*}
%\int_I (A_{\tau_k} \nabla \bar{u}_\tau, \nabla\delta p)_{H_\tau}\leq C\norm{A_{\tau_k}}_{L^\infty(D;\mR^{n\times n})}\int_I \norm{\nabla \bar{u}_\tau}_{L^2(I,H_\tau)}\norm{\nabla\delta p}_{L^2(I,H_\tau)}\leq\\ C(\tau) \norm{\delta\psi}_F \norm{\bar{u}}_{H^1(I,\tw{W}_\tau)}
%\end{align*}

\underline{Proof of 3}

We get back the state equations, thanks to linearity, and by testing separately with $\delta \psi =(\delta q, 0)$ and $\delta \psi = (0,\delta p)$, so that a unique solution exists by \cref{thm:eq_pde}.
%
%\underline{Proof of 4}
%
%Every piece but $b$ is linear or constant in the state $\phi$. We only need to prove that $[0,1]\ni s \mapsto b(k, su^k + (1-s)u^0)$ is $AC[0,1]$. But by the structure of the cost function $J$, transported on $\tau(U_r)$, we see that the latter is a quadratic polynomial in $s$, hence, absolutely continuous.

%\underline{Proof of 5}
%
%For the pieces with the gradients, it follows as above, by in case employing the simmetry of $A_{\tau_k}$.
%
%Now, for instance the linear form $\delta v_0 \mapsto \int_I (\delta v_{0t},p |\det(D\tau_k)|)_{H_\tau}$ is also bounded by $C(d) \norm{\delta v_0}_{Q(I,\tw{V}_\tau)}\norm{\delta q}_{Q(I,\tw{W}_\tau)}$ just like before.
%
%What remains to check is the Fréchet differentiability of $b$.
%
%To do so, perturb $\phi$ by $\delta \phi$ and expanding the square:
%
%\begin{align*}
%\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\delta v_0+\bar{u}_\tau - w-\delta w|^2|\det(D\tau_k)| = \\\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|+\\\frac{1}{2}\int_I \int_{\tau(U_r)}|\delta v_0-\delta w|^2|\det(D\tau_k)|+\\\int_I \int_{\tau(U_r)}(v_0+\bar{u}_\tau - w)(\delta v_0-\delta w)|\det(D\tau_k)|
%\end{align*} 
%
%Now, $\ds \int_I \int_{\tau(U_r)}|\delta v_0-\delta w|^2|\det(D\tau_k)|\leq C(\tau_k)\norm{\delta v_0-\delta w}_{L^2(I,H_\tau)}^2\leq C(\tau_k)\norm{\phi}_E^2$, so that this term is of higher term.
%
%And $\ds \int_I \int_{\tau(U_r)}(v_0+\bar{u}_\tau - w)(\delta v_0-\delta w)|\det(D\tau_k)|$ is linear and bounded by reasonings similar to the former ones.
%
%\underline{Proof of 6}
%
%By the last point:
%
%\begin{align*}
%d_\phi G(k, \phi ,\psi)[\delta \phi] =\\
%\int_I ((v_0+\bar{u}_\tau - w)|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
%\int_I (\delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
%\int_I (\delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
%\end{align*}
%
%so that:
%
%\begin{align*}
%d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi] = \\
%\int_I ((s(v_0^k+\bar{u}_\tau - w^k)+(1-s)(v_0^0+\bar{u}_\tau - w^0))|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
%\int_I ( \delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
%\int_I ( \delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
%\end{align*}
%
%which is a degree $1$ polynomial in $s$, hence, $L^1(0,1)$.

\underline{Proof of 7}

Is is easily seen that:

\begin{align*}
\int_0^1d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds = \\
\int_I (((v_0^k+\bar{u}_\tau - w^k)+(v_0^0+\bar{u}_\tau - w^0))/2|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
\int_I ( \delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
\int_I ( \delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
\end{align*}

As in \cref{prop:change_boch}, $ \delta w_t  = (\delta w\circ \tau_k^{-1})_t\circ \tau_k$, where $\delta w\circ \tau_k^{-1} \in Q_0(I,\tw{W}_{\tau_k \circ \tau})$ by \cref{prop:change_boch} (that can be applied thanks to the smallness of $\tau_k$).
Applying a change of variables we are left with:

\begin{align*}
\int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds = \\
\int_I \left (\frac{v_0^k-w^k}{2}\circ \tau_k^{-1}+ \frac{v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta v_0\circ \tau_k^{-1}-\delta w\circ \tau_k^{-1}\right)_{H_{\tau_k \circ \tau}}+\\
\int_I ((\delta w\circ \tau_k^{-1})_t , q\circ \tau_k^{-1} )_{H_{\tau_k \circ \tau}}+ (\nabla (\delta w\circ \tau_k^{-1}), \nabla( q\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}+\\
\int_I ( (\delta v_{0}\circ \tau_k^{-1})_t,p \circ \tau_k^{-1})_{H_{\tau_k \circ \tau}} + ( \nabla \delta (v_0\circ \tau_k^{-1}), \nabla (p\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}
\end{align*}

Here, as we saw in \cref{prop:change_boch}, we have $\delta w\circ \tau_k^{-1}, w\circ \tau_k^{-1} \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta v_{0}\circ \tau_k^{-1}, v_{0}\circ \tau_k^{-1} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$, $q\circ \tau_k^{-1}\in Q^0(I, \tw{W}_{\tau_k \circ \tau})$ and $p\circ \tau_k^{-1}\in Q^0(I, \tw{V}_{\tau_k \circ \tau})$.

Because $\circ \tau_k^{-1}$ is a bijection of $Q_0(I,\tw{V}_{\tau_k \circ \tau})$ and $Q_0(I,\tw{V}_{\tau_k})$ as we saw in \cref{prop:change_boch} (and analogously for $\tw{W}$), we have that  $\int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds=0$ for all $\delta \phi \in E$ if and only if:

\begin{align*}
\int_I \left (\frac{v_0^k+w^k}{2}\circ \tau_k^{-1}- \frac{v_0^0+w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0-\delta W\right)_{H_{\tau_k \circ \tau}}+\\
\int_I ( \delta W_t , q\circ \tau_k^{-1})_{H_{\tau_k \circ \tau}}+ (\nabla\delta W, \nabla( q\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}+\\
\int_I ( \delta V_{0t},p \circ \tau_k^{-1})_{H_{\tau_k \circ \tau}} + ( \nabla \delta V_0, \nabla (p\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}} = 0
\end{align*}

for all $\delta W \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta V_{0} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$.

We wish to find a (unique) solution $(q^k, p^k) \in Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)$ of this problem. We can equivalently (by \cref{prop:change_boch}) find $(Q^k, P^k) \in Q^0(I, \tw{W}_{\tau_k \circ \tau})\times Q^0(I, \tw{V}_{\tau_k \circ \tau})$ satisfying:

\begin{align*}
\int_I \left (\frac{v_0^k-w^k}{2}\circ \tau_k^{-1}+ \frac{v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0-\delta W\right)_{H_{\tau_k \circ \tau}}+\\
\int_I (\delta W_t ,Q^k )_{H_{\tau_k \circ \tau}}+ (\nabla \delta W, \nabla Q^k)_{H_{\tau_k \circ \tau}}+\\
\int_I( \delta V_{0t},P^k)_{H_{\tau_k \circ \tau}} + ( \nabla \delta V_0, \nabla P^k)_{H_{\tau_k \circ \tau}} = 0
\end{align*}

for all $\delta W, \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta V_{0} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$.

Upon testing first with $\delta W=0$ and then with $\delta V_0=0$, an application of integration by parts in time (see \cref{prop:Q}) yields the problems which are the weak formulations (cfr. \cref{thm:eq_pde}, \cref{pb:diri_ext}, \cref{pb:neu}) of the PDEs:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-Q^k_t-\Delta Q^k =\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} \\
Q^k(T)=0\\
\partial_\nu Q^k = 0 \text{ on } \Sigma_f\\
Q^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
, \quad &
\left\{\begin{matrix}
-P^k_t-\Delta P^k =-\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}-\bar{u}_\tau\circ \tau_k^{-1} \\
P^k(T)=0\\
P^k = 0 \text{ on } \Sigma_f\\
P^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}

Applying the time reversal $t\mapsto T -t$ (where $I = (0,T)$), these are a couple of standard heat equations for which we have available existence, uniqueness and stability results (see \cref{chap:parab_eq}, and \cref{prop:eq_form}).

By calling then $\pi^k = (Q^k \circ \tau^k,P^k \circ \tau^k)$ we conclude the proof.
\end{mproof}

We now turn to the verification of Gateaux differentiability of $J$, applying the techniques proposed in \cite{avg_adj}.

\begin{prop}[Averaged adjoint method for Gateaux derivatives]
\label{prop:adv_adj}

If $J'(\tau) \in \Te^*$ satisfies:

$$\lim_{k}\frac{G(k,u^0,\pi^k)-G(0,u^0,\pi^k)}{t_k}=J'(\tau)[\delta \te]$$

where $\delta\te_k = t_k\delta \te$ for $t_k\rightarrow 0$, then $J'(\tau)$ is the Gateaux derivative of $J$ at $\tau$.

\end{prop}

\begin{mproof}

See theorem 3.1, \cite{avg_adj}.

%We have $G(k,u^k,\pi^k)-G(k,u^0,\pi^k)  = \int_0^1 d_\phi G(k, su^k + (1-s)u^0,\pi^k)[u^k-u^0]ds = 0$ because $u^k-u^0 \in E$, and by absolute contintinuity and integrability of derivative as seen in \cref{prop:lagr}.
%
%Moreover, calling $g_k = G(k,u^k,0)-G(0,u^0,0)$, we have:
%
%\begin{itemize}
%	\item $g_0 = 0$
%	\item $g_k = J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau)$, thanks again to a change of variables
%	\item $g_k = G(k,u^k,\pi^k)-G(0,u^0,\pi^k)$ thanks to $\pi^k \in F$ and the state equations (note, this is possible because $k,u^k$ appear, and $0,u^0$ appear, so that the indices don't mix)
%\end{itemize}
%
%And now, $J(\tau+\delta\te_k)-J(\tau) = J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau) = g_k = G(k,u^k,\pi^k)-G(0,u^0,\pi^k) = G(k,u^k,\pi^k)-G(k,u^0,\pi^k)+G(k,u^0,\pi^k)-G(0,u^0,\pi^k) = G(k,u^0,\pi^k)-G(0,u^0,\pi^k)$.
\end{mproof}

\begin{prop}[Gateaux differentiability of $J$]
\label{prop:gateaux_diff}
Given $\tau \in \cT_a$, $J$ is Gateaux differentiable at $\tau$ with respect to the $W^{1,\infty}$ topology. The Gateaux differential is:


\begin{align*}
J'(\tau)[\delta \te] =\\ \int_I (w_t^\tau \dive(\delta \te\circ  \tau^{-1}), q^\tau )_{L^2(\tau(U_r))}+ \int_I (A'(\delta\te \circ \tau^{-1})\nabla v^\tau, \nabla p^\tau)_{L^2(\tau(U_r))}+\\
\int_I (v_t^\tau \dive(\delta \te\circ  \tau^{-1}), p^\tau )_{L^2(\tau(U_r))}+ \int_I (A'(\delta\te \circ \tau^{-1})\nabla w^\tau, \nabla q^\tau)_{L^2(\tau(U_r))}+\\
\frac{1}{2}\int_I\int_{\tau(U_r)}|v^\tau-w^\tau|^2\dive(\delta \te\circ  \tau^{-1})
\end{align*}

where $p^\tau$, $q^\tau$ solve:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-q^\tau_t-\Delta q^\tau =v^\tau-w^\tau\\
q^\tau(T)=0\\
\partial_\nu q^\tau = 0 \text{ on } \Sigma_f\\
q^\tau = 0 \text{ on } \Sigma_m
\end{matrix}\right., \quad & \left\{\begin{matrix}
-p^\tau_t-\Delta p^\tau = - v^\tau+ w^\tau \\
p^\tau(T)=0\\
p^\tau = 0 \text{ on } \Sigma_f \\
p^\tau = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}

and where $A'(\delta\te )= - D\delta \te -(D\delta\te)^t + \dive(\delta\te)I$.

\end{prop}

\begin{mproof}

\underline{The shape derivative is linear and bounded}

Linearity is immediate. For the boundedness, with $C$ independent of $\delta \te$:

\begin{align*}
|J'(\tau)[\delta \te]| \leq C \left ( \norm{\dive(\delta \te\circ  \tau^{-1})}_{L^\infty(\tau(U_r))}+\left(\sum_{ij} \norm{(A'(\delta\te \circ \tau^{-1})_{ij}}_{L^\infty(\tau(U_r))}\right )\right )\leq
C\norm{\delta \te }_{W^{1,\infty}(\mR^n;\mR^n)}
\end{align*}

where in the last step we applied point i) of lemme 2.2, \cite{murat}. 

\underline{Conclusion}

Assume at first that $p^k \weakc p^0$ in $Q(I,\tw{V}_\tau)$ and $q^k \weakc q^0$ in $Q(I,\tw{W}_\tau)$, something which will be later verified.

Now, using that $u^0=(w^\tau, v_0^\tau)$, and cancelling the boundary integral:

\begin{align*}
G(k,u^0,\pi^k)-G(0,u^0,\pi^k) =\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2(|\det(D\tau_k)|-1)+\\
\int_I ( w_t^\tau (|\det(D\tau_k)| -1), q^k)_{H_\tau}+ ((A_{\tau_k}-I)\nabla w^\tau, \nabla q^k)_{H_\tau}+\\
\int_I (v_t^\tau (|\det(D\tau_k)|-1),p^k )_{H_\tau} + ((A_{\tau_k}-I) \nabla v^\tau, \nabla p^k)_{H_\tau} \\
\end{align*}

Now, the application $\delta \te \mapsto \id +\delta \te \circ \tau^{-1}$ is Fréchet differentiable at $\delta \te =0$, as a map of $\Te$ into $\cV^1$, with Fréchet derivative $\delta \te \circ \tau^{-1}$, which is linear and bounded by point i) of lemme 2.2, \cite{murat}. Note, we needed here $\tau \in \cT^1$.

Also, the maps $\delta \eta \mapsto |\det(D\eta)|$ and $\eta\mapsto (D\eta)^{-1}(D\eta)^{-t}|\det D\eta|$ are Fréchet differentiable at $\id$, from $\cV^1$ into $L^\infty(\mR^n;\mR)$ and $L^\infty(\mR^n;\mR^{n\times n})$, as stated in lemma 4.16, page 80 of \cite{lindemann}. Their Fréchet derivatives are $\dive (\beta)$ and $I-D\beta-(D\beta)^t$, respectively.

Therefore, composition with  $\delta \te  \mapsto \id+ \delta \te \circ \tau^{-1}$ yields two Fréchet differentiable maps, $\delta \te_k \mapsto |\det(D\tau_k)|$ and $\delta \te_k \mapsto A_{\tau_k}$, whose derivatives at $0$, in direction $\delta \te \in \Te$ are exactly $\dive(\delta \te \circ \tau^{-1})$ and $A'(\delta \te \circ \tau^{-1})$, so that:

\begin{itemize}
	\item $|\det(D\tau_k)|-1 = |\det(D\tau_k)|-1 - t_k\dive(\delta \te \circ \tau^{-1})+t_k\dive(\delta \te \circ \tau^{-1}) = o^1_k + t_k\dive(\delta \te \circ \tau^{-1})$
	\item $A_{\tau_k}-I = A_{\tau_k}-I - t_k A'(\delta \te \circ \tau^{-1}) + t_k A'(\delta \te \circ \tau^{-1}) = o_k^2 + t_k A'(\delta \te \circ \tau^{-1}) $
\end{itemize}

where $o_1^k \in L^\infty(\mR^n;\mR)$ and $o^2_k \in L^\infty(\mR^n;\mR^{n\times n})$ being higher order terms, in $L^\infty$ and with respect to $t_k$. We can then write $(G(k,u^0,\pi^k)-G(0,u^0,\pi^k))/t_k = a_k + o_k$.

Here:

\begin{align*}
a_k :=\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2\dive(\delta \te \circ \tau^{-1})+\\
\int_I ( w_t^\tau \dive(\delta \te \circ \tau^{-1}), q^k)_{H_\tau}+ (A'(\delta \te \circ \tau^{-1}) \nabla w^\tau, \nabla q^k)_{H_\tau}+
\int_I (v_t^\tau \dive(\delta \te \circ \tau^{-1}),p^k )_{H_\tau} + (A'(\delta \te \circ \tau^{-1})  \nabla v^\tau, \nabla p^k)_{H_\tau} 
\end{align*}

Thanks to the assumed weak convergence, $a_k\rightarrow J'(\tau)[\delta \te]$. So, we still have to show that:

\begin{align*}
o_k:=
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2 o^1_k t_k^{-1}+
\int_I ( w_t^\tau o^1_kt_k^{-1}, q^k)_{H_\tau}+ (t_k^{-1}o^2_k\nabla w^\tau, \nabla q^k)_{H_\tau}+
\int_I (v_t^\tau o^1_k t_k^{-1},p^k )_{H_\tau} + (t_k^{-1}o^2_k \nabla v^\tau, \nabla p^k)_{H_\tau} 
\end{align*}

goes to zero. This is true thanks to the boundedness of the averaged adjoint states, which stems from their weak convergence, and othe properties of $o_k^1,o_k^2$.


\underline{Weak convergence of states}

We assumed $p^k \weakc p^0$ in $Q(I,\tw{V}_\tau)$ and $q^k \weakc q^0$ in $Q(I,\tw{W}_\tau)$. We now prove these claims. We show at first  $v_0^k \weakc v^0_0$ in $Q(I,\tw{V}_\tau)$ and $w^k \weakc w^0$ in $Q(I,\tw{W}_\tau)$. We do this by uniformly estimating these quantities on $k$. To do this, use the equations of $V_0^k:=v_0^k\circ \tau_k^{-1}$ and $W^k:=w^k\circ \tau_k^{-1}$ (see \cref{thm:eq_pde}) and \cref{prop:diri_wp},  \cref{prop:wp_neu}, to obtain the stability estimates:

\begin{align*}
\norm{V^k}^2_{C([0;T],H_{\tau_k\circ \tau})}+\norm{V^k}_{L^2(I,H_{\tau_k\circ \tau})}^2+ \norm{\nabla V^k}_{L^2(I,H_{\tau_k\circ \tau})}^2 + \norm{(V^k)_t}^2_{L^2(I,H_{\tau_k\circ \tau})}\leq C\norm{U^k}_{H^1(I,\tw{W}_{\tau_k\circ \tau})}^2\\
\norm{W^k}^2_{C([0;T],H_{\tau_k\circ \tau})}+\norm{W^k}_{L^2(I,H_{\tau_k\circ \tau})}^2+ \norm{\nabla W^k}_{L^2(I,H_{\tau_k\circ \tau})}^2 + \norm{W^k_t}^2_{L^2(I,H_{\tau_k\circ \tau})}\leq C\norm{g}_{H^1(I,L^2(\Gamma_f))}^2
\end{align*}


where $C$ is independent of $k$.

%But $\norm{U^k}_{H^1(I,V_{T_k\circ T})}^2 = \norm{\bar{u}\circ T_k^{-1}}_{H^1(I,V_{T_k\circ T})}^2\leq N_k\norm{\bar{u}}_{H^1(I,V_{ T})}^2$ by \cref{lemma:bochner_Hk_map}, where $N_k:=\norm{\circ T_k}_{L(V_{T_k\circ T},V_{T}))}$.

Now, consider \cref{thm:change}. It says that for almost every time:

\begin{align*}
\norm{U^k}_{\tw{W}_{\tau_k\circ \tau}}\leq \left ( 1+\norm{\det D\tau_k}_{L^\infty(\mR^n)}\right)^{1/2} \norm{(D\tau_k)^{-1}}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{\bar{u}}_{H^1(\tau(U_r));\mR^n)}
\end{align*}

and a similar estimate we have for the first derivative. 


%The term $( \norm{\det DT_k}_{L^\infty(\mR^n)})^{1/2}$ is bounded with respect to $k$ as we already saw, and with analogous reasonings, so is $ \norm{(DT_k)^{-1}}$, thanks to the Fréchet differentiability of $\delta \te_k \rightarrow  (DT_k)^{-1}$ established in lemme 4.3, page IV.8 \cite{murat}.

This bound is uniform on $k$ because of the continuity of the bound, with respect to $k$, as seen in 4.12, page IV.6, \cite{murat}.

We conclude that $\norm{U^k}_{H^1(I,\tw{W}_{\tau_k\circ \tau})}^2$ is bounded and we thus have that $W^k \in Q_0(I, \tw{W}_{\tau_k\circ \tau}), V_0^k \in Q_0(I,\tw{V}_{\tau_k\circ \tau})$ are bounded.

Now, for almost all times, using 4.11, page IV.6 of \cite{murat}, we obtain that, for instance:

\begin{align*}
\norm{v_0^k}_{\tw{W}_{ \tau}}\leq \left ( 1+\norm{\det (D\tau_k)^{-1}}_{L^\infty(\mR^n)}\right)^{1/2} \norm{D\tau_k}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{V_0^k}_{H^1(\tau_K(\tau(U_r)))}
\end{align*}

where we remember that $H^1_0$ was chosen to be normed with the full $H^1$ norm.

The same goes for $w^k$ and the first derivatives in time, yielding that $w^k \in Q_0(I, \tw{W}_{ \tau}), v_0^k \in Q_0(I,\tw{V}_{\tau})$ are bounded.

We thus have $w^k\weakc w^? \in Q_0(I, \tw{W}_{ \tau})$, $v_0^k \weakc v_0^? \in Q_0(I,\tw{V}_{\tau})$, in the weak topologies of, respectively, $Q(I, \tw{W}_{ \tau}), Q(I,W_{\tau})$, and modulo subsequences. The initial values are preserved becase $Q_0$ is closed and convex in the Hilbert space $Q$ (see also \cref{prop:Q}). 
%The closedness follows from the fact that the embedding into continuous function is linear bounded, and evaluation at $0$ is linear bounded from continuous functions.

We now prove that $w^?=w^0$, $v^?=v^0$, and this will yield the weak convergence of the whole sequence.
To prove e.g. that $v^?=v^0$, let us look at the weak formulations of $v_0^k$:

\begin{align*}
\int_I (v_{0t}^k,p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0^k, \nabla p)_{H_\tau}+(\bar{u}',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla \bar{u} , \nabla p)_{H_\tau} = 0
\end{align*}

for all $p \in Q_0(I,\tw{V}_{\tau})$.
Let's analyize the first term, which is $\int_I (v_{0t}^k,p |\det(D\tau_k)|)_{H_\tau} ) =(v_{0t}^k,p |\det(D\tau_k)|)_{L^2(I,H_\tau)}$.
We can write:

\begin{align*}
(v_{0t}^k,p |\det(D\tau_k)|)_{L^2(I,H_\tau)} = (v_{0t}^k,p )_{L^2(I,H_\tau)} + (v_{0t}^k,p (|\det(D\tau_k)|-1))_{L^2(I,H_\tau)}
\end{align*}

Because $p \in  Q(I,\tw{V}_{\tau})$, the first term converges to $(v_{0t}^?,p )_{L^2(I,H_\tau)}$, see \cref{prop:Q} for details on why we can write the time derivative of the limit. The other term can be estimated as follows:

\begin{align*}
|(v_{0t}^k,p (|\det(D\tau_k)|-1))_{L^2(I,H_\tau)}|\leq\norm{v_{0t}^k}_{L^2(I,H_\tau)}\norm{p }_{L^2(I,H_\tau)} \norm{|\det(D\tau_k)|-1}_{L^\infty}
\end{align*}

where the first term in the product is bounded by the weak convergence property, and the last one goes to $0$ by continuity, see again 4.12, page IV.6 of \cite{murat}. 
In a similar fashion for the other pieces, and by passing to the limit:
\begin{align*}
\int_I (v_{0t}^?,p)_{H_\tau} + (\nabla v_0^?, \nabla p)_{H_\tau}+(\bar{u}',p)_{H_\tau}+(\nabla \bar{u} , \nabla p)_{H_\tau} = 0
\end{align*}

so that $v^?=v^0$.

\underline{Weak convergence of averages adjoint states}

So, $v_0^k \weakc v_0^0, w^k\weakc w^0$ in the sense of the $Q(I,\tw{V}_\tau)$ and $Q(I,\tw{W}_\tau)$ weak convergence.
We now claim that $p^k \weakc p^0, q^k\weakc q^0$, in a similar style as before. We bound $P^k:=p^k\circ \tau_k^{-1}$ and $Q^k:=q^k\circ \tau_k^{-1}$.
By \cref{thm:const_track}, we will obtain a bound in $Q$  as soon as we have a bound on $\ds \frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}$ in the $L^2(I,H)$ norm, and of $U^k:=\bar{u}_\tau\circ \tau_k^{-1}$. The latter was proven above.

So, by \cref{thm:change} and 4.12 of \cite{murat} at page IV.6, it suffices to have an $L^2(I,H)$ bound on $\ds \frac{v_0^k+w^k+v_0^0+w^0}{2}\circ \tau_k^{-1}\circ \tau_k = \frac{v_0^k+w^k+v_0^0+w^0}{2}$ which we have, since we just proved that $v_0^k, w^k$ are weakly convergent in e.g. $L^2(I,H)$.
We conclude that $Q^k,P^k$ are bounded in the $Q(I,\tw{W}_{\tau_k\circ \tau})$ and $Q(I,\tw{V}_{\tau_k\circ \tau})$ sense, so that, just as above,  a bound on $q^k, p^k$ in the $Q(I,\tw{W}_{ \tau})$ and $Q(I,\tw{V}_{ \tau})$ can be obtained.

We conclude that there exist $q^?, p^?$ in $Q^0(I,\tw{W}_{ \tau})$, $Q^0(I,\tw{V}_{ \tau})$, that are, modulo subsequences, the weak limits of $q^k, p^k$.
To show e.g. $q^?=q^0$ and conclude the convergence of the full sequence, we analyze the weak formulation of $q^k$, which reads, after going to the moving domain and applying integration by parts in time (see \cref{prop:Q}):

\begin{align*}
-\int_I \left (\frac{((v_0^k+\bar{u}_\tau - w^k)+(v_0^0+\bar{u}_\tau - w^0)}{2}\right )|\det(D\tau_k)|,\delta w)_{H_\tau}=
-\int_I (  q^k_t ,   \delta w |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q^k)_{H_\tau}
\end{align*}

for all $\delta w \in Q_0(I,\tw{W}_{ \tau})$.

We show the convergence of e.g. the member: $\int_I( v_0^k|\det(D\tau_k)|,\delta w)_{H_\tau}$. By splitting the scalar product as we saw above, we are left with checking that $\int_I (v_0^k,\delta w)_{H_\tau}\rightarrow  \int_I (v_0^0,\delta w)_{H_\tau}$, which is true, since we proved that $v_0^k \weakc v_0^0$ in $Q(I,\tw{V}_\tau)$. We conclude, upon passing to the limit, that:

\begin{align*}
-\int_I \left (\frac{((v_0^0+\bar{u}_\tau - w^0)+(v_0^0+\bar{u}_\tau - w^0)}{2}\right ),\delta w)_{H_\tau} = 
-\int_I (  q^?_t ,   \delta w )_{H_\tau}+ (\nabla \delta w, \nabla q^?)_{H_\tau}
\end{align*}

which is satisfied also by $q^0$, therefore $q^? = q^0$ and we have weak convergence of the entire sequence.
\end{mproof}

\begin{obs}[Fréchet differentiability]
\mbox{}\\
A promising track to show Fréchet differentiability is to start from the Gateaux differentiability of \cref{prop:gateaux_diff}, after showing continuity of $\tau\mapsto dJ(\tau)$. Stronger smoothness assumptions on the transformations $\tau$ must however be made. 
Yet another way would be to apply implicit function theorems.
\end{obs}

\section{Star-shaped reparametrization}
\label{sec:star}
%\textcolor{red}{You can add a generalization to a different star shaped reparametrization, if need be}

Here we reparametrize the problem assuming the domains $D, \Omega=\tau(\Omega_r)$ to be star-shaped with respect to the origin. We do this to justify the computer implementation of the solution algorithm. In particular, we define and analyze certain maps that convert functions on a sphere to radial deformation fields (see below for details), and based on those, detail the expression of the shape gradient of \cref{prop:gateaux_diff}. This is the result of \cref{prop:star_shaped_gradient}.

\begin{prop}[Star shaped boundary]
Let $f \in C(\mS)$, $f>0$. Define $\Omega_f:=\{x, |x|<f(\xh)\}\cup\{0\}$, where $\xh=x/|x|$. Then:
\begin{itemize}
\item $\Omega_f$ is open
\item $\Omega_f$ has boundary $\{x, |x|=f(\xh)\}$
\item $\Omega_f$ is a bounded Lipschitz domain
\end{itemize}
\end{prop}
%
%\begin{figure}[H]
%\centering
%\includegraphics[width=0.4\columnwidth]{Images/RadialDisplacement.pdf}
%\caption{Illustration of radial displacement}\label{fig:star}
%\end{figure}

\begin{mproof}

For $x \in \partial \Omega_f$ (so, $x\neq 0$) we find $x_n, y_n \rightarrow x$ with $|x_n|<f(\widehat{x_n})$ and $|y_n|\geq f(\widehat{y_n})$. For large $n$ and by continuity, $|x| = f(\xh)$ and we have shown one inclusion.

For the reverse, and $x, |x|=f(\xh)$ (so, $x\neq 0$), we define $x_n = \frac{n}{n+1} x$ which satisfies $|x_n|<|x|=f(\xh)=f(\widehat{x_n})$, that is, $x_n \in \Omega_f$, and also $x_n\rightarrow x$. This shows that $x \in \partial \Omega_f$.

It is a bounded Lipschitz domain by lemma 2 at page 96 of \cite{burenkov}, and lemma 5 at page 151 also of \cite{burenkov}, a fact that was not discussed in \cite{deckelnick}. Note that the definition of Lipschitz domain of \cite{burenkov} is completely equivalent to that of \cite{bello} (and at least implies that of \cite{mclean}, \cite{grisvard}, \cite{leoni}, \cite{adams}, a fact which is needed in the sequel), by an application of the Lebesgue number lemma, whose statement can be found at e.g. page 179 of \cite{munkres}.
\end{mproof}

We now define maps relating a radial function to its correspondent a star-shaped domain. We choose $0<\eps <f_D \in W^{1,\infty}(\mS)$, to parametrize the non moving part of the optimization domain. The reference domain is taken to be $\Omega_{f_D}\setminus \overline{B}_\eps$, and we call $D:=\Omega_{f_D}$

\begin{prop}[$H_f, A_f$]
Let $\eps <f_D \in W^{1,\infty}(\mS)$ and $0<f \in W^{1,\infty}(\mS), f<f_D$, and define:
\begin{itemize}
	\item $H_f(x):=\ds \left\{\begin{matrix}
\frac{x}{\epsilon}f(\hat{x}) &  x\neq 0\\ 
0 & x=0
\end{matrix}\right. $, as a function $\mR^n\rightarrow \mR^n$
	\item $A_f(x):=\left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh$, as a function $\mR^n\setminus\{0\}\rightarrow \mR^n$
\end{itemize}

They enjoy the following properties:

\begin{enumerate}
%	\item $H_f:\mR^n \rightarrow \mR^n$, $A_f:\mR^n \rightarrow \mR^n$ is Lipschitz, $A_f: \overline{D}\setminus B_\eps\rightarrow \mR^n$ is Lipschitz too
	\item $H_f(B_\eps)=\Omega_f$, $H_f(\eps \mS) = \partial \Omega_f$
	\item $A_f(D\setminus \overline{B_\eps}) = D\setminus \overline{\Omega_f}$, $A_f(\partial D) = \id$, $A_f(\eps \mS) = \partial \Omega_f$
	\item $A_f=H_f$ on $\eps\mS$
	\item $H_f^{-1}(y):=\ds \left\{\begin{matrix}
\epsilon \frac{y}{f(\hat{y})} &  y\neq 0\\ 
0 & y=0
\end{matrix}\right. $, as a function $\mR^n\rightarrow \mR^n$
	\item $A_f^{-1}(y):=\left (  \eps+\frac{f_D(\yh)-\eps}{f_D(\yh)-f(\yh)}(|y|-f(\yh)) \right )\yh$, as a function $\overline{D}\setminus \Omega_f \rightarrow \overline{D}\setminus B_\eps$
\end{enumerate}

\end{prop}


\begin{figure}[H]
\centering
%\includegraphics[width=0.3\columnwidth]{Images/RadialDisplacement.pdf}
%\caption{Illustration of radial displacement}\label{fig:star}
\includegraphics[width=0.6\columnwidth]{Images/A_f.pdf}
\caption{Illustration of the action of $A_f$}\label{fig:A_f}
\end{figure}

\begin{mproof}
All the properties are straightforward from the definitions. It helps to recognize that $A_f$ is just the linear map from the radial segment $[\eps, f_D(\xh)]$ to $[f(\xh), f_D(\xh)]$ and that $\overline{\Omega_{f_D}} \setminus \Omega_f = \{f(\xh)\leq|x|\leq f_D(\xh)\}$
\end{mproof}

They also satisfy a bi-Lipschitz condition.

\begin{prop}[Bi-Lipschitz condition]
We have that $A_f:  \overline{D}\setminus B_\eps\rightarrow \overline{D}\setminus \Omega_f $ is Lipschitz with Lipschitz inverse (bi-Lipschitz), and so is $H_f: \mR^n \rightarrow \mR^n$.
\end{prop}

\begin{mproof}

The second part of the proposition is contained in \cite{deckelnick} in a weaker for, we therefore proceed to prove all the statements.

\underline{$H_f$}

We can assume both $x,y\neq 0$. Then $|f(\xh)x-f(\yh)y|\leq |x||f(\xh)-f(\yh)|+f(\yh)|x-y|$. Employing direct and reverse triangle inequalities we get $|\xh-\yh|\leq \frac{2}{|x|}|x-y|$.
As $f$ is Lipschitz (see \cite{deckelnick}) we obtain:  $|f(\xh)x-f(\yh)y|\leq |x|C(f)\frac{2}{|x|}|x-y|+C(f)|x-y|$.

Now, $1/f$ is also Lipschitz and bounded, because $f>0$ and is continuous on a compact set. Thus the same proof shows the Lipschitz property also for $H_f^{-1}$.

\underline{$A_f$}

Call $A_f(x)=\left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh =:Q(x)\xh $. Because $|x|\geq\eps$, as before, we obtain $|A_f(x)-A_f(y)|\leq 2/\eps Q(x) |x-y|+|Q(x)-Q(y)|$, so that we need to show that $Q$ is bounded Lipschitz.

By continuity and compactness, $f_D(\xh)-\eps\geq \delta >0$ and boundedness follows. The Lipschitz property follows because $Q$ is sums of products of bounded Lipschitz functions. For instance, $f_D(\xh)$ is bounded and Lipschitz because $|x|\geq\eps$, as before, and so is $f_D(\xh)-\eps$. Is is a bounded Lipschitz function that is uniformly above $\delta$, so that its reciprocal is also a bounded Lipschitz function.

Analogous reasonings let us prove also the Lipschitz property of $A_f^{-1}$.
\end{mproof}

We now try to glue $H_f, A_f$ together and still obtain a bi-Lipschitz function. Even the Lipschitz property need not to hold in general, see page 7 of \cite{weaver} for a counterexample. We therefore proceed to the proof of this fact.

\begin{prop}[Gluing $H_f^{-1}, A_f^{-1}$]
\label{prop:gluing}
$H_f^{-1}, A_f^{-1}$, or also $A_f, H_f$ can be glued into a Lipschitz function $\overline{D}\rightarrow\overline{D}$.
\end{prop}
\begin{mproof}

Call $\tau_f^{-1}$ the gluing. It is Lipschitz $\overline{D}\rightarrow\overline{D}$ if and only if $\tau_f^{-1}\circ H_f$ is Lipschitz $H_f^{-1}(\overline{D})\rightarrow\mR^n$, because we proved that $H_f$ is bi-Lipschitz $\mR^n \rightarrow \mR^n$.
We are therefore left to prove that gluing Lipshitz function on $\mS$ produces a Lipschitz function, which would also yield the claim for $\tau_f$, the gluing of $A_f, H_f$. Note that by the preceding proposition, all the functions to be glued are Lipschitz and agree on their overlaps.

\underline{Gluing lemma for Lipschitz functions on $\mS$}

Let $A\supseteq \overline{B_\eps}$ be a set. Suppose $g:A\rightarrow\mR^n$ and $h:\overline{B_\eps}\rightarrow\mR^n$ are Lipschitz and agree on $\eps \mS$. Call $f$ their gluing.

For the proof we can assume that $x \in B_\eps$, $y \in A \setminus \overline{B_\eps}$.

Then, $|f(x)-f(y)|\leq |h(x)-h(\eps \yh)|+|g(\eps \yh)-g(y)|$.

We claim at first that $|y-\eps \yh|\leq  |x-y|$. To see this, choose $n:=\yh$. Then $|y-x|^2 \geq |(y-x)\cdot n n|^2$ by Pythagoras' theorem, so that $|y-x|\geq |(y-x)\cdot n| = |(y-\eps \yh)\cdot n + (\eps \yh -x)\cdot n|$. But $(y-\eps \yh)\cdot n=|y|-\eps \geq 0$, and $(\eps \yh -x)\cdot n = \eps - x\cdot n\geq 0 $ as $x\cdot n \leq |x|\leq \eps$.

Thus  $|y-x|\geq |(y-\eps \yh)\cdot n| + |(\eps \yh -x)\cdot n|\geq  |(y-\eps \yh)\cdot n|=|y-\eps \yh|$.

We also claim that $|x-\eps \yh|\leq |x-y|$. To do so, pick $n:=\frac{\eps\yh -x}{|\eps\yh-x|}$. By Pythagoras' theorem we obtain $|y-x|\geq |(y-x)\cdot n|=|(y-\eps \yh)\cdot n +(\eps \yh -x)\cdot n|$. The second summand is non-negative and for the first one, it is directly proportional to $(y-\eps \yh)\cdot(\eps \yh-x)=(|y|-\eps)(\eps-\yh\cdot x)\geq 0$. So, $|x-y|\geq |(\eps \yh -x)\cdot n|=|\eps \yh -x|$.

Thus $ |f(x)-f(y)|\leq C|x-y|$ as desired.

\end{mproof}

\begin{cor}[Radial to volumetric transformation]
\label{cor:star_shaped_transformation}
Let again $\eps <f_D \in W^{1,\infty}(\mS)$ and $0<f \in W^{1,\infty}(\mS), f<f_D$. Define:

\begin{itemize}
	\item $\ds \tau_f(x):=\left\{\begin{matrix}
 x & |x|\geq f_D(\xh)\\ 
 \left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh & \eps \leq |x| \leq f_D(\xh) \\ 
 \frac{x}{\epsilon}f(\hat{x}) & 0<|x|\leq \eps\\ 
 0 & |x|=0
\end{matrix}\right.$

	\item $\ds \tau_f^{-1}(y):=\left\{\begin{matrix}
 x & |y|\geq f_D(\yh)\\ 
 \left (  \eps+\frac{f_D(\yh)-\eps}{f_D(\yh)-f(\yh)}(|y|-f(\yh)) \right )\yh & f(\yh) \leq |y| \leq f_D(\yh) \\ 
 \epsilon \frac{y}{f(\hat{y})}& 0<|y|\leq f(\yh)\\ 
 0 & |y|=0
\end{matrix}\right.$
\end{itemize}


Then $\tau_f \in \cT$.
\end{cor}
\begin{mproof}

The final gluing on the border of $D$ yields a Lipschitz function: we can see this by taking $\id -\tau_f^{\pm 1}$, which is Lipschitz and $0$ on $\partial D$, so that we are considering the zero extension outside $D$ of a Lipschitz function, null on $\partial D$. This extension is Lipschitz.
\end{mproof}

Note that, as long as $f<f_D$, $\tau_f(B_\eps)$ will always be bounded Lipschitz.

We finally have a look at shape derivatives in this radial framework. The cost functional will be $j(q):=J(\tau_{\eps+q})$, where $0<q+\eps < f_D$. We are interested, for $h\in W^{1, \infty}(\mS)$, in the limit $$\lim_{t\rightarrow 0}\frac{j(q+th)-j(q)}{t}=\lim_{t\rightarrow 0}\frac{J(\tau_{\eps+q+th})-J(\tau_{q+\eps})}{t}$$

Now, we derive the expression of a displacement field $V_h$, to connect this difference quotient to the already computed shape derivative, see also \cite{deckelnick}. The ansatz $\tau_{q+th}=(\id + tV_h\circ \tau_q^{-1})\circ \tau_q$ brings us to $V_h = \ds \frac{\tau_q+th-\tau_q}{t}$, and by some computations, we obtain: 

$$V_h(x) :=\left\{\begin{matrix}
 0 & |x|\geq f_D(\xh)\\ 
 h(\xh)\frac{f_D(\xh)-|x|}{f_D(\xh)-\eps}\xh & \eps \leq |x| \leq f_D(\xh) \\ 
 \frac{x}{\epsilon}h(\hat{x}) & 0<|x|\leq \eps\\ 
 0 & |x|=0
\end{matrix}\right.$$

This expression only depends on $h$ and is the gluing of Lipschitz functions, that are either $0$ at the gluing points, or such that the gluing points lie in $\eps\mS$. Note, this vector field is just moving $\eps \mS$ by $h$ and radially damping this movement to $0$ close to $\partial D$. We can therefore conclude:

\begin{prop}[Shape derivative, star shaped case]
\label{prop:star_shaped_gradient}
We have the following facts, for $h \in W^{1,\infty}(\mS)$, $0<q<f_D$, $q \in W^{1,\infty}(\mS)$:

\begin{itemize}
	\item $\tau_{q+th}=(\id + tV_h\circ \tau_q^{-1})\circ \tau_q$
	\item $V_h \in \Te$
	\item $j$ is Gateaux differentiable at every $0<q<f_D$, $q \in W^{1,\infty}(\mS)$, with $j'(q)[h] = J'(\tau_{\eps+q})[V_h]$
\end{itemize}

\end{prop}
\begin{mproof}

We only need to show that $h\mapsto V_h$ is linear bounded $W^{1,\infty}(\mS)\rightarrow \Te$. Linearity is immediate and for the boundedness: $\sup_x|V_h(x)| = \norm{h}_\infty$, and we only therefore need to bound the Lipschitz constant of $V_h$. 

We only need to restrict ourselves to $\overline{D}$, as extending to zero a Lipschitz function doesn't increase its Lipschitz constant.

The gluing lemma \cref{prop:gluing} shows that it is sufficient to bound the Lipschitz constants of the two branches, separately.

These bounds are respectively: $C(\eps)(\norm{h}_\infty + 2\norm{D_T h}_\infty)$ and $[2\eps^{-1}(\norm{D_T h}_\infty + \norm{h}_\infty)]C(f_D,\eps) + C(f_D,\eps)\norm{h}_\infty$, which concludes the proof.
\end{mproof}

\subsection{Smooth star-shaped domains}

To ensure that $U$ has the smoothness required to perform numerical analysis, we want to increase the regularity of $f$ and see an increase in the regularity of $\partial \Omega_f$.

\begin{prop}[Smooth radial function yields smooth star shaped domain]
\label{prop:Co_domain}
Let $f>0$ which is either $C^{1,1}(\mS)$ (that is, $C^1$ with all the components of $D_T f$ Lipschitz) or $C^2(\mS)$.  

Then, $\Omega_f$ has boundary of class $C^{1,1}$ or $C^2$.

\end{prop}

\begin{mproof}

In what follows we generically write $ C^o$, $o=1,1 $ or $o=2$.


\underline{A punctured diffeomorphism of class $C^o$}

We consider $H_f$, neglecting the $\eps$ factor. It has gradient (see \cite{deckelnick}) $D H_f(x) = f(\xh)I+\xh \otimes D_Tf(\xh)$, and  $D H_f^{-1}(y) =1/f(\yh)I-1/f(\yh)^2 \yh \otimes D_Tf(\yh)$. They are $C^o$ away from the origin. In particular $H_f$ is $C^o$  outside of $B_\delta(0)$, $\delta < 1$. $H_f(B_\delta)$ also contains a ball around the origin, and the complement contains $\Omega_f$.

We conclude that $H_f: \overline{B_\delta(0)}^c \rightarrow \overline{H_f(B_\delta(0))}^c$ is a $C^o$ diffeomorphism, where the right set is open by $H_f$ being a homeomorphism of $\mR^n$. The Lischitz regularity of the gradients follows from the Lipschitz and boundedness of every factor, and the fact that we are setting ourselves away from the origin. In particular, $D_T f$ is Lipschitz, therefore continuous, on the sphere, and so bounded too.

We have therefore obtained a homeomorphism $\mR^n \rightarrow \mR^n$, which is $C^o$ as $\overline{B_\delta(0)}^c \rightarrow \overline{H_f(B_\delta(0))}^c$, so, in a neighbourhood of $\partial \Omega_f$.
For simplicity let's refer to such maps as $C^o$ punctured diffeomorphisms for $\Omega_f$.

\underline{Punctured diffeomorphism and $C^o$ domains}

Let $\Omega$ be of class $C^o$ (always locally) and bounded. Assume we have $F$, a punctured diffeomorphism for $\Omega$, so, $F:\mR^n\rightarrow \mR^n$ is a homeomorphism, and $F: U\rightarrow F(U)$ is $C^o$, $\partial \Omega \cc U$. Then, by analyzing the composition of $F$ with (small enough) charts of $\Omega$ we see that $F(\Omega)$ is another $C^o$ domain. 

\underline{From diffeomorphisms to graphs}

Let $\Omega$ be any $C^o$ domain, $x\in \partial \Omega$. We obtain $A\ni x, B$ open, and $\phi: A\rightarrow B$ a $C^o$ diffeomorphism, with $\phi^{-1}(B\cap \mR^n_+)=A\cap \Omega$, and $\phi(x)=0$.
%
%$\phi$ is a $C^1$ diffeomorphism, so $D\phi_n(x)\neq 0$, and we can assume $D\phi_n(x)$ to be proportional to $-e_n$ by a rotation of the axis.
%
%Thus $\partial_n\phi_n(z)<0$ in some $B(x)\subseteq A$. $B(x)$ is chosen small that $\phi$ is Lipschitz on $B(x)$.
%
%Apply the implicit function theorem to obtain $V',I$ open with $x \in V'\times I\subseteq B(x)$ and a function $\eta:V'\rightarrow I$ that is $C^o$ and Lipschtiz, with $\phi_n(z',z_n)=0 \iff z_n = \eta(z')$, for $z \in V'\times I$.
%
%$V'$ is open around $x'$, so let's restrict it to a square centered at $x'$. Relabel $\eta$ as the restriction to this new $V'$ and restrict $I$ to be the connected component of $G$ hosting $\eta(V')$, which is now an interval, as continuous image of a connected set. Because $x_n \in I$, and by continuity, $V'$ can be shrunk such that $\eta(V')\cc J \cc I$ for some open interval $J$. 
%
%All these shrinkings don't change the character of being the implicit function, i.e. $\eta$ still satisfies $\phi_n(z',z_n)=0 \iff z_n = \eta(z')$, for $z \in V'\times I$, and also,  $x \in V'\times I\subseteq B(x)$ and $\eta:V'\rightarrow I$ is still $C^o$ and Lipschitz.
%
%Now, the choice of $B(x)$ makes $z_n\mapsto \phi(z',z_n)$ strictly decreasing, for $(z',z_n) \in B(x)$.  So, for $z \in V'\times I$, we have $\phi_n(z', z_n) = \phi_n(z)>0=\phi_n(z',\eta(z')) \iff z_n<\eta(z')$ (by basic properties of strictly decreasing functions).
%
%But also, $\phi_n(z) >0 \iff \phi(z) \in B\cap \mR^n_+ \iff z \in \phi^{-1}(\mR^n_+\cap B)=A\cap \Omega$.
%
%Therefore, $z \in V'\times I, z_n<\eta_n(z) \iff z \in V'\times I, \phi_n(z) >0 \iff z \in A\cap \Omega \cap (V'\times I) = (V'\times I)\cap \Omega$.

Applying the implicit function theorem in a suitable way (e.g. through minor reworkings of the proofs at page 310, 311 of \cite{gilardi2}), we obtain:

\begin{itemize}
	\item a "square" and an interval $V', I$ with $V'\times I \ni x$
	\item $\eta: V'\rightarrow I$, Lipschitz, of class $C^o$
	\item $\phi(V') \cc J \cc I$
	\item $z \in V'\times I, z_n<\eta_n(z) \iff z \in (V'\times I)\cap \Omega$
	\item (and consequently, $z \in V'\times I, z_n=\eta_n(z) \iff z \in (V'\times I)\cap \partial \Omega$)
\end{itemize}

\underline{Conclusion}

Let a radial function $f>0$ be of class $C^o$. Thanks to $H_f$, a punctured diffeomorphism of class $C^o$, we we have that $\partial \Omega_f$ is the image of $\eps\mS$, a domain of class $C^o$ as well, locally. So $\Omega_f $ is of class $C^o$ locally, in the sense of diffeomorphisms, and by what we showed, also in the sense of graphs.

So, for $x \in \partial \Omega_f$ we can find a change of coordinates and a parallelepiped $V = V'\times I$ with $\phi: V'\rightarrow I$, $\phi$ of class $C^o$ and also Lipschitz, and $V\cap 	\Omega_f = V\cap \{x_n<\phi(x')\}$. We have moreover that $\phi \in J \cc I$ for some open interval $J$. By a compactness argument, finitely many $V_j = V_j'\times (a_n^j, b_n^j) $ are necessary to cover $\partial \Omega_f$. 

So, we have $V_j \cap \Omega_f = V_j\cap \{x_n<\phi_j(x')\} = V\cap \{a_n^j<x_n<\phi_j(x'), x' \in V_j'\}$. Choose $d>0$ to be the minimum gap between $\phi_j$ and $I_j$. $d>0$ by the existence of $J_j \cc I_j$. We call $L$ the maximum Lipschitz constant of $\phi_j$. 
We have therefore a Lipschitz and $C^o$ domain in the style of \cite{burenkov}, which yields, modulo an application of the Lebesgue number lemma, a $C^o$ and Lipschitz domain in the style of \cite{grisvard}.
\end{mproof}

\section{Hilbertian regularization framework}
\label{sec:hilbert}

Solving the optimization problem \cref{pb:shopt} cannot be done at the continous level: one must apply a discretization strategy and solve an optimization problem in finite dimensions isntead. We will adopt derivative based algorithms, where we compute search directions from the knowledge of the discretized shape derivative. It is important at this stage to respect the properties of the continuos problem when developing a discretization strategy. In general, the shape derivative on the continuous level is just a functional: one can try to extract a descent direction from its knowledge using the Riesz representation theorem. The choice of the inner product in which to find the representative is usually dictated by the control space, in optimal control. 

In shape optimization, however, one works with spaces which are not Hilbert, e.g. $W^{1,\infty}$. A way to tackle this is illustrated in \cite{deckelnick}, where descent directions are directly searched in $W^{1,\infty}$. The Hilbert space approach is nonetheless of easier implementation, and we decided to stick with it, in this work. We therefore face two problems. On one hand, we are doing something not completely rigorous, as we discuss below, and on the other hand it is not immediate which inner product to use in the finite dimensional optimization. Unfortunately, choosing the "wrong" scalar product can yield to descent directions that are too "squiggly" (see \cref{sec:experiments} for an example), or to mesh-dependence effects, where finer and finer meshes require more and more optimization iterations to converge (see \cite{mesh_dependence}).

In our implementation in particular, see \cref{chap:num_exp} and specifically \cref{sec:implementation}, we perform optimization with respect to the $H^1$ scalar product. On a continuous level, and in the star-shaped setting we put ourselves into, this means finding descent directions $h \in H^1(\mS)$ by:

$$(r(q),h)_{H^1(\mS)}  = j'(q)[h]$$

where $r(q)$ represents, via the Riesz representation theorem, the functional $j'(q)$. The reason for this is again to be able to find good enough (in the sense of smoothness) descent directions and to avoid mesh-dependence, as opposed to when the $L^2$ product is used instead. Despite not being a fully rigorous procedure, it is standard trick in shape optimization, and it worked well for us (see  \cref{chap:num_exp}). It is not rigorous because we pretend to simultaneously have $q$ smooth ($q \in H^2(\mS)$, for instance) and $r(q) \in H^1(\mS)$: $q-\alpha r(q)$ need not to be smooth too!

For further details regarding this so-called "Hilbertian regularization" procedure, we refer to \cite{allaire}. We just sketch a proof of the fact that $j'(q)$ is continuous in the $H^1$ topology, thus making the operation $r(q)$ well defined.

At first we remark that $h\mapsto V_h$ maps $H^1(\mS)$ functions into $H^1(\mR^n;\mR^n)$ functions. To see this, note that $h$ can be approximated by smooth functions $h_k$, in the $H^1$ norm (see definition 2.3 of \cite{aubin}). For the generic term of the approximating sequence we can employ integration in spherical coordinates and use the fact that $h_k$ is Cauchy, to get that $V_{h_k}$ is Cauchy in $H^1(\mR^n;\mR^n)$, and that it converges to $V_h$. 

Now, consider the expression of the shape derivative, given in \cref{prop:gateaux_diff}. We identify three different terms. We write $u$ for a state $v$ or $w$, and $a$ for the corresponding adjoint, leaving the dependence on $\tau$ for simplicity:

\begin{align*}
\int_I (u_t , \dive(\delta \te \circ \tau_q^{-1}) a)_{L^2(U)}, \quad \int_I (A'(\delta\te\circ \tau_q^{-1} )\nabla u, \nabla a)_{L^2(U)}, \quad \frac{1}{2}\int_I\int_{U} |v-w|^2\dive(\delta \te\circ \tau_q^{-1})
\end{align*}

Here, $U = \tau_q(U_r)$, $\delta \te = V_h$.

By \cref{thm:change}, we observe that $\dive(\delta \te\circ \tau_q^{-1})$, $A'(\delta\te\circ \tau_q^{-1} )$ are square integrable. Moreover, as we will discuss very soon, we can make hypothesis on the data and a suitable modification to the cost function so that $u, a \in H^1(I, H^2(U))$, see \cref{ass:num_discr_shopt}, where we need the regularity of $q$, to have $\partial U$ smooth enough to guarantee $H^2$ regularity (we have discussed this in \cref{prop:Co_domain}). Now, the Sobolev embedding $H^1\emb L^4$ (for spatial dimensions $n=2,3$, see e.g. \cite{adams}) and the Hölder's inequality, allow us to deduce that $j(q)$ can be indeed continuously extended to $H^1(\mS)$.


\chapter{Discretization}
\label{chap:discretization}
In this chapter we focus on giving justification to the numerical observations contained in \cref{chap:num_exp}. Linear finite elements are used to discretize the partial differential equations in space, whereas the implicit Euler or the Crank-Nicolson methods are used for advancing in time.

We account for the fact the non-discretized domain is smooth and the computational one is polygonal/polyhedral. 

We are not focusing here on optimization algorithms to solve the shape identification problem, nor on the specific domain parametrization. This will be done in \cref{chap:num_exp}.


As a summary of the discretization approach:

\begin{itemize}
	\item the PDEs are numerically solved on a polygonal/polyhedral approximation of the smooth domain $U$
	\item such approximation involves only knowing a finite number of points of $\partial U$, and not its entire parametrization
	\item only such nodal values of the boundary data is required (compatible, for instance, with the case where only finite number of measurements are realized)
	\item implicit Euler or Crank-Nicolson time steppings are adopted
	\item several optimal order error estimates are obtained
\end{itemize}

We chose such time steppings because of their simplicity, overall low regularity requirements, and the fact that they are unconditinoally stable, so that no restriction on the time step size must be made. We remark however that they still require a globally smooth solution, over time. To decrease such requirement, discontinuous Galerkin space-time methods can be adopted, see e.g. \cite{vexler}. The reason for this is that certain time integrals therein are not discretized in time, whereas the classical implicit Euler/Crank-Nicolson evaluate such quantities pointwise. The implicit Euler method can be in fact seen as a space-time method, with quadrature in time. More smoothness in time is therefore required, to treat this numerical quadrature.

We can reach such smoothness for the state equations, by requiring smooth data, and certain compatibility relations among them (see e.g. chapter 2 of \cite{lions}). Smoothness of the data alone is not enough: a regular solution is obtained, but only away from the starting time, where a singularity can develop (see e.g. the discussion in \cite{harbrecht}). The adjoint equations are however, in a certain sense, fixed by the particular cost functional we chose, and the state equation itself: unfortunately, for them, compatibility relations do not hold, in general.

In \cite{harbrecht}, they work with adjoint equations that have incompatible boundary data, and devise a non-standard time stepping scheme to deal with this. On the other hand, our choice of cost functional, makes it possible to obtain compatibility of order zero in the adjoint. This would be enough for a low order space-time method, but not for the chosen fully discrete schemes. To obtain more compatibility, i.e., to modify the data that enters the adjoint equations, since we cannot modify the PDE solved by the states $u,v$, we can only tweak the cost functional. This is what we will do, by introduction of a suitable temporal weight in the cost functional of \cref{pb:shopt}. Such operation will yield compatibility of arbitrary order, at the price of partially modifying the nature of the shape optimization problem. See \cref{sec:o-t-d} for a more thorough discussion.

An in-depth presentation and analysis of the discretization algorithms for states and adjoints is discussed in \cref{chap:inh_fem}. In what follows we will build on the results therein.

As a last note, let us mention the two canonical ways, in the literature on optimal control, of discretizing a problem posed on an infinite-dimensional level:

\begin{itemize}
	\item optimize-then-discretize: the gradient of the cost functional is derived on the continuous level (see e.g. \cref{prop:gateaux_diff} in our case), and some adjoint states appear. Then, one proceeds with discretizing states and adjoints, and obtains an optimality system on the discrete level, amenable to numerical solution
	\item discretize-then-optimize: the states and cost function, i.e. the continuous problem (\cref{pb:pdes} and \cref{pb:shopt}) are discretized, to obtain an optimization problem posed on the discrete level. Finite dimensional optimality conditions can now be derived
\end{itemize}

In any case, one starts from an infinite-dimensional problem and obtains discrete optimality conditions, that can be employed for a numerical implementation. When the obtained discrete optimality system is the same, we say that the two strategies, optimize-then-discretize and discretize-them-optimize commute. With a diagram:

\[\begin{tikzcd}
	&&& \text{continuous optimality system} \\
	\text{continuous problem} &&&&&& \text{discrete optimality system}  \\
	&&& \text{discrete problem} 
	\arrow["{\text{optimization}}"', from=3-4, to=2-7]
	\arrow["{\text{discretization}}", from=1-4, to=2-7]
	\arrow["{\text{optimization}}", from=2-1, to=1-4]
	\arrow["{\text{discretization}}"', from=2-1, to=3-4]
\end{tikzcd}\]

Although not a trivial task, there are several benefits implied by realizing a commutative scheme, we refer to the introduction of \cite{liu} for a comparison between the two strategies, and a discussion of advantages and disadvantages of each. See also \cite{flaig}, in the context of parabolic optimal control.

We can show that optimization and discretization commute, when using the implicit Euler case. We strongly suspect that this conclusion can be extended also to Crank-Nicolson, thanks to the work of \cite{flaig}.

Now:

\begin{itemize}
	\item in \cref{sec:o-t-d}, the continuous states and adjoints are discretized and the error in doing so, is quantified. We are taking an optimize-then-discretize approach, and obtain optimal order estimates, optimal with respect to the approximation properties of the finite element spaces and time stepping schemes
	\item in \cref{sec:d-t-o_IE}, a discretize-then-optimize approach is adopted, just like in \cref{chap:num_exp}. A result on the convergence of the discrete shape gradient, to the continuous one, is presented, in the case the time-stepping is done by the implicit Euler method
	\item in \cref{sec:superconv}, we only discretize in space and show that a better result than in \cref{sec:d-t-o_IE} is available. This is then applied to the case of implicit Euler to obtain a fully discrete result
	

\end{itemize}

In what follows, $\lesssim$ stands for $\leq C$, with $C$ independent on time and space discretization parameters.

\section{Approximation of PDEs, optimize-then-discretize}
\label{sec:o-t-d}

Consider the state and adjoint equations as seen in \cref{pb:pdes} and \cref{prop:gateaux_diff}. Let us have a unified notation (just like in \cref{pb:mix}).

\begin{pb}[Unified notation for state and adjoint equations]
\label{pb:uni_state_adj}
State equations:

\begin{align*}
\left\{\begin{matrix}
u_t-\Delta u =0 & \text{ in } U\times (0,T)\\ 
u = u_D & \text{ on } \Gamma_D\times(0,T)\\ 
\partial_\nu u = u_N & \text{ on } \Gamma_N\times(0,T)\\ 
u(0) =0 & 
\end{matrix}\right.
\end{align*}

Adjoint equations:

\begin{align*}
\left\{\begin{matrix}
-a_t-\Delta a =\eta (v-w) & \text{ in } U\times (0,T)\\ 
a = 0 & \text{ on } \Gamma_D\times(0,T)\\ 
\partial_\nu a = 0 & \text{ on } \Gamma_N\times(0,T)\\ 
a(T) =0 & 
\end{matrix}\right.
\end{align*}

We intend that $u$ can be $v$, in which case $a$ is $p$, or $u$ is $w$ and then $a$ is $q$, so that the Dirichlet and Neumann boundaries are coherent between state and adjoint equation. Note that we added a temporal weighting function $\eta$ which we will later specify.

\end{pb}

We have dropped, for simplicity, all the references to the domain transformation. Let us discuss the presence of the temporal weight $\eta$. This is a function $\eta: [0,T] \rightarrow \mR$ which in the above problem, we wrote equal for both adjoint states. This is a slight abuse of notation, in fact, for $p$ and $q$ we should be writing $\eta$ and $-\eta$.

Its presence in the right hand side of the adjoint equation can be justified by modifying the energy function in \cref{pb:shopt} to be:

$$J_\eta(\tau) = \frac{1}{2} \int_I \eta \norm{v_\tau - w_\tau}_{H_\tau}^2$$

This modification is reasonable for a reasonable $\eta$ and its main purpose is to facilitate the analysis of the numerical discretization. In particular, we choose $\eta$ to be a smooth cut-off function that is positive in $(0,T)$ and $0$ in $[T, +\infty]$. Note that in case a solution to the "classical" problem exists, then it is also a solution to this new problem, and viceversa. In fact, $J_\eta(\tau)=0 \implies \eta \norm{v_\tau - w_\tau}_{H_\tau}^2=0 \implies v_\tau = w_\tau$. This equality holds on all $I=[0,T]$ by the time continuity of the states.

Modifying the final-time behaviour of the energy might have detrimental effects if the boundary data exhibts strong variations close to final time, which is physically implausible, given the physical nature of the partial differential equation. In fact, it is known that solutions to the heat equation tend to a steady state for long times, and we are only measuring the value of one such solution on the external boundary of $U$: we thus expect that in practice, this boundary data will not exhibit oscillatory behaviour for large times, and that the introduction of $\eta$ will not cause issues.

We now proceed to discretize states and adjoints using the scheme presented in \cref{pb:num_scheme} (the adjoint equation can be cast into a standard heat equation by time reversal). In short, finite elements are used in space, a finite difference time stepping, in time. If one chose an optimize-then-discretize approach this would be satisfactory (at least with regards to the numerical approximation of states and adjoints). However we will conduct experiments in a discretize-then-optimize setting, so that the upcoming results are only partially satisfactory.

The spatial discretization is done on a polygonal approxumation of $U$. We explicitly account for this, see the introductory discussion in \cref{chap:inh_fem}. Note, the next assumption is formulated as if $U$, $U_h$ were given, i.e. they are not deformations of initial reference domains. This will be remarked later on, too. 

Throughout, set $\theta=1$ to obtain the implicit Euler method, $\theta=1/2$ for the Crank-Nicolson method.

\begin{ass}[Hypothesis for the numerical discretization of \cref{pb:uni_state_adj} ]
\label{ass:num_discr_shopt}
\textcolor{white}{ }
\begin{enumerate}
	\item $\partial U \in C^2$ (for instance, the star shaped functions must be of class $C^2$), $U_h$ is polygonal/polyhedrak and $\partial U_h$ interpolates $\partial U$. The mesh family of $U_h$ must be (shape) regular and quasi-uniform (for such definitions, see \cite{brenner_scott})
	\item $u_D \in H^1(I, H^{2}(\Gamma_D)) \cap H^{1/\theta+1}(I,H^{3/2}(\Gamma_D))$, $u_N \in H^2(I,L^2(\Gamma_N)) \cap H^{1/\theta}(I, H^2(\Gamma_D))$
	\item $g_D(0)=0$ and $g_N^{(k)}(0), g_D^{(k+1)}(0)  = 0$ for $k=0,..., 1/\theta-1$
	\item $\eta^{(k)}(T)  = 0$ for $k=0,..., 1/\theta-1$, $\eta \geq 0$ and $\eta \in C^{\infty}([0,T];\mR)$
\end{enumerate}

\end{ass}

We have written $u_N, u_D, \Gamma_D, \Gamma_N$ to mantain a flexible notation. With reference to \cref{pb:pdes} this translates to:

\begin{itemize}
	\item state $v$: $u_D=f$ on $\Gamma_f$, $=0$ on $\Gamma_m$, $\Gamma_D = \partial U=\tau(U_r)$, $\Gamma_N=\emptyset$
	\item state $w$: $u_N=g$ on $\Gamma_f$, $u_D = 0$ on $\Gamma_m$, $\Gamma_D = \Gamma_m$ and $\Gamma_f = \Gamma_N$
\end{itemize}

Call now $h$ the maximum element size of the mesh of $U_h$, and $\delta t$ one of the $K$ uniform intervals $[t^k,t^{k+1}]$, $k=0,...,K-1$, into which $I$ is subdivided.

\begin{pb}[Numerical discretization of \cref{pb:uni_state_adj}]
\label{pb:num_scheme_recall}
Consider $g_{N,h}^k, g_{D,h}^k$ to be the Lagrange interpolant of $g_N(t^k), g_{D,h}^k$. For the state $u$ we look for $u_h^k \in S^1_h$, $k=0,...,K$, with:

\begin{align*}
\left ( \frac{u_{h}^{k+1}-u_h^k}{\delta t}, v_h\right)_{L^2(U_h)} + (\nabla(\theta u_h^{k+1}+(1-\theta)u^k_h), \nabla v_h)_{L^2(U_h)} = (\theta g_{N,h}^{k+1} + (1 - \theta)g_{N,h}^{k} , v_h)_{L^2(\Gamma_{N_h})},\quad  1\leq k \leq K\\
u_h^{k+1}|_{\Gamma_{D_h}}=g_{D,h}^{k+1},\quad 1\leq k \leq K\\
u_h^0=0
\end{align*}

and $v_h \in S^1_{h,0,D_h}$. Here $\Gamma_{D_h}, \Gamma_{N_h}$ are the discrete counterparts of $\Gamma_{D}, \Gamma_{N}$, and $S^1_{h,0,D_h}$ is the linear finite element space on $U_h$, with the constraint of vanishing on $\Gamma_{D_h}$.

The same scheme is applied to the adjoint equations. We refrain from writing it fully, since we won't be using it in the implementation. Further details can be found in the appendix after \cref{pb:num_scheme}, of which \cref{pb:num_scheme_recall} is an instance.
\end{pb}

We now state the error estimates for \cref{pb:uni_state_adj}. Before doing so, we remind that the continuous solution is defined on a smooth domain $U$, whereas the discretized solution on a polygonal/polyhedral approximation $U_h$. To compare e.g. $u$ and $u_h$ we must have a way of "lifting" $u_h$ to $U$ or viceversa. This procedure is possible and we denote it by $(\cdot)^l$: we thus compare $u: U\times I \rightarrow \mR$ and $u_h^l:U\times\{0,...,K\}\rightarrow \mR$. For details regarding the lifting action we refer to \cref{prop:lift}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\columnwidth]{Images/Lift.pdf}
\caption{Lifting action}\label{fig:lift}
\end{figure}


\begin{prop}[Optimize-then-discretize approximation of state and adjoint equations]
\label{prop:o-t-d}
Let \cref{ass:num_discr_shopt} be fulfilled. Then, for $0\leq k \leq K$:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(U)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(U)}^2} \lesssim h + (\delta t)^{1/\theta}\\
	\left | \int_I (\partial_t u , w_K)_{L^2(U)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(U)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(U))}
\end{align*}

and

\begin{align*}
	\norm{a(t^k)-(a_h^k)^l}_{L^2(U)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
	\sqrt{\delta t \sum_{k=1}^{K} \norm{(1-\theta)(a(t^{k}) - a_h^{k})^l) + \theta(a(t^{k-1}) - a_h^{k-1})^l)}_{H^1(U)}^2} \lesssim h + (\delta t)^{1/\theta}\\
	\left |- \int_I (\partial_t a , w_K)_{L^2(U)}-\delta t \sum_{k=1}^{K}\left ( \frac{(a^{k-1}_h)^l - (a_h^{k})^l}{\delta t} , w_{K,k}\right )_{L^2(U)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(U))}
\end{align*}

where $w_K$ is piecewise constant on the time discretization, and with values $w_{K,k}$, on $[t^k,t^{k+1}]$, that belong to $H^1_{0,D}(U)$ (i.e. it is $0$ on the Dirichlet boundary), and $\lesssim$ means $\leq C$, with $C\geq 0$ independent of $h$ and $\delta t$.

\end{prop}

Note, writing $H^1_{0,D}$ is flexible because the Dirichlet boundary varies between $v,w$. In fact, for $v$, $H^1_{0,D}=H^1_0$, whereas for $w$ we have $H^1_{0,D}=H^1_{0,m}=\{u \in H^1, u(\Gamma_m)=0\}$.

\begin{mproof}

We show the satisfaction of all the hypothesis necessary to obtain \cref{thm:fully_discr_est_par} (where we track from there all the necessary assumptions), and then bound the constants therein, uniformly with respect to the space/time discretization. We do this for $u$ at first, then for $v$. We do not track the dependency on the domain $U$.
% This is just a more detailed repetition of the proof of the more general result \cref{cor:actual_par_est}.

We note at first that in the star shaped setting, $\partial U \in C^2$ can be ensured by \cref{prop:Co_domain}.

\underline{Smoothness of $u$: \cref{ass:smoothness_par_discr} and  \cref{ass:basic_par_mix}}: we need to ensure that $u \in H^1(I,H^2(U))$. To do so we turn to \cref{thm:mix_reg}, which we apply with $k=1$. Hypothesis $1$ to $3$ suffice. 

\underline{Assumptions for spatial semidiscretization of $u$: \cref{ass:discr_reg}}: they are also satisfied by $1-3$.

\underline{Assumptions for full discretization of $u$: \cref{ass:full_discr_smoothness}}: the smoothness of the problem data is ensured by point $2$. We turn to the compatibility conditions of order $1,...,1/\theta$. The compatibility "residuals" $\delta_h^k(0)$ are all $0$ (see \cref{ass:full_discr_smoothness} for the notation) by hypothesis $3$.

\underline{Bounding the constants $A,B,C,D$ of $u$: \cref{thm:fully_discr_est_par}}: to bound $A,B$ uniformly with respect to $h$ we only need to note that the equation for $u$ has no source term. To bound $C$, this last fact, together with $\delta_h^k(0)$, $k=0,...,1/\theta$, suffices. $D=0$, in turn.

We now turn verify the same facts for the adjoint states $a$.

\underline{Smoothness of $a$}: we need to ensure that $a \in H^1(I,H^2(U))$. To apply \cref{thm:mix_reg} with $k=1$ we see that $\eta(T)(v(T)-w(T))$ should be zero on the Dirichlet boundary, which it is, given the fact that $\eta(T)=0$. We also need $v,w$ (so, generically, $u$), to be $H^1(I, L^2(U))$, which we have already checked (we even have $u \in H^1(I,H^2(U))$.  \cref{ass:basic_par_mix} is also easily verified.

\underline{Assumptions for spatial semidiscretization of $a$}: to fulfill \cref{ass:discr_reg} we see by the triangle inequality that $\norm{\eta(u-u_h^l)}_{L^2(U)}\lesssim C_u h^2$ would suffice, for a suitable $C_u$ (see \cref{ass:discr_reg} for the definition of $C_u$). Actually, given the properties of $\eta$, only $\norm{u-u_h^l}_{L^2(U)}\lesssim C_u h^2$ has to be asked. But the hypothesis we have verified for $u$ were sufficient for the conclusions of \cref{thm:semidiscrete_error_bound} to hold. We can therefore take $C_u = A = A(u)$, which is a constant in space and time, independent of $\delta t$ and $h$, as we saw before.

\underline{Assumptions for full discretization of $a$}: the compatibility conditions listed in \cref{ass:full_discr_smoothness} are satisfied as long as $\eta(T)=0$ in the case $\theta = 1$, and also $\eta'(T)=0$ in the case $\theta=1/2$. We also have $u_h \in H^{1/\theta}(I,S^1_h)$ by $2$.

\underline{Bounding the constants $A(a),B(a),C(a),D(a)$ of $a$}: this would be the last step to ensure the thesis of \cref{thm:fully_discr_est_par}, for $a$. Starting from $D(a)^2$, we see, thanks to the boundedness of $\eta$, that $D(a)^2 \lesssim \delta t \sum_{k=0}^{K-1}\norm{\theta(u_h(t^{k+1})-u_h^{k+1}) + (1-\theta)(u_h(t^k)-u_h^k)}^2_{L^2(U_h)}$. This $O(\delta t^{2/\theta})$ by \cref{prop:d_vd_sd} and the above reasonings ($D=D(u)=0$, $C=C(u)$ is bounded uniformly).

Moving on to $C(a)$. We see that there only remains to bound, by the triangle inequality, the already checked compatibility relations and the boundedness of $\eta$, the term $\ds \int_I\norm{u_h^{1/\theta}}_{-1,h}^2\lesssim \int_I\norm{u_h^{1/\theta}}_{L^2(U_h)}^2$. This can be done as above \cref{eqn:dd_est}.

To bound $A(a)$ (equivalently $B(a)$), we need to check the boundedness of $\ds \int_IC_{\eta(v-w)}^2 + \int_I \norm{\eta(v_h - w_h)}_{H^1(U_h)}^2$. In fact, we have chosen $\eta(v_h - w_h) \in S^1_h$ as a right hand side for the semidiscrete equation of $a_h$. A triangle inequality and basic energy estimates yield a bound for the second term. The definition of $C_{\eta(v-w)}$ comes directly from \cref{ass:discr_reg} and we see that, thanks to \cref{thm:semidiscrete_error_bound}, it is dominated by $A(v)+A(w)$, which we have already estimated.
\end{mproof}

\section{Approximation of shape gradient, discretize-then-optimize with implicit Euler}
\label{sec:d-t-o_IE}

In the numerical experiments (see \cref{chap:num_exp}) we adopt a discretize-then-optimize approach. When employing the implicit Euler method in time, we can see that optimization and discretization commute, as explained below. We are moreover able to quantify the error generated when substituting the continuous with the fully discretized shape gradient. 

A future line of research could be to extend such conclusions to the case of the Crank-Nicolson method, so as to fully justify the adopted algorithms in some of the numerical experiments we conducted. A promising direction would be to find a way to adapt the arguments of \cite{flaig}, at least to show commutativity of optimization and discretization. But for now, we assume $\theta = 1$ throughout.

We begin by defining the discretized problem, where we employ continuous and piecewise linear transformations $\tau_h$, that thus preserve the finite element spaces and the polygonal/polyhedral nature of the discrete reference domain $U_{r,h}$.

\begin{pb}[Discrete shape optimization problem]
\label{pb:discr_shopt}
Given a polygonal/polyhedral reference domain $U_{r,h}$ and transformations $\tau_h$, vector valued finite element fields that are the identity on $\Gamma_{m,h}$ and with small enough $W^{1,\infty}$ norm, so as to keep $U_{r,h}$ bounded Lipschitz and preserve the mesh quality, we solve:

$$\inf_{\tau_h }\frac{\delta t}{2}\sum_{k=1}^{K}\norm{v_h^k-w^k_h}_{L^2(\tau_h(U_{r,h}))}^2=:J_{h,\delta t}(\tau_h)$$


where $v_h^k, w^k_h$ are defined in \cref{pb:num_scheme_recall}, and their dependence on $\tau_h$ is not highlited in the notation.

\end{pb}

At this level, for simplicity, but also for the sake of generality, we work with again with arbitrary vector fields in place of radial fields.

\begin{prop}[Discrete shape gradient]
\label{prop:discrete_shape_gradient}
The discrete shape gradient of \cref{pb:discr_shopt} is:

\begin{align*}
	J_{h,\delta t}'(\tau_h)[\delta \theta_h] =\\
	\delta t \sum_{k=1}^{K} \left (\frac{w_h^{k}-w_h^{k-1}}{\delta t}, \dive(\delta \theta_h \circ \tau_h^{-1}) q_h^{k-1} \right )_{L^2(\tau_h(U_{r,h}))} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h \circ \tau_h^{-1}) \nabla w_h^k, \nabla q_h^{k-1})_{L^2(\tau_h(U_{r,h}))}+\\
	\delta t \sum_{k=1}^{K} \left (\frac{v_h^{k}-v_h^{k-1}}{\delta t}, \dive(\delta \theta_h \circ \tau_h^{-1}) p_h^{k-1} \right )_{L^2(\tau_h(U_{r,h}))} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h \circ \tau_h^{-1}) \nabla v_h^k, \nabla p_h^{k-1})_{L^2(\tau_h(U_{r,h}))}+\\
	\frac{\delta t}{2} \sum_{k=1}^{K} \int_{\tau_h(U_{r,h})} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h \circ \tau_h^{-1})
\end{align*}

Again, we dropped the dependence of $v,w$ on $\tau_h$, for simplicity. Here, the discretized adjoint states satisfy:

\begin{pb}[]

\begin{align*}
	\left ( \frac{p_h^{k-1}-p_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla p_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} + \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	p_h^k = 0 \text{ on }  \tau_h (\partial U_{h,r}), \quad 1\leq k \leq K\\
	p_h^K=0 
\end{align*}

and 

\begin{align*}
	\left ( \frac{q_h^{k-1}-q_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla q_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} - \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	q_h^k = 0 \text{ on } \tau_h (\Gamma_{D_h,r}), \quad 1\leq k \leq K\\
	q_h^K=0 
\end{align*}

The test functions are zero on the entire boundary for the equation of $p_{h}^k$, and only on the moving boundary for $q_h^k$.

\end{pb}

\end{prop}

\begin{mproof}[Sketch of proof]

We give a sketch of a proof, only to justify the time indices that appear in the expressions of the adjoint equations. For a rigorous proof one could adopt the same techniques employed in the continuous case. For simplicity we decide here to make use of the method proposed in and \cite{lindemann2}, section 4 (or more generally, \cite{lindemann}), to which we refer, for additional details: it is worth noting that such method can be fully justified, and that we numerically verified the correctness of such derivation.

To this end, we form a discretized Lagrangian just like in \cref{prop:lagr}, were integrals are replaced by Riemann sums (evaluated at the end of the time sub-intervals), and derivatives by difference quotients.

Since we have $v_h^0=w_h^0=0$ we can slighlty simplify the procedure to obtain the discretized adjoints (that are exact on a discrete level): we only need to differentiate such Lagrangian by $v_h^k, w_h^k$, $k=1,...,K$. 

In doing so, we obtain the following scheme, for e.g. $p_h^k$:

\begin{align*}
	\left ( \frac{p_h^{k-1}-p_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla p_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} + \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	p_h^k = 0 \text{ on } \partial \tau_h (U_{h,r}), \quad 1\leq k \leq K\\
	p_h^K=0 
\end{align*}

where we test by $v_h \in S^1_{h,0}$. For now, the time indices are only suggestive notation. However, note that by applying implicit Euler to the time reversed $p$, this is exactly the \cref{pb:num_scheme} applied to the equation of $p$, modulo a time shift in the right hand side: we thus obtain an implicit method, with an "explicit" right hand side $\eta(t^k)(v_h^k-w_h^k)$.

Therefore $p_h^k$ is an approximation of  $p(t^k)$, and we will later quantify this assertion.

Also note, it is important that $\tau_h$ is piecewise linear on the discretization, and continous, so that finite element functions remain finite element functions after an application of $\tau_h$, and the geometry remains of polygonal/polyhedral nature. See again \cite{lindemann2} for further details on this matter.
\end{mproof}

\begin{obs}[$\tau$ and $\tau_h$]
\label{obs:tau_vs_tau_h}
\mbox{}\\
Throughout the rest of the section, we won't try to take into account the fact that the reference domains $U_r$ and and $U_{r,h}$ are changing under the actions of $\tau$ and $\tau_h$. It means that the estimates are $\tau, \tau_h$ dependent. Therefore we will fix $U = \tau(U_r)$ and $U_h=\tau_h(U_{r,h})$ once and for all. \mbox{}\\


Remember that \cref{ass:num_discr_shopt} must hold, which implies a specific form of $\tau_h$, i.e. that it must interpolate $\tau$. We refrain from generalizing the estimate to more arbitrary $\tau_h$, and we note that our result may be a first step of a more general argument (just like in finite element error estimates, the error between exact and discretized solution is decomposed into two parts by the introduction of a suitable interpolant). \mbox{}\\

This is in any case a novelty with respect to e.g. \cite{paganini}, where similar estimates to the ones we are up to derive, and in which $H^2$ regularity is asked on non-convex polygonal domains. \mbox{}\\
\end{obs}

We now give a quantitative estimate on the approximation power of the discrete adjoints we just obtained. This is needed, because the scheme they satisfy is not exactly the implicit Euler treated in \cref{prop:o-t-d}.

\begin{prop}[Error estimates for adjoint states]
\label{prop:d-t-o_estimates}
The adjoints satisfy the same asymptotic, optimal order error estimates of \cref{prop:o-t-d}, under the same assumptions (with $\theta = 1$).
\end{prop}

\begin{mproof}
The proof is exactly that of \cref{prop:o-t-d}. The only difference comes from the fact that the right hand sides of the adjoints are not "correct", i.e. they are shifted by $\delta t$. But this is not an issue, as we shall now show. 

We see that we only need to show a bound of  $\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})u_h(t^{k-1})-\eta(t^k)u_h^{k}}^2_{L^2(U_h)}$, where $u$ denotes the generic state corresponding state to the generic adjoint $a$ (this is the same notation as in the proof of \cref{prop:o-t-d}), $U_h=\tau_h(U_{r,h})$.

Applying the triangle inequality and using again the proof of \cref{prop:o-t-d}, we see that we actually only need to bound the term:

\begin{align*}
\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})u_h(t^{k-1})-\eta(t^k)u_h^k}^2_{L^2(U_h)}\lesssim\\
\underbrace{\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})(u_h(t^{k-1})-u_h(t^{k}))}^2_{L^2(U_h)}}_{\circled{1}}+
\underbrace{\delta t \sum_{k=1}^{K}\norm{(\eta(t^{k-1})-\eta(t^k))u_h(t^{k})}^2_{L^2(U_h)}}_{\circled{2}}+
\underbrace{\delta t \sum_{k=1}^{K}\norm{\eta(t^k)(u_h^k-u_h(t^k)))}^2_{L^2(U_h)}}_{\circled{3}}
\end{align*}

There holds $\ds  \circled{2} \leq \norm{\eta'}_\infty^2 \delta t^3 \sum_{k=1}^{K}\norm{u_h(t^{k})}^2_{L^2(U_h)}$. Call $\pi u_h := u_h(t^{k})$ for $t \in (t^k, t^{k+1})$. By \cref{lemma:pw_constant_appr} we see that, for $\delta t $ small enough, one has $\norm{\pi u_h}_{L^2(I, L^2(U_h))} \lesssim \delta t \norm{u_h'}_{L^2(I,L^2(U_h))}$. This yields:

\begin{align*}
	 \ds  \circled{2}\leq \norm{\eta'}_\infty^2 \delta t^3 \sum_{k=1}^{K}\norm{u_h(t^{k})}^2_{L^2(U_h)}  = \norm{\eta'}_\infty^2 \delta t^2 \int_I \norm{\pi_h u_h}^2_{L^2(U_h)}\lesssim \delta t^2 \norm{u_h'}_{L^2(I,L^2(U_h))}^2 \norm{\eta'}_\infty ^2
\end{align*}

On the other hand,  $\ds  \circled{1} \leq \norm{\eta}_\infty^2 \delta t \sum_{k=1}^{K}\norm{u_h(t^{k-1})-u_h(t^{k})}^2_{L^2(U_h)}$, and with a similar reasoning as in the proof of \cref{lemma:pw_constant_appr}, we conclude $\ds \circled{1} \leq \norm{\eta}_\infty^2 \delta t \sum_{k=1}^{K} \delta t \int_{I_k}\norm{u_h'}_{L^2(I_k , L^2(U_h))}^2$.

In both cases, $\norm{u_h'}_{L^2(I,L^2(U_h))}^2$ can be bounded uniformly with respect to $h$ (and $\delta t$), by energy estimates (see e.g. \cref{cor:L2_deriv_est}).

Note, it is clear from this estimate that a very steep $\eta$ will yield higher discretization errors.

Finally, by \cref{prop:d_vd_sd} (which we can apply by \cref{ass:num_discr_shopt}), we obtain $\ds \circled{3} \lesssim (h^2+\delta t)\norm{\eta}_\infty^2 $.

%This $O(\delta t^{2/\theta})$ by \cref{prop:d_vd_sd} and the above reasonings ($D=D(u)=0$, $C=C(u)$ is bounded uniformly).
\end{mproof}

\begin{obs}[Optimization and discretization commute]
\mbox{}\\
Optimization and discretization commute, in the case of $\theta=1$. In fact, we could have started from the continuous states and adjoint (see \cref{pb:pdes} and \cref{prop:gateaux_diff}), applied the scheme of \cref{pb:num_scheme_recall} to the states and the perturbed implicit Euler method of \cref{prop:discrete_shape_gradient} for the adjoints (which is a "legitimate" scheme, as we have just shown in \cref{prop:d-t-o_estimates}) to obtain exactly the same discrete quantities (states and adjoints).\mbox{}\\
With a diagram:

\[\begin{tikzcd}
	&&& \text{\cref{prop:gateaux_diff}} \\
	\text{\cref{pb:shopt}} &&&&&& \text{\cref{prop:discrete_shape_gradient}}  \\
	&&& \text{\cref{pb:discr_shopt}} 
	\arrow["{\text{optimization}}"', from=3-4, to=2-7]
	\arrow["{\text{discretization}}", from=1-4, to=2-7]
	\arrow["{\text{optimization}}", from=2-1, to=1-4]
	\arrow["{\text{discretization}}"', from=2-1, to=3-4]
\end{tikzcd}\]


\end{obs}


Before studying how well the discrete gradient approximates the continuous gradient, we need some additional error bounds for the state discretization. This is not strictly necessary: we do so to relax the smoothness requirements on the deformation field $\delta \theta$ in the upcoming arguments. This however entails assuming stronger compatibility relations for the state equations. From the physical point of view, this is not an issue: the state equations, unlike the adjoint ones, coming from a physical process, should naturally satisfy such compatibility. 

The following proposition is proven in this section, applied to our concrete (state) equations. The proof also applies to the general case, of course, under suitable assumptions.

\begin{prop}[Another bound on the state discretization]
\label{prop:another_bound}
There holds, under \cref{ass:num_discr_shopt}, the following error estimates:

\begin{align*}
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}\lesssim h + \delta t
\end{align*}

\end{prop}

\begin{mproof}
We again apply a separation into semidiscretization in space, and then full discretization, and adopt the notation $u$ to represent either one of the two state variables.

\underline{Estimating $Q_h^k$ in the $L^2$ norm}

Going to the proof of \cref{prop:d_vd_sd}, let us bound $Q_h^k$ in the stronger $L^2$ norm. There holds (also see \cite{quarteroni}, page 388):

\begin{align*}
	Q_h^k = -\frac{1}{\delta t}\int_{I_k}(s-t^k)u''_h(s)ds
\end{align*}

From here, $\norm{Q_h^k}_{L^2(U_h)}^2\leq \delta t \norm{u_h''}_{L^2(I_k,{L^2(U_h)})}^2$, by an application of the Cauchy-Schwarz inequality. 

Therefore, $\delta t \sum_{k=0}^{K-1} \norm{Q_h^k}_{L^2(U_h)}^2\leq \delta t^2 \norm{u_h''}_{L^2(I,{L^2(U_h)})}^2$. The latter norm can be bounded uniformly on $h$, thanks to \cref{ass:num_discr_shopt} and the reasoning of \cref{thm:const_track}. Note, we need here the stronger compatibility condition that $\delta_h'(0)$ is bounded in $H^1$, see \cref{prop:d_vd_sd} for the notation. In the current concrete case, $\delta_h'(0) = 0$ and this is thus not an issue.

\underline{Semidiscrete bound}

Consider \cref{eqn:discr_err}, where we remind that $e_h^k = u_h^k-u_h(t^k)$. We can test it by $\ds \frac{e_h^{k+1}-e_h^k}{\delta t}$ to obtain:

\begin{align*}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, \frac{e_{h}^{k+1}-e_h^k}{\delta t}\right)_{L^2(U_h)} + a_h \left (e_h^{k+1}, \frac{e_{h}^{k+1}-e_h^k}{\delta t} \right ) = \left ( Q_h^k,\frac{e_{h}^{k+1}-e_h^k}{\delta t}\right)_{L^2(U_h)}
\end{align*}

Hence, employing Young and Cauchy-Schwarz inequalities, we find:

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2 + \frac{1}{2\delta t}\left (\norm{\nabla e_h^{k+1}}^2_{L^2(U_h)} - \norm{\nabla e_h^k}^2_{L^2(U_h)}\right)\leq  \norm{Q_h^k}_{L^2(U_h)} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}
\end{align*}

Passing to summations, because $e_h^0=0$ and by the Cauchy-Schwarz inequality:

%\begin{align*}
%\delta t \sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2 \leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{L^2(U_h)}^2}\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2}
%\end{align*}
%
%This means that:

\begin{align*}
\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2} \leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{L^2(U_h)}^2} \lesssim \delta t
\end{align*}

where we used the first part of the proof.

\underline{Fully discrete bound}

We have, denoting with $(\cdot)^l$ the lifting of finite element functions defined in \cref{prop:G_h}, and using \cref{prop:lift} itself:

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2\lesssim \delta t \sum_{k=0}^{K-1} \norm{\frac{e(t^{k+1})-e(t^k)}{\delta t}}_{L^2(U)}^2 +  \delta t \sum_{k=0}^{K-1} \norm{\frac{e_h^{k+1}-e_h^{k}}{\delta t}}_{L^2(U_h)}^2
\end{align*}

The second term on the right is $O(\delta t^2)$ by above, so that we need to concentrate only on the first one, where $e=u-u_h^l$. But by a suitable modification of Lemma 3.2 of \cite{lshou}, we can reason as follows:

\begin{align*}
\delta t \sum_{k=0}^{K-1} \norm{\frac{e(t^{k+1})-e(t^k)}{\delta t}}_{L^2(U)}^2 = \delta t \sum_{k=0}^{K-1} \norm{\frac{1}{\delta t}\int_{I_k}e'}_{L^2(U)}^2\lesssim \norm{e'}_{L^2(I,L^2(U))}^2\lesssim h^2
\end{align*}

by \cref{cor:L2_deriv_est} and \cref{ass:num_discr_shopt}.
\end{mproof}

\begin{thm}[Fully discrete estimate for shape gradients, implicit Euler case]
\label{thm:ie_shape_grad_est}
Let  $U$ be fixed and $U_h$ as in \cref{ass:num_discr_shopt}. The same assumption must hold. Let $\delta \te \in W^{1,\infty}(U)$ and $\delta \te_h$ be a vector valued finite element function of $S^1_h=S^1_h(U_h)$. There exists a constant $\gamma$ that depends on $U$, the shape regularity and quasi-uniformity of the meshes, independent of $h, \delta t$, such that, for $h,\delta t$ small enough, we have:

\begin{align*}
|dJ(	U)[\delta \te]-dJ_{h,\delta t}(U_h)[\delta \te_h]|\leq \gamma\left [ (h+\delta t)(\norm{\delta \te}_{W^{1,\infty}(U)}+\norm{\delta \te_h}_{W^{1,\infty}(U_h)}) + \norm{\delta \te - \delta \te_h^l}_{W^{1,\infty}(U)}\right ]
\end{align*}

where the notation $dJ(U)[\delta \te]:=dJ(\tau)[\delta \te\circ \tau]$, if $U=\tau(U_r)$, is to emphasize that the dependence on $\tau$ is not tracked.
Analogously $dJ_{h,\delta t}(U_h)[\delta \te]:=dJ_{h,\delta t}(\tau_h)[\delta \te_h\circ \tau]$, with $U_h = \tau_h(U_{r,h})$ and a suitable $\tau_h$ that(linearly) interpolates $\tau$ on the spatial discretization nodes.

\end{thm}
\begin{mproof}

\underline{Forewarning}

As we have already mentioned in \cref{obs:tau_vs_tau_h}, we consider $U, U_h$ to be frozen in our estimate, and we assume $U_h$ to be interpolating $U$, as in \cref{ass:num_discr_shopt}. For simplicity, we are also considering $\delta \theta$ and $\delta \theta_h$ to be defined on the moving domain. We again recover the notation $u, a$ to indicate a state and its correspondent adjoint (so, $u=v \iff a = p$ or $u=w \iff a = q$). Therefore, the quantities to be compared become, thanks to \cref{prop:gateaux_diff} and \cref{prop:discrete_shape_gradient}:
%
%\begin{align*}
%	\delta t \sum_{k=1}^{K} \left (\frac{w_h^{k}-w_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) q_h^{k-1} \right )_{L^2(U_h)} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla w_h^k, \nabla q_h^{k-1})_{L^2(U_h)}+\\
%	\delta t \sum_{k=1}^{K} \left (\frac{v_h^{k}-v_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) p_h^{k-1} \right )_{L^2(U_h)} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h) \nabla v_h^k, \nabla p_h^{k-1})_{L^2(U_h)}+\\
%	\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h )\\
%\end{align*}
%
%and
%
%\begin{align*}
%	\int_I (w_t \dive(\delta \te), q)_{L^2(U)}+ \int_I (A'(\delta\te )\nabla v, \nabla p)_{L^2(U)}+\\
%\int_I (v_t\dive(\delta \te), p)_{L^2(U)}+ \int_I (A'(\delta\te )\nabla w, \nabla q)_{L^2(U)}+\\
%\frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te)
%\end{align*}
%
%To make a fair comparison we also need to have $\delta \te $ and $\delta \te_h$ to be somewhat related. We will discuss in the end some possible choices.
%
%\underline{Splitting into pieces}

%We separately bound the five pieces, which, if we again recover the notation $u, a$ to indicate a state and its correspondent adjoint (so, $u=v \iff a = p$ or $u=w \iff a = q$), means to find bounds just for the following three quantities:

\begin{align*}
	\circled{$\partial$}:=\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}  - \int_I (u_t , \dive(\delta \te) a)_{L^2(U)}
\end{align*}

\begin{align*}
	\circled{$\nabla$} := \delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)}
\end{align*}

\begin{align*}
	\circled{J}:=\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te)
\end{align*}

\underline{Derivatives: rewriting}

Denote again by $\pi a = a(t^k)$ on $(t^k,t^{k+1})$. Then:

\begin{align*}
	\circled{$\partial$}=\underbrace{- \int_I (u_t , \dive(\delta \te) (a -\pi a))_{L^2(U)}}_{\circled{1}}+ \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)} - \int_I (u_t , \dive(\delta \te) \pi a)_{L^2(U)}}_{\circled{R1}}
\end{align*}

Now:

\begin{align*}
	\circled{R1} = \delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)} - \delta t \sum_{k=1}^{K}\left (\frac{u(t^{k})-u(t^{k-1})}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}=\\
\underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u(t^{k})-u(t^{k-1})}{\delta t} -\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}}_{\circled{2}}+\\ \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}}_{\circled{R2}} 
\end{align*}

Lastly:

\begin{align*}
	\circled{R2} = \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}
		- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te_h^l)  a_h^{k-1,l}\right )_{L^2(U)} }_{\circled{3}}+ \\
	\underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , (\dive(\delta \te) - \dive(\delta \te_h^l)  )a_h^{k-1,l}\right )_{L^2(U)}}_{\circled{4}} + \underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te) \left(a(t^{k-1})-a_h^{k-1,l}\right)\right )_{L^2(U)}}_{\circled{5}}
\end{align*}

\underline{Derivatives: estimation}

We start with $\circled{1},\circled{2},\circled{5}$.

We have, by the Cauchy-Schwarz inequality and \cref{lemma:pw_constant_appr}:

\begin{align*}
\left |\circled{1}\right|\leq \delta t \norm{\dive(\delta \te)}_{L^\infty(U)}\norm{u_t}_{L^2(I,L^2(U))}\norm{a'}_{L^2(I,L^2(U))}\lesssim \delta t \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

Then, using again the Cauchy-Schwarz inequality:

\begin{align*}
\left |\circled{2}\right|\leq \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t \sum_{k=0}^{K-1} \norm{a(t^k)}^2_{L^2(U)}}\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}
\end{align*}

Employing \cref{prop:another_bound} at first, and \cref{lemma:pw_constant_appr} afterwards:

\begin{align*}
\left |\circled{2}\right|\lesssim (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\sum_{k=0}^{K-1} \int_{I_k}\norm{a(t^k)}^2_{L^2(U)}}\lesssim (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)} \norm{a'}_{L^2(I,L^2(U))}\lesssim  (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

Note, this is where we used \cref{prop:another_bound}. One could alternatively assume higher differentiability for $\theta$ and proceed with \cref{prop:o-t-d}.

Then:

\begin{align*}
	\left |\circled{5}\right|\leq  \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t\sum_{k=0}^{K-1} \norm{\frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}\sqrt{\delta t\sum_{k=0}^{K-1} \norm{a(t^{k})-a_h^{k,l}}_{L^2(U)}^2}
\end{align*}

Thanks to \cref{prop:d-t-o_estimates} we can write:

\begin{align*}
	\left |\circled{5}\right|\lesssim (h^2+\delta t)  \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t\sum_{k=0}^{K-1} \norm{\frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}
\end{align*}

Using \cref{prop:another_bound} and the last step of its proof:

\begin{align*}
	\left |\circled{5}\right|\lesssim (h^2+\delta t)  \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

And with similar reasonings:
\begin{align*}
	\left |\circled{4}\right|\lesssim \norm{\dive(\delta \te) - \dive(\delta \te_h^l)}_{L^\infty(U)}
\end{align*}

Member $\circled{3}$ can be bound with the help of \cref{prop:lin_appr}.

\underline{Gradients: rewriting}

We have:

\begin{align*}
	\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)} = \\
	\underbrace{\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)}- \int_I (A'(\delta\te )\nabla\tilde{\pi}u, \nabla \pi a)_{L^2(U)}}_{\circled{R3}} + \\\underbrace{- \int_I (A'(\delta\te )\nabla u, \nabla (a-\pi a))_{L^2(U)}}_{\circled{6}}\underbrace{- \int_I (A'(\delta\te )\nabla (u - \tilde{\pi}u), \nabla \pi a)_{L^2(U)}}_{\circled{7}} 
\end{align*}

Continuing the splitting:

\begin{align*}
\circled{R3} = \delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla u(t^{k}) , \nabla a(t^{k-1}))_{L^2(U)} = \\
\underbrace{\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \delta t \sum_{k=1}^{K} (A'(\delta\te_h^l )\nabla u_h^{k,l} , \nabla a_h^{k-1,l})_{L^2(U)}}_{\circled{8}}+
- \underbrace{\delta t \sum_{k=1}^{K} ((A'(\delta \te) - A'(\delta\te_h^l ))\nabla u_h^{k,l} , \nabla a_h^{k-1,l})_{L^2(U)}}_{\circled{9}}+\\
- \underbrace{\delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla (u(t^{k})-u_h^{k,l}) , \nabla a(t^{k-1}))_{L^2(U)}}_{\circled{10}}+
- \underbrace{\delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla u_h^{k,l} , \nabla (a(t^{k-1}) -a_h^{k-1,l}))_{L^2(U)}}_{\circled{11}}
\end{align*}
\underline{Gradients: estimation}

The terms $\circled{10}, \circled{11}$ can be estimated in a common way. We only need to make sure that $\ds \delta t \sum_{k=1}^{K} \norm{\nabla u_h^{k,l}}_{L^2(U)}^2 $ is bounded uniformly (true by \cref{prop:o-t-d}, \cref{lemma:pw_constant_appr} and the smoothness of $u$, ensured by \cref{ass:num_discr_shopt}), and also that $\ds \delta t \sum_{k=1}^{K} \norm{\nabla a(t^{k-1})}_{L^2(U)}^2$ is uniformly bounded (true by \cref{lemma:pw_constant_appr} and the smoothness of $a$, ensured by \cref{ass:num_discr_shopt}). Then an application of the Cauchy-Schwarz inequality, \cref{prop:d-t-o_estimates} and \cref{prop:o-t-d} yield:

\begin{align*}
	\left | \circled{10} \right |, \left |\circled{11}\right | \lesssim (h+\delta t) \norm{A'(\delta \te)}_{L^\infty(U)}
\end{align*}

Similarly:

\begin{align*}
	\left | \circled{9} \right | \lesssim (h+\delta t) \norm{A'(\delta \te_h^l)-A'(\delta \te)}_{L^\infty(U)}
\end{align*}

and the term $\circled{8}$ follows directly from \cref{prop:lin_appr}.

\underline{Cost functions: estimation}

We are missing a bound on: 

\begin{align*}
	\circled{J}:=\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te) = \\
	\underbrace{\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te_h^l)}_{\circled{R4}}+
	-\underbrace{ \frac{1}{2}\int_I\int_{U}\eta |v-w|^2(\dive(\delta \te) - \dive(\delta \te_h^l))}_{\circled{12}}
\end{align*}

We find:

\begin{align*}
	\left | \circled{12} \right | \lesssim \norm{\dive(\delta \te) - \dive(\delta \te_h^l)}_{L^\infty(U)}
\end{align*}

whereas:

\begin{align*}
\circled{R4} =\underbrace{ \frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{\delta t}{2} \sum_{k=1}^{K}\int_{U} \eta(t^k) |v_h^{k,l}-w_h^{k,l}|^2\dive(\delta \te_h^l)}_{\circled{13}}+\\
\underbrace{\frac{\delta t}{2} \sum_{k=1}^{K}\int_{U} \eta(t^k) (|v_h^{k,l}-w_h^{k,l}|^2- |v(t^k)-w(t^k)|^2)\dive(\delta \te_h^l)}_{\circled{14}}+
\underbrace{\frac{1}{2}\int_I\int_{U}\tilde{\pi} \eta (|\tilde{\pi} v-\tilde{\pi} w|^2-|v-w|^2)\dive(\delta \te_h^l)}_{\circled{15}}+
\underbrace{\frac{1}{2}\int_I\int_{U}(\tilde{\pi} \eta - \eta) |v-w|^2\dive(\delta \te_h^l)}_{\circled{16}}
\end{align*}

For $\circled{16}$ we can use the fact that that $\norm{\eta -\tilde{\pi} \eta}_\infty\leq \delta t \norm{\eta'}_\infty$ to ensure that:

\begin{align*}
	\left | \circled{16} \right |\lesssim \delta t \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

Similarly, also by applying the Cauchy-Schwarz' inequality and \cref{lemma:pw_constant_appr}:

\begin{align*}
	\left | \circled{15} \right |\lesssim  \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)} (\norm{v-\tilde{\pi} v}_{L^2(I,L^2(U))}+\norm{w-\tilde{\pi} w}_{L^2(I,L^2(U))})\lesssim \delta t \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

The Cauchy-Schwarz' inequality also yields:
\begin{align*}
	\left | \circled{14} \right | \lesssim \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}(E_v+E_w)(S_v+S_w)
\end{align*}

where $\ds E_u = \sqrt{\delta t \sum_{k=1}^{K}\norm{u(t^k)-u_h^{k,l}}_{L^2(U)}^2}$ and $\ds S_u = \sqrt{\delta t \sum_{k=1}^{K}\norm{u(t^k)+u_h^{k,l}}_{L^2(U)}^2} $.

Through \cref{prop:o-t-d} we find $E_u \lesssim \delta t + h^2$, whereas \cref{prop:o-t-d} combined with \cref{lemma:pw_constant_appr} yield $S_u \lesssim 1$, so that:

\begin{align*}
	\left | \circled{14} \right | \lesssim (\delta t + h^2)\norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}


Similarly, and reasoning as in \cref{prop:lin_appr}, we can also see that:

\begin{align*}
	\left | \circled{13} \right | \lesssim h \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

This concludes the proof.
\end{mproof}

Upon choosing $\delta \te = \delta \te_h^l$ we easily obtain the following corollary.

\begin{cor}
\label{cor:ie_shape_grad_est}

With the same hypothesis and notation of \cref{thm:ie_shape_grad_est}:

\begin{align*}
|dJ(	U)[\delta \te_h^l]-dJ_{h,\delta t}(U_h)[\delta \te_h]|\leq \gamma (h+\delta t)\norm{\delta \te_h}_{W^{1,\infty}(U_h)}
\end{align*}

\end{cor}

With this, similar estimates to those in \cite{paganini} were derived, in a slightly different context: in a time-dependent setting, and a precise handling of the geometry error. However, in \cite{paganini}, order $2$ estimates (in space) are obtained instead: this is because the deformation field $\delta \te$ is assumed to have an additional order of differentiability, so that certain duality techniques may be employed. Such a result doesn't fully explain why superconvergence happens in the context of just $W^{1,\infty}$ displacements. It is however a strong hint for the realization of such phenomenon, which is indeed observable in practice (see again the experiments in \cite{paganini}). In the next section we obtain similar superconvergence estimates, in our setting.


\section{Approximation of shape gradient, superconvergence for spatial semidiscretization}
\label{sec:superconv}

We now show that for smooth displacement fields $\delta \te$ that vanish in a neighbourhood of the fixed boundary, a superconvergence result for the shape gradient is available, in the spirit of \cite{paganini}. Such "compact support" assumption is not very strong in our setting: admissible displacements must already be zero at the fixed boundary, so as to yield a transformation that preserves $\Gamma_f$.

This result, in turn, is shown initially only for the spatial semidiscretization, which however suggests that such a result may be available also in the fully discrete case. This is also confirmed by the experiments in \ref{sec:experiments}, in both cases. We are able to give theoretical justification for the implicit Euler scheme.

The difference with the estimates of \cite{paganini} lies in the fact that we are explicitly taking into account the geometry discrepancy $U \neq U_h$ (in the special case that $U_h$ interpolates $U$), apart from the time dependent setting we are in.

Such estimates, as noted in \cite{paganini}, don't seem to be so easily obtainable for displacements $\delta \te \in W^{1,\infty}$ only.

Let us briefly briefly introduce the semidiscretized shape optimization problem, and its shape gradient.

\begin{prop}[Semidiscrete shape optimization problem]
\label{prop:sd_shopt}
We introduce the spatially semidiscrete state equation, with unified notation $u_h$, similarly to \cref{pb:num_scheme_recall}. Calling $g_{N,h}$ and $g_{D,h}$ the Lagrange interpolants (defined a.e. in time) of $g_N, g_D$, we define $u_h:I \rightarrow S^1_h$ as:
\begin{align*}
\left ( u_h', v_h\right)_{L^2(U_h)} + (\nabla u_h, \nabla v_h)_{L^2(U_h)} = (g_{N,h} , v_h)_{L^2(\Gamma_{N_h})}, \quad \text{for a.e. } t \in I\\
u_h|_{\Sigma_{D_h}}=g_{D,h}\\
u_h(0)=0
\end{align*}

and $v_h \in S^1_{h,0,D_h}$. This is an instance of \cref{pb:inh_parabolic_discr}, to which we refer for further details. The shape optimization problem is to find $\tau_h$, a vector valued finite element field that is the identity on $\Gamma_{m,h}$ and with small enough $W^{1,\infty}$ norm, so as to keep $U_{r,h}$ bounded Lipschitz and preserve the mesh quality, minimizing:

$$J_h(\tau_h)=\int_I\int_{\tau_h(U_{r,h})}\eta |v_h-w_h|^2$$

The adjoint state $a_h:I \rightarrow S^1_h$ to $u_h$ is:
\begin{align*}
-\left ( a_h', v_h\right)_{L^2(U_h)} + (\nabla a_h, \nabla v_h)_{L^2(U_h)} = (-1)^{\left [ u_h=v_h\right ]}\eta(v_h-w_h), \quad \text{for a.e. } t \in I\\
a_h|_{\Sigma_{D_h}}=0\\
a_h(T)=0
\end{align*}

and the semidiscrete shape gradient in direction $\delta \te_h$ (a vector valued finite element field that is zero on $\Gamma_{m,h}$) reads:

\begin{align*} 
	dJ_h(\tau_h)[\delta \te_h] =\\ \int_I (w_h' \dive(\delta \te_h\circ  \tau_h^{-1}), q_h )_{L^2(\tau_h(U_{r,h}))}+ \int_I (A'(\delta\te_h \circ \tau_h^{-1})\nabla v_h, \nabla p_h)_{L^2(\tau_h(U_{r,h}))}+\\
\int_I (v_h' \dive(\delta \te_h\circ  \tau_h^{-1}), p_h )_{L^2(\tau_h(U_{r,h}))}+ \int_I (A'(\delta\te_h \circ \tau_h^{-1})\nabla w_h, \nabla q_h)_{L^2(\tau_h(U_{r,h}))}+\\
\frac{1}{2}\int_I\int_{\tau(U_{r,h})}|v_h-w_h|^2\dive(\delta \te_h\circ  \tau_h^{-1})
\end{align*}

\end{prop}

\begin{mproof}
We skip it, it can be done similarly to \cref{prop:gateaux_diff} or \cref{prop:discrete_shape_gradient}.
\end{mproof}

\begin{thm}[Superconvergence result for shape gradients, spatially semidiscrete case]
\label{thm:superconvergence_sd}
Let $U$ be fixed and $U_h$ as in \cref{ass:num_discr_shopt}. Let \cref{ass:num_discr_shopt} itself hold, $\delta \te \in W^{2,\infty}(U)$, with $D\delta \te=0$ on the fixed boundary $\Gamma_f$. There exists a constant $\gamma$ that depends on $U$, the shape regularity and quasi-uniformity of the meshes, but independent of $h$, such that, for $h$ small enough, we have:

\begin{align*}
	\left |dJ(U)[\delta \te] - dJ_h(U_h)[\delta \te^{-l}] \right|\leq \gamma  h^2 \norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

where the notation for the shape gradients is analogous to that in \cref{thm:ie_shape_grad_est}.

\end{thm}

\begin{mproof}
The proof is similar to that of \cref{thm:ie_shape_grad_est}: we compare "derivative" terms, "gradient" terms and "cost function" terms, and use \cref{prop:lin_appr}, apart from the semidiscretization error estimates for the partial differential equations, to obtain an overall $O(h^2)$ term. We indicate $\delta \te^{-l}=:\delta \te_h$. For the expression of the semidiscretized shape gradient we make use of \cref{prop:sd_shopt}.

\underline{Derivatives}

We recover the notation $u\rightarrow$ generic state ($v$ or $w$), $a\rightarrow$ adjoint state of $u$.

We have:

\begin{align*}
	\int_I(u',a\dive(\delta \te))_{L^2(U)}-\int_I (u_h',a_h\dive(\delta \te_h))_{L^2(U_h)}=\\
	\underbrace{\int_I((u-u_h^l)',a\dive(\delta \te))_{L^2(U)}}_{\circled{1}}+
	\underbrace{\int_I((u_h')^l, (a-a_h^l)\dive(\delta \te))_{L^2(U)}}_{\circled{2}}+
	\underbrace{\int_I((u_h')^l, a_h^l\dive(\delta \te))_{L^2(U)}-\int_I (u_h',a_h\dive(\delta \te_h))_{L^2(U_h)}}_{\circled{3}}
\end{align*}

We apply \cref{cor:L2_deriv_est} to $\circled{1}$, a thing which we can do, as \cref{ass:num_discr_shopt} and by the reasonings of \cref{prop:o-t-d}, to obtain:

\begin{align*}
	\left | \circled{1} \right | \lesssim h^2\norm{\dive{\delta \theta}}_{L^\infty(U)}
\end{align*}

It is crucial here that $\te$ has two weak derivatives, so that $a\te$ is a test function, as required by \cref{cor:L2_deriv_est}. 

On the other hand, employing \cref{thm:semidiscrete_error_bound}, \cref{prop:lift} and suitable energy estimates to $u_h'$ (which are avaliable by \cref{ass:full_discr_smoothness}), we come as well to:

\begin{align*}
	\left | \circled{2} \right | \lesssim h^2\norm{\dive{\delta \theta}}_{L^\infty(U)}
\end{align*}

Employing \cref{prop:lin_appr}, and \cref{prop:lift}, we find:

\begin{align*}
	\left | \circled{3} \right |\lesssim  h^2 \norm{u_h'}_{L^2(I,H^1(U_h))}\norm{a_h}_{L^2(I,H^1(U_h))}\norm{\delta \te}_{W^{1,\infty}(U)} \lesssim  h^2 \norm{\delta \te}_{W^{1,\infty}(U)}
\end{align*}

\underline{Gradients}

We perform a suitable splitting:

\begin{align*}
	\int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)}-\int_I (A'(\delta\te_h )\nabla u_h, \nabla a_h)_{L^2(U_h)} = \\
	\underbrace{\int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla u^{-l}, \nabla a^{-l})_{L^2(U_h)}}_{\circled{4}}+\\
	\underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla a_h^l)_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla (u_h - u^{-l}), \nabla a_h)_{L^2(U_h)}}_{\circled{5}}+\\
	\underbrace{\int_I (A'(\delta\te )\nabla u, \nabla (a_h^l-a))_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla u^{-l}, \nabla (a_h-a^{-l}))_{L^2(U_h)}}_{\circled{6}}+\\
	- \underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla (a_h^l-a))_{L^2(U)}}_{\circled{7}}+
	- \underbrace{\int_I (A'(\delta\te )\nabla u, \nabla (a_h^l-a))_{L^2(U)}}_{\circled{8}}+
	- \underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla a)_{L^2(U)}}_{\circled{9}}
\end{align*}

We refer directly to \cref{prop:lin_appr} to show that $\ds |\circled{4}|\lesssim h^2\norm{\delta \te}_{W^{1,\infty}(U)}$. We also obtain, by additionally invoking \cref{prop:lift} and suitable energy estimates:

\begin{align*}
	\left | \circled{5} \right |, \left | \circled{6} \right |\lesssim h \norm{\delta \te}_{W^{1,\infty}(U)} \norm{u_h^l-u}_{L^2(I,H^1(U))},  h \norm{\delta \te}_{W^{1,\infty}(U)} \norm{a_h^l-a}_{L^2(I,H^1(U))}\lesssim h^2 \norm{\delta \te}_{W^{1,\infty}(U)}
\end{align*}

having used \cref{thm:semidiscrete_error_bound} in the last step. The same \cref{thm:semidiscrete_error_bound} is sufficient to conclude the bound $\ds \left | \circled{7} \right | \lesssim h^2 \norm{\delta \te}_{W^{1,\infty}(U)}$. The remaining terms are treated in the same way, we thus focus on $\circled{9}$. Using integration by parts \cref{thm:ibp}, the assumption on $D\delta \te$ and the fact that $u, u^l_h=0$ on the moving boundary $\Gamma_m$, we obtain:

\begin{align*}
	\left |\circled{9} \right |= \left |\int_I(\dive(A'(\delta \te)\nabla a), u_h^l-u)_{L^2(U)}\right |\lesssim h^2 \norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

where we used again \cref{thm:semidiscrete_error_bound}.

\underline{Cost function}

There holds:

\begin{align*}
	\int_I \int_U \eta |v-w|^2 \dive(\delta \te) - \int_I \int_{U_h} \eta |v_h-w_h|^2\dive(\delta \te_h)=\\
	\int_I\int_U\eta((v-v_h^l)-(w-w_h^l))((v+v_h^l)-(w+w_h^l))\dive(\delta \te) + \int_I\int_U\eta(v_h^l-w_h^l)^2\dive(\delta \te)-\int_I\int_{U_h}\eta (v_h-w_h)^2\dive(\delta \te_h)
\end{align*}

The first term is $\lesssim h^2\norm{\delta \te}_{W^{1,\infty}(U)}$ thanks to the Cauchy-Schwarz inequality and \cref{thm:semidiscrete_error_bound}, the second one because of \cref{prop:lin_appr}. This concludes the proof.
\end{mproof}

As a corollary, we can derive the same result as in \cref{thm:ie_shape_grad_est}, but with a better order of convergence in space.

\begin{cor}[Fully discrete superconvergence result]
\label{cor:superconvergence_sd_fd_IE}
With the same assumptions and notation of \cref{thm:superconvergence_sd} and in the discretize-then-optimize framework of \cref{sec:d-t-o_IE}, we can conclude:  

\begin{align*}
	\left |dJ(U)[\delta \te] - dJ_{h,\delta t}(U_h)[\delta \te^{-l}] \right|\leq \gamma  (h^2 + \delta t)\norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

\end{cor}
\begin{mproof}[Sketch of a proof]
The proof applies the same techniques as in \cref{thm:superconvergence_sd}, for what concerns the error committed by a time discretization. 
The overall argument is overall more transparent: it amounts to "inserting $dJ_h$ between $dJ$ and $dJ_{h,\delta t}$". Two pieces must then be estimated, and the first is exactly $O(h^2)$ by  \cref{thm:ie_shape_grad_est}.
The second one is $\ds dJ_h(U)[\delta \te^{-l}] - dJ_{h,\delta t}(U_h)[\delta \te^{-l}]$. Of this member, we give an appropriate splitting, where every piece is $O(\delta t)$ by the same arguments as in  \cref{thm:ie_shape_grad_est}. Let us recover the unified notation of \cref{pb:uni_state_adj}. Then:

\begin{align*}
	\int_I\int_{U_h}u_h'a_h\dive(\delta \te^{-l})-\delta t \sum_{k=1}^K \int_{U_h} \frac{u_h^k-u_h^{k-1}}{\delta t}a_h^k \dive(\delta \te^{-l})  =\\
	\int_I\int_{U_h}u_h'(a_h-\pi a_h)\dive(\delta \te^{-l})+
	\delta t \sum_{k=1}^K\int_{U_h}\frac{u_h(t^k)-u_h(t^{k-1})}{\delta t}(a_h(t^k)-a_h^k)\dive(\delta \te^{-l})+\\
	\delta t \sum_{k=1}^K \int_{U_h} \left (\frac{u_h(t^k)-u_h(t^{k-1})}{\delta t}-\frac{u_h^k-u_h^{k-1}}{\delta t}\right )a_h^k \dive(\delta \te^{-l})
\end{align*}

and:

\begin{align*}
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla u_h)\nabla a_h - \delta t \sum_{k=1}^K (A'(\delta \te^{-l})\nabla u_h^k)\nabla a_h^{k-1} =  \\
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla (u_h-\tilde{\pi} u_h)\nabla a_h + 
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla \tilde{\pi} u_h ) \nabla (a_h - \pi a_h) +\\
	\delta t \sum_{k=1}^K \int_{U_h} (A'(\delta \te^{-l})\nabla u_h(t^k) ) \nabla( a_h(t^{k-1})-a_h^{k-1}) +
	\delta t \sum_{k=1}^K \int_{U_h} (A'(\delta \te^{-l})\nabla (u_h(t^k)-u_h^k ) \nabla a_h^{k-1}
\end{align*}

Finally:

\begin{align*}
	\frac{1}{2} \int_I \int_{U_h} \eta |v_h-w_h|^2\dive(\delta \te^{-l}) - \frac{1}{2} \sum_{k=1}^K \int_{U_h}\eta(t^k)(v_h^k-w_h^k)^2\dive(\delta \te^{-l}) = \\
	\frac{1}{2} \int_I \int_{U_h} (\eta-\tilde{\pi}\eta) |v_h-w_h|^2\dive(\delta \te^{-l})+
	\frac{1}{2} \int_I \int_{U_h} \tilde{\pi} \eta (|v_h-w_h|^2 - |\tilde{\pi} v_h-\tilde{\pi}w_h|^2)\dive(\delta \te^{-l})+\\
	\frac{1}{2} \sum_{k=1}^K \int_{U_h}\eta(t^k)((v_h(t^k)-w_h(t^k))^2-(v_h^k-w_h^k)^2)\dive(\delta \te^{-l})
\end{align*}

Each of the pieces above is $O(\delta t)$, so that the conclusion follows.
\end{mproof}

\chapter{Implementation}
\label{chap:num_exp}

We now turn to discuss our implementation and to verify some of the results that were previosly shown:

\begin{itemize}
	\item \cref{sec:implementation} is devoted to the illustration of the computer implementation of the shape optimization problem, \cref{pb:diri}
	\item in \cref{sec:experiments} some numerical experiments are reported, and the results are discussed and analyzed. We also verify the error estimates for the shape gradients
\end{itemize}

\section{Algorithmic set-up}
\label{sec:implementation}

We anticipate that all the experiments and the code are hosted at the \href{https://github.com/leom97/Master-s-thesis.git}{following GitHub page}: 
\begin{center}
\texttt{https://github.com/leom97/Master-s-thesis.git}.
\end{center}
We wrote our code in Python, making heavy use of the FEniCS package (\cite{fenics}). This is the main tool to simulate the partial differential equations. One of the reasons for choosing FEniCS is the compatibility with dolfin-adjoint, an automatic differentiation toolbox that "derives the discrete adjoint and tangent linear models from a forward model written in the Python interface to FEniCS" (see \cite{dolfin-adjoint_1}, \cite{dolfin-adjoint_2} and \cite{dolfin-adjoint_3}). That is, we only needed to code the "forward model" (cost functional and partial differential equations), and the gradients, that are exact on the discrete level, would be automatically derived for us by dolfin-adjoint. The correctness of the gradients was also checked through comparison with \cref{prop:discrete_shape_gradient} and through Taylor tests. In addition, for the shape optimization part, we made use of Moola, "a set of optimisation algorithms specifically designed for PDE-constrained optimisation problems" (see \href{https://github.com/funsim/moola}{here}). GMSH (\cite{gmsh}) was used for the meshing.

The shape identification problem \cref{pb:shid} lends itself very well to debugging and numerical experiments, as one can build analytical solutions and then analyize whether that is recovered by the optimization process. One can for instance artificially create the "optimal" inclusion $\Omega_e$ and come up with e.g. Neumann measurements $g$, simulate the heat equation for $w$ (see \cref{pb:pdes}) and then obtain the correct Dirichlet data $f$. Starting then from an initial guess for the inclusion and making use of $g,f$, optimization can be started: $\Omega_e$ should be recovered.

Before delving into more details, here is an overview of the different components of the shape optimization code:
\begin{enumerate}
	\item meshing the reference domain
	\item transforming the reference domain to the "optimal domain" $\Omega_e$
	\item simulating the heat equation on $\Omega_e$ with artificial Neumann data $g$, to obtain the synthetic Dirichlet data $f$
	\item running the optimization routines with $f,g$ as data
\end{enumerate}

Let us now discuss more thoroughly some of the above components.

\underline{Meshing}

We want to remark that in the meshing procedure, we started from a smooth shape modeled in GMSH, and then triangulated it into a mesh, whose boundary nodes lie on the boundary of the smooth shape, as is required in e.g. \cref{ass:num_discr_shopt} and \cref{chap:inh_fem}. Instead of choosing a base mesh and then performing (uniform) refinements on it, we loaded a sequence of meshes with increasingly finer mesh widths: after a uniform refinement, not all discrete boundary nodes need to be again on the smooth boundary. One would need to correct for this, and to do so, one would need to know a parametrization of the entire boundary. We avoided this, as we tried to use the least possible knowledge of the smooth boundary.

\begin{figure}[H]
\centering
\includegraphics[width=0.75\columnwidth]{Images/UniformRefinement.pdf}
\caption{Problems with uniform refinements}\label{fig:uniform_refinement}
\end{figure}

\underline{Star-shaped parametrization}

For simplicity, we assume that the computational domain can only undergo radial displacements of the form given in \cref{cor:star_shaped_transformation}. This is realized as follows. The reference domain is fixed to be a triangular meshing of $D\setminus \overline{B_\epsilon(0)}=:U_r$, which induces the space of linear finite elements $S^1_h$, as we have denoted it in e.g. \cref{chap:inh_fem}. Consider another meshing of the unit sphere $\mS$, potentially independent of the previous one, to allow some flexibility, inducing (surface) linear finite elements $B^1_{\tilde{h}}$. Our control, i.e. our optimization variable, will be a function $ q_{\tilde{h}} \in B^1_{\tilde{h}}$, and we would be solving:

\begin{align*}
	\min_{q_{\tilde{h}} \in B^1_{\tilde{h}}} J_{h,\delta t}(\tau_{\eps+q_{\tilde{h}}}) = J_{h,\delta t }(\id  + V_{q_{\tilde{h}}})
\end{align*}

with $V_{q_{\tilde{h}}}$ being the replacement vector field described in  \cref{cor:star_shaped_transformation}. The issue with this formulation is that  $V_{q_{\tilde{h}}}$ doesn't preserve the polygonal/polyhedral nature of the volume meshes. Therefore, we actually implement:

\begin{align*}
	\min_{q_{\tilde{h}} \in B^1_{\tilde{h}}}J_{h,\delta t }(\id  + I_h V_{q_{\tilde{h}}})
\end{align*}

where $I_h$ means Lagrange interpolation onto piecewise linears. The transformation $q_{\tilde{h}} \mapsto I_h V_{q_{\tilde{h}}}$ is implemented in a custom block in dolfin-adjoint.

\underline{Synthetic data}

As previously mentioned, to obtain the needed boundary data to perform shape optimization, we simulate the heat equation for $w$ on the exact computational domain $\Omega_{e,h}$. Because we are in a "volumetric" setting, we give the Neumann data and obtain the Dirichlet nodal values. The discrete Neumann trace need not to have an easy boundary expression, plus, we found the doing otherwise to be more complicated from a code point of view, at least with the tools at our disposal.

Using the same discretization parameters to generate the synthetic data, and then perform shape optimization, will result in committing an "inverse crime" (see \cite{wirgin}). To avoid this, there are two possibilities: either some noise is added to the synthetic data, or different computational models must be employed in synthesis and inversion/optimization. We experiment with both options, and in particular, for the second, we synthethize the data with a finer discretization than during the optimization process. We mention that in \cite{harbrecht}, synthesis and inversion are performed by solving integral equations of different kinds, but on the same discretization. The authors also add noise to the synthetic data.  

\underline{Finite elements}

We are adopting, as already mentioned, linear finite elements, for simplicity, but also computational efficiency. The framework of \cref{chap:inh_fem} can be however potentially adapted to accommodate isoparametric elements, see the works of e.g. \cite{edelmann}, \cite{elliott}, \cite{ranner}. Isoparametric elements elements are necessary, when adopting higher order basis functions, in order to preserve optimal accuracy (see section 4.4 of \cite{strang} for a discussion on this). The version of FEniCS we are using (2019.1) doesn't provide support for curved geometries, and the latest release FEniCSx is not yet interfaced with dolfin-adjoint. Alternatively, Firedrake could be employed, which has compatibility with dolfin-adjoint, although we felt it to be not flexible enough with the transfering of functions between non conforming meshes, something we needed to at several places throughout our code.

This in constrast to \cite{harbrecht}, where the authors employ order $2$ isoparametric elements (in the context of the boundary element method).

The motivation for this is that the analysis of \cite{paganini}, which we partially repeated in our setting, suggests that the volume form of the shape gradient is more accurate a boundary form. 

The main drawback of adopting a distributed setting is the added computational cost: the entire domain must be meshed, and the solution computed on interior nodes too.

\underline{Optimization}

As previously mentioned, we make use of the package Moola. This is because of its capabilities to natively handle optimization with respect to custom scalar products, and we found this to be especially important in our case, see \cref{sec:hilbert} for a theoretical justificationa and \cref{sec:experiments} for a further discussion.

We mostly experimented with an L-BFGS algorithm, but also with a modified Newton's method. We implemented the latter following the observations contained in \cite{eppler}, a work centered around a very similar shape optimization problem to ours, in an attempt to alleviate some spurious artifacts we observed, coming from the ill-posedness of the shape identification problem. We will soon discuss these aspects in \cref{sec:experiments}.

With regards to the temporal weight (see \cref{sec:o-t-d} for details), we chose $\eta(t) = \exp\{-a/(t-T)^2\}$, with a suitable $a>0$ ($a=0.005$ in our runs). $\eta$ roughly looks like this:

\begin{figure}[H]
\centering
\includegraphics[width=0.5\columnwidth]{Images/Eta.pdf}
\caption{The temporal weight $\eta$}\label{fig:eta}
\end{figure}

\section{Experiments}
\label{sec:experiments}

All the experiments are run on a laptop's Intel i7-6700HQ CPU at 2.60GHz, and 16 GB of RAM.

For simplicity we work in two dimensions and with $D:=B_2(0)$, $\Omega_r := B_{1}(0)$, so that $U_r$ is an annulus centered at the origin. 

\subsection{Shape optimization results}

We have $T=2$ throughout, and the reference mesh looks as follows. Note that in the following plots, the "exact" domain is always interpolated into the finite element space of the control $\tilde{q}_h$, to emphasize what is the best possible result that can be attained by the optimization routine.
%
%\begin{figure}[H]
%\centering
%\includegraphics[width=0.3\columnwidth]{Images/hourglass_constant/initial_domain.pdf}
%\caption{Initial guess for the shape optimization process}\label{fig:initial_domain}
%\end{figure}

\underline{Some exploratory runs}

Let us illustrate a few runs, performed with different Neumann data $g$ and with an hourglass-shaped inclusion. The challenge of this example is to correctly resolve the "corners" in the middle of the hourglass, which have a strong derivative (in the sense of radial functions), are far away from the external boundary (so that the influence on the boundary data of the heat equations may become weak), and where the mesh becomes very distorted, which worsens the quality of the mesh and thus, possibly, of the finite element solution.

To avoid the inverse crime, the Dirichlet data is generated on a mesh that is twice as fine as the to-be-optimized one, and with $120$ steps of the Crank-Nicolson method, whereas $60$ are used in the simulation. The parameter $\tilde{h}$ is set to $0.03$ during synthesis, and to $0.15$ during inversion. Such configuration will be referred to as "standard configuration".

We show the results of six runs performed with three different Neumann sources, having a common behaviour in time: $g_1 = t^2$, $g_2 = x_1g_1$, $g_3=x_2g_2, g_4 = t^2\sin(4t), g_5 = t, g_6 = 1$. The examples took $25, 20, 20, 25, 25, 25$ L-BFGS iterations to converge, amounting to around $4$ minutes for each run.

$g_2, g_3, g_4$ represent various complications of the base example $g_1$. 

\begin{figure}[H]
\centering
\includegraphics[width=0.3\columnwidth]{Images/hourglass_oscillating/comparison.pdf}
\includegraphics[width=0.3\columnwidth]{Images/hourglass_linear/comparison.pdf}
\includegraphics[width=0.3\columnwidth]{Images/hourglass_quadratic/comparison.pdf}
\caption{Exact and simulated inclusion (in red) for the runs with $g_2,g_3$ adn $g_4$, in order from left to right}\label{fig:comparison_neumann}
\end{figure}

On the other hand, $g_5,g_6$ lack, respectively, one and two orders of compatibility, that were required in \cref{ass:num_discr_shopt}. We can see a better result in $g_1$, then in $g_5$ and lastly in $g_6$:

\begin{figure}[H]
\centering
\includegraphics[width=0.2\columnwidth]{Images/hourglass_constant_1_2_cropped.pdf}
\caption{From the outside to the inside: run with $g_6, g_5, g_1$ and exact solution in blue}\label{fig:comparison_compatibility}
\end{figure}


%For completeness, we report a picture of the final deformed mesh corresponding to the $g_1$ run:

%\begin{figure}[H]
%\centering
%\includegraphics[width=0.3\columnwidth]{Images/hourglass_constant/estimated_domain.pdf}
%\caption{Estimated domain in the $g_1$ run}\label{fig:estimated_domain}
%\end{figure}

For completeness, we report the history of the cost function and the gradient $l^\infty$ norm:

\begin{figure}[H]
\centering
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant/comparison.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant/cost_function.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant/gradient_infty_norm.pdf}
\caption{Reconstruction, cost function (logarithm) and gradient history (logarithm) for the $g_1$ run and $25$ iterations}\label{fig:hourglass_constant}
\end{figure}

\underline{The effect of $\eta$}

We now show a visual comparison of the same example $g_1$, run with three different values $a$ for $\eta(t) = \exp\{-a/(t-T)^2\}$, which are $a=0.005, a = 0.05$ and $a=0$.

\begin{figure}[H]
\centering
\includegraphics[width=0.2\columnwidth]{Images/hourglass_constant_no_eta_more_eta_cropped.pdf}
\caption{From outside to inside: run with $g_1$ and $a=0$, $a = 0.05$, $a=0.005$ and exact solution in blue}\label{fig:eta_run}
\end{figure}

Some very small differences can be noticed: it seems that small values of $a$ yield an improvement over a $0$ value of $a$. Our hypothesis for this is in accordance with the behaviour of \cref{fig:comparison_compatibility}: $a=0$ means losing some compatibility. A too large value of $a$, on the other hand, perturbs the problem too much (so that the plot corresponding to $a=0.005$ is yields the best result here). From here, we conjecture that $a$ should be chosen small enough, but positive.


\underline{Inner product}

We found it beneficial to work with smooth descent directions by making use of the $H^1$ inner product during optimization, instead of the $L^2$ one. This is natively handled by Moola. Doing so we obtain smoother boundaries, and more admissible ones: note in fact that we are working in an unconstrained setting for simplicity, whereas the optimization variable $\tilde{q}_h$ should be positive and small enough for the computational domain to be contained in $B_{2}(0)$. With the $L^2$ scalar product we found that iterates were sometimes assuming negative values.

\begin{figure}[H]
\centering
\includegraphics[height=0.3\columnwidth]{Images/hourglass_constant_l2/comparison.pdf}
\caption{Reconstruction for the run $g_1$ and the $L^2$ inner product}\label{fig:l2}
\end{figure}


\underline{Ill-posedness}

\textit{Degeneration of the boundary}

It has already been noted in \cite{harbrecht} that \cref{pb:shid} is "severely ill-posed". The ill-posedness of the inverse problem is mirrored in the ill-posedness of the shape optimization problem \cref{pb:shopt}, where the responsible for such ill-posedness is the compactness of the continuous shape Hessian at the optimal domain: this phenomenon has been exhaustively analyzed in \cite{eppler} in an "elliptic" version of \cref{pb:shid}, but we expect their conclusions to be applicable also to our case.

We computed the shape Hessian at the optimal domain with the help of dolfin-adjoint and observed indeed large condition numbers, as expected (with values $\simeq 10^5$).

This means that small changes in the problem data might yield large changes in the reconstruction, and instabilities in the reconstruction process. In fact, as is commonplace in solving ill-posed inverse problems, proceeding further with the iterations of the solution algorithm will only at first improve the reconstruction, but later result in a degradation of the result (see e.g. \cite{kirsch}, section 2.1). As a remedy, one should impose prior knowledge on the reconstruction through regularization, and/or adopt some form of early stopping.

We did experience these phenomena: up to a certain number of L-BFGS iterations, we obtained acceptable results, the ones we showed above. Proceeding further led to a degradation of the inner boundary. The run with $g_1$ and stopping at $75$ iterations instead $25$, produced:

\begin{figure}[H]
\centering
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_degenerate/comparison.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_degenerate/cost_function.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_degenerate/gradient_infty_norm.pdf}
\caption{Reconstruction, cost function (logarithm) and gradient history (logarithm) for the $g_1$ run and $75$ iterations}\label{fig:degenerate}
\end{figure}

The solution obtained at around $25$ iterations remains unchanged and stable until about iteration $35$, then the cost function is further reduced, along some spurious descent direction.

This degeneration is even more evident and quicker, in case the implicit Euler method is used during optimization, in place of the Crank-Nicolson one, all the other parameters being unchanged (so that the exact data is still generated with the Crank-Nicolson method). This is one of the reasons for adopting the Crank-Nicolson method: the implicit Euler method yields a faster, worse degeneration of the boundary, and a less accurate one, when early stopping is applied. We show again reconstruction, cost function and gradient history.

\begin{figure}[H]
\centering
\includegraphics[height=0.25\columnwidth]{Images/comparison_25_45_euler.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_euler/cost_function_45.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_euler/gradient_infty_norm_45.pdf}
\caption{Reconstruction, cost function (logarithm) and gradient history (logarithm) for the $g_1$ run. The black boundary corresponds to $45$ iterations, the blue one to $25$. The presence of the lateral lobes in the black reconstruction indicates a negative radial function.}\label{fig:degenerate_euler}
\end{figure}

\textit{About the inverse crime}

Let us avoid the inverse crime in a different way, through application of noise to the problem data $f,g$. We therefore set the discretization parameters for the synthetization, equal to those used for the inversion. The noise level is $1$\%, with respect to the $L^\infty(I,L^\infty)$ norm of the data, and the perturbation is random uniform. 

We noticed that the optimization process is much more stable with the number of iterations, than when different discretizations are adopted, for inversion and synthesis. The reconstructed boundary is very similar as in the above runs, but it starts to present spurious oscillations  very late (only after iteration $80$, in the case of the $g_1$ run). The discrepancy between exact data, and data avalailable during optimization, is randomly distributed and of zero mean in the second approach, whereas we noted that it presents a "trend" given by the chosen PDEs discretization algorithm in the first one. This seems to be key to the degeneration behaviour that we observed. 

We did most of the experiments with different discretizations between inversion and synthesis, because this approach highlited better the ill-posedness of the problem. Moreover, in a real-world situation, the data can be interpreted to be sampled from a solution with discretization parameters tending to zero, hence another reason to proceed as we did.

\textit{Second order information}

The shape optimization problem is ill-posed, which is reflected in an ill-conditioned Hessian, at the optimal domain. This can cause undesired oscillations when employing first order optimization methods, a possible way out being the usage of additional second order information, like the shape Hessian.

We thus experimented with a regularized Newton method, following the observations of \cite{eppler} (to which we refer the reader for further details about the method), and found out that, indeed, spurious oscillations don't seem to happen: using $g_1$ as Neumann data, we find that it takes about $20$ iterations for the shape to stabilize. However, the runtime increases to about $2.75$ minutes per iteration, the shape Hessian being automatically computed by dolfin-adjoint. On top of this, the reconstruction seems to be less precise than when employing the L-BFGS method, with early stopping. This convinced us to stick with the L-BFGS method. 

\begin{figure}[H]
\centering
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_newton/comparison.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_newton/cost_function.pdf}
\includegraphics[height=0.25\columnwidth]{Images/hourglass_constant_newton/gradient_infty_norm.pdf}
\caption{Reconstruction, cost function (logarithm) and gradient history (logarithm) for the $g_1$ run, and the regularized Newton method from \cite{eppler}. The reconstructions after $20$ and $70$ shape are visually indistinguishable.}\label{fig:newton}
\end{figure}

\underline{Sea urchin}

Lastly, we show the reconstruction of a 2D version of the more complicated "sea urchin" inclusion of \cite{harbrecht}. The discretization configuration is the standard one. The reconstruction ran for $30$ iterations. This time, for completeness, we also applied $1$\% noise to the data.

\begin{figure}[H]
\centering
\includegraphics[height=0.3\columnwidth]{Images/sea_urchin/exact_domain.pdf}
\includegraphics[height=0.3\columnwidth]{Images/sea_urchin/estimated_domain.pdf}
\includegraphics[height=0.3\columnwidth]{Images/sea_urchin/comparison.pdf}
\caption{"Exact" domain, reconstruction, and comparison between reconstruction and the exact domain, interpolated to the optimization finite element space.}\label{fig:sea_urchin}
\end{figure}

%\tred{hessian in L-BFGS}

\subsection{Estimates for the shape gradients}

We go on to present some numerical evidence of the estimates shown in \cref{sec:d-t-o_IE} and \cref{sec:superconv}. Throughout, $U_h$ will be approximating $U = B_2(0)\setminus \overline{B_1(0)}$.

For $\theta=1$ (implicit Euler) or $\theta=1/2$ (Crank-Nicolson), we set $\delta t = C h^{2\theta}$, $C>0$. We choose a number of spikes $s$ from $0$ to $9$, an amplitude among $0.1$ and $0.2$ and we consider the resulting sinusoidal radial function $q(t) = A \cos(st)$, interpolated on a spherical mesh of size $\tilde{h} = 0.5$. This mesh parameter stays fixed across all the runs, when $h$ varies. Note, this yields a very coarse mesh: the rationale is to have the resulting displacement field (a finite element vector field on the mesh of size $h$) approximating a vector field that is in $W^{1,\infty}$ but not $W^{2,\infty}$. Doing so, we obtain $20$ different displacement fields $\delta \te_{h,\tilde{h}}^i$, $i=1,...,20$, with which we test the shape gradients.  


Not being able to represent non-discretized shape gradients, we content ourselves with analyzing the asymptotic behaviour of the quantity:

$$Q_h:=\max_{i=1,...,20}\frac{|dJ_{h_f,\delta t_f}(U_{h_f})[\delta \te_{h_f,\tilde{h}}^i]-dJ_{h,\delta t}(U_h)[\delta \te_{h,\tilde{h}}^i]|}{\norm{\delta \te_{h,\tilde{h}}^i}_{W^{1,\infty}(U_{h_f})}}$$

where $h_f \ll h$, $\delta t_f \ll \delta t$.

In particular, we set $h_f = 0.03125$, and $h = 2^l h_f$, for $l$ integer, where we refer to $2^l$ as "multiplier". We report the orders of convergence $\ds \frac{\log Q_h-\log Q_{2h}}{\log h - \log 2h}$ in four cases, corresponding to $\theta =1, 1/2$ and $a = 0.05, 0$, where $\eta =\exp\{-a/(t-T)^2\} $. We set $C=1$ (for $\delta t = C h^{2\theta}$) for Crank-Nicolson, and $C=5$ for implicit Euler, to have a number of timesteps that is always greater than $1$. For computational reasons, we made one less refinement in the implicit Euler case.
%
%\begin{table}[h]
%\centering
%\begin{tabular}{lllllll}
%\hline
%\textit{Multiplier} & $32$ & $16$ & $8$ & $4$ & $2$ & $1$\\ \hline
%$Q_h$ & $0.0557$ & $0.0139$ & $0.0047$ & $0.0013$ & $0.0003$ & $0.0$\\ \hline
%\textit{OOC} & $2.356$ & $1.8261$ & $2.0785$ & $2.4573$ & $\infty$ & $-$ \\ \hline
%\end{tabular}
%\caption{Run with Crank-Nicolson, $a = 0.05$ and $C = 1$}\label{tab:CN_eta_rough}
%\end{table}

\begin{table}[h]
\centering
\begin{tabular}{lllllll}
\hline
\multicolumn{7}{l}{Run with Crank-Nicolson, $a = 0.05$ and $C = 1$} \\ \hline
\textit{Multiplier} & $32$ & $16$ & $8$ & $4$ & $2$ & $1$\\ \hline
$Q_h$ & $0.0557$ & $0.0139$ & $0.0047$ & $0.0013$ & $0.0003$ & $0.0$\\ \hline
\textit{OOC} & $2.356$ & $1.8261$ & $2.0785$ & $2.4573$ & $\infty$ & $-$ \\ \hline
\hline
\multicolumn{7}{l}{Run with Crank-Nicolson, $a = 0$ and $C=1$} \\ \hline
\textit{Multiplier} & $32$ & $16$ & $8$ & $4$ & $2$ & $1$\\ \hline
$Q_h$ & $0.0697$ & $0.0078$ & $0.0021$ & $0.0006$ & $0.0001$ & $0.0$\\ \hline
\textit{OOC} & $3.7204$ & $2.1859$ & $2.1446$ & $2.3489$ & $\infty$ & $-$ \\ \hline
\end{tabular}
\caption{Order of convergence study with Crank-Nicolson}\label{tab:ooc_CN}
\end{table}


\begin{table}[h]
\centering
\begin{tabular}{lllllll}
\hline
\multicolumn{6}{l}{Run with implicit Euler, $a = 0.05$ and $C=5$} \\ \hline
\textit{Multiplier} & $16$ & $8$ & $4$ & $2$ & $1$\\ \hline
$Q_h$ & $0.0549$ & $0.0154$ & $0.0047$ & $0.001$ & $0.0$\\ \hline
\textit{OOC} & $2.1202$ & $1.9637$ & $2.3004$ & $\infty$ & $-$ \\ \hline
\hline
\multicolumn{6}{l}{Run with implicit Euler, $a = 0$ and $C=5$} \\ \hline
\textit{Multiplier} & $16$ & $8$ & $4$ & $2$ & $1$\\ \hline
$Q_h$ & $0.0594$ & $0.0126$ & $0.005$ & $0.0011$ & $0.0$\\ \hline
\textit{OOC} & $2.5864$ & $1.5225$ & $2.2349$ & $\infty$ & $-$ \\ \hline
\end{tabular}
\caption{Order of convergence study with implicit Euler}\label{tab:ooc_IE}
\end{table}

Note that we register an infinite order of convergence when the refinement brings us from $2h_f$ to $h_f$, and that the order of convergence value in the refinement before this, might be higher because of a "saturation" effect. We nonetheless think that, at least in the case $a>0$, these results confirm the theoretical considerations in  \cref{sec:d-t-o_IE} and \cref{sec:superconv}. In particular, we note the following facts:

\begin{itemize}
	\item the above tables suggest a superconvergence effect, for the implicit Euler's method, even with "rough" displacement vector fields, compare with  \cref{cor:ie_shape_grad_est} and \cref{cor:superconvergence_sd_fd_IE}
	\item although we haven't given a proof of the convergence behaviour in the case of the Crank-Nicolson method, the above results suggest that the quantity $Q_h$ is $O(h^2+\delta t^2)$, as we suspected. Note, also here it suffices to test with $W^{1,\infty}$ displacements, to obtain the spatial superconvergence effect
	\item the value of $1.5225$ in \cref{tab:ooc_CN} might be due to a lack of regularity of the adjoint states, since $a=0$. This does not contradict our predictions
\end{itemize}

\chapter{Conclusion}
\label{chap:conclusion}

We considered a model parabolic shape optimization problem and treated it in a volumetric fashion: the expression of the distributed shape gradient was derived, also in connection to a star-shaped parametrization of the domains.

The finite element method was employed to perform the spatial discretization, whereas a Crank-Nicolson or implicit Euler scheme was adopted for the temporal one. In the latter case, optimization and discretization are seen to commute.

We derived a semidiscrete (in space) error estimate relating the continuous shape gradient at a smooth enough domain $U$, and the discrete shape gradient at a polygonal/polyhedral interpolation $U_h$ of $U$. In the case of the implicit Euler method, we were able to derive fully discrete estimates.

Numerical experiments support such conclusions, and even suggest that the bounds that we proved for the implicit Euler method, might be obtainable with Crank-Nicolson method. We also show the results from the shape optimization process itself.

There are some interesting directions in which our work can be expanded:

\begin{itemize}
	\item one could at first prove that discretization and optimization commute also for Crank-Nicolson, as \cite{flaig} suggests
	\item from here, fully discrete estimates analogous to those for implicit Euler, should be derivable for the Crank-Nicolson method
	\item the error estimates for the shape gradients derived assuming a specific for of $U_h$: it could be worth to try to eliminate the requirement that $\partial U_h$ must interpolate $\partial U$. Moreover, one could try to explicitly account for $\tau, \tau_h$ (where $U=\tau (U_r), U_h = \tau(U_{r,h})$) in these estimates
\end{itemize}


\begin{appendices}

\appendix

\chapter{Functional spaces}
\label{chap:functional_spaces}
Let us collect, for the convenience of the reader, some technical results that will be used throughout our work. Where appropriate, we give a short proof or a reference for one.

\section{Sobolev spaces}

\begin{thm}[Integration by parts]
\label{thm:ibp}
Let $\Omega$ be a bounded Lipschitz domain. Let $1<p<\infty$ and $f,g \in W^{1,p}(\Omega), W^{1,q}(\Omega)$, $q=p'$, the dual Hölder exponent. Then:

$$\int_\Omega f \partial_i g = -\int_\Omega g \partial_i f+\int_{\partial \Omega} \tr u \nu_i d\pazocal{H}^{n-1}$$
\end{thm}
\begin{mproof}

This follows from \cite{leoni}, theorem 18.1 at page 592, where $g$ needs to be $C^1_c(\mR^n)$. But \cite{adams}, theorem 3.18 at page 54, says that (thanks to the smoothness of the boundary) the set of the restriction of such functions is dense in $W^{1,q}(\Omega)$, so that we can conclude by a density argument.
\end{mproof}

%\begin{lemma}
%$f \in L^\infty(\Omega; \mR^N) \iff f_i \in L^\infty$, and two equivalent norms are $\norm{f}_a:=\norm{|f|}_\infty$, $\norm{f}_b:=\max_i\norm{f_i}_\infty$, for $|\cdot |$ any finite dimensional norm.
%\end{lemma}
%\begin{mproof}
%
%We choose $|\cdot |=|\cdot|_1$.
%
%Consider $f_n \in X_a = \{[f], f: \Omega \rightarrow \mR^n \text{ measurable }, \norm{f}_a\}$, Cauchy. Then every component is Cauchy in the scalar $L^\infty$, so that $f_n^i \rightarrow f^i $ in $L^\infty$. The limit $f$ is in $X_a$ because the functions $|f_i|$ are essentially bounded, and so is $|f|$. 
%
%Then $\norm{f_n-f}_a\leq \norm{f_n-f_m}_a+\sum_i\norm{f_m^i-f^i}_\infty$ for all $n,m$. Choose $m\geq n$ with $\norm{f_m^i-f^i}\leq 1/(Nn)$ and conclude $X_a$ is Banach.
%
%We know from \cite{leoni}, theorem B.88 at page 671, and page 669, we know that $X_b = \{[f], f: \Omega \rightarrow \mR^n \text{ measurable }, \norm{f}_b\}$ is Banach.
%
%Moreover $X_a=X_b$ as sets, so that the thesis follows.
%
%
%%We have that $\norm{f}_\infty = \sup_{\Omega\setminus X}f$ for all $X$ null sets on which $f \leq \norm{f}_\infty$ on $\Omega \setminus X$.
%%
%%In fact, that  $\norm{f}_\infty \geq \sup_{\Omega\setminus X}f$ is clear, whereas suppose there is $\epsilon >0$ with $\norm{f}_\infty -\epsilon \geq f$ on $\Omega \setminus X$. Then we contradict the definition of essential supremum and therefore $\norm{f}_\infty = \sup_{\Omega\setminus X}f$.
%%
%%Next up: for some $X,Y \subseteq \Omega$ of measure $0$, $f,g\leq \norm{f}_\infty, \norm{g}_\infty$ in $\Omega\setminus X, \Omega \setminus Y$, therefore, for some $N$ of null measure, $f,g\leq \norm{f}_\infty, \norm{g}_\infty$ in $\Omega \setminus N$. Therefore, $\norm{f}_\infty = \sup_{\Omega \setminus N}f, \norm{g}_\infty = \sup_{\Omega \setminus N}g$. 
%%
%%Therefore $ \max(\norm{f}_\infty, \norm{g}_\infty) = \max(\sup_{\Omega \setminus N}f,  \sup_{\Omega \setminus N}g) = \sup_{\Omega\setminus N}\max(f,g)$.
%%
%%So, $N$ is a null set and $\max(f,g)\leq \max(\norm{f}_\infty, \norm{g}_\infty)$, which by the reasoning of before.
%%
%%
%
%\end{mproof}

\begin{prop}[Characterization of $W^{1,\infty}$]
\label{prop:lip}
Let $\Omega$ be a bounded Lipschitz domain, or $\mathbb{R}^n$. Then $W^{1,\infty}(\Omega) = C^{0,1}\cap L^\infty(\Omega)$.

This means that $u\in W^{1,\infty}(\Omega)$ if and only if $u$ has a (unique) representative that is bounded, Lipschitz continuous. Weak and classical derivatives coincide a.e.
\end{prop}
\begin{mproof}

%\underline{ACL characterization}
%
%Let $\Omega$ be just a domain.
%
%Consider a line $\gamma$ intersecting $\Omega$. Then, the intersection is a disjoint union of open segments $\gamma_i$. We say $u\in AC_\gamma(\Omega)$ if and only if $u$ is $AC[a,b]$ for every $[a,b]\cc\eta_i$ for all $i$, for almost all lines $\eta$ parallel to $\gamma$ and intersecting $\Omega$.
%
%We say $u \in ACL(\Omega)$ if $u$ is $AC_{e_i}(\Omega)$ for all coordinate axis $e_i$. We also call $BL(\Omega)$ the set of $u$ with a representative $\tilde{u}$, with $\tilde{u}\in ACL(\Omega), \tilde{u}, \nabla \tilde{u} \in L^\infty$, $\nabla u$ being the classical (a.e.) gradient.
%
%We have the following result (see \cite{kufner}, page 276, theorem 5.6.5.): $u \in W^{1,\infty}(\Omega)$ if and only if $u$ has a representative $\tilde{u} \in BL(\Omega)$. Classical and weak derivatives then coincide a.e..

In the case $\Omega$ is bounded Lipschitz, then $\Omega$ is an extension domain for $W^{1,\infty}(\Omega)$ (see \cite{leoni}, theorem 13.17 at page 425, 13.13 at page 424, and definition 9.57 at page 273).

Let $u \in  W^{1,\infty}(\Omega)$. By \cite{leoni}, 11.50 at page 339, because $\Omega$ is an extension domain, we obtain that $u$ has a representative $\bar{u}$ that is bounded Lipschitz. Let $\phi \in C_c^\infty(\Omega)$. By The Kirszbraun theorem (see e.g. \cite{kirszbraun}), we can extend $\bar{u}$ to a Lipschitz on $\mathbb{R}^n$. Then, by Fubini's theorem and integration by parts for AC functions, we conclude $\ds \int_\Omega\bar{u}\partial_i\phi =-\int_{\Omega} \partial_i \bar{u} \phi $, so that $\nabla \bar{u} = \nabla u$ almost everywhere.

Conversely, let $u$ be bounded Lipschitz. The above reasoning shows that $u$ has essentially bounded weak derivatives equal to the a.e. classical derivatives.
\end{mproof}

%Therefore, for $\phi \in C_c^\infty(\Omega)$ we get $\ds -\int_\Omega u \phi_{,i}\ds = \int_\Omega \partial_i u\phi =  \int_\Omega g_i \phi$.
%
%Pick a cube $Q = [-M,M]^n$, $\Omega \cc Q$. So, upon extending in a bounded Lipschitz manner $g_i$ to $G_i$ with $G_i(\partial Q)=0$ (see \cite{kirszbraun} and multiply by a suitable cut-off function), and $\phi$ to $0$, we get $\ds ...=\int_\Omega G_i \phi$. Call $h_i^x(t)=G_i(...,x_{i-1},t,x_{i+1},...)$ which is $AC[-M,M]$. Because $\eta_i^x(s):= \int_{-M}^s h_i^x(z)dz$ is $AC[-M,M]$ too because $h_i^x$ is bounded, and $h_i^x(t) =  \eta_i^{x'}(t)$. Employing then Fubini:
%
%\begin{align*}
%...= \int_{-M}^M... \int_{-M}^M \int_{-M}^M G_i(...,x_{i-1},x_i,x_{i+1},...)\phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n  \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M h_i^x(x_i) \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^{x'}(x_i)  \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^{x'}(x_i)  \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= -\int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^x(x_i)  \phi_{,i} dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%=- \int_{-M}^M... \int_{-M}^M \int_{-M}^M \int_{-M}^{x_i} G_i(...,x_{i-1},z,x_{i+1},...) dz\phi_{,i} dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= -\int_Q k_i\phi_{,i}
%\end{align*}
%
%where in the last passage we have used again Fubini and the fact that 
%
%$$k_i(x):=\int_{-M}^{x_i} G_i(...,x_{i-1},z,x_{i+1},...) dz$$
%
% is measurable and bounded on $Q$.


\section{Bochner spaces}

%Here are some useful results about Bochner spaces.

\begin{prop}[Bochner integral and bounded operators]
\label{prop:bochner_bound}
Let $X,Y$ be separable Banach, let $T \in L(X,Y)$ be a linear bounded operator. For $f \in L^1(I,X)$ define $Tf (t):= T(f(t))$. Then $Tf \in L^1(I,Y)$ with $T\int_I f = \int_I Tf$.
\end{prop}
\begin{mproof}

Let $f_n$ be simple, $f_n\rightarrow f $ a.e., with $\lim_n \int_I f_n = \int_I f$ and $\norm{f_n}_X \leq C \norm{f}_X$ (see page 6, and corollary 2.7 at page 8 of \cite{kreuter}).

For almost all $t$, $T(f_n(t)) \rightarrow T(f(t))=Tf(t)$ in $Y$, so that $Tf$ is measurable (strongly).

By dominated convergence (corollary 2.6 of \cite{kreuter}) $Tf$ is integrable. Thus $\int_T Tf = \lim_n \int_I  Tf_n = \lim_n T\int_I  f_n$, because $f_n$ is simple. And now, by the choice of $f_n$, $\int_T Tf = \lim_n T\int_I  f_n = T \lim_n \int_I  f_n = T \int_I f$.
\end{mproof}

\begin{cor}	[Derivations and bounded operators]
\label{lemma:bochner_Hk_map}
As before, let $X,Y$ be separable Banach, let $T \in L(X,T)$ be a linear bounded operator.

For $k\geq 0$, $f \in H^k(I,X)\implies Tf \in H^k(I,Y)$, with weak derivatives $\partial_{t^i}Tf = T\partial_{t^i}f$, $0\leq i \leq k$.

The map $f \mapsto Tf$, $H^k(I,X)\rightarrow H^k(I,Y)$ is linear, and bounded by $\norm{T}$.
\end{cor}
%\begin{mproof}
%The case $k=0$ is proved above.
%
%We prove now that $\partial_{t^i}Tf = T\partial_{t^i}f$ for $i=1$. Note that $T\partial_t f \in L^2(I,Y)$, which qualifies as weak derivative.
%
%In fact, for $\phi \in C_c^\infty(I)$, we have $\int_I \phi T\partial_i f = \int_I T(\phi\partial_t f) = T \int_I\phi\partial_t f = -T\int_I\phi'f=-\int_I\phi'Tf$.
%
%Higher weak derivatives are treated analogously and the rest of the claims follow from the time stationarity of $T$ and by $\norm{\partial_{t^i}Tf}=\norm{T\partial_{t^i}f}\leq \norm{T}\norm{\partial_{t^i}f}$.
%
%\end{mproof}

\begin{prop}[Continuous representatives]
\label{prop:cts_repr}
Let $X$ be separable Banach. $f \in L^1(I,X)$ has at most a continuous representative on $[0,T]$.
\end{prop}
%\begin{mproof}
%Assume there exists two such continuous representatives, so that we get a function $\delta: [0,T] \rightarrow X$ that is zero almost everywhere and continuous. Hence, $[0,T] \ni t \mapsto \norm{\delta(t)}$ is continuous in $\mR$ and zero a.e., so that it must be zero everywhere.
%\end{mproof}

%\begin{prop}[Weak derivatives and Gelfand triples]
%\label{prop:sob_implies_W}
%Let $H\subseteq V$ be separable Hilbert spaces, $H$ densely embedded in $V$.
%
%Then $y \in L^2(I,V)\cap H^1(I,H) \subseteq W(I,V)$.
%\end{prop}
%\begin{mproof}
%We note that $V$ is Hilbert separable, so, reflexive Banach and separable, so that $V^*$ is separable too. Then, call $i$ the embedding $H \emb V^*$.
%
%For $\phi \in C^\infty_c(I)$ we obtain $\int_I i(y_t)\phi=\int_I i(y_t\phi)= i \left ( \int_I y_t\phi \right )$ by \cref{prop:bochner_bound}. Therefore $\int_I i(y_t)\phi=-i \left ( \int_I y\phi' \right ) =\int_I i(y)\phi'  $ , proving that $y \in W(I,V)$.
%
%\end{mproof}

We now check that a vector valued test function has weak derivatives of all orders.

\begin{prop}[Weak derivatives of test functions]
\label{prop:weak_class}
Let $\phi \in C^1([0,T],X)$, for $X$ separable Banach. It means that the limit of the difference quotients exists for all points of $I$, that $t\mapsto \phi(t), \phi'(t)$ are continuous, and that they can be continuously extended to $[0,T]$.

Then these classical derivatives coincide a.e. with the weak derivatives of $u$.

\end{prop}
\begin{mproof}


Apply proposition 3.8 of \cite{kreuter} at page 26, thanks to theorem 6 at page 146 of \cite{mvt}, a mean value theorem for vector valued function.
\end{mproof}

We also need a time dependent trace lemma, which we provide under non-optimal regularity assumptions, but for the sake of making some arguments easier and more transparent.

\begin{defn}[Time dependent trace]
Let $\Omega$ be a bounded Lipschitz domain. For $k\geq 0$ we define $\tr: H^k(I,H^1(\Omega))\rightarrow H^k(I, H^{1/2} (\partial \Omega))$ by $\tr(u)(t):=\tr(u(t))$
\end{defn}

Below are some properties of this operator.

\begin{prop}[Properties of trace operator]
\label{prop:trace}
The trace operator just defined:
\begin{enumerate}
\item is well posed, linear and bounded
\item admits a linear bounded right inverse, for instance, $E(g)(t):=E(g(t))$ (for $E$ a right inverse of the static trace)
\item $\tr$ and $E$, in the case of $k \in \mathbb{N}_0$, coincide (in the time a.e. sense) for the case $l\geq k$
\item for $k\geq 1$, $\tr u(0)=0 \iff u(0)=0$ (in the sense of continuous representatives)
%\item it coincides with the trace treated for instance in \cite{lions}
\end{enumerate}
\end{prop}
\begin{mproof}

\underline{Proof of the proposition}

We recall that the trace operator is bounded surjective onto $H^{1/2}(\partial \Omega)$, with a right inverse $E$ (see theorem 3.37 at page 102 of \cite{mclean}). The first three points are consequences of this fact and of \cref{prop:bochner_bound}.

The fourth property follows by the definition of $\tr, E$ and the fact that $H^l\subseteq H^k$, for $k\leq l$.

Let now $k\geq 1$. We know that $H^1, H^{1/2}$ are separable and Banach (the latter is separable because the continuos image of $H^1$ separable, and Banach (see \cite{grisvard}, page 20). Therefore, by \cite{evans}, theorem 2 of page 286, we obtain the embeddings $H^k(I,H^1)\emb C([0,T],H^1)$ and the same goes for $H^k(I,H^{1/2})$, and we conclude by continuity in time of $u$ and $\tr u$.

%For the last point, let $k=0$. We have:
%
%\begin{enumerate}
%\item $H^1(\Omega)\cap C^1(\overline{\Omega})$ is dense in $H^1(\Omega)$ (see \cite{adams}, theorem 3.18 at page 54, where being $\Omega$ bounded Lipschitz is important)
%\item functions $\sum_{i\leq m} \phi_i(t)f_i$ for $\phi_i \in C_c^\infty(I), f_i \in H^1(\Omega)\cap C^1(\overline{\Omega})$ are dense in $L^2(I,H^1)$ (see \cite{hinze}, page 39, lemma 1.9)
%\end{enumerate}
%
%It follows by the third point that $C^1(\overline{\Omega\times I})$ is dense in $L^2(I,H^1)$, so that $u\mapsto u|_{I\times \partial \Omega}$ admits a unique extension by continuity to $L^2(I,H^1)$, so that this definition of trace coincides with the one from the literature (see \cite{lions}, theorem 4.1).
%, we expand this argument below.
%
%\underline{Proof of leftover facts}
%
%We call $C^k(\overline{\Omega}):=\{u \in C^k(\Omega) \text{ with }\partial_\alpha f \text{ extendable by continuity to } \overline{\Omega} \}$. 
%
%Consider $u(x,t):=\phi(t)v(x)$, for $\phi \in C^1([0,T]), v \in C^1(\overline{\Omega})$. Then, it has partial derivatives $u_t = \phi_t v, u_i = \phi u_i$. $u$ and all its partial derivatives are continuous on $I\times \Omega$, meaning that $u \in C^1(\Omega \times I)$.
%
%Moreover, $u, u_i, u_t \in C([0,T], C(\overline{\Omega}))$. We claim $ C([0,T], C(\overline{\Omega})) = C(\overline{\Omega\times I})$. In fact, one direction is trivial, and so, let $f \in C([0,T], C(\overline{\Omega})) = C(\overline{\Omega})$. Fix $(t,x) \in \overline{\Omega\times I}$. Then, $|f(s,y)-f(t,x)|\leq |f(t,y)-f(t,x)|+|f(t,y)-f(s,y)|\leq  |f(t,y)-f(t,x)|+\norm{f(t, \cdot)-f(s,\cdot)}_{\infty}$. If now $s$ is close to $t$, and $y$ is close to $x$, then $|f(s,y)-f(t,x)|$ is small.
%
%This shows $u, u_i, u_t \in C([0,T], C(\overline{\Omega})) \in C(\overline{\Omega\times I}) $, i.e. $u \in C^1(\overline{Q\times I})$.
%
%To conclude, let $u \in L^2(I,H^1)$. Approximate $u$ by $u_k:=\sum_{i\leq m_k} \phi_i^k(t)f_i^k$ as in point 2, and approximate $f_i^k$ by suitable $g_i^k \in H^1(\Omega)\cap C^1(\overline{\Omega})$, to obtain $u_k:=\sum_{i\leq m_k} \phi_i^k(t)g_i^k$
%
%Then $\norm{u-w_k}_{L^2(I,H^1)}\leq \norm{u_k-w_k}_{L^2(I,H^1)}+\norm{u_k-u}_{L^2(I,H^1)}$. We only need to estimate $ \norm{u_k-w_k}_{L^2(I,H^1)}\leq\ds  T \sum_{i\leq m_k} \norm{\phi_i^k}_\infty\norm{f_i^k-g_i^k}_{H^1}$. By the first point, $\norm{f_i^k-g_i^k}_{H^1}$ can be made as small as it is necessary to conclude.

%\underline{Last remarks}
%
%Again with reference to \cite{lions}, consider the anisotropic spaces $H^{r,s}:=L^2(I,H^r)\cap H^s(I,L^2)$. We restrict to the case $r = 1$, $s\geq 0$. Denote the traces $\tr_s$ defined in theorem 4.1, mapping $H^{1,s}(\Omega \times I)\rightarrow H^{1/2, s/2}(\partial \Omega \times I)$. For $\partial \Omega$ Lipschitz this theorem is still valid, as $1/2\leq 1$, see the discussion above lemma 2.4 in \cite{costabel}. As stated in \cite{lions}, $\tr_s$ is an extension of  $u\mapsto u|_{I\times \partial \Omega}$, defined on the dense suspace $C^\infty(\overline{Q\times I})$ of $H^{1,s}$ (that this space is dense can be proved as in lemma 2.22 of \cite{costabel}). So, let $C^\infty(\overline{Q\times I})\ni u_n \rightarrow_{H^{r,s}} u \in H^{1,s}$.
% 
%We have $\tr_s u_n = \tr_0 u_n$. Then, $u_n \rightarrow_{H^{1,s}} u$, $u_n \rightarrow_{H^{1,0}} u$, so that $\tr_s u_n \rightarrow_{H^{1/2,s/2}}\tr_s u$ (hence $\tr_0 u_n \rightarrow_{H^{1/2,0}}\tr_s u$) and $\tr_0 u_n  \rightarrow_{H^{1/2,0}} \tr_\sigma u$.
%
%Thus $\tr_0 u = \tr_s u$.
%
%Using what we derived before, we can conclude the characterization of the traces in the anisotropic settign define 
\end{mproof}

%And now some sanity checks in the case of Gelfand triples. 
%
%\begin{prop}[Sanity checks for Gelfand triples]
%\label{prop:sanity}
%
%Consider the following Gelfand triples (the diagram commutes):
%
%\[\begin{tikzcd}
%	{V} &&& {V^*} \\
%	& H & {H^*} \\
%	{W} &&& {W^*}
%	\arrow["c", hook, from=3-1, to=1-1]
%	\arrow["a", hook, from=1-1, to=2-2]
%	\arrow["b"', hook, from=3-1, to=2-2]
%	\arrow["{a^*}", hook, from=2-3, to=1-4]
%	\arrow["r", from=2-2, to=2-3]
%	\arrow["{b^*}"', hook, from=2-3, to=3-4]
%	\arrow["{c^*}", hook, from=1-4, to=3-4]
%\end{tikzcd}\]
%
%Here $W\subseteq V \subseteq H$ are all separable Hilbert spaces, $a,b,c$ the trivial injections, $r$ the Riesz isomorphism of $H$. We denote by $i_V$ the Gelfand triple embedding $V\emb V^*$, so, $i_V=a^*ra$.
%
%Then:
%
%\begin{enumerate}
%	\item $H^1(I,V)\subseteq W(I,V)$ with continuous embedding. The $W(I,V)$ derivative of $u \in H^1(I,V)$ is $i_V u_t$.
%	\item for $u \in W(I,W)$ with $(i_W u)'\in L^2(I,H)$ (i.e. $(i_W u)_t = b^*r h$ for $h$ in $L^2(I,H)$) we obtain $u \in W(I,V)$ (i.e. $cu \in W(I,V)$), with derivative $(i_V cu)'=a^*r h$, so that also $(i_V cu)' \in L^2(I,H)$. It also holds $(i_V cu)'|_W = (i_W u)'$. $h$ is also the weak derivative $L^2(I,H)$ of $bu$.
%	\item let $u, v \in W(I,V)$ with $u-v \in W$. Then $u-v \in W(I,W)$ with derivative $(i_W(u-v))'=(i_V u)'|_W-(i_V v)'|_W$.
%\end{enumerate}
%
%\end{prop}
%\begin{mproof}
%
%We use several times that time integrals and bounded linear static operators commute, see \cref{prop:bochner_bound}. $\phi$ denotes $\phi \in C^\infty_c(I)$.
%
%\underline{First point}
%
%We need to check that $a^* r a u \in H^1(I, V^*)$. This follows from \cref{lemma:bochner_Hk_map}, so that $(a^* r a u)_t = a^* r a u_t$.
%
%\underline{Second point}
%
%At first we claim that $h$ is a weak derivative of $bu \in L^2(I,H)$. In fact, $b^* r \int_I bu \phi' = \int_I (i_W u)\phi' = \ind{\mind{u \in W(I,W)}} =-\int_I(i_Wu)'\phi=-\int_I b^*r h\phi = b^*r (-\int_I h \phi)$. By density (definition of Gelfand triple), $b^*$ is injective, $r$ is too, and thus $\int_I bu \phi' = -\int_I h \phi$, which shows that $bu$ has weak derivative $h$, in the $H^1(I,H)$ sense.
%
%And now $\int_I i_V c u \phi'= \int_I a^*racu \phi' = a^*r\int_I bu\phi' = \ind{by what we just proved}=-a^*r \int_I h \phi$, proving that $(i_V cu)'=a^*r h$.
%
%Morevoer $(i_V cu)'|_W = c^*a^*r h=b^*rh=\ind{assumption} = (i_W u)'$.
%
%\underline{Third point}
%
%We check the derivative. We have $\int_i i_W(u-v)\phi' =\ind{\mind{u-v \in W\subseteq V}} = \int_I b^* r a (u-v) = c^*\int_I(i_Vu - i_Vv)\phi' = -\int c^*((i_V u)'- (i_V v)')\phi$.
%
%\end{mproof}

\begin{lemma}[Piecewise constant approximation]
\label{lemma:pw_constant_appr}
Let $X$ be a separable Banach space, and $u \in H^1(I,X)$. Discretize $I$ into uniform subintervals $I_k:=[t^k,t^{k+1}]$ of width $\delta t$. Call $\pi u \in L^2(I,X)$ the function $\pi u(t)=u(t^{k})$, for $t \in (t^k,t^{k+1})$.

Then, $\norm{u-\pi u}_{L^2(I,X)}\leq C \delta t \norm{u'}_{L^2(I,X)}$, for $C=1/\sqrt{2}$, and the same holds for $\tilde{\pi}u(t) = u(t^{k+1})$ for $t \in (t^k,t^{k+1})$.

\end{lemma}

\begin{mproof}
There holds $\ds \int_{I_k}\norm{\pi u - u(t)}_X^2 dt = \int_{I_k} \norm{\int_{t^k}^{t} u'(s)ds}_X^2 dt\leq \int_{I_k}\left ( \int_{t^k}^{t} \norm{u'(s)}_X ds \right )^2 dt$. 

By Hölder's inequality we then see that $ \ds \int_{I_k}\norm{\pi u - u(t)}_X^2 dt \leq  \int_{I_k} \norm{u'(s)}_X^2 ds  \int_{I_k}(t-t^k)dt = \frac{\delta t ^2}{2} \norm{u'}_{L^2(I_k,X)}^2$. The result follows after summation.
\end{mproof}

\chapter{Parabolic equations}
\label{chap:parab_eq}

\section{Abstract theory}

\begin{ass}[Basic assumption for parabolic problems]
\label{ass:basic_par}

Let $V\subseteq H$ be real separable Hilbert spaces, $V$ dense in $H$. Then $H\hookrightarrow V^*$ is also dense, as stated in \cite{trol} at page 147. This embedding is $H \ni f \mapsto (f, \cdot )_H$. We thus obtain a Gelfand triple, and we have $W(I,V)\subseteq C(I,H)$.

Let $A:V\rightarrow V^* $ be linear bounded, $u \in W(I;V)$, $f \in L^2(I,V^*)$ and $u_0 \in H$.

We also assume that $\langle Av, v \rangle_{V^*,V}+ \lambda \HN{v}^2\geq \alpha \VN{v}^2$ for $\lambda \geq 0, \alpha >0$.
\end{ass}

We are interested in the following problem:

\begin{pb}[Abstract parabolic equation]
\label{eqn:general_parabolic}
\begin{align}
	u_t+Au=f \text{ in }V^* \text{ and for a.e. } t \in (0,T)\\
	u(0)=u_0
\end{align}
\end{pb}

\begin{thm}[Basic well posedness of \cref{eqn:general_parabolic}]
\label{thm:well_pos_parabolic}
Under \cref{ass:basic_par}, \cref{eqn:general_parabolic} has a unique solution $u$. Moreover $u$ satisfies the energy estimate:
\begin{equation}
	\label{eqn:en_est}
	\norm{u}_{W(I,V)} + \norm{u}_{C([0,T],H)}\leq c(\lambda, \alpha, \VSN{A}, T)(\HN{u_0}+\norm{f}_{L^2(I,V^*)})
\end{equation} 
\end{thm}
\begin{mproof}
See \cite{gilardi} at page 19, theorem 26.
\end{mproof}

We can also obtain additional regularity. Here are further assumptions to make this possible.

\begin{ass}[Assumptions for additional regularity]
\label{ass:reg_par}
We assume $u_0 \in V$, $f = f_1+f_2 \in L^2(I,H)+H^1(I,V^*)$. We also need $A$ to be symmetric (i.e. $\langle Au,v \rangle_{V^*,V} = \langle Av,u \rangle_{V^*,V}$).
\end{ass}

%\begin{thm}[Regularity of time derivative]
%\label{thm:\textbf{reg_time}}
%Suppose \cref{ass:basic_par} and \cref{ass:reg_par}. Then $u_t \in L^2(I, H)$ with the estimate:
%\begin{align}
%	\norm{u}_{W(I,V)} + \norm{u}_{C(I,H)} + \norm{u_t}_{L^2(I,H)} \leq\\ c(\lambda, \alpha, \VSN{A}, T)(\VN{u_0}+\norm{f_1}_{L^2(I,H)} + \norm{f_2}_{H^1(I,V^*)})
%\end{align}
%
%\end{thm}
%\begin{mproof}
%Note that:
% 
%\begin{align*}
%	\int_0^t \langle f_2,u_n' \rangle_{V^*,V} = -\int_0^t \langle f_2',u_n \rangle_{V^*,V} + \langle f_2,u_n \rangle_{V^*,V}(t)-\langle f_2,u_n \rangle_{V^*,V}(0)
%\end{align*}
%
%The proof is now essentially as page 26 of \cite{gilardi}, theorem 28.
%
%\end{mproof}

%For the case where $H=L^2$, $H^1\supseteq V\supseteq H^1_0$,  $f_2|_{H^1_0}=0$ we have even more regularity available.
%
%\begin{thm}[Additional regularity]
%\label{thm:par_reg}
%Suppose \cref{ass:basic_par} and \cref{ass:reg_par}. 
%
%Let additionally $H=L^2$, $H^1\supseteq V\supseteq H^1_0$,  $f_2|_{H^1_0}=0$. Then $Au|_{H^1_0}$ extends to $\overline{Au_{H^1_0}} \in L^2(I,H)$ with:
%\begin{align}
%	\norm{u}_{W(I,V)} + \norm{u}_{C([0,T],H)} + \norm{u_t}_{L^2(I,H)} +\norm{\overline{Au|_{H^1_0}}}_{L^2(I,H)}\leq\\ c(\lambda, \alpha, \VSN{A}, T)(\VN{u_0}+\norm{f_1}_{L^2(I,H)} + \norm{f_2}_{H^1(I,V^*)})
%\end{align}
%
%Moreover $u_t+\overline{Au_{H^1_0}}=f_1$ in $L^2(0,T,L^2)\cong L^2(Q)$ and $\overline{Au|_{H^1_0}}=Au$ on $H^1_0$.
%
%\end{thm}
%\begin{mproof}
%
%For $v \in H^1_0$ we get $ \langle Au,v \rangle_{V^*,V} =  \langle f_1-u_t,v \rangle_{V^*,V} = ( f_1-u_t,v )_H$, for almost all $t \in (0,T)$. From here we conclude that $Au(t)$ extends for a.a. $t$ to an element of $H$ with $(\overline{Au}-f_1+u_t,v)_{L^2}=0$ for all $v \in H^1_0$, almost all $t$. By density, $\overline{Au}-f_1+u_t=0$ in $H$ for almost all $t$, so that $\overline{Au}=f_1-u_t$ in $L^2(0,T,L^2)\cong L^2(Q)$.
%
%This isometric isomorphism is stated in \cite{trol}, page 144. 
%
%\end{mproof}

\begin{prop}[Time regularity and tracking the costants]
\label{thm:const_track}
With \cref{ass:basic_par} there holds:
\begin{align}
\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq C\exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})\\
C\norm{u'}_{L^2(I,V^*)}\leq \norm{A}_{L(V,V^*)}\alpha^{-1/2}\sqrt{\exp(2\lambda T)}\HN{u_0} +\\\left (\norm{A}_{L(V,V^*)}\alpha^{-1}\sqrt{\exp(2\lambda T)}+1\right ) \norm{f}_{L^2(I,V^*)}
\end{align}

With additionally \cref{ass:reg_par} we obtain $u \in H^1(I,H)$ with:

\begin{align}
C\norm{u'}^2_{L^2(I,H)}\leq 
(1+(1+C_0)\alpha^{-1})\norm{f_2}_{H^1(I,V^*)}^2+\\
(1+\norm{A}_{L(V,V^*)})\VN{u_{0}}^2+C_0\HN{u_0}^2+\\
\norm{f_1}_{L^2(I,H)}^2+C_0\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}
\end{align}

with $C>0$ a real number independent of problem data and solution, space dimension, and which need not to be the same for the three estimates. 

Here $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$.

\end{prop}
\begin{mproof}

\underline{No regularity}

From page 21 of \cite{gilardi} we obtain that $\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq \exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})$, where from here onwards, in this proof, we leave out purely numeric constants that are independent of the solution, the space dimension, the data of the problem.

Moreover $\norm{u'}_{L^2(I,V^*)}\leq \norm{Au}_{L^2(I,V^*)}+\norm{f}_{L^2(I,V^*)}\leq \norm{A}\norm{u}_{L^2(I,V)}+\norm{f}_{L^2(I,V^*)}$.

All in all, we obtain:

\begin{align*}
\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq \exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})\\
\norm{u'}_{L^2(I,V^*)}\leq \norm{A}_{L(V,V^*)}	\alpha^{-1/2}\sqrt{\exp(2\lambda T)}(\HN{u_0}+\alpha^{-1/2}\norm{f}_{L^2(I,V^*)})+\norm{f}_{L^2(I,V^*)}
\end{align*}

\underline{More regularity}

We tie back to page 25 of \cite{gilardi}. In particular:

\begin{align*}
\int_0^t\HN{u_n'}^2+\int_0^t\langle A u_n, u_n'\rangle_{V^*,V}=\int_0^t(f_1,u_n')_H+\int_0^t \langle f_2, u_n'\rangle_{V^*,V}
\end{align*}

%Now, taking $u_{n0}$ to be the orthogonal projection of $u_0$ onto $V_n$ with the scalar product of $V$, we can assume $\VN{u_{n0}}\leq\VN{u_0}$.

Then:
\begin{align*}
\int_0^t\langle A u_n, u_n'\rangle_{V^*,V}\geq \frac{\alpha}{2}\VN{u_n(t)}^2-\frac{\lambda}{2}\HN{u_n(t)}^2-\frac{\norm{A}}{2}\VN{u_{n0}}
\end{align*}

whereas, with integration by parts:
\begin{align*}
	\left | \int_0^t \langle f_2,u_n' \rangle_{V^*,V}\right | \leq
	\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{\alpha}{4}\VN{u_n(t)}^2 +\\
	+ \frac{4}{\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+ \frac{1}{2}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1}{2}\VN{u_{n0}}^2
\end{align*}

Also:
\begin{align*}
\int_0^t(f_1,u_n')_H\leq \frac{1}{2}\norm{f_1}_{L^2(I,H)}^2+\frac{1}{2}\int_0^t\HN{u_n'}^2
\end{align*}

This brings us to:

\begin{align}
\label{eqn:weak_der_bound}
\frac{1}{2}\int_0^t\HN{u_n'}^2+\frac{\alpha}{4}\VN{u_n(t)}^2-\frac{\lambda}{2}\HN{u_n(t)}^2\leq \\
\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 +\\
+ \frac{8+\alpha}{2\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1+\norm{A}}{2}\VN{u_{n0}}^2+\\
+\frac{1}{2}\norm{f_1}_{L^2(I,H)}^2
\end{align}

and thus, because norms are lower semicontinuous and because we have weak convergence of the time derivative, and $V$-strong convergence of the initial data (see again \cite{gilardi} for this):

\begin{align*}
\int_0^T\HN{u'}^2\leq 
\norm{f_2'}_{L^2(I,V^*)}^2+(1+\alpha^{-1})\norm{f_2}_{L^\infty(I,V^*)}^2+(1+\norm{A})\VN{u_{0}}^2+\norm{f_1}_{L^2(I,H)}^2+\\
\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )
\end{align*}


For the last term, employing the exact argument as in the first part of the proof:

\begin{align}
\label{eqn:limsup}
\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )\leq C_0(\HN{u_0}^2+\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}+\alpha^{-1}\norm{f_2}^2_{L^2(I,V^*)})
\end{align}


where $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$.

Therefore:

\begin{align*}
\int_0^T\HN{u'}^2\leq 
\norm{f_2'}_{L^2(I,V^*)}^2+(1+\alpha^{-1})\norm{f_2}_{L^\infty(I,V^*)}^2+(1+\norm{A})\VN{u_{0}}^2+\norm{f_1}_{L^2(I,H)}^2+\\
C_0(\HN{u_0}^2+\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}+\alpha^{-1}\norm{f_2}^2_{L^2(I,V^*)})
\end{align*}


The embedding $H^1(I,V^*)\emb C([0,T],V^*)$ has norm that only depends on $T$, which follows from the equality $f_2(t)=f_2(s)+\int_s^tf_2'$, for $0\leq s \leq t \leq T$, a bound being $1+T$.

Thus:

\begin{align*}
\int_0^T\HN{u'}^2\leq 
(1+(1+C_0)\alpha^{-1})\norm{f_2}_{H^1(I,V^*)}^2+(1+\norm{A})\VN{u_{0}}^2+C_0\HN{u_0}^2+\norm{f_1}_{L^2(I,H)}^2+C_0\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}
\end{align*}

\end{mproof}


Proving higher time regularity under additional compatibility assumptions and smoothness of the data can also be done as follows.

\begin{prop}[Higher time regularity]
\label{prop:time_reg}

Let $k\geq 1$. Suppose $f \in H^k(I, V^*)$, together with:

\begin{itemize}
	\item $g_j:=f^{(j-1)}(0)-Ag_{j-1} \in H$, for $j = k$
	\item $g_{j-1} \in V$ for $1\leq j\leq k$
\end{itemize}

where $g_0 = u_0$.

Then, there holds, for $1\leq j\leq k$:

\begin{align*}
\left\{\begin{matrix}
u^{(j+1)}+Au^{(j)} = f^{(j)}
\\
u^{(j)}(0) = f^{(j-1)}(0) - Ag_{j-1}
\end{matrix}\right.
\end{align*}

In particular $u \in H^k(I,V)$, and $u^{(k+1)} \in L^2(I,V^*)$. One can prove, with the help of \cref{thm:well_pos_parabolic}, a-priori estimates on these successive derivatives.


\end{prop}

\begin{mproof}

See \cite{wloka}, theorem 27.2, page 406.

%The proof is a simplification of his argument, since our operator $A$ is for simplicity, independent in time. We also prove the proposition for the lowest order of differentiation, being the extension to higher derivatives  tractable with equal arguments.
%
%Consider the problem:
%
%\begin{align*}
%	v_t + Av = f'\\
%	v(0) = f(0) - Au (0)
%\end{align*}
%
%By assumption, $f(0) - Au (0) \in H$, and $f' \in L^2(I,V^*)$, so that, by \cref{thm:well_pos_parabolic} we obtain $v \in W(I;V)$.
%
%Define $w(t):=u(0) + \ds \int_0^tv(s)ds$, an absolutely continuous $V$-valued function, being $u(0) \in V$ by assumption. We have $w_t = v$, so that $w \in H^1(I,V)$. We show that $w = u$.
%
%Integrating the equation of $v$ we obtain, with equalities holding in $V^*$, that:
%
%\begin{align*}
%	w_t(t) = v(t) = \int_0^t f' -\int_0^t Av + v(0) = \\
%	f(t) - f(0) + f(0) - Au(0) - \int_0^t A(w_t) = \\
%	f(t) - f(0) + f(0) - Au(0) - Aw (t) + Au(0) = f(t) - Aw(t)
%\end{align*}
%
%Therefore, $w$ solves the same equation as $u$ and thus, $w=u$. From here we obtain both $u \in H^1(I,V)$, together with $u_{tt} = w_{tt} = v_t \in L^2(I,V^*)$, and the equation:
%
%\begin{align*}
%	u_{tt} + Au_t = f'\\
%	u_t(0) = f(0) - Au (0)
%\end{align*}
%
\end{mproof}

% This proposition assumes the same compatibility of that above, for k=1, and it is far more complicated.

%Under slightly different assumptions we can prove similar results, for $k=1$.
%
%\begin{ass}[Even more assumptions for even more regularity]
%\label{ass:zero_comp}
%We make the hypothesis $u_0=0$, which is the only case that is of interest for us, together with $A$ symmetric. Moreover, we require that the source term is a generic $f\in H^1(I,V^*)$ (in particular, the split $f=f_1 +f_2 \in L^2(I,H)+H^1(I,V^*)$ is not sufficient anymore), so that it is continuous  (\cite{evans}, page 286, theorem 2), and we can therefore ask the additional condition $f(0) \in H$.
%\end{ass}
%
%
%\begin{prop}[More smoothness from zero-order compatibility]
%Let \cref{ass:basic_par} and \cref{ass:zero_comp} hold. Then $u \in H^1(I,V)$ (in particular, $u \in C([0,T];V)$), and  $u' \in L^\infty(I,H)$ with the estimates:
%
%\begin{align*}
%\norm{u'}^2_{L^\infty(I,H)} \leq \exp(2\lambda T) \left (  \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2\right )
%\end{align*}
%
%and:
%
%\begin{align*}
%\int_0^T \VN{u'}^2 \leq  \frac{1}{\alpha } \HN{f(0)}^2 + C_1\norm{f}_{H^1(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha^2}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%with $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$, $C$ is a purely numeric constant without dependences on the problem, $C_1:=\alpha^{-2} + 4 \lambda C C_0 \alpha^{-2} + 2\lambda\alpha ^{-1} $.
%
%There also holds $u'' \in L^2(I,V^*)$ and:
%
%\end{prop}
%
%\begin{mproof}
%
%We consider again the functions $u_n$ as defined in \cite{gilardi}, page 22, equation (54).
%
%Thanks to the smoothness of $u_n$ and $f$, which are both $H^1$ in time, we can conclude that $u_n \in H^2(I,V_n)$, due to a bootstrapping argument from equation (56) of \cite{gilardi}.
%
%So, upon differentiation, we get that $\langle u_n'', v_n\rangle_{V^*,V} + \langle A u_n', v_n\rangle_{V^*,V} = \langle f', v_n \rangle_{V^*,V}$ for almost every $t$ (actually, for all $t$). Anyhow, thanks to the smoothness of $u_n'$, we can substitute it as $v_n \in V_n$ and integrate from $0$ to $t$ to obtain:
%
%\begin{align*}
%\int_0^t \langle u_n'', u_n'\rangle_{V^*,V} + \int_0^t\langle A u_n',u_n'\rangle_{V^*,V} = \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Equivalently, being $u_n'(t) \in H$, we can write:
%
%\begin{align*}
%\int_0^t (u_n'', u_n')_H + \int_0^t\langle A u_n',u_n'\rangle_{V^*,V} = \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Using the assumptions on $A$:
%
%\begin{align*}
%\int_0^t (u_n'', u_n')_H + \alpha \int_0^t \VN{u_n'}^2 - \lambda \int_0^t \HN{u_n'}^2 \leq \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Therefore:
%
%\begin{align*}
%\frac{1}{2} \HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \frac{1}{2} \HN{u_n'(0)}^2+ \lambda \int_0^t \HN{u_n'}^2 +\frac{1}{2\alpha} \int_0^t \VSN{ f'}^2+ \frac{\alpha}{2}\int_0^t \VN{u_n'}^2
%\end{align*}
%
%We need to estimate the $H$ norm of $u_n'(0)$, for which the compatibility condition on $f(0)$ is essential.
%
%In fact, because the ODE for $u_n$ held a.e., and now that $u_n' \in H^1(I,V)$, the ODE holds for all times and we can conclude that $(u_n'(0),u_n'(0))_H + \langle A u_n(0), u_n'(0)\rangle_{V^*,V} = ( f(0), u_n'(0))_H$. Here comes in handy the fact that $u_0=0$, so that $u_n(0)=0$ too and therefore $\HN{u_n'(0)}^2  \leq 2^{-1}\HN{f(0)}^2 + 2^{-1} \HN{u_n'(0)}^2$ and therefore, $\HN{u_n'(0)}^2\leq \HN{f(0)}$.
%
%With this bound:
%
%\begin{align*}
%\HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \HN{f(0)}^2+ 2\lambda \int_0^t \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%\underline{The $L^\infty$ estimate}
%
%Gronwall's lemma (in the form of \cite{gilardi} at page 19) yields:
%
%\begin{align*}
%\HN{u_n'(t)}^2 \leq \exp(2\lambda T) \left (  \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2\right )
%\end{align*}
%
%This alone doesn't show that $u'\in L^\infty(I,H)$, but if this was true, and is $u_n'(t)\rightarrow_H u'(t)$ for a.e. $t$ modulo subsequences, then this would yield the required estimate on the norm.
%
%Now, $u_n, u_n' \rightharpoonup_H u, u'$ (where $u'$ is the $L^2(I,H)$ representative of the derivative of $u$ in the distributional sense, see the proof of \cref{thm:reg_time}). This is true modulo a common subsequence
%
%%, but since we also know the boundedness of $u_n, u_n' $ in $L^2(I,H)$ (cfr the proof of \cref{thm:reg_time} and page 23 of \cite{gilardi}), we conclude the convergence of the full sequences.
%
%Because $u_n', u'$ are the $L^2(I,H)$ sense derivatives of $u_n, u$ (thanks to the injectivity of $H^* \emb V^*$), then, by the compactness theorem 2.1 at page 271 of \cite{navier_stokes} with $X_0=X=X_1=H$ we conclude that $u_n \rightarrow u$ strongly in $L^2(I,H)$. Thanks to proposition 2.13 at page 10 of \cite{kreuter}, $u_n\rightarrow_H u$ for a.e. $t$, modulo a further subsequence.
%
%The bound shown above implies that $u' \in L^\infty(I,H)$ as we wished. 
%
%\underline{$u' \in L^2(I,V)$}
%
%
%We know:
%
%
%\begin{align*}
%\HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2+ 2\lambda \int_0^t \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%so that:
%
%
%\begin{align*}
%\alpha \int_0^T \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2+ 2\lambda \int_0^T \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%But the proof of \cref{thm:const_track} says (cfr. \cref{eqn:weak_der_bound}):
%
%\begin{align*}
%\frac{1}{2}\int_0^t\HN{u_n'}^2+\frac{\alpha}{4}\VN{u_n(t)}^2\leq \\
%\frac{\lambda}{2}\HN{u_n(t)}^2 + \frac{1}{2}\norm{f'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{8+\alpha}{2\alpha}\norm{f}_{L^\infty(I,V^*)}^2\\
%\end{align*}
%
%In particular:
%
%\begin{align*}
%2\lambda\int_0^T\HN{u_n'}^2\leq \\
%4 \lambda \left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2\\
%\end{align*}
%
%so that:
%
%\begin{align*}
%\alpha \int_0^T \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2+\\
%4 \lambda \left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%As we have already seen (or as it is explained at page 23 of \cite{gilardi}), the term in the brackets is bounded above.
%
%%Now, remember that $u_n$ was bounded in $L^2(I,V)$, and that any weakly convergent subsequence would solve the parabolic problem. Thus, $u_n \rightharpoonup u$ in $L^2(I,V)$ (cfr. page 23 in \cite{gilardi}).
%
%Morevoer, we showed in the proof of \cref{thm:reg_time} that $u_n'$ is bounded in $L^2(I,H)$, and that any weakly convergent subsequence would reach $u'$, thus yielding the weak convergence of the full sequence.
%
%
%Also we now have that $u_n'$ is bounded in $L^2(I,V)$, thus admitting a weakly convergent subsequence to $w$, in $L^2(I,V)$. Because it is implied the weak convergence in $L^2(I,H)$, to $w$, we obtain that $w=u' $. Reiterating the argument and thanks to the boundedness of the full sequence, the full sequence must converge weakly in $L^2(I,V)$ to $u'$.
%
%By lower semicontinuity of the norm:
%
%\begin{align*}
%\alpha \int_0^T \VN{u'}^2 \leq \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2+\\
%4 \lambda \limsup_n\left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%Remembering \cref{eqn:limsup}:
%
%\begin{align*}
%\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )\leq\\
%C C_0 \alpha^{-1}\norm{f}^2_{L^2(I,V^*)}
%\end{align*}
%
%
%where $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$ and $C$ is a purely numeric constant without dependences on the problem, so that:
%
%\begin{align*}
%\int_0^T \VN{u'}^2 \leq \\ \frac{1}{\alpha } \HN{f(0)}^2 + C_1\norm{f}_{H^1(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha^2}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%for $C_1:=\alpha^{-2} + 4 \lambda C C_0 \alpha^{-2} + 2\lambda\alpha ^{-1} $.
%
%Because the embedding $H\emb V$ is injective, $u'$ is also the weak derivative, $L^2(I,V)$ sense, of $u \in L^2(I,V)$, so that $u \in H^1(I,V)$. And thus, thanks to theorem 2 at page 286 of \cite{evans}, we obtain $u \in C([0,T]; V)$.
%
%\end{mproof}

\section{Application to inhomogeneous parabolic problems}

\subsection{Inhomogeneous Dirichlet problem}
\label{subs:inh_diri}

We make the following assumption.

\begin{ass}[Assumptions for \cref{pb:diri}]
\label{ass:diri}
We assume $\Omega \cc D $ to be bounded Lipschitz domains, so that $U:=D\setminus \Omega$ is bounded Lipschitz too and  the trace operator is bounded surjective onto $H^{1/2}(\partial U)$, with a right inverse $E$ (see theorem 3.37 at page 102 of \cite{mclean}). For such a choice we also have $H^1_0=H^1\cap \text{ker }\tr$, see \cite{leoni}, page 595, theorem 18.7.

Moreover, we select $f \in H^1(I, H^{1/2}(\Gamma_f))$, $f(0)=0$.
\end{ass}

Note that, given a bounded extension operator $E: H^{1/2}(\partial U) \rightarrow H^1(U)$, we obtain by \cref{lemma:bochner_Hk_map} that $Ef \in H^1(I, H^1(U))$. We have defined $\tr u (t):= tr(u(t))$ and analogously $Eu(t):=E(u(t))$ (see \cref{prop:trace}).

Call $H=L^2(U)$, $V=\{ v \in H^1(U), \tr u = 0 \text{ on } \Gamma_m\}=:H^1_{0,m}$. $V$ is a closed subspace of $H^1$, which is Hilbert separable, hence also Hilbert separable. We norm it with the full $H^1$ norm. Because $H^1_0(U)$ is dense in $H$, so is $V$ and we obtain a Gelfand triple. 

%That $V$ is a closed subspace of $H^1$ follows from the observation that if $u_n\rightarrow u$ in the $V$ norm, then $\tr u_n \rightarrow \tr u$ in $L^2(\partial U)$. We can take an almost everywhere pointwise convergent sequence, so that $\tr u_n \rightarrow \tr u$ a.e., and by the fact that $\Gamma_m$ has positive Hausdorff measure, we conclude $\tr u = 0$ on $\Gamma_m$.

We define $A$ by $(Au)v:=\int_u\nabla u \nabla v$.

The problem under consideration is the following. For $U = D\setminus \Omega$ we have:

\begin{pb}[Inhomogeneous heat equation, Dirichlet conditions]
\label{pb:diri}
\begin{align}
u_t - \Delta u = 0 \text{ in } (0,T)\times U\\
u(\Sigma_f)=f\\
u(\Sigma_m)=0\\
u(0)=0
\end{align}

By this we mean:

\begin{align}
u \in W(I,H^1_{0,m}) \\
u_t|_{H^{-1}} + A u = 0 \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
\tr u = f \text{ on } \Sigma_f\\
u(0)=0
\end{align}

\end{pb}

\begin{thm}[Well posedness and regularity for \cref{pb:diri}]
\label{prop:diri_wp}
Given \cref{ass:diri}, the solution $u$ to \cref{pb:diri} is unique with $u_t \in L^2(I,H)$. 

%The uniqueness holds in more generally in $L^2(I,V)\cap H^1(I, H^{-1})$.

The problem is equivalent to:

\begin{pb}[Equivalent formulation with extension]
\label{pb:diri_ext}
\begin{align}
\delta \in W(I,H^1_0) \\
\delta' + A \delta = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
\delta(0)=0
\end{align}
\end{pb}

with $\bar{u}$ any given $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. This means that $u$ solves \cref{pb:diri}, then $u-\bar{u}$ solves \cref{pb:diri_ext}, and if $\delta(\bar{u})$ solves  \cref{pb:diri_ext}, then $\bar{u}+\delta(\bar{u})$ solves \cref{pb:diri}.

Furthermore: 

\begin{align}
\norm{u}^2_{C([0;T],H)}+\norm{u}_{L^2(I,H)}^2+ \norm{\nabla u}_{L^2(I,H)}^2 + \norm{u'}^2_{L^2(I,H)}\leq C(T)\norm{\bar{u}}_{H^1(I,V)}^2
\end{align}

with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.

\end{thm}
\begin{mproof}

\underline{Extension of the boundary data}

Let $\bar{u}\in H^1(I,H^1_{0,m}(U))$ be such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. We can choose for instance $E\tilde{f}$, see \cref{prop:trace}, where $\tilde{f}=0$ on $\Sigma_m$, $\tilde{f}=f$ on $\Sigma_f$. $\tilde{f} \in H^1(I,H^{1/2}(\partial U))$, because $\Gamma_f$ and $\Gamma_m$ have positive distance (see the definition of the norm in \cite{grisvard}, page 20).  

\underline{Reformulation (first part)}

We consider the problem: 

\begin{align}
\delta \in W(I,H^1_0) \\
\delta' + A \delta = -(f_1+f_2) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
\delta(0)=0
\end{align}

Here, $f_1:= u_t \in L^2(I,H)$. Moreover, $A \in L(V, H^{-1})$, so, by \cref{lemma:bochner_Hk_map}, $f_2:=A\bar{u} \in H^1(I, H^{-1})$.

\underline{Existence}

By \cref{thm:const_track} we get a solution of the above problem with $\delta' \in L^2(I, H)$, which is easily seen to satisfy \cref{pb:diri}. 

\underline{Uniqueness}

For two solutions $u_1, u_2$ of $\cref{pb:diri}$ we can form $d:=u_1-u_2\in W(I,H^1_0)$. Clearly, $d(0)=0$. Moreover, $d' - Ad = 0$. 
By uniqueness stated in \cref{thm:well_pos_parabolic} we obtain $d=0$ in $L^2(I,H)$, so that the solution is unique and doesn't depend on the choice of the extension of the Dirichlet datum.

\underline{Reformulation (part 2)}

Therefore $u=\bar{u}+\delta$ above is the unique solution of \cref{pb:diri}. So, given any $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$, we can construct $\delta$ as above and get $u=\bar{u}+\delta$ solving \cref{pb:diri}.

Viceversa, let $u$ solve \cref{pb:diri}. Call $\delta = u- \bar{u}$. Then, as seen above, $\delta \in W(I,H^1_0)$ and it is readily seen that $\delta$ solves \cref{pb:diri_ext}.

%\begin{itemize}
%\item $u_0 \in L^2(I,H^1_0)$
%\item $u_0' \in L^2(I,V^*)+L^2(I,H)\subseteq L^2(I,H^{-1})$
%\item $u_0(0)=0$ in $H$
%\item $u_0$ solves $u_0' + A u_0 = -((\bar{u}',\cdot)_H+\langle A \bar{u},\cdot\rangle_{H^{-1},H^1_0})$
%\end{itemize}

\underline{Regularity}

Let $u=\bar{u}+\delta$ be the unique solution, as before, of \cref{pb:diri}. But $u' = \bar{u}'+\delta'$, proving the additional time smoothness claim.

\underline{Stability}

Let $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. Then $u=\bar{u}+\delta$. The desired estimate follows by such splitting and upon applying \cref{thm:const_track} to $\delta$. Note that we norm $H^1_0$ with the full $H^1$ norm, and that we can choose $\alpha = \lambda = 1$.
\end{mproof}

\subsection{Inhomogeneous Neumann-Dirichlet problem}

We make the following assumption.

\begin{ass}[Assumptions for \cref{pb:diri}]
\label{ass:neu}
We keep \cref{ass:diri} (apart from the Dirichlet datum). We consired $g \in H^1(I, L^2(\Gamma_f))$, $g(0)=0$.
\end{ass}

Again, call $H=L^2(U)$, $V=\{ v \in H^1(U), \tr u = 0 \text{ on } \Gamma_m\}=:H^1_{0,m}$. $H,V$ induce a Gelfand triple as seen before. 


The problem under consideration is:

\begin{pb}[Inhomogeneous heat equation, Neumann conditions]
\label{pb:neu}
\begin{align}
u_t - \Delta u = 0 \text{ in } (0,T)\times U\\
\partial_\nu u(\Sigma_f)=g\\
u(\Sigma_m)=0\\
u(0)=0
\end{align}

By this we mean:

\begin{align}
u \in W(I,H^1_{0,m}) \\
u_t + A u = G \text{ in } V^* \text{ and for a.e. } t \in (0,T) \\
u(0)=0
\end{align}

where $\langle G(t), v \rangle_{V^*,V}:=\int_{\Gamma_f} g(t)\tr v d\sigma$, $\sigma$ the $1$-codimensional Hausdorff measure, and $A$ was introduced before in $L(V,H^{-1})$.

\end{pb}

Note, by \cref{lemma:bochner_Hk_map}, $G \in H^1(I,V^*)$. Moreover, $\langle A v, v \rangle_{V^*,V}+ 1 \cdot \HN{v} = 1\cdot \norm{V}$, so that we can immediately conclude:

\begin{thm}[Well posedness and regularity for \cref{pb:neu}]
\label{prop:wp_neu}
Given \cref{ass:neu}, the solution $u$ to \cref{pb:neu} is unique with $u_t \in L^2(I,H)$.

Furthermore: 

\begin{align}
\norm{u}^2_{C([0;T],H)}+\norm{u}_{L^2(I,H)}^2+ \norm{\nabla u}_{L^2(I,H)}^2 + \norm{u'}^2_{L^2(I,H)}\leq C(T)\norm{g}_{H^1(I,L^2(\Gamma_f))}^2
\end{align}

with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.
\end{thm}
\begin{mproof}

It is an application of \cref{thm:well_pos_parabolic}, \cref{thm:const_track} and \cref{thm:const_track}.
\end{mproof}

\subsection{Space-time regularity for a more general problem}

Here, we build on the results of the last subsections, and prove higher spatial and time regularity, under suitable smoothness assumptions.

The overall problem, comprehensive of both \cref{pb:diri} and \cref{pb:neu}, is:

\begin{pb}[Inhomogeneous heat equation, general case]
\label{pb:mix}
\begin{align*}
u_t - \Delta u = f \text{ in } (0,T)\times U\\
\partial_\nu u(\Sigma_N)=g_N\\
u(\Sigma_D)=g_D\\
u(0)=u_0
\end{align*}

Calling $V:=H^1_{0,m}(U)$ (see \cref{ass:neu}), and $H=L^2(U)$, we mean:

\begin{align*}
u \in W(I,H^1) \\
u_t + A u = f + G \text{ in the sense of } V^* \text{ and for a.e. } t \in (0,T) \\
\tr u =g_D \text{ on } \Sigma_D\\
u(0)=u_0
\end{align*}

where $\langle G(t), v \rangle_{V^*,V}:=\int_{\Gamma_N} g(t)\tr v d\sigma$, $\sigma$ the $1$-codimensional Hausdorff measure.

\end{pb}

It is known that global-in-time regularity of solutions to parabolic equations depends on the satisfaction of certain compatibility conditions by the boundary data and the source term, see \cite{lions}, chapter 2, for instance. Taking these into account, in a situation of minimal regularity on the problem data, is beyond the scope of this work: we will see that assuming more regularity on the data, it is possible to obtain higher regularity of the solution in a fairly easy way.

\begin{ass}[Basic assumption for \cref{pb:mix}]
\label{ass:basic_par_mix}
\textcolor{white}{ }
\begin{enumerate}
	\item $u_0 \in H^1(U)$
	\item $\Omega \cc D$ are bounded Lipschitz domains
	\item $A: H^1 \rightarrow (H^1)^*$, $(Au)v = \int_U \nabla u \nabla v$
	\item $g_D \in H^1(I, H^{1/2}(\Gamma_D))$. Here $\Gamma_D\neq \emptyset$ is either $\partial U, \partial D $ or $\partial \Omega$, with $g_D(0) = u_0$ on $\Gamma_D$
	\item $g_N \in H^1(I, L^2(\Gamma_N))$, where $\Gamma_N = \partial U \setminus \Gamma_D$
	\item $f \in L^2(I, H)$
\end{enumerate}
\end{ass}

\begin{ass}[Time regularity assumption for \cref{pb:mix}]
\label{ass:time_reg_mix}

Let $k\geq 1$, consider any splitting $u = \bar{u} + \delta$, where, similarly to \cref{pb:diri_ext}, $\bar{u}$ extends the Dirichlet data.

We ask, aside from \cref{ass:basic_par_mix}:

\begin{enumerate}
%	\item $\partial U \in C^{1,1}$
	\item $g_D \in H^{k+1}(I, H^{1/2}(\Gamma_D))$
	\item $g_N \in H^{k}(I, L^2(\Gamma_N))$
	\item $f \in H^k(I, H)$
	\item $g_j(\delta)  \in V$, for $j=0,...,k-1$, where $g_j(\delta)$ are the terms $g_j$ of \cref{prop:time_reg}, for the equation satisfied by $\delta$
	\item $g_j(\delta) \in H$
%	\item $A^lf^{(j-l-1)}(0) \in V$, for $j=1,...,k-1$ and for $l=1,...,j$, and $f^{(j-1)}(0)\in H^1(U)$ with $f^{(j-1)}(0) = g_D^{(j)}(0)$ on $\Gamma_D$, for $j = 1, ..., k-1$ (\textcolor{red}{also wrong})
\end{enumerate}
\end{ass}

\begin{ass}[Additional time regularity assumptions]
\label{ass:add_time_reg_mix}
Apart from \cref{ass:basic_par_mix} and \cref{ass:time_reg_mix}, suppose that, for $k\geq 1$, there holds:

\begin{itemize}
	\item $g_N \in H^{k+1}(I, L^2(\Gamma_N))$
	\item $g_k(\delta)  \in V$
\end{itemize} 
\end{ass}


\begin{ass}[Spatial regularity assumptions]
\label{ass:space_reg_mix}
Let \cref{ass:basic_par_mix} for $k=0$, and also \cref{ass:time_reg_mix} and \cref{ass:add_time_reg_mix} hold for $k\geq 1$. Further assume:

\begin{itemize}
	\item $\partial U \in C^{1,1}$
	\item $g_D \in H^k(I,H^{3/2}(\Gamma_D))$
	\item $g_N \in H^k(I,H^{1/2}(\Gamma_N))$
\end{itemize}

\end{ass}


\begin{thm}[Regularity results for \cref{pb:mix}]
\label{thm:mix_reg}

Under \cref{ass:basic_par_mix}:

\begin{itemize}
	\item there exists a unique $u \in W(I,H^1(U))$ solution to \cref{pb:mix}
	\item for such $u$ there holds $u' \in L^2(I,L^2(U))$ with:
	\begin{align*}
	\norm{u}^2_{L^2(I,H)}+\norm{\nabla u}^2_{L^2(I,H)} + \norm{u'}^2_{L^2(I,H)} \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))}   + C(U) \norm{g_D}^2_{H^1(I,H^{1/2}(\Gamma_D))} + \norm{u_0}^2_{H^1(U)}\right )
\end{align*}
\end{itemize}

Under \cref{ass:time_reg_mix} have that $u \in H^k(I,V)\cap ( H^{k+1}(I,V) + H^{k+1}(I,V^*))$.


Under \cref{ass:add_time_reg_mix}, $u^{k+1} \in H^1(I,H)$, or $u \in H^{(k+1)}(I,H)$, and, for $1\leq j \leq k$:

\begin{align*}
	\left\{\begin{matrix}
(u^{(j+1)},v)_H + (\nabla u^{(j)}, \nabla v)_H = ( f^{(j)}, v)_H + (g_N^{(j)}, v)_{L^2(\Gamma_N)} \\
u^{(j)}(0)  \in H^1(U) \\
\tr u^{(j)}(\Sigma_D) = g_D^{(j)}
\end{matrix}\right.
\end{align*}


Finally, if \cref{ass:space_reg_mix} holds, then $u \in H^{k}(I,H^2(U)) \cap H^{k+1}(I,H)$.

\end{thm}

\begin{mproof}

\underline{Well-posedness, stability}

Existence and uniqueness follow with similar arguments as in the previous subsections.
In particular, $u=G_D + \delta$, where $G_D=\bar{u}$ is (for a.e. $t$), an extension of $g_D$. Using the results of trace theory we know, in particular, that $G_D \in H^1(U)$ with $\norm{G_D}_{H^1}\leq C(U) \norm{g_D}_{H^{1/2}(U)}$.

$\delta \in W(I,V) \cap H^1(I,H)$ is the solution to:

$$
\left\{\begin{matrix}
(\delta_t,v)_H + (\nabla \delta, \nabla v)_H = (f - \partial_t G_D,v)_H + (g_N,v)_{L^2(\Gamma_N)} \text{ for all } v \in V\\ 
\delta(0) = u_0 - G_D(0) \in V
\end{matrix}\right.
$$

Note that $G_D(0)$ makes sense, being $g_D \in C([0,T], H^{1/2}(\Gamma_D))$ and $g_D \mapsto G_D$ is linear bounded, so that we can apply \cref{lemma:bochner_Hk_map}.

We can therefore deduce the estimate:

\begin{align*}
	\norm{u}^2_{L^2(I,H)}+\norm{\nabla u}^2_{L^2(I,H)} + \norm{u'}^2_{L^2(I,H)} \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))}  + \norm{G_D}^2_{H^1(I,H^1(U))}\right )  \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))} + C(U) \norm{g_D}^2_{H^1(I,H^{1/2}(\Gamma_D))} + \norm{u_0}^2_{H^1(U)}\right )
\end{align*}

%\underline{Regularity: compatibility relations}
%%
%%We note that for $\partial U$ this smooth we can apply the trace theory stated in theorem 1.5.1.2, page 38, \cite{grisvard}. 
%%
%%We can therefore solve the problem: 
%%
%%$$
%%\left\{\begin{matrix}
%%-\Delta G_N(t) = 0 & \text{ in } U\\ 
%%\partial_\nu G_N(t) = g_N(t) & \text{ on } \Gamma_D\\ 
%%G_N(t) = 0 & \text{ on } \Gamma_D
%%\end{matrix}\right.
%%$$
%%
%%and obtain $G_N \in H^2(U)$, with $\norm{G_N}_{H^2(U)}\leq C(U) \norm{g_N}_{H^{1/2}(\Gamma_N)}$ (see also the regularity results in chapter 2 of \cite{grisvard}).
%%
%%Therefore, for $v \in H^1_c(U)$ (which means that $v=0$ on $\Gamma_D$):
%%
%%\begin{align*}
%%	\int_{\Gamma_N} g_N v d\sigma = \int_{\Gamma_N} \partial_\nu G_N v d\sigma = \int_U v \Delta G_N + \int_U \nabla G_N \nabla v = \int_U \nabla G_N \nabla v
%%\end{align*}
%%
%%Calling $\gamma := \delta - G_N$ we conclude that:
%%
%%$$
%%\left\{\begin{matrix}
%%(\gamma_t,v)_H + (\nabla \gamma, \nabla v)_H = (f-\partial_t G_D - \partial_t G_N, v)_H \\
%%\gamma(0) = u_0 - G_D(0) - G_N(0) \in V
%%\end{matrix}\right.
%%$$
%%
%%where the initial condition holds because $G_N=0$ on $\Gamma_D$.
%
%$F:=(f-\partial_t G_D, \cdot)_H + (g_N, \tr(\cdot))_{L^2(\Gamma_N)}$ is, thanks to the smoothness assumptions, in $H^k(I,V^*)$. We apply \cref{prop:time_reg}, to the problem:
%
%$$
%\left\{\begin{matrix}
%(\delta_t,v)_H + (\nabla \delta, \nabla v)_H = (F, v)_H \\
%\delta(0) = \delta_0 \in V
%\end{matrix}\right.
%$$
%
%for $\delta_0 = - G_D(0)$.
%
%We check its hypothesis, for $k\geq 1$.
%
%In particular $F^{(k-1)} = (f^{(k-1)} - G^{(k)}_D, \cdot)_H +(g_N^{(k-1)}, \tr(\cdot))_{L^2(\Gamma_N)}$.
%
%Because $f\in H^k(I,H)$, and $g_N, G_D \in  H^{k+1}(I,H^{1/2}(\Gamma_D)), H^{k+1}(I,H^1(U))$, we can define $F^{(k-1)}(0)$, which is $F^{(k-1)}(0) = (f^{(k-1)}(0) - G^{(k)}_D (0), \cdot)_H +(g_N^{(k-1)}(0), \tr(\cdot))_{L^2(\Gamma_N)}$. As $g_N^{(k-1)}(0) = 0$, we get:
%
%\begin{align*}
%	F^{(k-1)}(0) = (f^{(k-1)}(0) - G^{(k)}_D (0), \cdot)_H
%\end{align*}
%
%We now compute the terms $g_k$.
%
%We have $g_k = \sum_{j=0}^{k-1}(-1)^j A^j F^{(k-j-1)}(0) + (-1)^k A^k( - G_D(0))$, $g_0 = -G_D(0)$.
%
%
%Note, $AG_D(v) = (\nabla G_D, \nabla v )=0$ for $v \in V$. Therefore, $A^jG_D(0)=0$ and we get to $g_k = \sum_{j=0}^{k-1}(-1)^j A^j F^{(k-j-1)}(0)$, $k \geq 1$.
%
%Let's start to check that $g_k \in H$. To do so, note that for $j=0, ..., k-1$ we have that $A^j F^{(k-j-1)}(0) = A^j f^{(k-j-1)}(0)  -A^j G^{(k-j)}_D (0)$.
%
%So, for $j=0$: $A^j F^{(k-j-1)}(0) = f^{(k-1)}(0)  - G^{(k)}_D (0)$, whereas for $j\geq1$: $A^j F^{(k-j-1)}(0) = A^jf^{(k-j-1)}(0)  -A^{j-1} A G^{(k-j)}_D (0)$.
%
%Because $f \in H^k(I,H), G_D \in H^{k+1}(I, H^1(U))$, the term for $j=0$ is in $H$.
%
%For $j\geq1$. Note that, by calling $h: H^{1/2}(\Gamma_D)\rightarrow H^1(U)$ the operator $g_D\mapsto G_D$, thanks to the assumption $g_D \in H^{k+1}(I, H^{1/2}(\Gamma_D))$ and to \cref{lemma:bochner_Hk_map}, we have $\partial_{t^k} h g_D = h \partial_{t^k} g_D$, so that $A G^{(j)}_D = 0$, for all $t$ and all $j\leq k$. Therefore $A^{j-1} A G^{(k-j)}_D (0)=0$ for $j\geq 1$ without other assumptions, and we have to ask for $ \sum_{j=1}^{k-1}(-1)^j A^j F^{(k-j-1)}(0) = \sum_{j=1}^{k-1}(-1)^jA^j(f^{(k-j-1)}(0))\in H$.
%
%It now remains to ask that $g_j \in V$ for $j=1,...,k-1$.
%
%We have $g_j = \sum_{l=0}^{j-1}(-1)^l A^l F^{(j-l-1)}(0)$, for $j=1,...,k-1$, and, as seen before, $AG_D^{(j-l)}=0$, so that we must ensure:
%
%\begin{align*}
%	f^{(j-1)}(0) - G_D^{(j)}(0) + \sum_{l=1}^{j-1}(-1)^l A^l f^{(j-l-1)}(0)  \in V
%\end{align*}
%
\underline{Regularity: time smoothness}

So, \cref{prop:time_reg} ensures then that $\delta \in H^k(I,V)$, $\delta^{(k+1)} \in L^2(I,V^*)$. Because we $G_D \in H^{k+1}(I,H^1(U))$ by our assumptions and \cref{lemma:bochner_Hk_map} we obtain that $u = G_D + \delta$ is in $H^{k+1}(I,H^1(U)) + H^{k+1}(I,V^*)$ and in $H^k(I,H^{1}(U))$.

\underline{Regularity: time smoothness again}

By \cref{prop:time_reg} we also have:

\begin{align*}
\left\{\begin{matrix}
\langle \partial_t \delta^{(k)},v\rangle_{V^*,V} + (\nabla \delta^{(k)}, \nabla v)_H = \langle F^{(k)}, v\rangle_{V^*,V} \\
\delta^{(k)}(0) = g_k \in H
\end{matrix}\right.
\end{align*}

The right hand side $F^{(k)} = (f^{(k)} - G^{(k+1)}_D, \cdot)_H +(g_N^{(k)}, \tr(\cdot))_{L^2(\Gamma_N)}$ is now an element of $L^2(I,H) + H^1(I,V^*)$, meaning that we can apply \cref{thm:const_track} to obtain $\delta \in H^{k+1}(I,H)$, provided that we ask for $g_k \in V$.

With analogous reasoning to \cref{prop:diri_wp} we conclude that $u \in H^{(k+1)}(I,H)$, and, for $1\leq j \leq k$:

\begin{align*}
	\left\{\begin{matrix}
(u^{(j+1)},v)_H + (\nabla u^{(j)}, \nabla v)_H = ( f^{(j)}, v)_H + (g_N^{(j)}, v)_{L^2(\Gamma_N)} \\
u^{(j)}(0) = g_k + G_D^{(j)}(0)  \in V \\
\tr u^{(j)}(\Sigma_D) = g_D^{(j)}
\end{matrix}\right.
\end{align*}

\underline{Spatial regularity}

This last equation reads also:

\begin{align*}
\left\{\begin{matrix}
- \Delta  u^{(j)} = f^{(j)} - u^{(j+1)} \\
u^{(k)}(\Gamma_D) = g_D^{(k)} \\
\partial_\nu u^{(j)}(\Gamma_N) = g_N^{(j)}
\end{matrix}\right.
\end{align*}

This holds for $0\leq j \leq k$, and for a.e. $t \in I$.

$H^2$ regularity results that can be found in chapter 2 of \cite{grisvard} let us conclude the proof.
\end{mproof}

\section{Reformulation of parabolic equations}

We just saw that the two parabolic equations of interest can be recasted into the problem of finding $u\in W(I,V)$, $u(0)=0$, $u_t+Au=f$ for a.e. $t$ in $V^*$, with notation from preceding sections.

In particular, $f \in L^2(I, V^*)$ and so is $Au$ (because $A\in L(V,V^*)$, and by \cref{lemma:bochner_Hk_map}).

Call then $E(u):=u_t+Au-f \in L^2(I,V^*)$ and $W_0(I,V)$ the $W(I,V)$ functions with zero initial value. Then, the differential equation reads $\langle E(u)(t),v\rangle_{V^*,V}=0$ for all $v\in V$, for a.a. $t$, equivalently, $E(u)=0$ for a.a. $t$. Thus, we are interested in the abstract problem:

\begin{pb}[Even more abstract parabolic equation]
\label{pb:more_abstr_par}
Given a function $E: W(I,V)\rightarrow L^2(I,V^*)$, find $u\in W_0(I,V)$, such that $E(u)=0$ for a.a. $t$.
\end{pb}
 
We can view $L^2(I,V^*)\cong L^2(I,V)^*$. Hence $\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=\int_I \langle E(u)(t),v(t) \rangle_{V^*,V} dt$ (see \cite{hinze}, theorem 1.31 at page 39). We are now ready to restrict both state and adjoint space, in view of the proof of \cref{prop:gateaux_diff}.

\begin{defn}[$Q(I,V)$]
\label{def:Q}
We define $Q(I,V)=H^{1,1}=L^2(I,V)\cap H^1(I,H)$, with the norm $\norm{v}_Q^2=\norm{v}_{L^2(I,V)}^2 + \norm{v_t}_{L^2(I,H)}^2$.
\end{defn}

\begin{prop}[Properties of $Q$]
\label{prop:Q}
There holds:
\begin{itemize}
	\item $Q=Q(I,V)$ is Hilbert with $(v,w)_{L^2(I,V)} + (v_t,w_t)_{L^2(I,H)}$ 
	\item $Q(I,V)$ is dense in $L^2(I,V)$
	\item $Q(I,V)\emb C([0,T],H)$
	\item $Q_0(I,V)$ is dense in $L^2(I,V)$, $Q_0(I,V)$ the space of $Q(I,V)$ function with zero initial value
	\item $Q(I,V) = W(I,V)\cap H^1(I,H)$, $Q_0(I,V) =  W_0(I,V)\cap H^1(I,H)$ as sets
	\item integration by parts in time holds: $\ds \int_I(v_t,w)_H = -\int_I(w_t,v)_H +(v(T),w(T))_H-(v(0),w(0))_H$
	\item if $q_n$ is bounded in $Q(I,V)$, then there exists a weakly convergent subsequence $q_k$ such that $q_k\weakc q$ in $L^2(I,H)$, $\partial_i q_k\weakc \partial_i q$ in $L^2(I,H)$ and $q_k'\weakc q'$ in $L^2(I,H)$
\end{itemize}
\end{prop}
\begin{mproof}

%\underline{Completeness}
%
%We have the inclusions $L^2(I,H)\subseteq L^2(I,V)\cap H^1(I,H)\subseteq H^1(I,V)$.
%
%If $q_n$ is Cauchy in $Q$, then it is Cauchy in the individual norms of $ L^2(I,V), H^1(I,H)$, so that $q_n$ convergens to two limits, one in $L^2(I,V)$ and one in $H^1(I,H)$. The convergence is common in $L^2(I,H)$, which implies that the two limits coincide at $q \in Q(I,V)$. The convergence in $Q(I,V)$ of $q_n$ to $Q$ follows from the individual convergences of $q_n, \nabla q_n, q_{nt}$ in $ L^2(I,H), L^2(I,H),L^2(I,H)$.
%

\underline{Continuity}

Follows from the embedding $H^1(I,H)\emb C([0,T],H)$, as seen in \cite{evans}, theorem 2 of page 286.

\underline{Density}

We have $C_c^\infty(I,V) \subseteq Q(I,V) \subseteq L^2(I,V)$. The first inclusion holds because of \cref{prop:weak_class}, so that $C_c^\infty(I,V)\subseteq H^1(I,V)$. Moreover $H^1(I,V)\subseteq  Q(I,V) $ trivially, where the $H^1(I,H)$ derivative is the $H^1(I,V)$ derivative. $C_c^\infty(I,V)$ is dense in $ L^2(I,V)$ by \cite{hinze}, page 39, lemma 1.9. In particular,  $C_c^\infty(I,V) \subseteq Q_0(I,V)\subseteq L^2(I,V)$, and as before, the density result follows.

%\underline{Relationship with $W(I,V)$}
%
%Consider the chain:
%
%\[\begin{tikzcd}
%	V & H & {H^*} & {V^*}
%	\arrow["a", hook, from=1-1, to=1-2]
%	\arrow["r", from=1-2, to=1-3]
%	\arrow["{a^*}", hook, from=1-3, to=1-4]
%\end{tikzcd}\]
%
%where $a$ is the trivial embedding and $r$ the Riesz isomorphism.
%
%We claim that for $v \in Q(I,V)$, then $(a^*ra v)' = a^*r (av)'$, where $av \in H^1(I,H)$. In fact, for $\phi \in C^\infty_c(I)$, we get $\int_I a^*ra v \phi' = \ind{\cref{prop:bochner_bound}} = a^*r\int_I av\phi' = -a^*r\int_I(av)'\phi =-\int_I a^*r(av)' \phi$.
%
%Now, let $u \in W(I,V)$, with $(a^*ra u)' = a^*r h$, $h \in L^2(I,H)$. Then $ a^*r \int_I h \phi = \ind{\cref{prop:bochner_bound}} = \int_I a^*r h \phi  = \int_I (a^*ra u)' \phi =  a^*r (-\int au \phi')$.
%
%We know that $a^*$ is injective and so is $r$, so that $ \int_I h \phi  = -\int_I au \phi'$ as we wanted.
%
\underline{Integration by parts}

We note that $v,w \in Q(I,V)\subseteq W(I,V)$: we can now apply theorem 3.11 at page 148 of \cite{trol}.

\underline{Weak convergence}

At first we note that $\partial_i, \partial_t$ are linear bounded operators from $Q(I,V)$ to $L^2(I,H)$.
Remember that in any case, $V$ is a closed subspace of $H^1$. Then, $\partial_i : V\rightarrow H$ is linear and bounded, because $V$ is bounded by the full $H^1$ norm, as we declared already.
Therefore, by \cref{lemma:bochner_Hk_map}, $\partial_i$ extends to a linear bounded map from $L^2(I,V)$ to $L^2(I,H)$, therefore, to a linear bounded map on $Q(I,V)	$, in the sense of:

\[\begin{tikzcd}
	{Q(I,V)} & {L^2(I,V)} & {L^2(I,H)}
	\arrow["i", hook, from=1-1, to=1-2]
	\arrow["{\partial_i}", from=1-2, to=1-3]
\end{tikzcd}\]

Here, $i$ is the natural injection. Because $q_n$ is bounded in the Hilbert space $Q(I,V)$, it has a weakly convergent subsequence $q_k\weakc q \in Q(I,V)$. Therefore, $\partial_i (i(q_k))\weakc \partial_i (i(q))$ in $L^2(I,H)$. By the Hilbert space property of $L^2(I,H)$ we conclude that $(\partial_i q_k,p)_{L^2(I,H)}\rightarrow (\partial_i q,p)_{L^2(I,H)}$ for all $p \in L^2(I,H)$.

For the time derivative, and the convergence $(q_k,p)_{L^2(I,H)}\rightarrow (q,p)_{L^2(I,H)}$ for all $p \in L^2(I,H)$, we can reason analogously.
\end{mproof}

We can therefore restrict the testing space.

\begin{prop}[Equivalent testing]
\label{prop:eq_test}
Let $E: W(I,V)\rightarrow L^2(I,V^*)$, and $u\in W_0(I,V)$.

Then:

\begin{align*}
E(u)=0 
\iff 
\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=0 \quad \forall v \in L^2(I,V) \text{ or }\forall v \in W^0(I,V) \text{ or } \forall v \in Q^0(I,V) 
\end{align*}

\end{prop}


We have also seen that with smoothness assumption on data (\cref{ass:diri} and \cref{ass:neu}) we obtain that the solutions of \cref{pb:diri}, \cref{pb:neu} have $Q_0(I,V)$ smoothness. 

We can therefore formulate the two partial differential equations directly on $Q_0(I,V)$ as follows.

\begin{align*}
w \in W_0(I, H^1_{0,m}),\bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)\\
w' + A w = (g,\cdot)_{L^2(\Gamma_f)} \text{ in }H^{1*}_{0,m} \text{ and for a.e. } t \in (0,T) \\
v_0' + A v_0 = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) 
\end{align*}

with $\bar{u}$ any given $\bar{u}\in H^1(I,H^1_{0,m})$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$.
We are working under \cref{ass:diri}, \cref{ass:neu}.
Thanks to \cref{prop:eq_form}, by the regularity ensured by \cref{prop:diri_wp}, \cref{prop:wp_neu}, and thanks to \cref{prop:Q}, we get:
\begin{align*}
w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) \\
\int_I ( w' , q)_H+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I (v_0',p)_H + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

where now the derivatives are in the $H^1(I,H)$ sense.

Conversely, a solution $w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) $ to the above problem satisfies $w \in W_0(I, H^1_{0,m}), \bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)$, see \cref{prop:Q}, and the proof of \cref{prop:diri_wp} . And by \cref{prop:Q} at first, and then by \cref{prop:eq_test} we obtain back:

\begin{align*}
w \in W_0(I, H^1_{0,m}),\bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)\\
w' + A w = (g,\cdot)_{L^2(\Gamma_f)} \text{ in }H^{1*}_{0,m} \text{ and for a.e. } t \in (0,T) \\
v_0' + A v_0 = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) 
\end{align*}

Therefore:

\begin{prop}[Equivalent formulation]
\label{prop:eq_form}

Under \cref{ass:diri}, \cref{ass:neu}, \cref{pb:diri}, \cref{pb:neu} can be equivalently formulated as:

\begin{align*}
w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) \\
\int_I ( w' , q)_H+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I (v_0',p)_H + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

Existence, uniqueness and stability proved already in  \cref{prop:diri_wp}, \cref{prop:wp_neu} carry over to this new formulation.

\end{prop}

\chapter{Domains transformations}
\label{chap:domain_transformations}
\section{Transforming domains}

%\begin{prop}[Measurability of composition]
%\label{prop:circ_wd}
%
%Define $\pazocal{M}:=\{\tau: \mR^n \rightarrow \mR^n \text{ Lebesgue measurable } \}/\sim$, the quotient being the almost everywhere equal relation (according to the Lebesgue measure).
%
%Consider also $U$ from $\pazocal M_c :=\{\tau: \mR^n \rightarrow \mR^n \text{ continuous } \}/\sim$, the application "unique continuous representative", and $\pazocal{M}_{BL} :=\{\tau: \mR^n \rightarrow \mR^n \text{ Lipschitz homeomorphism} \}/\sim \subseteq \pazocal{M}_c$.
%
%We can then define $\circ:  \pazocal{M} \times \pazocal{M}_{BL}, \pazocal{M}_c \times \pazocal{M} \rightarrow \pazocal{M}$ by, respectively, $[f]\circ g := [f\circ U(g)], f \circ [g]:= [U(f)\circ g]$. These definitions are well posed.
%
%\end{prop}
%\begin{mproof}
%
%\underline{$\pazocal{M}_c$}
%
%$U(f)$ is Borel measurable, so the preimage of a Borel set is Borel measurable, and $g$ is Lebesgue measurable, so his preimage of such Borel set is Lebesgue measurable (\textcolor{red}{see \href{https://math.stackexchange.com/questions/283443/is-composition-of-measurable-functions-measurable}{here} for the different notions of measurability}).
%
%This shows that $U(f)\circ g$ is measurable.
%
%To complete the well posedness, if $h=g$ a.e., then clearly $U(f)\circ g= U(f)\circ  h$ a.e..
%
%\underline{$\pazocal{M}_{BL}$}
%
%Consider $f\circ U(g)$. We need to prove it is measurable and that is only depends on $[f]$.
%
%For the measurability: the preimage of a Borel set, by $f$, is Lebesgue measurable $L$. $U(g)$ has a Lipschitz inverse, which will map this set to a Lebesgue set. Indeed, $L = B \cup N$, with $B$ Borel and $N$ Lebesgue measurable and null (\textcolor{red}{see \href{https://math.stackexchange.com/questions/3420145/lebesgue-measurable-set-union-of-borel-set-and-null-set}{here}}). Image and unions commute, so, $U(g)^{-1}(L) = U(g)^{-1}(B) \cup U(g)^{-1}(N)$. The first set is Lebesgue measurable by measurability of $U(g)$, the second one is null, because Lipschitz maps map null sets into null sets, see 9.54 at page 271 of \cite{leoni}. 
%
%%Suppose $f,g \in [f]$. Then $f=g$ everywhere but on the null set $E$. Because $\psi \in \cT^1$ we know that $U(\psi)$ is a Lipschitz homeomorphism, so that $U(\psi)^{-1}(E)$ has zero measure by the lemma of Vitali. For the same reason, the composition is measurable, see \cite{murat}, remarque 2.2, page II-7.
%
%\end{mproof}


Throughout, $D$ is a bounded Lipschitz domain. We define as in \cite{murat} the following spaces of transformations:

\begin{defn}[Spaces of transformations]
We define:
\begin{itemize}	
	\item $\cV^k=\{\tau \in \pazocal{M}, \tau-\id \in W^{k,\infty}(\mR^n,\mR^n)\}$, $k\geq 1$
%	\item $\circ: \cV^1 \times \cV^1 \rightarrow \cV^1$ and $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow W^{1,\infty}(\mR^n,\mR^n)$ by $\tau_1\circ\tau_2 = [U(\tau_1)\circ \tau]$, for any $[\tau]=\tau_2$, $[]$ being an equivalence class according to $\sim$.
	\item $\cT^k=\{\tau \in \cV^k \text{ with an } \eta \in \cV^k, \tau \circ \eta = \eta \circ \tau = \id\}$. Any such $\eta$ is unique, we denote it by $\tau^{-1}$ and we have that $U(\tau)$ is a Lipschitz homeomorphism with $U(\tau^{-1})=U(\tau)^{-1}$
\end{itemize} 
\end{defn}

%\begin{obs}[A technicality]
% \mbox{}\\
%Technically, in the original definition of \cite{murat}, $\tau$ need not to be a continuous function, although this is suggested e.g. in remarque 2.1 at page II-4.  \mbox{}\\
%
%Going to equivalence classes of $\tau$ makes the identification with continuous functions more precise, as we now show.  \mbox{}\\
%
%\underline{One implication} \mbox{}\\
%
%Let $\tau: \mR^n\rightarrow\mR^n$ with $[\tau-\id] \in W^{k,\infty}$. Then $\tau$ is equal a.e. to a (Lebesgue) measurable function, hence also (Lebesgue) measurable, and thus $[\tau] \in \cV^k$ as we have defined it (\textcolor{red}{this is proved \href{https://heil.math.gatech.edu/6337/spring11/section3.4.pdf}{here}; note that $\{g\neq f\}$ is measurable as the Lebesgue measure is complete}). \mbox{}\\
%
%Now, suppose $\tau$ is a bijection, and $[\tau^{-1}-\id] \in W^{k,\infty}$ too. Then $\tau = \id + g = G, \tau^{-1} = \id + h = H$ almost everywhere. Here, $G,H$ are at least Lipschitz.
%But then $\tau \circ H = \id $ a.e., and since $H$ is Lipschitz, we can conclude also $G\circ H = \id$ a.e., so, everywhere. With a symmetric reasoning, we are lead to $G=H^{-1}$, so that $G$ is bi-Lipschitz. \mbox{}\\
%
%Thus, $[\tau]\circ [\tau^{-1}]:=[U(\tau)\circ U(\tau^{-1})] = [G\circ G^{-1}] = \id$ and an analogous reasoning leads to $[\tau] \in \cT^k$ as we have defined it. \mbox{}\\
%
%\underline{The other implication} \mbox{}\\
%
%It is immediate for $\cV^k$ and for $\cT^k$, in the equivalence class of $\tau \in \cT^k$ there is a unique $U(\tau)$ at least bi-Lipschitz, hence invertible, with $[U(\tau)]=\tau$. \mbox{}\\
%
%This shows that:
%
%\begin{enumerate}
%\item $\{\tau: \mR^n\rightarrow\mR^n$ with $[\tau-\id] \in W^{k,\infty}\} / \sim = \cV^k$
%\item $\{\tau: \mR^n\rightarrow\mR^n$ bijection with $[\tau^{\pm 1}-\id] \in W^{k,\infty}\}/\sim = \cT^k$
%\end{enumerate}
%
%\end{obs}
%
%We need to check the well-posedness of $\circ$.
%
%\begin{prop}
%\label{prop:circ_wd_V}
%$\circ: \cV^1 \times \cV^1 \rightarrow \cV^1$ and $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow W^{1,\infty}(\mR^n,\mR^n)$ are well defined.
%\end{prop}
%\begin{mproof}
%
%We start by $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow \cV^1$. We have $\te\circ \tau =[ U(\te)\circ U(\tau)]$ for instance (see \cref{prop:circ_wd}); the latter is a bounded Lipschitz map, so it remains in $W^{1,\infty}$.
%
%For the second claim, just write $\eta \circ \tau -\id = (\eta - \id)\circ \tau + \tau -\id$ and use the first part. 
%
%\end{mproof}


\begin{prop}[Chain rule for $k=1$]
\label{prop:chain}
Let $f \in W^{1,\infty}(\mR^n,\mR^n)$ or $\cV^1$, together with $\psi \in \cT^1$.  Then:

\begin{itemize}

\item $f \circ \psi$ has essentially bounded weak derivatives, and $D(f \circ \psi) = Df \circ \psi D\psi$.

\item  $D(\psi^{-1}) = (D\psi)^{-1} \circ \psi^{-1}$, where $(D(\psi^{-1}))^{-1}:=[(DU(\psi^{-1}))^{-1}]$

\item $|\det(D\psi)|$ is an essentially bounded measurable function with $|\det(D\psi)|\geq \delta>0$ a.e.. 
\end{itemize} 

\end{prop}
\begin{mproof}
See \cite{murat}, lemme 2.1 at page II-6, lemme 4.2, pag. IV-7.

%\underline{Weak derivatives}
%
%We notice that $f \circ \phi$ has a unique Lipschitz representative, that is $U(f)\circ U(\phi)$. The desired formula follows as in \cite{murat}, lemme 2.1 at page II-6, for the classical derivatives, because Lipschitz function are almost everywhere differentiable by the Rademacher theorem (\tred{see \href{https://abel.math.harvard.edu/archive/212b_spring_05/handouts/Rademacher.pdf}{here}}). The chain rule holds for functions differentiable only at one point. 
%
%% (or from \cite{ziemer}, page 53, theorem 2.2.2 in the case of left composition by $ W^{1,\infty}(\mR^n,\mR^n)$ vector fields) (	\tred{this needs the Rademacher theorem, see \href{https://abel.math.harvard.edu/archive/212b_spring_05/handouts/Rademacher.pdf}{here}. The set of differentiability is measurable, see \cite{leoni}, 9.17}).
%
%Now, to identify the weak derivatives:
%
%\begin{itemize}
%	\item $U(f)$ is Lipschitz, so that $DU(f)$, the classical derivative, is also the weak derivative $Df$ (note that $f$ need not to be essentially bounded to state this). The latter is a measurable function, as a.e. limit of difference quotients.
%%	\item $DU(f)\circ U(\psi)$,  as pointed out in \cite{murat}, remarque 2.2, page II-7, is measurable. It is also essentially bounded.
%	\item $DU(f)\circ U(\psi)$, is measurable, see \cref{prop:circ_wd}. It is also essentially bounded.
%	\item By \cref{prop:circ_wd} we observe that $DU(f)\circ U(\psi)$ represents $Df \circ \psi$
%	\item $D\psi = [DU(\psi)]$ as seen above
%	\item the product of equivalence classes is always defined as the product of their representatives
%\end{itemize}
%
%Therefore $ Df \circ \psi D\psi = [DU(f)\circ U(\psi) DU(\psi)]$.
%
%And now, because $f \circ \phi$ is Lipschitz, it has weak derivatives, $D(f \circ \phi)$, equal to the classical derivatives $DU(f\circ \phi) = D (U(f)\circ U(\psi)) = DU(f)\circ U(\psi) DU(\psi)$, where the last equality holds a.e., as mentioned at the beginning of the proof.
%
%This let us conclude the first claim.
%
%\underline{Inverse Jacobian}
%
%For the second one, put $f = \psi^{-1}$. Then, for the classical derivatives, $I = DU(\psi)\circ U(\psi)^{-1} DU(\psi^{-1})$ a.e., so that both $DU(\psi)\circ U(\psi)^{-1}, DU((\psi)^{-1})$ are invertible as matrices, a.e.. 
%
%\underline{Determinant}
%
%We have defined $|\det(D\psi)|:=[|\det DU(\psi)|]$, see \cref{prop:circ_wd}. The claim follows as in lemme 4.2, pag. IV-7 of \cite{murat}, and because $\det$ is a polynomial of essentially bounded functions.
\end{mproof}

We go on to define the space of admissible transformations.

\begin{defn}[Admissible transformations]
\label{def:adm}
We define $\Theta:=\{\theta \in W^{1,\infty}(\mR^n,\mR^n) \text{ with } \theta=0 \text{ on } \mR^n \setminus D\}$, a Banach subspace of $ W^{1,\infty}(\mR^n,\mR^n)$.


We also define $\cT:=\{\tau \in \cT^1, \tau^{\pm 1}|_{\mR^n\setminus D}=\id\}$. 

\end{defn}

\begin{prop}[Some group properties of $\cT$]
\label{prop:group}
Let $\eta, \tau \in \cT, \te \in \Te$. Then:

\begin{itemize}
	\item $\eta \circ \tau \in \cT$
	\item $\te \circ \tau \in \Te$
	\item $\id$ is the neutral element
	\item $\eta^{-1} \in \cT$
\end{itemize}

\end{prop}
%\begin{mproof}
%
%%\underline{Stability under composition (regularity)}
%%
%%We start by showing that $\tau \circ \eta |_D \in W^{2,\infty}$.
%%
%%%By $\tau \in \cV^1$, we sure have that $\tau \circ \eta \in \cV^1$ by \cref{prop:circ_wd_V}. So, 
%%
%%$U(\tau)\circ U(\eta)$, is a bounded Lipschitz function. Morevoer $ D(U(\tau)\circ U(\eta)) = D(U(\tau))\circ U(\eta) DU(\eta) $ everywhere in $D$, because $\eta, \tau$ happen to be in $W^{2,\infty}(D)$, so that $U(\eta), U(\tau) \in C^{1,1}(D)$, see \cref{prop:lip}.
%%
%%This is a product of a bounded Lipschitz function and a bounded Lipschitz function, so it is also bounded Lipschitz. Therefore, $D(U(\tau)\circ U(\eta))\in C^{0,1}(D)$ and thus $U(\tau)\circ U(\eta) \in C^{1,1}_B(D)$, so that by $\cref{prop:lipk}$, $[U(\tau)\circ U(\eta)|_D] = \tau \circ \eta|_D \in W^{2,\infty}(D)$.
%%
%%This same proof shows that for $\te \in \Te$, $\tau \in \cT$, $\te \circ \tau \in \Te$, because $\te \circ \tau$ was already a $W^{1,\infty}$ function by \cref{prop:circ_wd}, and because $\tau$ fixes $\mR^n \setminus D$.
%
%\underline{Stability under inversion}
%
%It is trivial, because the definition of $\cT$ is symmetric with respect to inversion.
%
%\underline{Stability under composition ($\cT^1$)}
%
%$\eta \circ \tau$ is surely in $\cV^1$ by \cref{prop:circ_wd}. Now, by the above point, $\tau^{-1} \circ \eta^{-1}$ is in $\cV^1$ too, and the composition yields: $(\eta \circ \tau)\circ (\tau^{-1} \circ \eta^{-1}) = [U(\eta)\circ U(\tau)]\circ [(U\tau)^{-1} \circ (U\eta)^{-1}] = \id$.
%
%\end{mproof}

\begin{prop}[Small perturbations of $\cT$]
\label{prop:ptb_id}
Let $\te \in \Te$ with small enough $\norm{\te}_{W^{1,\infty}(\mR^n;\mR^n)}$. Then, $\id+\te\in \cT$.

Let $\delta \te \in \Te$ with small enough $\norm{\delta\te}_{W^{1,\infty}(\mR^n;\mR^n)}$, and $\tau \in \cT$. Then, $\tau + \delta \te\in \cT$.

\end{prop}
\begin{mproof}

\underline{Perturbation of identity}

We only need to check the properties of the inverse map.

$\tau^{-1}$ exists and is Lipschitz, see the proof of lemme 2.4 of \cite{murat}, page II-16, so that $\tau \in \cT^1$. The fact that $\tau = \id$ outside of $D$ automatically implies $\tau^{-1}=\id$ outside of $D$.

%Moreover, $D\tau$ is a function in $W^{1,\infty}(D;\mR^{n\times n})$. Because of the Banach algebra properties listed in proposition 2.1 of \cite{murat}, page II-5 (which apply to $D$, just by extending $W^{1,\infty}(D)$ functions to $0$), the theorem of Neumann series holds (for $D\te$!), and by the assumptions on the norm of $\te$ we observe that $D\te$ has a small norm $W^{1,\infty}(D;\mR^{n\times n})$: by $D\tau   = I + D\te$ , we conclude that there is $ S \in W^{1,\infty}(D;\mR^{n\times n})$ with $SD\tau = D\tau S = I$, in the sense of matrix multiplication.
%
%This shows $(D\tau)^{-1} \in W^{1,\infty}(D;\mR^{n\times n})$.
%
%Because $\tau \in \cT^1$, we have from \cref{prop:chain}, that $D\tau^{-1} = (D\tau)^{-1}\circ \tau^{-1}$, so that $D\tau^{-1} $ is the composition of a $W^{1,\infty}(D;\mR^{n\times n})$ by a $\cT$ function. This implies that $\tau^{-1}$ is $W^{2,\infty}(D)$, because $\tau^{-1}$ maps $D$ into $D$.

\underline{Perturbation, not of identity}

We solve the equation $\tau + \delta \te =\eta \circ \tau$, i.e., we define $\eta:=\id + \delta \te \circ \tau^{-1}$. Because $\tau^{-1} \in \cT$ and $\delta \te \in \Te$ we observe that $\delta \te \circ \tau^{-1} \in \Te $, thanks to \cref{prop:group}.

We only need to prove that $\delta \te \circ \tau^{-1}$ is small, and then use the first part. 

But by \cref{prop:chain} this follows immediately.
% One can alternatively apply point i) of lemme 2.2, \cite{murat}.
\end{mproof}

\begin{thm}{Small perturbations of identity, Lipschitz property}
\label{thm:ptb_id_lip}
Let $U\cc D$ be Lipschitz bounded. There exists $0<C(U)<1$ such that, for $\tau \in W^{1,\infty}(\mR^n;\mR^n)$ and $\norm{\tau - \id}_{W^{1,\infty}(\mR^n;\mR^n)}\leq C(U)$, then $T(U)$ is also bounded Lipschitz, where $T$ is $U(\tau)$, the unique Lipschitz continuous representative of $\tau$ (see \cref{prop:lip}).

This result can be applied to, e.g., $\tau \in \cT$ which is a small perturbation of identity in the $W^{1,\infty}$ topology.
\end{thm}

\begin{mproof}
It is done in \cite{bello}, lemma 3, page 629.
\end{mproof}

%\begin{prop}[Gateaux differentiability]
%Consider $J:\cT \rightarrow E$ for $E$ some Banach space.
%
%Let $\tau \in \cT$. Then:
%
%$$ \forall \delta\te \in \Te \text{ exists } \lim_{t\rightarrow 0}\frac{J(\tau + t \delta\te)-J(\tau)}{t} \iff  \forall \delta\te \in \Te  \text{ exists }\lim_{t\rightarrow 0}\frac{J((\id +t \delta \te)\circ \tau)-J(\tau)}{t}$$
%
%In case of existence, we have:
%
%$$ \lim_{t\rightarrow 0}\frac{J((\id +t \delta \te)\circ \tau)-J(\tau)}{t} = \lim_{t\rightarrow 0}\frac{J(\tau + t \delta \te\circ \tau)-J(\tau)}{t}$$
%
%Note that $\id + t \delta \te \in \cT$ for small $t$.
%
%\end{prop}
%
%\begin{mproof}
%
%It suffices to show that $\Te \circ \tau = \Te$.
%
%In fact, $\delta \te \circ \tau \in \Te$ for $\te \in \Te$, as we verified in \cref{prop:group}. Using the same result, $\tau^{-1} \in \cT$, $(\delta \te \circ \tau ) \circ \tau^{-1}  \in \Te$ and $(\delta \te \circ \tau ) \circ \tau^{-1} = [U(\delta \te)\circ U(\tau)]\circ[U(\tau)^{-1}] = [(U(\delta \te)\circ U(\tau))\circ(U(\tau)^{-1})]=\delta \te$.
%
%\end{mproof}
%

\section{Transforming Sobolev spaces}

\begin{thm}[Change of variables]
\label{thm:change}

Let $U$ be open and $\tau = U(\tau)$ for $\tau \in \cT^1$, and let $p \in [ 1,\infty]$. Then:

\begin{enumerate}
	\item $f \in L^p(T(U)) \iff f\circ \tau \in L^p(U)$ and there holds, for $f \in L^p(\tau(U))$:
	$$ \norm{f}_{L^p(\tau(Q))}\leq \left ( \norm{\det D\tau}_{L^\infty(\mR^n)}\right)^{1/p} \norm{f\circ \tau}_{L^p(Q)}$$
	\item $f \in W^{1,p}(\tau(U)) \iff f\circ \tau \in W^{1,p}(U)$ and there holds, for $f\in W^{1,p}(\tau(U))$:
	$$Df \circ \tau = (Df)^{-t}D(f\circ \tau)$$
	$$ \norm{Df}_{L^p(\tau(Q);\mR^n)}\leq \left ( \norm{\det D\tau}_{L^\infty(\mR^n)}\right)^{1/p} \norm{(D\tau)^{-1}}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{D(f\circ \tau)}_{L^p(Q;\mR^n)}$$
	\item if $p \in (1, \infty)$, $f \in W^{1,p}_0(\tau(U)) \iff f\circ \tau \in W^{1,p}_0(U)$
	\item therefore, composition by $\tau$ is a linear isomorphism between $W^{k,p}(\tau(U))\rightarrow W^{k,p}(U)$ for $k=0,1$, and between $W^{1,p}_0(\tau(U))\rightarrow W^{1,p}_0(U)$ for $k=0,1$, $p \in (1, \infty)$
	\item for $D$ a bounded Lipschitz domain and $\cT, \Te$ defined before, we get, for $f \in H^1(D)$, that $\tr_D f = \tr_D(f\circ \tau)$
	\item if moreover, $\Omega, \tau(\Omega) \cc D$ are also bounded Lipschitz domains, letting $U:=D\setminus \Omega$, another bounded Lipschitz domain, for $f \in H^1(\tau(U))$ and $\tr_{\tau(U)} f =0 $ on $ \partial \tau(\Omega) $, then $\tr_{U} f\circ \tau=0$ on $\partial \Omega$ and $\tr_{\tau(U)} f = \tr_{U} f\circ \tau$ on $\partial D$
	\item so, $\circ \tau$ is a linear isomorphism of $H^1_{0,m}(U)$ and $H^1_{0,m}(\tau(U))$ ($H^1_{0,m}$ is defined in \cref{subs:inh_diri} as $\{u \in H^1, u(\Gamma_m)=0$)
\end{enumerate}

\end{thm}

\begin{mproof}

We need to prove only the last points, for the other are proved in \cite{murat}, pages IV.4, IV.5, IV.6.

\underline{Static strace}

Let $f_n \in C(\overline{D})\cap H^1(D)$ converging in $H^1(D)$ to $f$ (see theorem 3.18 of \cite{adams}, page 54). By point 4, we have $f_n \circ \tau\rightarrow f\circ \tau$ in $H^1(D)$ (rememeber, $\tau(D)=D$ by invertibility of $\tau$ and the fact that $\tau(x)=x$ outside of $D$). Therefore we have:

$$\tr_D f \leftarrow_{L^2(\partial D)}\tr(f_n) = f_n|_{\partial D} = (f_n\circ \tau)|_{\partial D}= \tr(f_n \circ \tau)\rightarrow_{L^2(\partial D)} \tr_D(f \circ \tau)$$

\underline{Moving trace}

First of all, as $\tau$ is a homeomorphism of $\mR^{n}$, $\tau U=D\setminus \tau(\Omega)$, $\tau\partial U = \partial D \sqcup \partial \Omega$, $\tau\partial \Omega = \partial \tau \Omega$.
%
Now, an application of \cref{thm:ibp} yields that the zero extension to $\tau\Omega$ of $f$, call it $\bar{f}$, is $H^1(D)$, with $\partial_i \bar{f}=\partial_i f$ in $\tau U$, $0$ in $\tau(\Omega)$.

We have moreover $\tr_D \bar{f} = \tr_{\tau(U)} f|_{\partial D}$ (using approximation arguments based on theorem 3.18 of \cite{adams}, page 54).

Using this: $ \tr_{\tau(U)}f|_{\partial D} = \tr_D \bar{f} = \ind{point 5} = \tr_D(\bar{f}\circ \tau) = \tr_D(\overline{f \circ \tau}) = \tr_U (f\circ \tau)|_{\partial D}$, where we used that $\bar{f}\circ \tau$ is zero in $\tau^{-1}\tau\Omega = \Omega$ (because $\tau$ maps Lebesgue null sets into null sets, being bi-Lipschitz), so it is the zero extension $\overline{f \circ \tau}$ of $f\circ \tau$, and applied the same reasoning as above to conclude $\tr_D(\overline{f \circ \tau}) = \tr_U (f\circ \tau)|_{\partial D}$. Both $\bar{f}\circ \tau$ and $f\circ \tau$ are $H^1$ functions by point 2.

Now that we know that $ \tr_{\tau(U)}f|_{\partial D}  = \tr_U (f\circ \tau)|_{\partial D}$, it is left to show $\tr_U f\circ \tau=0 $ on $\partial \Omega$, via some additional steps.

%In fact, let $\phi \in C^\infty_c(D)$. Then $ \int_D \bar{f}\circ T \phi_{,i} = \int_U  f\circ T \phi_{,i} = \ind{using \cref{thm:ibp}} = \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma -\int_U \partial_i(f\circ T)\phi =  \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma -\int_D \partial_i(\bar{f}\circ T)\phi  =  \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma +\int_D \bar{f}\circ T \phi_{,i}  $.
%
%It follows that $\int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma = 0$ for all $\phi \in C^\infty_c(D)$. Let now $\phi_n \in C^\infty_c(\mR^n)$ approximate $f\circ T$ in $H^1(U)$ as seen above. Choose a cut-off function $\eta$ that is $1$ in a small neighbourhood of $ \Omega$ and $0$ in the complement of $D$ and a small neighbourhood of $\partial_D$. Then $\eta \phi_n$ is in $C^\infty_c(D)$ and:

%$$(\eta \phi_n)|_{\partial \Omega} = \tr_U( \phi_n|_U)_{\partial \Omega} \rightarrow \tr_U(f \circ \tau)_{\partial \Omega}$$
%
%the limit being in $L^2(\partial \Omega)$. Because  $\eta \phi_n$ is in $C^\infty_c(D)$ we can choose it $\phi$ in $\int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma = 0$, yielding:
%
%$$\int_{\partial \Omega}\tr_U(f\circ T) \phi_n \eta \nu_i d\sigma = 0$$ 
%
%This implies, thanks to the boundedness and measurability of $\nu_i$, that:
%
%$$\int_{\partial \Omega}\tr_U(f\circ T)^2\nu_i d\sigma = 0$$

\textit{Multiplication by a $W^{1,\infty}$ function}

For $\psi \in W^{1,\infty}(\mR^n;\mR)$ and $f \in H^1(U)$, $f\psi$ has the same trace as $f$ as long as $\psi = 1$ in a neighbourhood of $\partial U$. This follows again by an approximation argument on $f$ by smooth functions and by \cref{prop:lip}.

%Note that $f\psi \in H^1(U)$ still. Now: approximate $f$ by restriction of test functions $f_n$. Then $f_n \psi$ is $C(\overline{U})\cap H^1(U)$ (thanks also to \cref{prop:lip}), so that $\tr_U(f_n\psi) = \tr_U(f_n)$. Because $f_n \psi \rightarrow f \psi$ is $H^1(U)$ the claim is valid.
%
%This last convergence follows from $\norm{(f_n-f)\psi}_{L^2}\leq \norm{(f_n-f)}_{L^2}\norm{\psi}_{L^\infty}$, the chain rule $\partial_i(f_n\psi)=\partial_i f_n \psi + \partial_i \psi f_n$ (see \textcolor{red}{corollary 4.1.18 \href{https://www.math.stonybrook.edu/~joa/PUBLICATIONS/SOBOLEV.pdf}{here}}) and again $\norm{\partial_i(f_n-f)\psi}_{L^2}\leq \norm{\partial_i(f_n-f)}_{L^2}\norm{\psi}_{L^\infty}$, $\norm{(f_n-f)\partial_i\psi}_{L^2}\leq \norm{(f_n-f)}_{L^2}\norm{\partial_i\psi}_{L^\infty}$.

\textit{Reducing to a function of $0$ trace}

Let $\eta$ be a smooth cut-off function which is $1$ close to $\partial D$ and $0$ close to $\partial \tau\Omega$, $\beta=0$ close to $\partial D$ and $1$ close to $\partial \tau\Omega$. They can be found by e.g. building a suitable partition of unity of the compact sets $\partial \Omega$ and $\partial D$.
$f\beta$ has zero trace, as it can be verified by approximating $f$ by suitable smooth functions $f_n$: 
$\ds\tr_{\tau(U)} f\beta \leftarrow_{L^2(\partial \tau(U))} \tr_{\tau(U)} f_n \beta $
, where the latter quantity is $\tr_{\tau(U)} f_n $ on $\partial \tau(\Omega)$ and $0$ on $\partial D$.
% By restricting the convergence  to first $\partial D$ and then to $\partial \tau(U)$, and using almost everywhere convergent subsequences, we conclude that $\tr_{\tau(U)} f \beta = \tr_{\tau(U)} f $ on $\partial \tau(U)$ and  $\tr_{\tau(U)} f \beta = 0 $ on $\partial D$, i.e.  $f\beta$ has zero trace.

%The same argument yields that $\tr_{T(U)} f \eta = \tr_{T(U)} f $ on $\partial D$ and  $\tr_{T(U)} f \eta = 0 $ on $\partial T(U)$.
%
%Hence $\tr_{T(U)} f |_{\partial T(U)}= \tr_{T(U)} f\beta |_{\partial T(U)}$, with $f\beta$ of zero trace on $T(U)$. 

\textit{Domain transformation}


We have that $\beta \circ \tau +  \eta \circ \tau$ is $W^{1,\infty}$ and $1$ near $\partial U$. 
So, $\tr_U f\circ \tau = \tr_U f\circ \tau(\beta \circ \tau +  \eta \circ \tau) = \tr_U ((f\circ \tau)(\beta \circ \tau)) + \tr_U ((f\circ \tau )( \eta \circ \tau))$.

Approximate $f\circ \tau$ by $g_n$ smooth as seen above.  Then, $\tr_U (g_n \eta \circ \tau)$ is $0$ on $\partial \Omega$ , and  selecting an almost everywhere convergent subsequence, we conclude $\tr_U (f\circ \tau \eta \circ \tau) = 0$ on $\partial \Omega$. 

Finally, $\tr_U f\circ \tau|_{\partial \Omega} = tr_U (f\circ \tau)(\beta \circ \tau)|_{\partial \Omega} =  tr_U ((f\beta) \circ \tau)|_{\partial \Omega}= 0$, where at last we used point $3$ (zero trace functions in $H^1(\tau(U))$, since $\tau(U)$ is assumed to be bounded Lipschitz, are exactly the functions $H^1_0(\tau(U))$ (theorem 18.7 at page 595 of \cite{leoni})).
\end{mproof}

%We need to define the pullback of functionals. 
%
%\begin{ass}[Defining pullbacks]
%\label{ass:pull}
%
%Throughout, $\Omega\cc D$ is another bounded Lipschitz domain, and we assume $\tau \in \cT$ preserves this property, i.e., that $T (\Omega) $ is also bounded Lipschitz, $T=U(\tau)$.
%
%We denote by $V$ either $H^1_0(U)$ or $H^1_c(U)$ (see \cref{subs:inh_diri} for the definition of this space, and by $V_T$ either  $H^1_0(T(U))$ or $H^1_c(T(U))$.
%\end{ass}
%
%\begin{prop}[Pullback]
%\label{prop:pull}
%
%Under \cref{ass:pull}, let $F \in V_T^*$. We define $F\circ T \in V^*$ by:
%
%$$\langle F, v\rangle_{V^*_T,V_T} = \langle F\circ T , |\det(DT)| v\circ T\rangle_{V^*,V}$$
%
%The definition is well posed.
%
%Moreover:
%\begin{itemize}
%\item the maps $V\rightarrow V$, $w\mapsto w|\det(DT)|$, and $S_T: V_T\rightarrow V$, $v \mapsto |\det(DT)| v\circ T$ are linear isomorphisms
%\item taking pullbacks, seen as a map $P_T: V_T^*\rightarrow V^*$, is linear and bounded
%\item we have $P_T = S_T^{-*}$, so that taking pullbacks is also a linear isomorphism
%
%\end{itemize}
%
%
%\end{prop}
%\begin{mproof}
%
%\underline{Existence by density}
%
%Let $H_T \ni f_n \rightarrow F$ in $V_T^*$, possible by density of $H_T=L^2(T(U))$ in $V_T^*$.
%
%By \cref{thm:change} we observe that $g_n:=f_n\circ T \in H$ is Cauchy in $V^*$. In fact:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V}  = \int_U (g_n-g_m)w =\ind{change of variables} = \\
%\int_{T(U)} (f_n-f_m)w\circ T^{-1} |\det(D(T^{-1}))| = \\
%\langle f_n-f_m ,  w\circ T^{-1} |\det(D(T^{-1}))| \rangle_{V^*_T,V_T} 
%\end{align*}
%
%We have to prove that $w\circ T^{-1} |\det(D(T^{-1}))| \in V_T$. We start by showing that $|\det(D(T^{-1}))| \in W^{1,\infty}(D)$. Because $\tau \in \cT$, then $\det(D(T^{-1}))\in W^{1,\infty}(D)$, as a product of $W^{1,\infty}(D)$ functions, because we have $\tau^{-1}|_D \in W^{2,\infty}(D)$ (i.e. a product of bounded Lipschitz functions, hence, still bounded Lipschitz, see \cref{prop:lip}). And now, the absolute value of a $W^{1,\infty}(D)$ function, is still $W^{1,\infty}(D)$, because the absolute value preserve the Lipschitz continuity, and the boundedness.
%
%Also, $W^{1,\infty}\subseteq H^1$, so that $w\circ T^{-1} |\det(D(T^{-1}))| \in H^1(T(U))$. For the traces, we know by \cref{thm:change} that $w\circ T^{-1} \in V_T$. Suppose e.g. that $\tr(w\circ T^{-1})=0$ on $\partial T(U)$. Approximate $w\circ T^{-1}$ by $v_n$ smooth to conclude that  $\tr (w\circ T^{-1} |\det(D(T^{-1}))|) = \tr(w\circ T^{-1})\cdot  |\det(D(T^{-1}))|$. Here we have used that a $C^{0,1}_B$ function can be extended by continuity to the boundary, in view of its uniform continuity. This shows that $w\circ T^{-1} |\det(D(T^{-1}))| \in V_T$.
%
%Thus:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V} \leq \\
%\norm{f_n-f_m }_{V^*_T}\norm{  w\circ T^{-1} |\det(D(T^{-1}))| }_{V_T} 
%\end{align*}
%
%Call $d:=|\det(D(T^{-1}))| \in W^{1,\infty}(D)$. By the product rule we get $\norm{D( w\circ T^{-1} d)}_{L^2(T(U))}^2\leq \sum_i \left( \norm{d}_{L^\infty(D)}^2 +\norm{\partial_i d}_{L^\infty(D)}^2\right )^2 \norm{D(w\circ T^{-1})}_{V_T}^2$, which means that:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V} \leq \\
%C(T)\norm{f_n-f_m }_{V^*_T}\norm{w\circ T^{-1} }_{V_T} \leq\\
%C(T)\norm{f_n-f_m }_{V^*_T}\norm{w}_{V}
%\end{align*}
%
%where we used \cref{thm:change} in the last passage. Hence also $g_n$ is Cauchy in the Banach space $V^*$ and we can thus conclude the existence of $G \in V^*$ such that $g_n\rightarrow G$ in $V^*$.
%
%And now:
%
%\begin{align*}
%\langle f,  v \rangle_{V^*_T,V_T} = \lim \langle f_n,  v \rangle_{V^*_T,V_T} = \\
%\lim( f_n,v)_{H_T} =\ind{change of variables} =\\
%\lim( g_n,v\circ T |\det(DT)|)_{H} = \\
%\lim\langle g_n, v\circ T |\det(DT)| \rangle_{V^*,V} = \\
%\langle G, v\circ T |\det(DT)| \rangle_{V^*,V}
%\end{align*}
%
%where we used the fact that $v\circ T |\det(DT)| \in V_T$, in complete analogy with the above reasonings.
%
%\underline{Well posedness}
%
%So, $\langle F,  v \rangle_{V^*_T,V_T} = \langle G, v\circ T |\det(DT)| \rangle_{V^*,V}$.
%
%$|\det(DT)|$ is represented by $d \in C^{0,1}_B(D)$. In \cref{prop:chain} we saw $C\geq d\geq \delta >0$ almost everywhere in $\mR^n$. The inequality holds everywhere on $D$, by continuity of $d$. Then $1/d$ is bounded and Lipschitz, as we can verify by:
%
%$$\left | \frac{1}{d(x)}-\frac{1}{d(y)}\right |=\left| \frac{d(x)-d(y)}{d(x)d(y)}\right |\leq \delta^{-2}C|x-y|$$
%
%Therefore, multiplication by $d$ is a bijection of $V$ (a linear isomorphism actually, we already proved the boundedness, and the boundedness of the inverse follows from the bounded inverse theorem).
%
%Assume there exists another $G_2$ satisfying $\langle F,  v \rangle_{V^*_T,V_T} = \langle G_2, v\circ T |\det(DT)| \rangle_{V^*,V}$.
%
%Then  $\langle G_2-G, v\circ T |\det(DT)| \rangle_{V^*,V} = 0$ for all $v \in V_T$. Because $\circ T$ is another bijection, we can conclude  $\langle G_2-G, w \rangle_{V^*,V} = 0$ for all $w \in V$, which yields the uniqueness.
%
%\underline{Boundedness}
%
%Also, $S_T: V_T \rightarrow V$ defined by $S_Tv = |\det(DT)|v\circ T$ is a linear isomorphism, as a composition of linear isomorphism (see also \cref{prop:chain}). 
%
%Therefore:
%
%$$\langle F, v\rangle_{V^*_T,V_T} = \langle F\circ T , S_Tv\rangle_{V^*,V} =  \langle S_T^*(F\circ T), v\rangle_{V^*,V}$$
%
%This shows that $S_T^{-*}F=F\circ T = P_T F$, and this concludes the proof.
%		
%%Now, $w\circ T^{-1} \in V_T$ by \cref{thm:change}. We can also say that $|w \circ T^{-1} |\in V_T$, with $\norm{|w \circ T^{-1}|}_{V_T}\leq \norm{w \circ T^{-1}}_{V_T}$ (\tred{see \href{https://math.stackexchange.com/questions/2578760/if-u-in-h1-omega-then-u-in-h1-omega}{here} for the bound on the gradient, or \href{https://www.math.ucdavis.edu/~hunter/pdes/ch3.pdf}{here, prop. 3.22}}).
%%
%%In fact, absolute value preserves zero traces. To see this, suppose that $\tr f = 0$ on $\partial \Omega$. Then, as in the proof of \cref{thm:change}, $\tr |f| |_{\partial \Omega} = \tr(|f|\beta)|_{\partial \Omega}$, $\beta$ smooth, $1$ close to $\partial \Omega$ and $0$ close to $\partial D$. Approximating $|f_n|$ by smooth functions we see that: $\tr(|f|\beta)$
%
%\end{mproof}

\section{Transforming Bochner spaces}

\begin{prop}[Isomorphism between $Q$ spaces]
\label{prop:change_boch}

Let $\tau \in \cT$. Then:

$$\circ \tau : Q(I,V_\tau)\rightarrow Q(I,V)$$

is a linear isomorphism, and so is:

$$\circ \tau : Q_0(I,V_\tau)\rightarrow Q_0(I,V)$$

In particular, $(u\circ \tau)' = u'\circ \tau$.

\end{prop}

\begin{mproof}
From \cref{thm:change}, with the help of \cref{lemma:bochner_Hk_map} and thanks to the properties of $Q$ listed in \cref{prop:Q}, we obtain that $\circ \tau \circ \tau : Q(I,V_\tau)\rightarrow Q(I,V)$ is linear bounded, and by the inverse function theorem, an isomorphism. Reasoning by continuous representatives (in time), we get $(\circ \tau)(Q_0(I,V_\tau))\subseteq Q_0(I,V)$, and the same goes for $\circ \tau^{-1}$.
\end{mproof}


\section{Transforming partial differential equations}

We consider again the two parabolic equations of interest, namely, \cref{pb:diri} and \cref{pb:neu}. We are working under the assumption:

\begin{ass}
\label{ass:pull}

We have $\tau \in \cT$, $U\cc D$ bounded Lipschitz domains and we also assume that $\tau(U)$ is bounded Lipschitz.
\end{ass}

Suppose the problem is formulated on $\tau(U)$. To ease the notation, call $H^1_{0,m}(\tau(U))=\tw{W}_\tau, H^1_{0,m}(U)=\tw{W}, H^1_0(U)=\tw{V}$ and analogously for the other spaces.
We continue from \cref{prop:eq_form}. Applying a change of variables, and noting that:

\begin{itemize}
	\item $\tr_{\tau(U)} q = \tr_U(q\circ \tau)$ on $\Sigma_f$ by \cref{thm:change}
	\item $w_t^\tau\circ \tau = (w^\tau\circ \tau)_t$ by \cref{prop:change_boch} and analogously for $v_0$
	\item by \cref{prop:change_boch},$\circ \tau$ is a bijection between $Q^0(I,\tw{W}_\tau)$ and $Q^0(I,\tw{W})$ and analogously for $\tw{V}$
	\item $\bar{u} \in H^1(I,\tw{W}_\tau)$ and that $\bar{u}'$ denoted the weak derivative in the $H^1(I,\tw{W}_\tau)$ sense, so that \cref{prop:bochner_bound} yields $\bar{u}\circ \tau \in H^1(I,\tw{W})$ and $(\bar{u}\circ \tau )' = \bar{u}'\circ \tau $
\end{itemize}

we get, equivalently:

\begin{align*}
w^\tau \in Q_0(I, \tw{W}_\tau), v_0^\tau \in Q_0(I,\tw{V}_\tau) \\
\int_I ( (w^\tau\circ \tau)_t , q |\det(D\tau)|)_H+ (A_\tau\nabla (w^\tau\circ \tau), \nabla q)_{H} = \int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( (v_0^\tau\circ \tau)_t,p |\det(D\tau)|)_H + (A_\tau \nabla (v_0^\tau\circ \tau), \nabla p)_{H}=\\ -\int_I((\bar{u}\circ \tau)',p|\det(D\tau)|)_{H}+(A_\tau \nabla (\bar{u} \circ \tau), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}

and by \cref{prop:change_boch}, we also get $w^\tau\circ \tau \in Q_0(I,\tw{W}), v_0^\tau\circ \tau \in Q_0(I,\tw{V})$. Here $A_\tau = |\det(D\tau)|D\tau^{-1}(D\tau)^{-t}$.


%\tred{Note, here one could absorb $\det$ into the test functions, complicate the PDE but get rid of the time coefficients. From here one could prove a continuity result for the states and then get Fréchet differentiability from Gateaux differentiability}.

On the other hand, consider:

\begin{align*}
w \in Q_0(I, \tw{W}), v_0 \in Q_0(I,\tw{V}) \\
\int_I ( w_t , q |\det(D\tau)|)_H+ (A_\tau\nabla w, \nabla q)_{H} =\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( v_{0t},p |\det(D\tau)|)_H + (A_\tau \nabla v_0, \nabla p)_{H}=\\ -\int_I((\bar{u}\circ \tau)',p|\det(D\tau)|)_{H}+(A_\tau \nabla (\bar{u} \circ \tau), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}

Then, we note the following:

\begin{itemize}
	\item by \cref{prop:change_boch}, $w\circ \tau^{-1} \in Q_0(I, \tw{W}_\tau), v_0\circ \tau^{-1} \in Q_0(I,\tw{V}_\tau) $, and as seen above, $((w\circ \tau^{-1})\circ \tau)_t = (w\circ \tau^{-1})_t\circ \tau$ and the same goes for $v_0\circ \tau^{-1}$
\end{itemize}

Therefore we obtain, equivalently:

\begin{align*}
w\circ \tau^{-1} \in Q_0(I, \tw{W}_\tau), v_0\circ \tau^{-1} \in Q_0(I,\tw{V}_\tau) \\
\int_I ((w\circ \tau^{-1})_t , q^\tau)_{H_\tau}+ (\nabla (w\circ \tau^{-1}), \nabla q^\tau)_{H_\tau} = \int_I(g,\tr_{\tau(U)} q^\tau)_{L^2(\Gamma_f)}, \quad \forall q^\tau \in Q^0(I, \tw{W}_\tau) \\
\int_I ((v_0\circ \tau^{-1})_t,p^\tau)_{H_\tau} + (\nabla (v_0\circ \tau^{-1}), \nabla p^\tau)_{H_\tau}= -\int_I(\bar{u}',p^\tau)_{H_\tau}+(\nabla \bar{u}, \nabla p^\tau)_{H_\tau}, \quad \forall p^\tau \in Q^0(I, \tw{V}_\tau)
\end{align*}

and $w\circ \tau^{-1} \in Q_0(I, \tw{W}_\tau), v_0\circ \tau^{-1} \in Q_0(I,\tw{V}_\tau)$.

These findings can be summarized as follows.

\begin{thm}[Equivalent formulations with transported domain]
\label{thm:eq_pde}

Let \cref{ass:diri}, \cref{ass:neu}, \cref{ass:pull} hold.

Consider the following problems, where $\tau \in \cT$.

\begin{pb}[Joint parabolic problem, moving domain]
\label{pb:joint_mov}
\begin{align*}
w^\tau \in Q_0(I, \tw{W}_\tau), v_0^\tau \in Q_0(I,\tw{V}_\tau) \\
\int_I  (w^\tau_t , q^\tau)_{H_\tau}+ (\nabla w^\tau, \nabla q^\tau)_{H_\tau} = \int_I(g,\tr_{\tau(U)} q^\tau)_{L^2(\Gamma_f)}, \quad \forall q^\tau \in Q^0(I, \tw{W}_\tau) \\
\int_I (v^\tau_{0t},p^\tau)_{H_\tau} + (\nabla v_0^\tau, \nabla p^\tau)_{H_\tau}= -\int_I(\bar{u}',p^\tau)_{H_\tau}+(\nabla \bar{u}, \nabla p^\tau)_{H_\tau}, \quad \forall p^\tau \in Q^0(I, \tw{V}_\tau)
\end{align*}
\end{pb}

\begin{pb}[Joint parabolic problem, reference domain]
\label{pb:joint_ref}
\begin{align*}
w \in Q_0(I, \tw{W}), v_0 \in Q_0(I,\tw{V}) \\
\int_I ( w_t , q |\det(D\tau)|)_H+ (A_\tau\nabla w, \nabla q)_{H} =\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( v_{0t},p |\det(D\tau)|)_H + (A_\tau \nabla v_0, \nabla p)_{H}=\\ -\int_I((\bar{u}\circ \tau)',p|\det(D\tau)|)_{H}+(A_\tau \nabla (\bar{u} \circ \tau), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}
\end{pb}

We have the following:

\begin{itemize}
	\item consider $w^\tau \in Q_0(I, \tw{W}_\tau), v_0^\tau \in Q_0(I,\tw{V}_\tau)$. They solve \cref{pb:joint_mov} $\iff$ $w^\tau\circ \tau , v_0^\tau\circ \tau $ solve \cref{pb:joint_ref}
	\item consider $w \in Q_0(I, \tw{W}), v_0^\tau \in Q_0(I,\tw{V})$. They solve \cref{pb:joint_ref} $\iff$ $w\circ \tau^{-1}, v_0\circ \tau^{-1}$ solve \cref{pb:joint_mov} 

\end{itemize}

Here, $A_\tau:=  (D\tau)^{-1}(D\tau)^{-t}|\det(D\tau)|$.

\end{thm}

\chapter{Finite element method on smooth domains}
\label{chap:inh_fem}
Handling smooth geometries in finite element analysis is not a trivial task. On one hand, finite element discretization is naturally done on polygonal/polyhedral domains, whereas the solution smoothness required to obtain optimal order error estimates, can only be achieved with a smooth boundary (or more generally, when $U$ is convex, which it isn't, in our case). An apparent contradiction therefore arises, and many authors simply conduct theoretical analysis on the polyhedral domains, but assuming enough smoothness of the solutions (this is the contradiction of "polygonal smooth" domains, mentioned in \cite{tiihonen}): an example of this in a setting close to ours, is contained in \cite{paganini}. 

There are few different ways to go about this dilemma, many of them are only a partially satisfactory answer to the problem. For instance, finite elements formulated directly on arbitrarily curved simplices have been studied, see \cite{zlamal}. This requires complete knowledge of the (curved) boundary of the computational domain. Optimal order estimates are also observed in \cite{bramble}. Their techniques work with smooth and rough data, but also require complete knowledge of a parametrization of the boundary, and are not easily extendable to a dimension higher than $2$. Interestingly, shape optimization techniques can be applied to analyze the discrepancy between discrete and smooth geometry in the solution process, see \cite{tiihonen}: the techniques therein presented only yield optimal order estimates in the $H^1$ norm.

The presence of Dirichlet boundary conditions further complicates the analysis. The Dirichlet values might be imposed strongly, i.e. enforced at the boundary nodes, or weakly (see e.g. \cite{chiba} for the elliptic case, or, more generally, the discussion in \cite{chouly}, and that in \cite{benner} for the parabolic case). The latter solution is viable only if one can extend to the whole volume the boundary data.

We chose the approach that was the least intrusive possible with regards to the exact geometry and data: it only requires the knowledge of the smooth domain and boundary data at some points of the smooth boundary. It is straightforward to implement, both from a meshing point of view and from a finite element code point of view. Standard meshing tools can be used without modification, GMSH being our choice (\cite{gmsh}), and powerful finite element libraries can be directly used to simulate the partial differential equations, we used Fenics (\cite{fenics}).

In short, the discrete solution is computed on a polygonal/polyhedral approximation $\Omega_h$ of the smooth domain $\Omega$, where the nodes of $\partial \Omega_h$ lie on $\partial \Omega$, and the Dirichlet conditions are imposed strongly. The boundary data is substituted by its Langrange interpolant, thus requiring its knowledge only on the boundary nodes of $\partial \Omega_h$.

The drawback is that we require "unnatural" smoothness to the boundary data, because we evaluate it pointwise ("unnatural" is compared to he hypothesis necessary to obtain $H^2$ regularity in the elliptic case, i.e. $H^{1/2}$ smoothness for Neumann data and $H^{3/2}$ smoothness for Dirichlet data: we will require both to be $H^2$ on the boundary). Such surplus of smoothness is however present in virtually all other works that analyze the change in geometry in detail. Strong imposition of Dirichlet boundary conditions, on the other hand, may not me the best solution for all PDEs, see e.g. \cite{hughes}.

The approach we took is based on the work of \cite{elliott}, \cite{ranner}, \cite{bernardi} and \cite{edelmann}.

We mention that one might alternatively solve the PDEs resulting from shape optimization, on the reference domain, rather than on the moving domain. This however complicates the variational formulation, and in the case of more difficult equations (more than a Poisson, or a heat equation in our case), already existing high performance solvers may be unavailable.


\section{Preliminaries}

\begin{ass}[Geometric assumptions]
\label{ass:geo_ass_discr}
Consider a domain $\Omega \subseteq \mR^n$, $n=2,3$, with $C^2$ boundary.

We define a polygonal/polyhedral meshing made of triangles/tetrahedra $\Omega_h$ (open) of $\Omega$, which has boundary nodes on $\partial \Omega$. The family of meshes for $\Omega_h$ must be regular and quasi-uniform in the sense of \cite{brenner_scott}.

Denoting by $\Gamma_D, \Gamma_N \subseteq \partial \Omega$ subsets of $\partial \Omega$ where Dirichlet and Neumann boundary conditions will be imposed, we call their discretizations $\Gamma_{D_h}, \Gamma_{N_h}$.

We assume $\Gamma_D \neq \emptyset $ for simplicity (but many of the following arguments work with suitable adaptations otherwise), and $\overline{\Gamma_D}\cap \overline{\Gamma_N} = \emptyset$.

\end{ass}

Call $S^1_{h,0,D_h} $ the space of piecewise linear lagrangian FEM $S^1_h$ which are zero on $\Gamma_{D_h}$.

We collect some useful tools to relate $\Omega$ and $\Omega_h$.

\begin{prop}[Deformation into smooth boundary]
\label{prop:G_h}
Assume we have a quasi-uniform mesh. There exists, for $h$ small enough, $G_h: \overline{\Omega_h} \rightarrow \overline{\Omega}$ satisfying:

\begin{itemize}
	\item $G_h|_T = \id$ on interior simplices $T$ (those with at most one node on $\partial \Omega$)
	\item $G_h(\partial \Omega_h) = \partial \Omega$, $G_h|_e=p$, where $e$ is an edge/face of $\partial \Omega_h$ and $p$ is the closest point operator to $\partial \Omega$ (so that $G_h|_{\partial \Omega_h}$ coincides with the boundary lift in Definition 4.12 of \cite{elliott})
	\item $G_h$ is bi-Lipschitz, with $\norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}\lesssim h$, and $\norm{|\det(DG_h)|-1}_{L^\infty(\Omega_h)}\lesssim h$
	\item given $G_h(K)$, all the facets are at least $C^1$ smooth
	\item $G_h|_T$ is of class $C^1(T)$ for all closed simplices $T$ composing $\Omega_h$
\end{itemize}

\end{prop}
\begin{mproof}

See section 4.1 of \cite{elliott} for the first two points, which follow from the definition of $G_h$. See also Lemma 8.16 of \cite{ranner}.

The last one is contained in Lemma 8.12, \cite{ranner}. We give more detail for the third and fourth point, which are not addressed in \cite{ranner}, \cite{elliott}.

\underline{$G_h$ is a bi-Lipschitz homeomorphism}

We first note that $G_h|_K$ agrees with $G_h|_{K'}$ for $K\cap K' \neq \emptyset$. Therefore $G_h$ is continuous on $\overline{\Omega_h}$.

Then, we also note that $G_h$ has $DG_h \in L^\infty(\Omega_h)$ as weak derivative, where the gradient is defined element-wise. To see this, pick $\phi \in C^\infty_c(\Omega_h)$.

Then, applying \cref{thm:ibp}:
$$\int_{\Omega_h} G_h \partial_i \phi = \sum_K \int_{\partial K}G_h|_{K} \phi \nu_{K,i}  - \int_{\Omega_h}\partial_i G_h \phi$$

The first integral on the right is zero, because $G_h$ is continuous, the normal on the same interior facet is equal of opposite sign when referred to the two parent simplices it belongs to, and because $\phi=0$ on exterior facets.

Thus, $G_h \in W^{1,\infty}(\Omega_h)$, and Lemma 8.12 of \cite{ranner} shows that $\norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}\lesssim h$. Thanks to \cref{prop:lip}, we obtain that $G_h$ has a bounded Lipschitz representative, i.e., $G_h$ is bounded and Lipschitz on $\Omega_h$.Then $G_h$ is Lipschitz on all of $\overline{\Omega_h}$, and $\text{Lip}(\id -G_h) \lesssim  \norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}$.

So, $G_h$ is a Lipschitz perturbation of identity, on $\overline{\Omega_h}$.  An application of the reverse triangle inequality also shows that $|G_h(x)-G_h(y)|\geq (1-\text{Lip}(G_h))|x-y|$, which shows that $G_h$ is bijective (for small $h$), with a Lipschitz inverse.

%By compactness arguments, we see that it is a closed map $\overline{\Omega_h}\rightarrow\overline{\Omega}$.


\underline{Smooth facets of curved simplex}

From the last point we know that $G_h$ is of class $C^1$ when restricted to $K$, a closed simplex. By Whitney's extension theorem on simplices (see \cite{whitney}) we can conclude that $G_h|_K$ extends to a $C^1$ function on a neighbourhood of $K$. This extension is injective on $K$ as we saw before, and by Lemma 8.16 of \cite{ranner} (the determinant of $G_h$ is small), it has invertible jacobian on $K$. An application of a global version of the inverse function theorem (see e.g. \cite{pollack}, chapter 1) yields that $G_h$ extends to a $C^1$ diffeomorphism around $K$, so that the smoothness of $\partial K$ follows.
\end{mproof}

Given $G_h$, we can define pullbacks and pushforwards of functions defined on $\Omega$ or $\Omega_h$.


\begin{prop}[Lift]
\label{prop:lift}
We define, for $u: \Omega \rightarrow \mR$, $u^{-l}:=u\circ G_h : \Omega_h \rightarrow \mR$, and analogously for $u_h: \Omega_h \rightarrow \mR$ we define $u_h^l:=u_h\circ G_h^{-1}$. We also need the mesh to be quasi-uniform (see proposition 4.7 of \cite{elliott}).

There holds:

\begin{itemize}
	\item $v\in H^m(Q)$ if and only if $v^{-l} \in H^m(G_h(Q))$, for $m=0,1$, and $Q\subseteq \Omega_h$ open
%	\item for $v_h \in S^1_{h}$, we have $v_h^l \in H^1(\Omega)$
	\item for $v_h \in S^1_{h,0,D_h}$, we have $v_h^l \in H^1(\Omega)$, with zero trace on $\Gamma_D$ 
	\item for $v_h  \in S^1_h$, one has the following norm equivalences, which don't depend on $h$:
	\begin{enumerate}
		\item $\norm{v_h}_{L^2(\partial \Omega_h)} \sim \norm{v_h^l}_{L^2(\partial \Omega)}$
		\item $\norm{v_h}_{L^2( \Omega_h)} \sim \norm{v_h^l}_{L^2( \Omega)}$
		\item $\norm{\nabla v_h}_{L^2( \Omega_h)} \sim \norm{\nabla v_h^l}_{L^2( \Omega)}$
	\end{enumerate}
	\item consequently, the lifting operator $S^{1}_{h,0,D_h}\rightarrow H^k_{0,D}(\Omega)$ is bounded, for the $L^2$ norms if $k=0$, and $H^1$ norms if $k=1$ 
	
\end{itemize}

\end{prop}

\begin{mproof}

The first point follows by the fact that $G_h$ is bi-Lipschitz, see \cref{prop:G_h}, and theorem 11.53 of \cite{leoni}.

%We refer to \cite{bernardi} for the first point, to Lemma 2.3. This is applicable as $G_h(T)$ is a curved simplex of class $C^1$ in the notation of \cite{bernardi}, and this fact is guaranteed by lemma 8.13 and by following example 2 of \cite{bernardi}.
%
%The lifted $v_h$ mantains continuity at the edges, so that $v_h^l$ is in $H^1(\Omega)$ by an application of the divergence theorem on every (possibly curved) simplex $T^l$ composing $\Omega$.
%
%For the zero trace property, given that $v_h^l \in H^1(\Omega)\cap C(\overline{\Omega})$, we use $G_h(\partial \Gamma_{D_h}) = \partial \Gamma_D$.

The second point follows by applying the arguments about conformity outlined in section 5 of \cite{bernardi}. Following Example 2 therein, we discover that we can apply proposition and corollary 5.1.

The last point can be found in \cite{elliott}, see e.g proposition 4.9 and 4.13.
%
%\underline{First point}
%
%
%
%For an element $T$ (which we assume to be closed), it is stated in \cite{ranner}, lemma 8.12, page 1791, that $G_h|_T$ is a $C^2(T)$. $v^{-l}$ is measurable being the gluing of element-wise measurable functions.
\end{mproof}

\begin{prop}[Interpolation on curved domains]
\label{prop:interp_curv}
Let $u \in H^2(\Omega)$, let $g \in H^2(\partial \Omega)$.

Let $u\in H^2(\Omega)$ and define $\Pi_c u = (\Pi_h u )^l$, where $\Pi_h$ is the usual pointwise Lagrange interpolator on $S^1_h$.

We can also define $\Pi_c g $ for $g \in H^2(\partial \Omega)$ in the same fashion.

It follows that:

\begin{itemize}
	\item $\norm{u-\Pi_c u}_{L^2(\Omega)} + h \norm{u-\Pi_c u}_{H^1(\Omega)}\lesssim h^2\norm{u}_{H^2(\Omega)}$
	\item $\norm{g-\Pi_c g}_{L^2(\partial \Omega)} + h \norm{g-\Pi_c g}_{H^1(\partial \Omega)}\lesssim h^2\norm{g}_{H^2(\partial \Omega)}$
\end{itemize}
Here $a \lesssim b$ means $a \leq Cb$ for $C\geq 0$ not depending on $h$.
\end{prop}

\begin{mproof}
See proposition 5.4 of \cite{elliott}.
\end{mproof}

\begin{prop}[Approximation of linear and bilinear forms]
\label{prop:lin_appr}
Let $v_h, w_h \in S^1_h$, $v,w \in H^2(\Omega)$, $\delta \te_h \in (S^1_h)^d$ ($d$ is the dimension of $\Omega$), $\delta \te \in W^{1,\infty}(\Omega;\mR^d)$, $\delta_h \te \in W^{1,\infty}(\Omega_h;\mR^d)$. Then:

\begin{enumerate}
	\item $\ds \left | \int_\Omega v_h^lw_h^l - \int_{\Omega_h}v_hw_h\right |\lesssim h^{k+1} \norm{v_h}_{H^k(\Omega_h)}\norm{w_h}_{H^k(\Omega_h)}$, $k=0,1$
	\item $\ds \left | \int_{\partial \Omega} v_h^lw_h^l - \int_{\partial \Omega_h}v_hw_h\right |\lesssim h^2 \norm{v_h}_{L^2(\partial \Omega_h)}\norm{w_h}_{L^2(\partial \Omega_h)}$
	\item $\ds \left | \int_\Omega \nabla v_h^l\nabla w_h^l - \int_{\Omega_h}\nabla v_h\nabla w_h\right |\lesssim h \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)}$
	\item $\ds \left | \int_\Omega \nabla v\nabla w - \int_{\Omega_h}\nabla v^{-l}\nabla w^{-l}\right |\lesssim h^2 \norm{v}_{H^2(\Omega)}\norm{w}_{H^2(\Omega)}$
	\item $\ds \left | \int_\Omega v_h^l w_h^l \dive(\delta  \te_h^l) - \int_{\Omega_h}v_h w_h \dive(\delta \te_h)\right |\lesssim h^{k+1} \norm{v_h}_{H^k(\Omega_h)}\norm{w_h}_{H^k(\Omega_h)} \norm{\dive(\delta \te_h)}_{L^\infty(\Omega_h)}$, $k=0,1$
	\item $\ds \left | \int_\Omega (A'(\delta	\te_h^l)\nabla v_h^l)\nabla w_h^l - \int_{\Omega_h}(A'(\delta	\te_h)\nabla v_h)\nabla w_h\right |\lesssim h \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)}\norm{D\delta \te_h}_{L^\infty(\Omega_h)}$
	\item $\ds \left | \int_\Omega (A'(\delta	\te)\nabla v)\nabla w - \int_{\Omega_h}(A'(\delta	\te^{-l})\nabla v^{-l})\nabla w^{-l}\right |\lesssim h^2 \norm{v}_{H^2(\Omega)}\norm{w}_{H^2(\Omega)}\norm{D\delta \te}_{L^\infty(\Omega)}$
\end{enumerate}
\end{prop}

\begin{mproof}
See \cite{edelmann}, and in particular, for the second point, Lemma 5.6 of \cite{kovacs}. Only the last three points are not already present in the literature, but the follow with very similar arguments as the others. See for instance, section 6 of \cite{elliott}: one needs to apply a change of variables to the integrals on $\Omega_h$, and then use the approximation properties in \cref{prop:G_h}. To obtain $O(h^2)$ estimates, the "narrow band" inequality Lemma 6.3, \cite{elliott}, as suggested in  Lemma 6.4 of \cite{elliott}, has to be used.

%\underline{Proof of $5$}
%
%We can reason as in section 6 of \cite{elliott}. To this end, we perform integration by parts:
%
%\begin{align*}
%	\int_{\Omega_h}v_h w_h \dive(\delta \te_h) = \int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l)(D(G_h^{-1}))^{-1})|\det(D(G_h^{-1}))|=\\
%	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l)(D((G_h^{-1}))^{-1} - \id))|\det(D(G_h^{-1}))|+\\
%	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l))(|\det(D(G_h^{-1}))|-1)+\\
%	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l))
%\end{align*}
%
%The conclusion now follows from \cref{prop:G_h} and the fact that, for square matrices $A,B$, we have $|\tr(AB)|\leq \norm{A}_F\norm{B}_F$, and $\norm{\cdot }_F$ is the Frobenius norm.
%
%By noting that the first and second integrals are zero on the interior elements, and upon using the "narrow band" inequality Lemma 6.3, \cite{elliott}, as suggested in  Lemma 6.4 of \cite{elliott}, we are able to also conclude the case $k=1$.
%
%\underline{Proof of $6, 7$}
%
%It is very similar to the previous ones. The only peculiarity is the appearance of a term like $A'(\delta \te_h)\circ G_h^{-1} - A'(\delta \te_h^l)$. This is estimated, in the $L^\infty$ norm, as follows:
%
%\begin{align*}
%	\norm{A'(\delta \te_h)\circ G_h^{-1} - A'(\delta \te_h^l)}_{L^\infty(\Omega_h)}\leq\\
%	2\norm{D(\delta \te_h^l)(D(G_h^{-1}))^{-1} - D(\delta \te_h^l)}_{L^\infty(\Omega_h)}+\\
%	\norm{\tr(D(\delta \te_h^l)(D((G_h^{-1}))^{-1} - \id))}_{L^\infty(\Omega_h)}
%\end{align*}
%
%and we can now use \cref{prop:G_h} to conclude.
%
\end{mproof}

\begin{prop}[Uniform coercivity]
\label{thm:a_h_coercive}
For $h$ small enough, $a_h(v_h,w_h):=\ds \int_{\Omega_h} \nabla v_h \nabla w_h$ is coercive, uniformly with respect to $h$.
\end{prop}
\begin{mproof}

For $C$ not depending on $h$:

\begin{align*}
a_h(v_h,v_h) \geq C\norm{v_h^l}_{H^1(\Omega)}^2 - |a_h(v_h,v_h) - a(v_h^l,v_h^l)\geq C\norm{v_h}_{H^1(\Omega_h)}^2 -C h \norm{v_h^l}_{H^1(\Omega)}^2\geq C(1-h)\norm{v_h}_{H^1(\Omega_h)}^2
\end{align*} 

We used the $h-$uniform coercivity of $a$ (descending from the Poincaré inequality in which functions vanish only on part of the boundary, $\Gamma_D$, see e.g. lemma 1 of \cite{dorfler}), \cref{prop:lift} on $\norm{v_h^l}_{H^1(\Omega)}^2$ and \cref{prop:lin_appr}.
\end{mproof}

\section{Semidiscrete estimates}
\label{sec:semid}
We partly build upon the previous section, to deal with problems of the following form.

\begin{pb}[Inhomogeneous parabolic problem]
\label{pb:inh_parabolic}

With reference to \cref{pb:mix}, we define:

$$
\left\{\begin{matrix}
\partial_t u-\Delta u = f & \text{ on } \Omega \times I \\ 
u = g_D & \text{ on } \Gamma_D \times I\\ 
\partial_\nu u = g_N & \text{ on } \Gamma_N \times I \\
u(0) =  u_0
\end{matrix}\right.
$$

We ask \cref{ass:basic_par_mix}.

\end{pb}

We provide a semidiscrete estimate, in the sense that only space is discretized. To do so we follow a classical argument involving the use of Ritz projections, see \cite{thomee} in e.g. theorem 1.2. To deal with the polygonal/polyhedral domain approximation we adapt some arguments contained in \cite{ranner}, where parabolic problems are treated on moving domains, but with homogeneous boundary conditions. The inhomogeneous Dirichlet boundary conditions require special care.

We start indeed from the Ritz projection, by keeping the same notation as in the last section for the lift.

Throughout this section, $\lesssim$ means $\leq C $, for $C$ independent of both the discretization parameter $h$, and time.

\begin{defn}[Inhomogeneous Ritz projection]
Consider $z \in H^2(\Omega)$. We define $R_h z \in S^1_h$ by:

$$a_h(R_h z , v_h) = a(z, v_h^l), v_h \in S^1_{h,0,D_h}$$
$$R_h z = \Pi_h z \text{ on } \partial \Omega_h$$

We denote $R_c z := (R_h z)^l$.

\end{defn}

Here are some useful properties of such projection.

\begin{prop}[Properties of the Ritz projection]
\label{prop:ritz}
The following facts hold true about $R_h$, where we assume that $h$ is small enough:

\begin{enumerate}
	\item $R_h$ is well defined
	\item $R_h$ is continuous, uniformly in $h$, from $H^2(\Omega)$, to $S^1_h$, i.e., $\norm{R_hz}_{H^1(\Omega_h)}\lesssim \norm{z}_{H^2(\Omega)}$
	\item $\norm{R_c z - z}_{H^1(\Omega)}\lesssim h\norm{z}_{H^2(\Omega)}$
	\item $\norm{R_c z - z}_{L^2(\Omega)}\lesssim h^2 \norm{z}_{H^2(\Omega)} + \norm{z-\Pi_c z}_{L^2(\Gamma_D)}$
	\item for $z \in H^1(I,H^2(\Omega))$, $R_c \frac{d}{dt} = \frac{d}{dt} R_c$ and we can therefore use the above properties also for $z_t$
\end{enumerate}

\end{prop}

\begin{mproof}

\underline{Existence, uniqueness and stability}

The splitting $\delta_h := R_h z - \Pi_h z$, the fact that $a_h$ is ($h$-uniformly) coercive on $S^1_{h,0,D_h}$ by \cref{thm:a_h_coercive} and the Lax-Milgram lemma yield existence, uniqueness follows as in \cref{prop:diri_wp}

Now, for the stability: by uniform coercivity and the definition of $R_h$: $\norm{R_h z}_{H^1(\Omega_h)}^2 \lesssim a_h(R_h z, R_h z) = a_h(\delta_h,R_h z) + a_h(\Pi_h z, R_h z)$, so that $\norm{R_h z}_{H^1(\Omega_h)} \lesssim \norm{\delta_h }_{H^1(\Omega_h)} + \norm{\Pi_h z }_{H^1(\Omega_h)}$. We only need now to apply \cref{prop:lift}, \cref{prop:interp_curv}, \cref{prop:lin_appr}.

\underline{Error bounds}

For the $H^1$ error bound, we refer to \cite{ranner}, in particular to the proof of lemma 3.8 at page 1720. Note that $H^2$ stability of $R_h$ is sufficient, instead of the stronger $H^1$ stability they use.

For the $L^2$ error bound, we apply a variant of the Aubin-Nitsche trick. Call $e:= z - R_c z \in H^1(\Omega)$ (this holds by \cref{prop:lift}), and define $w$ by:

$$
\left\{\begin{matrix}
-\Delta w = e & \text{ on } \Omega \\ 
w = 0 & \text{ on } \Gamma_D \\ 
\partial_\nu w = 0 & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

Now, by $H^2$ regularity:

$$\norm{e}^2_{L^2(\Omega)} = a(w,e) - \int_{\partial \Omega} e \partial_\nu w  $$

and:

\begin{align*}
\norm{e}^2_{L^2(\Omega)} \leq a(w,e) + C \norm{e}_{L^2(\Gamma_D)}\norm{e}_{L^2( \Omega)} = F_h(w) + C \norm{e}_{L^2(\Gamma_D)}\norm{e}_{L^2( \Omega)}
\end{align*}

The first term is bounded as in the proof of lemma 3.8 of \cite{ranner}, whereas, using $H^2$ regularity for $w$ we are able to conclude:
$$\norm{z-R_c z}_{L^2(\Omega)}\lesssim h^2\norm{z}_{H^2(\Omega)} + \norm{z-\Pi_c z}_{L^2(\Gamma_D)} $$

\underline{Commutation with time derivative}

Follows from \cref{lemma:bochner_Hk_map}, and the fact that $R_c$ is linear and bounded. The latter is true as lifting a finite element function is a linear bounded map, see \cref{prop:lift}.
\end{mproof}

\begin{ass}[Smoothness requirement on continuous solution]
\label{ass:smoothness_par_discr}

We assume that $u \in H^1(I, H^2(\Omega))$.
\end{ass}

Note, for the parabolic problems arising from shape optimization (\cref{pb:pdes}), \cref{thm:mix_reg} suffices.

We now can attempt an error estimate for \cref{pb:inh_parabolic}, for the following spatial semidiscrete formulation.

\begin{pb}[Spatially semidiscrete approximation of \cref{pb:inh_parabolic}]
\label{pb:inh_parabolic_discr}
We look for $u_h \in H^1(I, S^1_h)$ satisfying: 
$$(\partial_t u_h, v_h)_{L^2(\Omega_h)} + a_h(u_h, v_h) = (f_h, v_h)_{L^2(\Omega_h)} + (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})}, v_h \in S^1_{h,0,D_h}, \text{ for a.e. }t\in I$$
$$u_h=g_{D,h}\text{ for a.e. }t \text{,  on } \Gamma_{D_h}$$
$$u_h(0)=u_{0h}$$

We are making the following assumptions on the data:

\begin{ass}[Assumptions for the spatial semidiscretization]
\label{ass:discr_reg}
\textcolor{white}{ }
\begin{itemize}
	\item \cref{ass:geo_ass_discr}
	\item $g_N \in L^2(I,H^2(\Omega))$, so that $g_{N,h}:=\Pi_h g_N \in L^2(I, S^1_h(\Gamma_{N_h}))$
	\item $g_D \in H^1(I, H^{2}(\Gamma_D))$, so that, with reference to \cref{prop:trace}, we have $G_D:=Eg_D \in H^1(I,H^2(\Omega))$ and therefore (see \cref{lemma:bochner_Hk_map}), there holds	 $G_{D,h}:=\Pi_h G_D \in H^1(I, S^1_h)$ and $g_{D,h}:=G_{D,h}|_{\Gamma_{D_h}} \in H^1(I, S^1_h(\Gamma_{D_h}))$ (note, $g_{D,h} = \Pi_h g_D$)
	\item $f \in L^2(I,L^2(\Omega))$ and $f_h \in L^2(I, S^1_h)$, with error bound  $\norm{f-f_h^l}_{L^2(\Omega_h)}\lesssim C_f h^2$, for a.e. $t$, $C_f$ independent of $h$ and belonging to $L^2(I)$.
	\item $u_0\in H^2(\Omega$), with the compatibility condition $u_{0} = g_{D}(0)$ on $\Gamma_{D}$, and $u_{0h}:=\Pi_h u_0$
\end{itemize}

(note that these assumptions can be relaxed for proving the well posedness of the scheme, and other choices of the discrete data might be possible. They become important when proving error bounds, so that we assume them right away. In particular, one could choose $f_h=\Pi_h f$, for $f\in L^2(U, H^2(\Omega))$ and obtain the same results).

\end{ass}

\end{pb}

\begin{prop}[Well posedness of \cref{pb:inh_parabolic_discr}]
\label{prop:wp_discr_par}
There exists a unique solution to \cref{pb:inh_parabolic_discr}, and this satisfies the stability estimate, holding for small enough $h$:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)}  + \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} + \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D)))} + \norm{u_{0}}_{H^2(\Omega)}
\end{align*}

We remember that $\lesssim$ stands for $\leq C$, $C\geq 0$ independent of $h$ and $t$.

\end{prop}

\begin{mproof}

\underline{Existence and uniqueness}

A function $\delta_h \in H^1(I, S^1_{h,0,D_h})$ can be written as $\delta_h=\sum_j d_{hj}(t)v_{hj}$, for the usual finite element basis $\{v_{hj}\}_j$ of $S^1_{h,0,D_h}$. We employ the splitting technique $\delta_h = u_h - G_{D,h}$. By testing with the equation of \cref{pb:inh_parabolic_discr} with the basis functions $v_{hj}$ we obtain the problem:
\begin{align}
\label{eqn:ode}
	M_h d_h'(t)+A_hd_h(t)= F_h(t), \text{ a.e. } t\\
	d_h(0) = d_{h,0}	
\end{align}

Here, $M_{h,ij} = (v_{hi}, v_{hj})_{L^2(\Omega_h)}, A_{h,ij} = a(v_{hi}, v_{hj})$ are the so called mass and stiffness matrices, both invertible, with respect to the nodal basis of $S^1_{h,0,D_h}$. We also have $F_{h,j}(t):= - (\partial_t G_{D,h}, v_{hj})_{L^2(\Omega_h)} - a_h(G_{D,h}, v_{hj}) + (f_h, v_{hj})_{L^2(\Omega_h)} + (g_{N,h}, v_{hj})_{L^2(\Gamma_{N_h})}$, together with $d_{h,0}:= u_{0h} - G_{D,h}$, in the sense of the non-Dirichlet nodal values (we are able to come to this problem thanks to the assumed compatibility between $u_{0h}, g_{D,h}$).

Thanks to the smoothness assumptions on the data, we have that $F$ has $L^2(I)$ entries.

Hence, by basic theory of ordinary differential equations (theorem 3.4 of \cite{odes}, for instance), we conclude the existence (and uniqueness) of $d \in H^1(I)$ solving the problem above. The function $u_h:=\sum_j d_j(t)v_{hj} + G_{D,h}$ is therefore a solution to the original problem. 

Uniqueness (and hence, independence on the particular extension $G_{D,h}$) follows by usual energy estimates.
\underline{Stability}

Following \cite{gilardi}, page 20, 21, we can prove energy estimates for $\delta_h$ and then, by triangle inequality:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)} + \norm{g_{N,h}}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}}_{H^1(I,H^1(\Omega_h)))}+\norm{u_{0h}}_{L^2(\Omega_h)}
\end{align*}

Now, thanks to \cref{ass:discr_reg}:

\begin{itemize}
%	\item $\norm{f_h}_{L^2(I,L^2(\Omega_h))}^2\lesssim \int_I C_f^2$ (here we use the same arguments as in \cref{prop:rough_L2_est_ell})
	\item $\norm{g_{N,h}}_{L^2(I,L^2(\Gamma_{N_h}))} \lesssim \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} $ (here is suffices to use \cref{prop:interp_curv}))
	\item because the Lagrange interpolator is linear bounded $H^2(\Omega)\rightarrow S^1_h$ there holds, by \cref{prop:interp_curv}: $\partial_t G_{D,h}=\Pi_h \partial_t G_D$, so that $\norm{\partial_t G_{D,h}}_{H^1(\Omega_h)} = \norm{\Pi_h \partial_t G_D}_{H^1(\Omega_h)} \lesssim \norm{\partial_t G_D}_{H^2(\Omega))}$, where we used \cref{prop:interp_curv} and \cref{prop:lift}. Thanks to the properties of $G_D$, and the fact that the extension $E$ of \cref{prop:trace} commutes with $\Pi_h$ (by \cref{lemma:bochner_Hk_map}), there holds $\norm{\partial_t G_{D,h}}_{H^1(\Omega_h)}\lesssim \norm{\partial_t g_D}_{H^{3/2}(\Gamma_D)}$. With analogous reasonings we can conclude that $\norm{G_{D,h}}_{H^1(I,H^1(\Omega_h)))}\lesssim \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D))}$
	\item similarly, $\norm{u_{0h}}_{L^2(\Omega_h)}\lesssim \norm{u_{0}}_{H^2(\Omega)}$
\end{itemize}

All in all:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)} + \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} + \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D)))} + \norm{u_{0}}_{H^2(\Omega)}
\end{align*}
\end{mproof}

\begin{thm}[Semidiscrete error bound]
\label{thm:semidiscrete_error_bound}
There holds:

\begin{align*}
	 \norm{u(t)-u_h^l(t)}_{L^2(\Omega)}^2 + h^{2}\int_0^T\norm{u-u_h^l}^2_{H^1(\Omega)} \lesssim\\
	 h^4A^2
\end{align*}

where $A^2:= \ds \norm{u}_{H^1(I,H^2(\Omega))}^2 + \norm{g_D}_{H^1(I,H^2(\Gamma_D))}^2 + \norm{u_0}_{H^2(\Omega)}^2 +  \int_0^T C_f^2+ \int_0^T \norm{f_h}_{H^1(\Omega_h)}^2 + \int_0^T  \norm{g_N}_{H^2(\Gamma_N)}^2 $.

For this to hold, \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix} must be fulfilled.

\end{thm}

\begin{mproof}

Also here, we adapt the argument from \cite{ranner}, in particular, those of pages 1727, 1728, 1729, which are modifications of standard techniques that can be traced in e.g. \cite{thomee}, theorem 1.2.

\underline{Error split}

We want to bound $e:=u-u_h = u-R_cu +R_c u -u_h^l =: \rho + \theta_h^l$. We already have the needed bounds on $\rho$ by \cref{prop:ritz}.

\underline{An equation for $\theta_h$}

Consider then $\theta_h := R_h u -u_h$. Is is an element of $H^1(I,S^1_{h,0,D_h})$ (i.e. it is $0$ on the Dirichlet boundary), making it a suitable test function: this is the primary reason to impose boundary conditions on $R_h$.

So, we have, for $v_h \in S^1_{h,0,D_h}$:

\begin{align*}
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} + a_h(R_h u, v_h) = \ind{definition of Ritz projection}=\\
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} + a(u, v_h^l) =\\
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t u, v_h^l)_{L^2(\Omega)} + (f, v_h^l)_{L^2(\Omega)} + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} 
\end{align*}

Adding the equation for $u_h$, and then adding and subtracting $(\partial_t R_cu, v_h^l)_{L^2(\Omega)}$:


\begin{align}
\label{eqn:theta}
(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h) = 
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t R_c u , v_h^l)_{L^2(\Omega)}\\
- (\partial_t \rho, v_h^l)_{L^2(\Omega)}\\ + (f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}\\ + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} 
\end{align}

This means that we can estimate the right hand sides of the above equation to quantify the size of $\theta_h$.

\underline{Estimating the size of $\theta_h$: right hand sides}

By \cref{lemma:bochner_Hk_map} we can write $\partial_t R_h u = R_h \partial_t u, \partial_t R_c u = (R_h \partial_t u)^l$.

Hence, $|(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t R_c u , v_h^l)_{L^2(\Omega)}|\lesssim h^2 \norm{\partial_t u}_{H^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)}$, where we used \cref{prop:lin_appr}, and \cref{prop:ritz}.

Similarly, we have $\partial_t \rho = \partial_t u - R_c\partial_t u$.

Thus $| (\partial_t \rho, v_h^l)_{L^2(\Omega)}|\lesssim h^2 \norm{\partial_t u}_{H^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)} + \norm{\partial_t(g_D - g_{D,h}) }_{L^2(\Gamma_D)}\norm{v_h}_{H^1(\Omega_h)}$ by \cref{prop:ritz}. By the choice of $g_{D,h}$ and by \cref{prop:interp_curv}, $| (\partial_t \rho, v_h^l)_{L^2(\Omega)}|\lesssim h^2 (\norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)})\norm{v_h}_{H^1(\Omega_h)}$.

Moreover:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\leq\\
	|(g_{N} - g_{N,h}^l, v_h^l)_{L^2(\Gamma_{N})}| + |(g_{N,h}^l, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |
\end{align*}

By \cref{prop:lin_appr} and trace theorems there holds:

%$|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N,h})} |\lesssim h^2$:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\lesssim\\
	\norm{g_{N} - g_{N,h}^l}_{L^2(\Gamma_{N})}\norm{v_h^l}_{H^1(\Omega)} + h^2\norm{g_{N,h}}_{L^2(\Gamma_{N_h})} \norm{v_h}_{H^1(\Omega_h )}
\end{align*}

Using the choice of $g_{N,h}$ and also \cref{prop:interp_curv}, \cref{prop:lift}, we obtain:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\lesssim 	h^2 \norm{g_N}_{H^2(\Gamma_N)}\norm{v_h}_{H^1(\Omega_h)}
\end{align*}

Analogously:

\begin{align*}
	|(f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}|\lesssim\\
	\norm{f-f_h^l}_{L^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)} + h^2 \norm{f_h}_{H^1(\Omega_h)}\norm{v_h}_{H^1(\Omega_h)}\lesssim (C_f + \norm{f_h}_{H^1(\Omega_h)}) h^2 \norm{v_h}_{H^1(\Omega_h)}
\end{align*}

We used throughout \cref{ass:discr_reg}.

Calling $E_h(v_h):=(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h)$, we discovered that:

\begin{align}
\label{eqn:theta_residual}
	|E_h(v_h)|\lesssim h^2 \norm{v_h}_{H^1(\Omega_h)} (C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} )
\end{align}

\underline{Estimating the size of $\theta_h$: energy estimate}

By the equation of $\theta_h$, and by the possibility of testing with $v_h = \theta_h$ itself, we obtain:

\begin{align*}
	\frac{1}{2} \frac{d}{dt} \norm{\theta_h}_{L^2(\Omega_h)}^2 + \norm{\theta_h}^2_{H^1(\Omega_h)} - \norm{\theta_h}^2_{L^2(\Omega_h)} = E_h(\theta_h)
\end{align*}

Hence, calling  $Q:=C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)}$, by Young's inequality, some algebraic manipulations and by using Gronwall's inequality (25, page 19 of \cite{gilardi}), for all $t \in [0,T]$ we have:

\begin{align}
\label{eqn:theta_energy}
	\norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \int_0^T\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim 8h^4\int_0^T Q^2 + 2\norm{\theta_h(0)}_{L^2(\Omega_h)}^2
\end{align}

We can apply also \cref{prop:lift} to obtain an estimate in spaces that don't depend on $h$:


\begin{align*}
	\norm{\theta_h^l(t)}_{L^2(\Omega)}^2 + \int_0^T\norm{\theta_h^l}^2_{H^1(\Omega)} \lesssim h^4\int_0^T Q^2 + \norm{\theta_h^l(0)}_{L^2(\Omega)}^2
\end{align*}

\underline{Conclusion}

We have, for $e=u-u_h^l = \rho + \theta_h^l$, and $h$ small, by combining \cref{eqn:theta_energy} and \cref{prop:ritz}:

\begin{align*}
	\norm{e(t)}_{L^2(\Omega)}^2 + h^2\int_0^T\norm{e}^2_{H^1(\Omega)} \lesssim \\
	 h^4 \norm{u(t)}_{H^2(\Omega)}^2 + h^4\norm{g_D(t)}_{L^2(\Gamma_D)}^2 + h^2h^2\int_0^T\norm{u}^2_{H^2(\Omega)} +  h^4\int_0^T Q^2 + \norm{\theta_h^l(0)}_{L^2(\Omega)}^2
\end{align*}

A triangle inequality applied to $\norm{\theta_h^l(0)}_{L^2(\Omega)}^2$, an application of \cref{prop:ritz} and the definition of $Q$ allow us to conclude.
\end{mproof}

We can also prove convergence of the derivatives in a rather strong norm.

\begin{cor}[Refined error estimate]
\label{cor:L2_deriv_est}
Apart from \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix}, further assume that $g_{N}\in H^1(I, H^2(\Gamma_N))$. Then, for all $t \in (0,T)$:

\begin{align*}
	\int_0^T\norm{\partial_tu - (\partial_t u_h)^l}^2_{L^2(\Omega)} + \norm{u(t)-u_h^l(t)}_{H^1(\Omega)}^2 \lesssim h^2 B^2
\end{align*}


where $B:=\ds \norm{u}_{H^1(I,H^2(\Omega))}^2 + \norm{g_D}_{H^1(I,H^2(\Gamma_D))}^2 +  \int_0^T C_f^2+  \norm{f_h}_{L^2(I,L^2(\Omega_h))}^2 +\norm{g_N}_{H^1(H^2(\Gamma_N))}^2+\norm{u_0}_{H^2(\Omega)}^2$.

\end{cor}

\begin{mproof}

We employ again the error decomposition $e = \rho + \theta_h^l$.

%\underline{Isomorphism between $H^1$ spaces}
%
%We show that there exists an isomorphism $H^1(\Omega) \rightarrow H^1(\Omega_h)$ that has norms independent of $h$ (for small $h$).
%
%To do so, note that $H^1_T(\Omega_h) = H^1(\Omega_h)$ and $H^1_B(\Omega)=H^1(\Omega)$, where the subscript $B$ means "broken". For a definition of broken Sobolev space, see (4.18), page 1737, \cite{ranner}. The equivalence is proven in lemma 4.20, page 1738. 
%
%The lifting map induces the desired isomorphism between broken spaces, hence, between unbroken spaces, see proposition 8.14, page 1792, \cite{ranner}, where we can also deduce that the norms of such isomorphism can be bounded by numbers that don't depend on $h$.

\underline{Another estimate for $\theta_h$}

Consider again \cref{eqn:theta}. We intend to test by $\partial_t \theta_h \in L^2(I,S^1_{h,0,D_h})$. This is possible also by the reasonings in \cite{hinze}, (1.61), page 42. Integrate from $0$ to $t$ to obtain:

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \left ( a_h(\theta_h(t), \theta_h(t)) - a_h(\theta_h(0), \theta_h(0))\right ) = 
\int_0^t(\partial_t R_h u , \partial_t\theta_h)_{L^2(\Omega_h)} - \int_0^t(\partial_t R_c u , \partial_t\theta_h^l)_{L^2(\Omega)}\\
- \int_0^t(\partial_t \rho, \partial_t\theta_h^l)_{L^2(\Omega)}\\ + \int_0^t(f, \partial_t\theta_h^l)_{L^2(\Omega)} - \int_0^t(f_h, \partial_t\theta_h)_{L^2(\Omega_h)}\\ + \int_0^t(g_{N}, \partial_t\theta_h^l)_{L^2(\Gamma_{N})} - \int_0^t(g_{N,h}, \partial_t\theta_h)_{L^2(\Gamma_{N_h})} 
\end{align*}

By suitable estimations of the left hand side (involving \cref{thm:a_h_coercive}), using integration by parts for the terms with $g_N, g_{N,h}$ and \cref{prop:lin_appr} on the right hand side, plus the Young inequality, we get: 


\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \norm{\theta_h(t)}_{H^1(\Omega_h)}^2 \leq  \frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2} \norm{\theta_h(0)}_{H^1(\Omega_h)}^2\\
+ Ch^2\int_0^t \norm{\partial_t u}_{H^2(\Omega)}^2 + \frac{1}{6}\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)}\\
+ Ch^2\int_0^t(\norm{\partial_t u}_{H^2(\Omega)}+	\norm{\partial_t g_D}_{H^2(\Gamma_D)})^2 + \frac{1}{6} \int_0^t\norm{\partial_t \theta_h}_{L^2(\Omega_h)}^2\\
+ Ch^2\int_0^t C_f^2+ Ch^2\int_0^t \norm{f_h}_{L^2(\Omega_h)}^2  + \frac{1}{6}\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)}\\ 
+ Ch^2\int_0^t \norm{\partial_t g_N}_{H^2(\Gamma_N)}^2 + \int_0^t \norm{ \theta_h}_{H^1(\Omega_h)}^2\\
+ Ch^2\norm{g_N(t)}_{H^2(\Gamma_N)}^2 + \frac{1}{4}\norm{ \theta_h(t)}_{H^1(\Omega_h)}^2\\
+ Ch^2\norm{g_N(0)}_{H^2(\Gamma_N)}^2 + \frac{1}{2}\norm{ \theta_h(0)}_{H^1(\Omega_h)}^2
\end{align*}


where $C$ is independent of $h$ and $t$. We re-arrange, and apply \cref{eqn:theta_energy} to the term $\ds \norm{ \theta_h(t)}^2_{L^2(\Omega_h)} + \int_0^t \norm{ \theta_h}_{H^1(\Omega_h)}^2$. 

Calling $q=\ds \int_0^T \left [ \norm{\partial_t u}_{H^2(\Omega)}^2 +	\norm{\partial_t g_D}_{H^2(\Gamma_D)}^2 + C_f^2 +  \norm{f_h}_{L^2(\Omega_h)}^2 + Q^2+ \norm{g_N}_{H^2(\Gamma_N)}^2 + \norm{\partial_t g_N}_{H^2(\Gamma_N)}^2 \right ] $, and upon using \cref{prop:lift}, \cref{prop:ritz} and \cref{prop:interp_curv}:

\begin{align*}
\int_0^T\norm{\partial_t \theta_h^l}^2_{L^2(\Omega)} + \norm{\theta_h(t)^l}_{H^1(\Omega)}^2 \lesssim  \norm{\theta_h(0)}_{H^1(\Omega_h)}^2+ h^4q \lesssim h^2\norm{u_0}_{H^2(\Omega)}^2+ h^4q
\end{align*}

\underline{Conclusion}

There holds 

\begin{align*}
\norm{e(t)}_{H^1(\Omega)}^2 + \int_0^T\norm{\partial_t e}^2_{L^2(\Omega)}  \leq \\
\int_0^T\norm{\partial_t \rho}^2_{L^2(\Omega)} + h^2\norm{\rho(t)}_{H^1(\Omega)}^2 + \int_0^T\norm{\partial_t  \theta_h^l}^2_{L^2(\Omega)} + \norm{ \theta_h^l(t)}_{H^1(\Omega)}^2\leq \ind{above, and \cref{prop:ritz}}\leq \\
h^2\int_0^T(\norm{\partial_t u }_{H^2(\Omega)}^2 + \norm{\partial_t g_D }_{H^2(\Gamma_D)}^2) + h^2\norm{u(t)}_{H^2(\Omega)}^2 +  h^2\norm{u_0}_{H^2(\Omega)}^2+ h^4q
\end{align*}
\end{mproof}

If however we content ourselves with estimating the convergence of the derivatives in a weaker norm, we can actually obtain $O(h^2)$ convergence, in every case. To do so, it will be crucial to establish the $H^1$ stability of the $L^2$ projection in our context. This fact is known for polyhedral domains with some assumptions on the meshes, see e.g. \cite{yserentant}.

\begin{cor}[Order two convergence of derivatives in dual norm]
\label{cor:deriv_est_semid}
Under \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix} we have, for all $w \in L^2(I,H^1_{0,D}(\Omega))$:

\begin{align*}
\left | \int_I (\partial_t(u-u_h^l), w)_{L^2(\Omega)}\right |\lesssim h^2 A \norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

\end{cor}

\begin{mproof}

We introduce the $L^2$ projection $\pi_h: L^2(\Omega) \rightarrow S^1_{h,0,D_h}$, given by:

$$(\pi_h w, v_h)_{L^2(\Omega_h)}=(w, v_h^l)_{L^2(\Omega)},\quad \forall  v_h \in S^1_{h,0,D_h}$$

The definition is remimniscent of that of the Ritz projection. We will prove well-posedness and $H^k$ stability of such projection, i.e. $\norm{\pi_h w}_{H^k(\Omega_h)}\lesssim\norm{w}_{H^k(\Omega)}$, for $k=0,1$.
First, let us show how this projection helps in the estimate.

\underline{Conclusion}

For $w \in H^1_{0,D}(\Omega)$ we estimate $(\partial_t(\theta_h^l), w)_{L^2(\Omega)} = (w, (\partial_t\theta_h^l))_{L^2(\Omega)} =  (\pi_h w,\partial_t\theta_h)_{L^2(\Omega_h)}$. We have also used that lifting and differentiating with respect to time commute, by \cref{prop:lift} and \cref{lemma:bochner_Hk_map}. We can now apply \cref{eqn:theta}:

\begin{align*}
	(\partial_t(\theta_h^l), w)_{L^2(\Omega)} = a_h(\theta_h, \pi_h w) - E_h(\pi_h w ) \lesssim \ind{\cref{eqn:theta_residual}}\lesssim\\
	\norm{\theta_h}_{H^1(\Omega_h)} \norm{\pi_h w}_{H^1(\Omega_h)} + h^2 (\norm{\pi_h w }_{H^1(\Omega_h)} C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} ) \lesssim\\
	\norm{\theta_h}_{H^1(\Omega_h)} \norm{ w}_{H^1(\Omega)} + h^2 \norm{w }_{H^1(\Omega)} (C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} )
\end{align*}

where in the last step we used the supposed stability of $\pi_h$. Integrating in time and using the Cauchy-Schwarz inequality:

\begin{align*}
	\left | \int_I(\partial_t(\theta_h^l), w)_{L^2(\Omega)} \right |^2 \lesssim\\
	\left (\int_I \norm{\theta_h}_{H^1(\Omega_h)}^2+ h^4 \int_I (C_f^2 + \norm{f_h}_{H^1(\Omega_h)}^2 + \norm{g_N}^2_{H^2(\Gamma_N)} + \norm{\partial_t u}^2_{H^2(\Omega)} + \norm{\partial_t g_D}^2_{H^2(\Gamma_D)} )\right) \int_I\norm{ w}_{H^1(\Omega)}^2 \lesssim \ind{\cref{eqn:theta_energy}} \lesssim\\
	h^4 \left (  \int_I Q^2 + \norm{u_0}_{H^2(\Omega)}^2 + \int_I (C_f^2 +\norm{f_h}_{H^1(\Omega_h)}^2 + \norm{g_N}^2_{H^2(\Gamma_N)} + \norm{\partial_t u}^2_{H^2(\Omega)} + \norm{\partial_t g_D}^2_{H^2(\Gamma_D)} )\right) \norm{w}_{L^2(I,H^1(\Omega))}^2
\end{align*}

We can also estimate:
\begin{align*}
\left | \int_I (\rho_t, w)_{L^2(\Omega)}\right |\lesssim \ind{as in the proof of \cref{thm:semidiscrete_error_bound}}\lesssim\\\int_I
h^2 (\norm{\partial_t w}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)})\norm{w}_{H^1(\Omega_h)} \lesssim \ind{Cauchy-Schwarz}\lesssim\\
h^2 \sqrt{\norm{\partial_t u}_{H^2(\Omega)}^2 + \norm{\partial_t g_D}_{H^2(\Gamma_D)}^2}\norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

and by the usual splitting $e=\rho + \theta_h^l$ we can conclude.

\underline{$L^2$ projection: well-posedness}

From the definition of $\pi_h$ we obtain:

$$(\pi_h w, v_h)_{L^2(\Omega_h)}=(w, v_h^l)_{L^2(\Omega)}  = (w^{-l} \xi, v_h)_{L^2(\Omega_h)}$$

where $\xi \in L^\infty(\Omega_h)$ is a term originating from the change of variables. We therefore recognize that $\pi_h w$ is the usual $L^2$ projection of $w^{-l} \xi\in L^2(\Omega_h)$ onto the closed subspace $S^1_{h,0,D_h}$, for which we know existence and uniqueness.

\underline{$L^2$ projection: stability}

$L^2$ stability of $\pi_h$ follows by testing with $\pi_h w$ itself and using \cref{prop:lift}.
Also, denote by $\pi_h^*$ the usual $L^2$ projector:

$$(\pi_h^* v - v, v_h)_{L^2(\Omega_h)}=0,\quad \forall  v_h \in S^1_{h,0,D_h}$$

We have, for $w \in L^2(\Omega)$, that $(\pi_h w - \pi_h^* w^{-l}, v_h)_{L^2(\Omega_h)} = (w, v_h^l)_{L^2(\Omega)} - (w^{-l}, v_h)_{L^2(\Omega_h)}$. An application of \cref{prop:lin_appr} and of \cref{prop:lift} yields:

\begin{align*}
	\norm{\pi_h w - \pi_h^* w^{-l}}^2_{L^2(\Omega_h)}\lesssim h \norm{w}_{L^2(\Omega)}\norm{\pi_h w - \pi_h^* w^{-l}}_{L^2(\Omega_h)}
\end{align*}

Now, we can adapt the original proof of \cite{bank} to our case, see in particular (A.1). 
In fact: $|\pi_h w|_{H^1(\Omega_h)}\leq |\pi_h w -\pi^* w^{-l}|_{H^1(\Omega_h)} + |\pi_h^* w^{-l}|_{H^1(\Omega_h)}$.

We can apply an inverse inequality to the first member: $|\pi_h w -\pi^* w^{-l}|_{H^1(\Omega_h)}\lesssim h^{-1}\norm{\pi_h w -\pi^* w^{-l}}_{L^2(\Omega_h)}\lesssim \norm{w}_{L^2(\Omega)}$.

For the second term, consider a suitable $w_h \in S^{1}_{h,0,D_h}$. We have: $|\pi_h^* w^{-l}|_{H^1(\Omega_h)}\leq |\pi_h^* (w^{-l}-w_h)|_{H^1(\Omega_h)} +|\pi_h^* w_h|_{H^1(\Omega_h)}\lesssim h^{-1}\norm{\pi_h^*(w^{-l}-w_h)}_{L^2(\Omega_h)} +\norm{w_h}_{H^1(\Omega_h)}$, where we again applied inverse inequalities, together with the fact that $\pi_h^* w_h = w_h$ for $w_h \in S^1_{h,0,D_h}$ (i.e $\pi_h^*$ is really a projection, unlike $\pi_h$). Moreover, $\norm{\pi_h^* v}_{L^2(\Omega_h)}\leq \norm{v}_{L^2(\Omega_h)}$, so that $|\pi_h^* w^{-l}|_{H^1(\Omega_h)} \lesssim h^{-1}\norm{w^{-l}-w_h}_{L^2(\Omega_h)} +\norm{w_h}_{H^1(\Omega_h)}$. So, if there holds $\norm{w^{-l}-w_h}_{L^2(\Omega_h)}\lesssim h \norm{w}_{H^1(\Omega)}$ and $\norm{w_h}_{H^1(\Omega_h)}\lesssim \norm{w}_{H^1(\Omega)}$, then we are done.

\underline{Finding $w_h$}

Such $w_h$ will be the optimal order interpolator with boundary conditions described in (5.9) at page 1230, \cite{bernardi}. We need to check that our framework matches that of \cite{bernardi} to apply such a result.

But this is ensured by the construction outlined in \cite{ranner}, sections 8.5 and 8.6. The assumptions of theorem 5.1, in particular, are all satisfied: that the triangulations satisfy the so called $1$-regularity is proved in lemma 8.13 or \cite{ranner}, whereas all the other properties are already discussed in \cite{bernardi} following example 2 (see pages 1216, 1221, 1228, and remark 5.2 at page 1230).

Applying corollary 5.1 of \cite{bernardi} to $\Gamma_0=\Gamma_D$ ($\Gamma_0$ is in the notation of \cite{bernardi}) we find $w_h \in S^{1}_{h,0,D_h}$ (true by proposition and corollary 5.1, \cite{bernardi}), with:

\begin{itemize}
	\item $\norm{w-w_h^l}_{L^2(\Omega)}\lesssim h \norm{w}_{H^1(\Omega)}$
	\item $|w-w_h^l|_{H^1(\Omega)}\lesssim \norm{w}_{H^1(\Omega)}$
\end{itemize}

Therefore we also get $\norm{w_h^l}_{H^1(\Omega)} \lesssim(C(1+h)+1)\norm{w}_{H^1(\Omega)}$.

Applying \cref{prop:lift} we see that $w_h$ satisfies all the requirements. Note, is is essential here that $w=0$ on $\Gamma_D$.

%\textcolor{red}{One could be extra careful here, or maybe just assume the existence of $u_h$}
\end{mproof}

\section{Fully discrete estimates}
\label{sec:fullyd}
Here, we attempt at deriving fully discrete estimates given the semidiscrete results just above.

\begin{ass}[Assumptions for full discretization]
\label{ass:full_discr_smoothness}
\textcolor{white}{ }

We discuss the implicit Euler method ($\theta=1$) and the Crank-Nicolson method ($\theta=1/2$).

We ask \cref{ass:discr_reg}.

We further assume:

\begin{itemize}
	\item $g_N \in H^{1/\theta}(I, H^2(\Gamma_N))$
	\item $g_D \in H^{1/\theta+1}(I, H^{3/2}(\Gamma_D))$
	\item $f_h\in H^{1/\theta}(I, S^1_{h})$
	\item $\norm{\delta_{h}(0)^{(1/\theta)}}_{L^2(\Omega_h)}$ is bounded uniformly for small $h$
\end{itemize}

\end{ass}

We consider $f_h^k$ to be a suitable approximation of $f_h(t^k)$, i.e. $f_h^k \simeq f_h(t^k)$.

\begin{pb}[Numerical scheme]
\label{pb:num_scheme}
Under \cref{ass:full_discr_smoothness}, it is:

\begin{align*}
\left ( \frac{u_{h}^{k+1}-u_h^k}{\delta t}, v_h\right)_{L^2(\Omega_h)} + a_h(\theta u_h^{k+1}+(1-\theta)u^k_h, v_h) =\\ (\theta f_h^{k+1}+(1-\theta)f_h^k, v_h)_{L^2(\Omega_h)} + (\theta g_{N,h}^{k+1} + (1 - \theta)g_{N,h}^{k} , v_h)_{L^2(\Gamma_{N_h})},\quad v_h \in S^1_{h,0,D_h}, 1\leq k \leq K\\
u_h^{k+1}=g_{D,h}^{k+1},\quad 1\leq k \leq K \text{,  on } \Gamma_{D_h}\\
u_h^0=u_{0h}
\end{align*}

\end{pb}

\begin{prop}[Discrete versus semidiscrete]
\label{prop:d_vd_sd}
We are working under \cref{{ass:full_discr_smoothness}}.

Call $e_h^k:=u_h^k-u_h(t^k)$ and $\delta f_h^k:=f_h^k-f_h(t^k)$. Then, for $\theta=1, 1/2$, we have $u_h \in H^{1/\theta+1}(I, S^1_h)$ and, for $1\leq n \leq K$:

\begin{align*}
\delta t \sum_{k=0}^{n-1} \norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{(H^1_{0,D_h}(\Omega_h))^*}^2 + \norm{e_{h}^{n}}_{L^2(\Omega_h)}^2 + \delta t \sum_{k=0}^{n-1}\norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 \lesssim 
D^2 + (\delta t)^{2/\theta} C^2
\end{align*}

where $C^2:=\ds \int_I \norm{f^{(1/\theta)}_h}_{-1,h}^2+\int_I\norm{ g_{N}^{(1/\theta)}}_{H^{2}(\Gamma_{N})}^2 + \int_I\norm{g_D^{(1/\theta+1)}}_{H^{3/2}(\Gamma_D)}^2 + \norm{\delta_{h}(0)^{(1/\theta)}}_{L^2(\Omega_h)}^2$,  $\ds D_n^2:= \ds {\delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2}$.
See the proof of \cref{prop:wp_discr_par} for the definition and properties of $\delta_h$.

\end{prop}

Note, the difference quotient is estimated in the dual norm of $H^1_{0,D_h}=\{u \in H^1, u(\Gamma_{D_h})=0\}$.

\begin{mproof}

Recall the semidiscrete problem, \cref{pb:inh_parabolic_discr}, for  $u_h \in H^1(I, S^1_h)$. For the $L^2, H^1$ estimate we refer to \cite{quarteroni}, page 385 and following, in particular, theorem 11.3.1 and 11.3.2. In particular, calling $e_h^k:=u_h^k-u_h(t^k)$, and $\delta f_h^k:=f_h^k-f_h(t^k)$:

\begin{align}
\label{eqn:discr_err}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, v_h\right)_{L^2(\Omega_h)} + a_h(\theta e_h^{k+1}+(1-\theta)e^k_h, v_h) = (\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k, v_h)_{L^2(\Omega_h)} \\
e_h^{k+1}=0  \text{,  on } \Gamma_{D_h}\\
e_h^0=0
\end{align}

where we defined $Q_h^k:\ds =\frac{u_{h}(t^{k+1})-u_h(t^k)}{\delta t} -\theta \partial_t u_h(t^{k+1}) - (1-\theta)\partial_tu_h(t^k)$. The proof now consists in deriving discrete energy estimates for \cref{eqn:discr_err}, exactly how it is done in \cite{quarteroni}. We only remark a few facts that will be referenced in other proofs.

\underline{Estimating $Q_h^k$}

We provide estimates of $Q_h^k$ in a suitable norm. In the case $\theta = 1/2$, from the smoothness assumptions on the data we obtain $u_h \in H^3(I,S^1_h)$ and, exactly as in \cite{quarteroni}:

$$\delta t \sum_{k=0}^{n-1}\norm{ Q_h^k}_{-1,h}^2\lesssim \delta t^4 \int_I \norm{u_h'''}_{-1,h}^2$$

Differentiating \cref{pb:inh_parabolic_discr} twice we obtain:

$$\norm{u_h'''(t)}_{-1,h}\leq \norm{f''_h}_{-1,h}+\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})} + \norm{u_h''}_{H^1(\Omega_h)}$$

By energy estimates, as in \cref{prop:wp_discr_par}, through the splitting $u_h = \delta_h + G_{D,h}$ (see \cref{ass:discr_reg}):

\begin{align}
\label{eqn:dd_est}
\norm{u_h''}_{L^2(I,H^1(\Omega_h))}\lesssim \norm{f_h''}_{L^2(I,(S^{1}_{h,0,D_h})^*)} + \norm{g_{N,h}''}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}'''}_{L^2(I,H^1(\Omega_h)))} + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}
\end{align}

Under our hypothesis \cref{ass:full_discr_smoothness}, we have that $\norm{\delta_h''(0)}_{L^2(\Omega_h)}^2 \lesssim C$. This, and \cref{ass:discr_reg}, yield a bound, uniform on $h$, on $\ds \int_I \norm{u_h'''}_{-1,h}^2$.

This bound is:

\begin{align*}
	\int_I \norm{u_h'''(t)}_{-1,h}^2\lesssim \int_I \norm{f''_h}_{-1,h}^2+\int_I\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}^2 + \int_I\norm{G_{D,h}'''}_{H^1(\Omega_h)}^2 + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}^2
\end{align*}

But $\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}=\norm{\Pi_h g_{N}''}_{L^2(\Gamma_{N_h})}$, where $\Pi_h$ is the nodal interpolator (see \cref{ass:discr_reg}). By \cref{prop:lin_appr}, $\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}\lesssim \norm{\Pi_c g_{N}''}_{L^2(\Gamma_{N})}\leq (1+h^2)\norm{ g_{N}''}_{H^2(\Gamma_{N})}$, where we also used \cref{prop:interp_curv}. 
Moreover $\norm{G_{D,h}'''}_{H^1(\Omega_h)} = \norm{\Pi_h G_D'''}_{H^1(\Omega_h)}\lesssim  \norm{\Pi_c G_D'''}_{H^1(\Omega)}\lesssim (1+h)\norm{G_D'''}_{H^2(\Omega)}\lesssim \norm{g_D'''}_{H^{3/2}(\Gamma_D)}$.

Therefore:

\begin{align*}
	\int_I \norm{u_h'''(t)}_{-1,h}^2\lesssim \int_I \norm{f''_h}_{-1,h}^2+\int_I\norm{ g_{N}''}_{H^{2}(\Gamma_{N})}^2 + \int_I\norm{g_D'''}_{H^{3/2}(\Gamma_D)}^2 + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}^2
\end{align*}


The proof for $\theta=1$ is very similar.

%\underline{Conclusion: estimates in energy norm}
%
%We go back to \cref{eqn:discr_err}. Starting with the case $\theta = 1/2$, we test with $e_h^{k+1}-e_h^{k}$ instead. We obtain:
%
%\begin{align*}
%	a_h((e_h^{k+1}+e^k_h)/2, e_h^{k+1}-e_h^{k}) \leq \frac{1}{2}( \delta f_h^{k+1} + \delta f_h^k + Q_h^k, e_h^{k+1}-e_h^{k})_{L^2(\Omega_h)}
%\end{align*}
%
%This means:
%
%\begin{align*}
%	(\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} - \norm{\nabla e^k_h}_{L^2(I,\Omega_h)})(\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} + \norm{\nabla e^k_h}_{L^2(I,\Omega_h)})\leq\norm{ \delta f_h^{k+1} + \delta f_h^k + Q_h^k}_{-1,h}\norm{ e_h^{k+1}-e_h^{k}}_{H^1(\Omega_h)}
%\end{align*}
%
%Taking again advantage of the $h$ uniform coercivity $\norm{ v_h}_{H^1(\Omega_h)}\lesssim \norm{v_h}_{\nabla (\Omega_h)}$, for any $v_h \in S^1_{h,0,D_h}$, we find:
%
%\begin{align*}
%	\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} - \norm{\nabla e^k_h}_{L^2(I,\Omega_h)}\lesssim \norm{ \delta f_h^{k+1} + \delta f_h^k + Q_h^k}_{-1,h}
%\end{align*}
%
%\textcolor{red}{what if we are dividing by $0$? Np}

\underline{Estimates for the difference quotient}

We go back to \cref{eqn:discr_err}.  We employ the $L^2$ projection $\pi_h^*$ as in the proof of \cref{cor:deriv_est_semid}, where we proved its stability properties. Consider then any $v \in H^1_{0,D}(\Omega)$, so that $v^{-l} \in H^1_{0,D_h}(\Omega_h)$ (i.e. $v^{-l}=0$ on $\Gamma_{D_h}$).

Then:

\begin{align}
\label{eqn:der_err_eqn}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, v^{-l}\right)_{L^2(\Omega_h)} = \left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, \pi_h^* v^{-l}\right)_{L^2(\Omega_h)} =  \\- a_h(\theta e_h^{k+1}+(1-\theta)e^k_h, \pi_h^* v^{-l}) + (\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k, \pi_h^* v^{-l})_{L^2(\Omega_h)}
\end{align}

which leads us to:

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{(H^1_{0,D_h}(\Omega_h))^*} \lesssim  \norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)} + \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k}_{-1,h}
\end{align*}

and we can conlude by the above estimates on $Q_h^k$ and the $H^1$ estimate.
\end{mproof}

\begin{thm}[Fully discrete estimates]
\label{thm:fully_discr_est_par}
With the hypothesis and notation of \cref{thm:semidiscrete_error_bound}, \cref{prop:d_vd_sd}, \cref{cor:L2_deriv_est}, \cref{cor:deriv_est_semid}, there holds:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim  h^2 A  + D +  (\delta t)^{1/\theta}C\\
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - (u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - (u_h^{k})^l)}_{H^1(\Omega)}^2} \lesssim hB + D + (\delta t)^{1/\theta} C\\
	\left | \int_I (\partial_t u , w_K)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(\Omega)} \right |\lesssim \left ( h^2A + D + (\delta t)^{1/\theta} C\right ) \norm{w_K}_{L^2(I,H^1_{0,D}(\Omega))}
\end{align*}

where $D^2:= \ds {\delta t\sum_{k=0}^{K-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2}$. Here $w_K$ is assumed to be piecewise constant on the time discretization, and with values $w_{K,k}$, on $[t^k,t^{k+1}]$, that belong to $H^1_{0,D}(\Omega)$.
% \textcolor{red}{If we put $w \in H^(I,H^1_{0,D)}$ this probably still works, by choosing to evaluate the sum on the right on the local averages of $w$, and employing dual estimates for such projection}.
\end{thm}

\begin{mproof}

\underline{$L^2$ norm}

By \cref{thm:semidiscrete_error_bound}, $\norm{u(t)-u_h^l(t)}_{L^2(\Omega)}^2 \lesssim	 h^4A^2$. Combining this with the $L^2$ estimates proved in \cref{prop:d_vd_sd} we see, thanks to \cref{prop:lift}:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim \\ \norm{u(t^k)-u_h^l(t^k)}_{L^2(\Omega)}+ \norm{u_h(t^k)-u_h^k}_{L^2(\Omega)}\lesssim \\A h^2 + \sqrt{\delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} + C (\delta t)^{1/\theta} 
\end{align*}

\underline{$H^1$ norm}

%If we employed \cref{cor:L2_deriv_est}, which yields $\norm{u(t)-u_h^l(t)}_{H^1(\Omega)} \lesssim Bh$, we would obtain a suboptimal estimate in space. We do otherwise: c

Using \cref{prop:d_vd_sd} and \cref{prop:lift}:

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(\Omega)}^2 \lesssim \\
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h(t^{k+1})^l) + (1-\theta)(u(t^{k}) -u_h(t^{k})^l)}_{H^1(\Omega)}^2 + \delta t \sum_{k=0}^{K-1} \norm{\theta e_h^{k+1} + (1-\theta)e_h^k}_{H^1(\Omega)}^2 
\end{align*}

%For the case $\theta = 1/2$ one could argue by noticing that $ \ds \frac{e_h(t^k)+e_h(t^{k+1})}{2} = \frac{1}{\delta t}\int_{t^k}^{t^{k+1}}\Pi e_h(s) ds$, bounding the first sum by $\norm{\Pi u - u}_{L^2(I,H^1(\Omega))}^2 + \norm{\Pi u_h^l - u_h^l}_{L^2(I,H^1(\Omega))}^2 + \norm{e_h}_{L^2(I,H^1(\Omega))}^2$,  $\Pi e_h$ being the Lagrangian linear interpolator of $e_h:=u-u_h^l$, and then using the $O(\delta t^2)$ approximation power of $\Pi$, thus obtaining a bound that is  $O(\delta t^4 + h^2)$.

By employing \cref{cor:L2_deriv_est}: 

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h(t^{k+1})^l) + (1-\theta)(u(t^{k}) -u_h(t^{k})^l)}_{H^1(\Omega)}^2 \leq \\
	2\delta t \sum_{k=0}^{K} \norm{u(t^{k}) -u_h(t^{k})^l}_{H^1(\Omega)}^2 \lesssim \\
	2 \delta t K h^2 B^2
\end{align*}

%\lesssim\\
%	\delta t \sum_{k=0}^{K-1} B^2 h^2 + \delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + (\delta t)^{2/\theta} C^2 \lesssim\\
%	B^2h^2 + \delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + C^2(\delta t)^{2/\theta}

\underline{Estimate for the derivative}

Let $w \in L^2(I,H^1_{0,D}(\Omega))$ be piecewise constant in time, with values $w_k$ on $[t^k,t^{k+1}]$. We can then write:

\begin{align*}
	\int_I (\partial_t u , w)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)} = \\
	\int_I (\partial_t (u-u_h^l) , w)_{L^2(\Omega)} + \delta t \sum_{k=0}^{K-1}\left ( \frac{(e^{k+1}_h)^l - (e_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)}
\end{align*}

For the first term we can use \cref{cor:deriv_est_semid}. For the second one we can write, thanks to \cref{prop:lin_appr}:

\begin{align*}
	\left | \delta t \sum_{k=0}^{K-1}\left ( \frac{(e^{k+1}_h)^l - (e_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)}\right | \lesssim \\
	\delta t h \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)} \norm{w_k}_{H^1(\Omega)} + \delta t \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{-1,h} \norm{w_k}_{H^1(\Omega)} \leq \\
	\left ( h\sqrt{\delta t \sum_{k=0}^{K-1}  \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)}^2}  + \sqrt{ \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{-1,h}^2}\right ) \norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

If we can control $\ds \delta t \sum_{k=0}^{K-1} \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)}^2$ we are done, also by the estimates in \cref{prop:d_vd_sd}. 
We test \cref{eqn:discr_err} by $\ds \frac{e^{k+1}_h - e_h^k}{\delta t}$. Then, applying an additional Young's inequality in the case $\theta =  1$ this reads: 

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 + \frac{\norm{\nabla e_h^{k+1}}_{L^2(\Omega_h)}^2}{2\delta t}-  \frac{\norm{\nabla e_h^{k}}_{L^2(\Omega_h)}^2}{2\delta t}\leq  \left (\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)} + \norm{Q_h^k}_{-1,h} \right )\norm{\frac{e^{k+1}_h - e_h^k}{\delta t}}_{H^1(\Omega_h)}
\end{align*}

or also, as $e^0_h=0$:

\begin{align*}
\delta t \sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 \leq  \left (\sqrt{\delta t \sum_{k=0}^{K-1}\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} +\sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{-1,h}^2} \right )\sqrt{\delta t \sum_{k=0}^{K-1}\norm{\frac{e^{k+1}_h - e_h^k}{\delta t}}_{H^1(\Omega_h)}^2}
\end{align*}


Applying inverse inequalities and by the proof of \cref{prop:d_vd_sd}, for $h$ small:

\begin{align*}
h\sqrt{\delta t\sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 }\leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} + (\delta t)^{1/\theta} C
\end{align*}
\end{mproof}


%\begin{cor}[Further estimates for $A,B,C,D$]
%\label{cor:actual_par_est}
%Assume that $f_h^k$ and $f_h$ are given as fully discrete and semidiscrete solutions (see \cref{pb:num_scheme} and  \cref{pb:inh_parabolic_discr}) of \cref{pb:inh_parabolic}, for which all the assumptions of \cref{thm:fully_discr_est_par} hold (in particular, all the continuous and discrete compatibility conditions).
%
%We assume for simplicity, for the right hand side of the equation of $f$, call it $F$, that $F \in H^{1/\theta}(I,H^2(\Omega))$ and we take $F_h = \Pi_h F$ and $F_h^k=F_h(t^k)$.
%
%We can therefore say that:
%
%\begin{align*}
%	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
%	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(\Omega)}^2} \lesssim h + (\delta t)^{1/\theta}\\
%	\left | \int_I (\partial_t u , w_K)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(\Omega)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(\Omega))}
%\end{align*}
%
%and $w_K$ is as in \cref{thm:fully_discr_est_par}.
%
%Note, the Dirichlet and Neumann boundaries need not to be the same for $f$, $u$.
%
%\end{cor}


%\begin{mproof}

%Follows immediately from the results derived in \cref{sec:semid}, \cref{sec:fullyd}. We give a detailed proof in the case of the PDEs arising from the shape optimization problem in \cref{prop:o-t-d}.

%We start to establish semidiscrete and fully discrete estimates for $f$.
%
%We assume the following notation for its problem, see \cref{pb:inh_parabolic}:
%
%$$
%\left\{\begin{matrix}
%\partial_t f-\Delta f = F & \text{ on } \Omega \times I \\ 
%f = \gamma_D & \text{ on } \Gamma_D' \times I\\ 
%\partial_\nu f = \gamma_N & \text{ on } \Gamma_N' \times I \\
%f(0) =  f_0
%\end{matrix}\right.
%$$
%
%By our hypothesis, we can apply \cref{thm:fully_discr_est_par} to $f$ and obtain error bounds with constants $A(f), B(f), C(f), D(f)$ which we now show to be bounded, uniformly with respect to $h, \delta t$.
%
%In particular, by the choice of $F_h^k$, we see that $D(f)=0$.
%
%For $C(f)$, the requirement of compatibilty leaves only one last bound to be made, that on $\ds \int_I\norm{F_h^{(1/\theta)}}_{-1,h}^2$. This one is surely bounded with $h$, by the choice of $F_h=\Pi_h F$, the time smoothness of $F$, and \cref{prop:interp_curv}.
%
%For $A(f), B(f)$ we only need to estimate $\ds \int_I C_F^2$ and $\ds \int_I \norm{F_h}_{H^1(\Omega_h)}^2$. The latter term is done as above. Morevoer, by \cref{prop:interp_curv}, $C_F$ is just $\norm{F}_{H^2(\Omega)}$, whose integral in time is bounded by assumption.
%
%Therefore, \cref{prop:d_vd_sd} yields the estimate:
%
%\begin{align*}
%	D^2 = \delta t \sum_{k=0}^{K-1} \norm{\theta(f_h(t^{k+1}) - f_h^{k+1}) + (1-\theta)(f_h(t^{k}) - f_h^{k})}_{H^1(\Omega)}^2 \lesssim (\delta t)^{2/\theta}
%\end{align*}
%
%and $C_f = A_f$ by \cref{thm:semidiscrete_error_bound}.
%
%There remains to check that $A, B, C$ are also bounded with $h, \delta t$.
%
%For $C$, the assumed compatibility requirements leave us only the estimation of $\ds\int_I\norm{f_h^{(1/\theta)}}_{-1,h}^2$. To avoid complications with the fact that  this dual norm $\{-1,h\}$ might not actually be the same dual norm of the problem of $f$ (in fact, the Dirichlet and Neumann boundaries may not be the same between $f$ and $u$), we proceed to estimate the stronger $L^2(\Omega_h)$ norm. This can be done as above \cref{eqn:dd_est}. The bound uniform on $h$ is again a consequence of the assumed compatibility conditions, and the fact that $\norm{F_h^{(2/\theta)}}_{L^2(I,L^2(\Omega_h))} $ is bounded, by the requirements on $F$.
%
%There remains to bound $A, B$. Our smoothness assumptions allow us to only check $A$, where we see that we need to bound $\ds \int C_f^2$ (already done, by above $C_f=A_f$) and $\ds \int_I \norm{F_h}_{H^1(\Omega_h)}^2$. This term is bounded by basic energy estimates on $f_h$.
%
%This concludes the proof of $7$, that of $9$ follows just like $6$ implied $8$, see above.

%\end{mproof}

%\textcolor{red}{Make a comment on why imposing BCs with interpolation of nodal values exactly on the boundary, is the right thing to do, in shape optimization... for instance, when the boundary moves, a projected bc would also move and we would need to know the exact transformation etc}

%\textcolor{red}{One could be extraprecise and track the dependence on $\Omega$ too, this is very difficult though}
\end{appendices}

\newpage

\pagenumbering{gobble}

\printbibliography[title={Bibliography}]

\addcontentsline{toc}{chapter}{Bibliography}

\end{document}
