% Packages and bibliography
\documentclass[english,a4paper,9pt,oneside]{scrbook}	% it was 12 pt, remove me in case
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[english]{babel}
\usepackage{marvosym}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mathtools}
\usepackage{calrsfs}
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\usepackage[toc,page]{appendix}
\usepackage{xcolor}
\usepackage{cleveref}
\usepackage[backend=bibtex]{biblatex}
\usepackage[nottoc,notlot,notlof]{tocbibind}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage[many]{tcolorbox}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{geometry}	% remove me in case
 \geometry{
 a4paper,
 left=10mm,
 top=20mm,
 right=10mm,
 bottom=20mm,
 }
\addbibresource{Bibliography/bibliography.bib}

% Formatting options
\setlength{\parindent}{0em}
\parskip = 0.35cm \relax
%\renewcommand{\baselinestretch}{1.25}

% equations and theorems style
\counterwithin*{equation}{section}
\counterwithin*{equation}{subsection}
\renewcommand{\theequation}{%
  \thesection.%
  \ifnum\value{subsection}>0 \arabic{subsection}.\fi
  \arabic{equation}%
}
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\upshape}{}%
  {\bfseries}{}%
  {\newline}{}%
\theoremstyle{break}
\newtheorem{thm}[equation]{Theorem}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{lemma}[equation]{Lemma}
\newtheorem{defn}[equation]{Definition}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{ass}[equation]{Assumption}
\newtheorem{pb}[equation]{Problem}
\newenvironment{mproof}[1][\proofname]{%
  \begin{proof}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{proof}
}
\renewcommand*{\proofname}{Proof}
\theoremstyle{remark}
\newtheorem{obs}[equation]{Observation}
\newtheorem{es}[equation]{Example}

% Colors
\tcolorboxenvironment{thm}{colback=green!25!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{cor}{colback=green!5!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{lemma}{colback=green!5!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{defn}{colback=black!5!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{prop}{colback=green!15!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{ass}{colback=red!15!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{pb}{colback=blue!15!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{es}{colback=black!5!white,colframe=black!5!black, opacityframe=0}
\tcolorboxenvironment{obs}{colback=black!5!white,colframe=black!5!black, opacityframe=0}

% Useful commands
\newcommand{\mR}{\mathbb{R}}
\newcommand{\mS}{\mathbb{S}^{n-1}}
\newcommand{\cV}{\pazocal{V}}
\newcommand{\ds}{\displaystyle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\HN}[1]{\norm{#1}_{H}}
\newcommand{\VN}[1]{\norm{#1}_{V}}
\newcommand{\VSN}[1]{\norm{#1}_{V^*}}
\newcommand{\tr}{\text{tr}}
\newcommand{\cc}{\subset\subset}
\newcommand{\emb}{\hookrightarrow}
\newcommand{\ind}[1]{\{\text{ #1 }\}}
\newcommand{\mind}[1]{$#1$}
\newcommand{\cT}{\pazocal{T}}
\newcommand{\id}{\text{Id}}
\newcommand{\te}{\theta}
\newcommand{\Te}{\Theta}
\newcommand{\tred}[1]{\textcolor{red}{#1}}
\newcommand{\dive}{\text{div}}
\newcommand{\weakc}{\rightharpoonup}
\newcommand{\xh}{\hat{x}}
\newcommand{\yh}{\hat{y}}
\newcommand{\eps}{\epsilon}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\newcommand{\tw}[1]{\texttt{#1}}

\begin{document}

% Titelseite
\pagestyle{empty}       % keine Seitennummer
  \parbox{1.5cm}{\resizebox*{110pt}{!}{\includegraphics{Logos/blau/2015_Logo_TUM_CMYK.pdf}}}\hspace{310pt}%
  \parbox{1.5cm}{\resizebox*{90pt}{!}{\includegraphics{Logos/08_Mathematik/MA_blau/FAK_MA_CMYK.pdf}}}%
\vspace*{1.5cm}
\begin{center}
{\Huge Technical University of Munich}
\\
\vspace*{1.5cm}
{\huge \textsc{Department of Mathematics}}
\\
\vspace*{3cm}
{\Huge \textbf{[Thesis Title]}}
\\
\vspace*{3cm}
{\Large Master's Thesis}\linebreak \\
{\Large von}\linebreak \\
{\Large Leonardo Mutti}\\
\vspace*{3cm}
{\Large 
\begin{tabular}{ll}
Supervisor: & Prof. Dr. Michael Ulbrich\\
Advisor: & Michel Ulbrich\\
Submission Date: & [Day. Month. Year]
\end{tabular}
}
\end{center}
\newpage    % Seitenwechsel

% Seite 2
\vspace*{18cm}
\noindent
I hereby declare that this thesis is my own work and that no other sources have been used except those clearly indicated and referenced.
\\[2cm]
Place, Date\\
original, hand-written signature
\newpage

% vertikaler Leerraum
\vspace*{2.2cm}
\noindent %kein Einzug
{\Huge \textbf{Acknowledgements}} \\
\vspace*{1.6cm} \\
% Seitennummerierung "rï¿½misch
\pagenumbering{roman}
% Kopfzeilen (automatisch erzeugt)
\pagestyle{headings}
[text of acknowledgements]

% Seite 3
\newpage
\section*{German Abstract}
[abstract text]
\section*{English Abstract}
[abstract text]
%Seite 4
\newpage
\tableofcontents  

\pagenumbering{arabic}  % Nummerierung der Seiten in 'arabisch' % neues Kapitel mit Namen "Introduction"

\chapter{Introduction}  \setcounter{page}{1}   % setzt Seitenzaehlung auf 1



\chapter{Infinite dimensional setting}
\label{chap:cts_shape_opt}

This chapter is devoted to the analysis of the non-discretized shape optimization problem:

\begin{itemize}
	\item in \cref{sec:shid} we introduce the shape identification problem we are interested in
	\item in \cref{sec:shopt_treatment} we reformulate it as a shape optimization problem, and compute the shape gradient of the cost functional to be minimized
	\item in \cref{sec:star}, we discuss the ansatz that the sought domains are star-shaped, to give some justification for our computer implementation
\end{itemize}

\section{Shape identification problem}
\label{sec:shid}

Let $D\subseteq\mR^n$ be a sufficiently smooth domain, and $\Omega \cc D$. We then call $\Gamma_f=\partial D$, $\Gamma_m = \partial \Omega$. We let $T>0$ and $I = (0,T)$, $\Sigma_f=I\times \Gamma_f$, $\Sigma_m=I\times \Gamma_m$.

\begin{figure}[H]
\centering
\includegraphics[width=0.25\columnwidth]{Images/Domains.pdf}
\caption{Space-time cylinder with labels}\label{fig:space_time}
\end{figure}

Let us interpret $D$ as a certain uniform and isotropic body, inside which a solid/liquid inclusion of zero temperature $\Omega$ is present. The temperature $u$ inside $D\setminus \Omega = U$ evolves over time according to the heat equation, at least approximately. What one might do, is to access the outer boundary $\partial D$ and measure its surface temperature and heat flux, and wonder about the actual shape of the inaccessible inclusion $\Omega$. We ask ourselves how to reconstruct such information from the knowledge of the boundary data only. This is a non-linear and ill-posed inverse problem (according to e.g. \cite{harbrecht}). 

Our problem is therefore, given the outer temperature and outer heat flux, how to reconstruct the shape of $\Omega$ that induced, through heat diffusion, those boundary quantities.

In a more mathematical language, let us consider a heat equation on $U\times I$, with zero initial condition and no volumetric forcing term. On $\Sigma_f$ are prescribed smooth enough Dirichlet and Neumann data, simultaneously, call them $f$ and $g$, whereas on $\Sigma_m$, homogeneous Dirichlet conditions are imposed.

\begin{pb}[Overdetermined heat equation]
\label{pb:pdes}
Call $U:=D\setminus \Omega$. We look for $u:U \times I \rightarrow \mR$ solving:
\begin{align*}
\left\{\begin{matrix}
u_t -\Delta u=0 & \text{on }U\times I \\ 
u(0)=0 & \\ 
u = f, \partial_\nu u=g & \text{on }\Sigma_f\\
u = 0 & \text{on }\Sigma_m\\
\end{matrix}\right.
\end{align*}

We introduce the splitting:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
v_t -\Delta v=0 & \text{on }U\times I \\ 
v(0)=0 & \\ 
v = f& \text{on }\Sigma_f\\
v = 0 & \text{on }\Sigma_m\\
\end{matrix}\right. &, \quad  \left\{\begin{matrix}
w_t -\Delta w=0 & \text{on }U\times I \\ 
w(0)=0 & \\ 
\partial_\nu w=g & \text{on }\Sigma_f\\
w = 0 & \text{on }\Sigma_m\\
\end{matrix}\right.
\end{matrix}
\end{align*}
\end{pb}

This overdetermined partial differential equation for $u$ need not to have a solution. It can be however shown that, for given $f,g$, there exists at most one $\Omega$ such that \cref{pb:pdes} is solvable (see \cite{chapko1}, \cite{chapko2}).

Our aim is to find a numerical approximation for such domain. We are therefore trying to solve a shape identification problem. In particular, the equations for $v,w$ are always uniquely solvable, and $u=v$, $u=w$, in case $u$ exists, i.e. when the shape identification problem admits a solution. One way to tackle it is therefore, given data $f,g$, a guess $\Omega$ of the sought domain, to simulate $v,w$, measure their discrepancy $\norm{v-w}$ and use this knowledge to improve the iterate $\Omega$.

\begin{figure}[H]
\centering
\includegraphics[width=0.25\columnwidth]{Images/NormalDiscrepancy.pdf}
\caption{Discrepancy between the Neumann data corresponding to the correct domain $\Omega$, and a guess of it, $\hat{\Omega}$}\label{fig:normal_discrepancy}
\end{figure}

Summing up, the thesis is devoted to the analysis of the following problem.

\begin{pb}[Shape identification problem]
\label{pb:shid}
We aim at finding $\Omega$ such that $u$, defined in \cref{pb:pdes}, exists, i.e. such that $v=w$.
\end{pb}

This same problem was addressed in \cite{harbrecht} using a different approach than ours, involving boundary integral equations, boundary element methods and non-standard time stepping schemes. On the other hand our focus has a rather "volumetric" flavour, as we will make clear in the following chapters. 

As already mentioned, some uniqueness results are already available. \textcolor{red}{no source: very important} We are not concerned with the problem of existence of $\Omega$, likewise this aspect is not addressed in the aforementioned work \cite{harbrecht}. Some advances in this direction are done in the case where $\Omega$ is allowed to evolve with time, this is addressed in \cite{brugger}.

In the following we will formalize assumptions, setting and notation, and we will tackle \cref{pb:shid} by shape optimization techniques.

\section{Treatment by shape optimization}
\label{sec:shopt_treatment}

\begin{ass}[Geometry assumptions for the shape optimization problem]
\label{ass:geo_sh}
Let $D\subseteq \mR^n$ be a bounded Lipschitz domain, and $\Omega_r \cc D$ also bounded Lipschitz. Call $U_r:=D\setminus \Omega_r$, another bounded Lipschitz domain.
\end{ass}

\begin{defn}[Admissible transformations]

Given $D$, we consider the set $\cT$ of bi-Lipschitz homeomorpshisms of $\mR^n$ that fix $D^c$, endowed the perturbation space $\Te$, i.e. Lipschitz deformation fields null on $D^c$. See also \cref{def:adm}.

We will consider transformations of $U$ that belong to $\cT_a:=\cT \cap \{ \tau \in W^{1,\infty}(\mR^n, \mR^n), \norm{\tau - \id}_{W^{1,\infty}(\mR^n, \mR^n)}<C(U_r)\}$, where the existence of $C(U_r)$ is guaranteed by \cref{thm:ptb_id_lip}. This is to ensure that $\tau(U_r)\cc D$ is also bounded Lipschitz.


\end{defn}

We remark that there exists a unique Lipschitz continuous representive $T$ of $\tau \in \cT_a$ (see \cref{prop:lipk}), and that we denote it also by $\tau$, for simplicity. By $\tau(U_r)$ we precisely mean $T(U_r)$.

We recast \cref{pb:shid} in a new form, akin to shape optimization. To do so, we must at first analyze the well posedness of the equations for $v,w$ of \cref{pb:pdes}. This is done in detail in the appendix for the sake of presentation. What we remark is that such well-posedness holds, and that, given any extension $\bar{u}$ to $f$ onto $U\times I$, then $v = v_0+\bar{u}$, where $v_0$ solves the heat equation with homogeneous Dirichlet boundary conditions, but a non trivial source term. We write $v^\tau = v_0^\tau + \bar{u}$, and $v_0^\tau, w_\tau$ to emphasize the dependence on $\tau$, and refer to \cref{pb:joint_mov} and \cref{pb:diri_ext} for additional details. The adequate conditions for well-posedness are \cref{ass:diri}, \cref{ass:neu}.

\begin{pb}[Shape optimization problem]
\label{pb:shopt}
Suppose that \cref{ass:geo_sh}, \cref{ass:diri}, \cref{ass:neu} hold. We want to solve:

$$\inf_{\tau \in \cT_a}\frac{1}{2}\norm{v^\tau-w^\tau}_{L^2(I,H_\tau)}^2=:J(\tau)$$

The notation for the spaces also comes from  \cref{pb:joint_mov}: $\cdot_\tau$ means a space defined on the moving domain, $H=L^2, \tw{V}=H^1_0, \tw{W} = H^1_{0,m}=\{v \in H^1, v(\Gamma_m)=0\}$ (see also \cref{subs:inh_diri} for the last space).

\end{pb}

Therefore, we are now concerned with finding a function $\tau$, instead of a generic set $\Omega$: this way we can make use of functional analytic techniques and results from optimal control.

\begin{obs}[Well-posedness of $J$]
\mbox{}\\
We know from \cref{prop:diri_wp} that $v_0^\tau + \bar{u}$ doesn't depend on the particular choice of $\bar{u}$, therefore, for different $\tau$ yielding the same domain $U$, $J(\tau)$ doesn't change.

\end{obs}

\begin{obs}[Tracking type cost functional]
\mbox{}\\
We have chosen the $L^2(I,L^2)$ norm to measure the discrepancy $v\simeq w$. Apart from having favourable functional analytic properties (Fréchet differentiability, to mention one), such cost functional will also allow us to obtain "better behaved" adjoint states. In fact, contrary to \cite{harbrecht}, the heat equations for the adjoint states (see \cref{prop:gateaux_diff}) will have compatibility between initial condition and boundary conditions. This simplifies the numerical analysis of such equations.
\end{obs}


Now, let $U:=\tau(U_r)$, for $\tau \in \cT_a$ and let $\delta \te \in \Te$. To find a better (in the sense of the energy $J$) candidate $\tau$ for the solution of \cref{pb:shopt}, we can use gradient information, i.e. perturb our current guess $\tau$ in the direction of steepest descent for $J$. We are hence interested in finding the form $J'(\tau) \in \Te^*$ such that, for all $\delta \te_k \rightarrow 0$ in $\Te$, we have:


$$\lim_{k}\frac{|J(\tau+\delta \te_k)-J(\tau)-J'(\tau)(\delta \te_k)|}{\norm{\delta \te_k}_{\Te}}$$

We have set $\norm{\te}_\Te = \norm{\te}_{W^{1,\infty}(\mR^n;\mR^n)}=\norm{\te}_{W^{1,\infty}(D;\mR^n)}$.

Note, thanks to \cref{prop:ptb_id}, a small $\delta \te \in \Te$ perturbation of $\tau \in \cT_a$, small with respect to the $W^{1,\infty}(D;\mR^n)$ topology, yields an element $\tau +\delta  \te \in \cT_a$: it will be this the way in which an initial guess for the sought domain $\Omega = \tau(\Omega_r)$ will be refined, i.e. by iteratively adding to $\tau$, small perturbations $\delta \te$. We remark that for $k$ large enough, $\tau+\delta \te_k \in \cT_a$.

\begin{obs}
\mbox{}\\
To carry out all the reasonings with such a general form of tranformation $\tau$, an assumption of smallness (such as the one involving $C(U_r)$) is necessary. We will see a more transparent way of obtaining $\tau(U_r)\cc D$ Lipschitz, in \cref{sec:star}.
\mbox{}\\
Note, we need $\tau$ to have a Lipschitz inverse to conclude $\tau(U_r)\cc D$: for $x \in D$, we have $0<\delta = \inf_{d \in \partial D}|x-d|\leq \norm{\tau^{-1}}_{W^{1,\infty}(\mR^n,\mR^n)}\inf_{d \in \partial D}|\tau(x)-d|$.
\end{obs}

%Note, $\tau+\delta \te_k \in \cT_a$ for large enough $k$. In fact, $\tau+\delta \te_k \in \cT$ for large $k$ as in \cref{prop:ptb_id}, and the condition on $C(U_r)$ is satisfied too, because $\te :=\tau-\id$ was already in the $W^{1,\infty}$ open ball of radius $C(U_r)$ centered at the origin, and so will be $\te + \delta_k\te$, always for large $k$.

Now, $\tau+\delta \te_k  = (\id+\delta\te_k \circ \tau^{-1})\circ \tau$, and $\id+\delta\te_k \circ \tau^{-1}$ is in $\cT_a$ (it is in $\cT$ by \cref{prop:ptb_id} and the reasoning above shows it is also in $\cT_a$). We are then equivalently interested in:

$$\lim_{k}\frac{|J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau)-J'(\tau)(\delta \te_k)|}{\norm{\delta \te_k}_{\Te}}$$

This amounts to setting the reference domain to $\tau(U_r)$ instead of $U_r$ and perturbing the former, at least for the sake of computing derivatives.

We now introduce a Lagrangian functional, so as to derive the gradient expression of $J$. There are several ways to compute the so called "shape gradient" $dJ$, in the literature. We will adopt that contained in \cite{avg_adj}, but a valid alternative, at least formally, is the method of Cea, see \cite{cea}. The former requires the PDEs of $v=v^\tau$, $w=w^\tau$ to be reformulated on a non-moving domain, the reference domain $U_r$. We can perform such operation by considering the variational formulations of $v^\tau$ and $w^\tau$ and then applying a change of variables to the appearing integrals. This is precisely the content of \cref{thm:eq_pde}, whose applicability is ensured by \cref{ass:pull}, which holds by \cref{ass:geo_sh}.

Remembering that $k$ large, i.e. $k\geq K(\tau)$, we have $\tau_k:=\id+\delta\te_k \circ \tau^{-1} \in \cT_a$, as seen above, and  having \cref{thm:eq_pde} in mind we can set:

\begin{align*}
L_\tau(k,w,v_0,q,p) = \\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u} \circ \tau_k - w|^2|\det(D\tau_k)|+\\
\int_I ( w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla w, \nabla q)_{H_\tau} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)} +\\ \int_I (v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0, \nabla p)_{H_\tau}+\int_I((\bar{u}\circ \tau_k)',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla (\bar{u} \circ \tau_k), \nabla p)_{H_\tau}
\end{align*}

Here $w \in Q_0(I, \tw{W}_\tau), v_0 \in Q_0(I,\tw{V}_\tau), q \in Q^0(I, \tw{W}_\tau), p \in Q^0(I, \tw{V}_\tau)$, where the space $Q$ is thoroughly described after its introduction in \cref{def:Q}, which we recall: $Q(I,V)=H^{1,1}=L^2(I,V)\cap H^1(I,H)$, and $Q^0$ means the imposition of a zero terminal condition ($Q_0$ means zero initial condition). We have set $A_\tau:=  (D\tau)^{-1}(D\tau)^{-t}|\det(D\tau)|$.

$L_\tau$ is composed of three parts: the cost functional, the variational formulation of $v_0^\tau$ and that of $w^\tau$, all transported to the domain $\tau(U_r)$, which will remain fixed, for the sake of computing the shape gradient.

Note that to be precise, $\bar{u}$ is an extension (any extension in fact, satisfying the conditions of \cref{pb:diri_ext}) of the Dirichlet datum $f$, on the moving domain $\tau_k(\tau(U_r))$. Because of this, let's fix $\bar{u}_\tau$ with this property on $\tau(U_r)$. We show that $\bar{u}:=\bar{u}_\tau\circ \tau_k^{-1}$ satisfies the conditions stated in \cref{pb:diri_ext}. 

In particular:

\begin{itemize}
	\item composition with $\tau$ preserves the smoothness of the extension, as seen in \cref{lemma:bochner_Hk_map}, given that $\circ \tau_k^{-1}$ is a linear bounded operator between $\tw{W}_\tau$ and $\tw{W}_{\tau_k \circ \tau}$ (see \cref{thm:change})
	\item the initial value is preserved, as seen in the proof of \cref{prop:change_boch}
	\item the trace on $\Sigma_f$ is preserved, because the trace on $\Gamma_f=\partial D$ is preserved, see \cref{thm:change}
\end{itemize}

Therefore we can state the following definition.

\begin{defn}[Lagrangian]

For a fixed $\tau \in \cT_a$ and  $k\geq K(\tau)$, for $\tau_k:=\id+\delta\te_k \circ \tau^{-1} \in \cT_a$, we define:

\begin{align*}
L_\tau(k,w,v_0,q,p) = \\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|+\\
\int_I ( w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla w, \nabla q)_{H_\tau} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)} +\\ \int_I (v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0, \nabla p)_{H_\tau}+\int_I(\bar{u}_\tau',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla \bar{u}_\tau , \nabla p)_{H_\tau}
\end{align*}

$L_\tau$ is defined as a map $\{k\geq K(\tau)\}\times Q_0(I, \tw{W}_\tau)\times Q_0(I,\tw{V}_\tau)\times Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)\rightarrow \mR$.

We call $u = (w,v_0)$, $\pi = (q,p)$, $G(k,u,\pi) = L_\tau(k,w,v_0,q,p)$ to ease the notation.

We also call $b(k, u) = \frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|$ and $a(k, u,\pi) = G(k,u,\pi)-b(k, u)$, $E = Q_0(I, \tw{W}_\tau)\times Q_0(I,\tw{V}_\tau)$, $F=Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)$.

\end{defn}

The rest of this section is devoted to applying the averaged adjoint method \cite{avg_adj} to our problem, so as to identify the shape gradient. To this end we will have to understand which properties the Lagrangian $L_\tau $ enjoys.

\begin{prop}[Properties of the Lagrangian]
\label{prop:lagr}

$L_\tau$ satisfies the following properties:

\begin{enumerate}
	\item $\psi \mapsto a(k, \phi,\psi)$ is linear, no matter what $\phi,k$
	\item $G$ is Fréchet differentiable with respect to $\psi$ at $(k,\phi,0)$ for all $k, \phi$
	\item $d_\psi G(k,\phi,0)[\delta \psi]=0$ for all $\delta \psi \in F$ admits a unique solution $\phi = u^k$
	\item $[0,1]\ni s \mapsto G(k, su^k + (1-s)u^0,\psi)$ is $AC[0,1]$, no matter what $k, \psi$
	\item $G$ is Fréchet differentiable with respect to $\phi$ at $(k,\psi,\phi)$ for all $k, \psi, \phi$
	\item $[0,1]\ni s \mapsto d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]$ is $L^1(0,1)$, no matter what $k, \psi, \delta \phi$
	\item there exists a unique solution $\psi = \pi^k$ to $\ds \int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds =0$ for all $\delta \psi$ 
\end{enumerate}

In particular $\pi^k = (Q^k \circ \tau^k,P^k \circ \tau^k)$, where we introduced the averaged adjoint problems on the moving domain:

\begin{pb}[Averaged adjoint equations]
\label{pb:avg_adj_pb}
\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-Q^k_t-\Delta Q^k =\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} \\
Q^k(T)=0\\
\partial_\nu Q^k = 0 \text{ on } \Sigma_f\\
Q^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
, \quad &
\left\{\begin{matrix}
-P^k_t-\Delta P^k =-\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}-\bar{u}_\tau\circ \tau_k^{-1} \\
P^k(T)=0\\
P^k = 0 \text{ on } \Sigma_f\\
P^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}
\end{pb}

\end{prop}

\begin{mproof}

The first point is immediate.

\underline{Proof of 2}

All the pieces are linear in $\psi$. We only check the boundedness of the various differentials. For simplicity, call $|\det(D\tau_k)|=d$, and note that   $\norm{qd}_{H_\tau}\leq C(d)\norm{q}_{H_\tau}$.

And now, for instance:
%\int_I \langle w_t , q |\det(DT_\e)|\rangle_{V^*_T,V_T}+ (A_{T_\e}\nabla w, \nabla q)_{H_T} -\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}
\begin{align*}
\int_I ( w_t , \delta q |\det(D\tau_k)|)_{H_\tau} = \int_I ( w_t , \delta q d )_{H_\tau}\leq\\ C(d) \int_I \norm{w_t}_{H_\tau}\norm{\delta q}_{H_\tau}\leq C(d) \norm{w_t}_{L^2(I,H_\tau)}\norm{\delta q}_{L^2(I,H_\tau)}\leq\\C(d) \norm{w}_{Q(I,\tw{W}_\tau)}\norm{\delta q}_{Q(I,\tw{W}_\tau)}\leq
C(d) \norm{w}_{Q(I,\tw{W}_\tau)}(\norm{\delta q}_{Q(I,\tw{W}_\tau)}+\norm{\delta p}_{Q(I,\tw{W}_\tau)}) =\\ C(d) \norm{w}_{Q(I,\tw{W}_\tau)}\norm{\delta\psi}_F
\end{align*}

Or also:

\begin{align*}
\int_I(g,\tr_{U} \delta q)_{L^2(\Gamma_f)}\leq \int_I \norm{g}_{L^2(\Gamma_f)}\norm{\delta q}_{\tw{W}_\tau}\leq \norm{g}_{H^1(I,L^2(\Gamma_f))}\norm{\delta\psi}_F
\end{align*}

and:

\begin{align*}
\int_I (A_{\tau_k} \nabla \bar{u}_\tau, \nabla\delta p)_{H_\tau}\leq C\norm{A_{\tau_k}}_{L^\infty(D;\mR^{n\times n})}\int_I \norm{\nabla \bar{u}_\tau}_{L^2(I,H_\tau)}\norm{\nabla\delta p}_{L^2(I,H_\tau)}\leq\\ C(\tau) \norm{\delta\psi}_F \norm{\bar{u}}_{H^1(I,\tw{W}_\tau)}
\end{align*}

\underline{Proof of 3}

We get back the state equations, thanks to linearity, and by testing separately with $\delta \psi =(\delta q, 0)$ and $\delta \psi = (0,\delta p)$, so that a unique solution exists by \cref{thm:eq_pde}.

\underline{Proof of 4}

Every piece but $b$ is linear or constant in the state $\phi$. We only need to prove that $[0,1]\ni s \mapsto b(k, su^k + (1-s)u^0)$ is $AC[0,1]$. But by the structure of the cost function $J$, transported on $\tau(U_r)$, we see that the latter is a quadratic polynomial in $s$, hence, absolutely continuous.

\underline{Proof of 5}

For the pieces with the gradients, it follows as above, by in case employing the simmetry of $A_{\tau_k}$.

Now, for instance the linear form $\delta v_0 \mapsto \int_I (\delta v_{0t},p |\det(D\tau_k)|)_{H_\tau}$ is also bounded by $C(d) \norm{\delta v_0}_{Q(I,\tw{V}_\tau)}\norm{\delta q}_{Q(I,\tw{W}_\tau)}$ just like before.

What remains to check is the Fréchet differentiability of $b$.

To do so, perturb $\phi$ by $\delta \phi$ and expanding the square:

\begin{align*}
\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\delta v_0+\bar{u}_\tau - w-\delta w|^2|\det(D\tau_k)| = \\\frac{1}{2}\int_I \int_{\tau(U_r)}|v_0+\bar{u}_\tau - w|^2|\det(D\tau_k)|+\\\frac{1}{2}\int_I \int_{\tau(U_r)}|\delta v_0-\delta w|^2|\det(D\tau_k)|+\\\int_I \int_{\tau(U_r)}(v_0+\bar{u}_\tau - w)(\delta v_0-\delta w)|\det(D\tau_k)|
\end{align*} 

Now, $\ds \int_I \int_{\tau(U_r)}|\delta v_0-\delta w|^2|\det(D\tau_k)|\leq C(\tau_k)\norm{\delta v_0-\delta w}_{L^2(I,H_\tau)}^2\leq C(\tau_k)\norm{\phi}_E^2$, so that this term is of higher term.

And $\ds \int_I \int_{\tau(U_r)}(v_0+\bar{u}_\tau - w)(\delta v_0-\delta w)|\det(D\tau_k)|$ is linear and bounded by reasonings similar to the former ones.

\underline{Proof of 6}

By the last point:

\begin{align*}
d_\phi G(k, \phi ,\psi)[\delta \phi] =\\
\int_I ((v_0+\bar{u}_\tau - w)|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
\int_I (\delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
\int_I (\delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
\end{align*}

so that:

\begin{align*}
d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi] = \\
\int_I ((s(v_0^k+\bar{u}_\tau - w^k)+(1-s)(v_0^0+\bar{u}_\tau - w^0))|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
\int_I ( \delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
\int_I ( \delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
\end{align*}

which is a degree $1$ polynomial in $s$, hence, $L^1(0,1)$.

\underline{Proof of 7}

Rewriting the formula above and integrating in $s$, we come to:

\begin{align*}
\int_0^1d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds = \\
\int_I (((v_0^k+\bar{u}_\tau - w^k)+(v_0^0+\bar{u}_\tau - w^0))/2|\det(D\tau_k)|,\delta v_0-\delta w)_{H_\tau}+\\
\int_I ( \delta w_t , q |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q)_{H_\tau}+\\
\int_I ( \delta v_{0t},p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla \delta v_0, \nabla p)_{H_\tau}
\end{align*}

As in \cref{prop:change_boch}, $ \delta w_t  = (\delta w\circ \tau_k^{-1})_t\circ \tau_k$, where $\delta w\circ \tau_k^{-1} \in Q_0(I,\tw{W}_{\tau_k \circ \tau})$ by \cref{prop:change_boch} (that can be applied thanks to the smallness of $\tau_k$).

Applying a change of variables we are left with:

\begin{align*}
\int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds = \\
\int_I \left (\frac{v_0^k-w^k}{2}\circ \tau_k^{-1}+ \frac{v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta v_0\circ \tau_k^{-1}-\delta w\circ \tau_k^{-1}\right)_{H_{\tau_k \circ \tau}}+\\
\int_I ((\delta w\circ \tau_k^{-1})_t , q\circ \tau_k^{-1} )_{H_{\tau_k \circ \tau}}+ (\nabla (\delta w\circ \tau_k^{-1}), \nabla( q\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}+\\
\int_I ( (\delta v_{0}\circ \tau_k^{-1})_t,p \circ \tau_k^{-1})_{H_{\tau_k \circ \tau}} + ( \nabla \delta (v_0\circ \tau_k^{-1}), \nabla (p\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}
\end{align*}

Here, as we saw in \cref{prop:change_boch}, we have $\delta w\circ \tau_k^{-1}, w\circ \tau_k^{-1} \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta v_{0}\circ \tau_k^{-1}, v_{0}\circ \tau_k^{-1} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$, $q\circ \tau_k^{-1}\in Q^0(I, \tw{W}_{\tau_k \circ \tau})$ and $p\circ \tau_k^{-1}\in Q^0(I, \tw{V}_{\tau_k \circ \tau})$.

Because $\circ \tau_k^{-1}$ is a bijection of $Q_0(I,\tw{V}_{\tau_k \circ \tau})$ and $Q_0(I,\tw{V}_{\tau_k})$ as we saw in \cref{prop:change_boch} (and analogously of $\tw{W}$), we have that  $\int_0^1 d_\phi G(k, su^k + (1-s)u^0,\psi)[\delta \phi]ds=0$ for all $\delta \phi \in E$ if and only if:

\begin{align*}
\int_I \left (\frac{v_0^k+w^k}{2}\circ \tau_k^{-1}- \frac{v_0^0+w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0-\delta W\right)_{H_{\tau_k \circ \tau}}+\\
\int_I ( \delta W_t , q\circ \tau_k^{-1})_{H_{\tau_k \circ \tau}}+ (\nabla\delta W, \nabla( q\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}}+\\
\int_I ( \delta V_{0t},p \circ \tau_k^{-1})_{H_{\tau_k \circ \tau}} + ( \nabla \delta V_0, \nabla (p\circ \tau_k^{-1}))_{H_{\tau_k \circ \tau}} = 0
\end{align*}

for all $\delta W, \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta V_{0} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$.

We wish to find a (unique) solution $(q^k, p^k) \in Q^0(I, \tw{W}_\tau)\times Q^0(I, \tw{V}_\tau)$ of this problem. We can equivalently (by \cref{prop:change_boch}) find $(Q^k, P^k) \in Q^0(I, \tw{W}_{\tau_k \circ \tau})\times Q^0(I, \tw{V}_{\tau_k \circ \tau})$ satisfying:

\begin{align*}
\int_I \left (\frac{v_0^k-w^k}{2}\circ \tau_k^{-1}+ \frac{v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0-\delta W\right)_{H_{\tau_k \circ \tau}}+\\
\int_I (\delta W_t ,Q^k )_{H_{\tau_k \circ \tau}}+ (\nabla \delta W, \nabla Q^k)_{H_{\tau_k \circ \tau}}+\\
\int_I( \delta V_{0t},P^k)_{H_{\tau_k \circ \tau}} + ( \nabla \delta V_0, \nabla P^k)_{H_{\tau_k \circ \tau}} = 0
\end{align*}

for all $\delta W, \in Q_0(I, \tw{W}_{\tau_k \circ \tau})$, $ \delta V_{0} \in Q_0(I,\tw{V}_{\tau_k \circ \tau})$.

By testing first with $\delta W=0$ and then with $\delta V_0=0$ we can equivalently look for:

\begin{align*}
(Q^k, P^k) \in Q^0(I, \tw{W}_{\tau_k \circ \tau})\times Q^0(I, \tw{V}_{\tau_k \circ \tau}) \text{ with }\\
\int_I (\delta W_t ,Q^k)_{H_{\tau_k \circ \tau}}+ (\nabla \delta W, \nabla Q^k)_{H_{\tau_k \circ \tau}} =\\ \int_I \left (\frac{v_0^k+w^k-v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta W\right)_{H_{\tau_k \circ \tau}}\\
\int_I ( \delta V_{0t},P^k)_{H_{\tau_k \circ \tau}}+ ( \nabla \delta V_0, \nabla P^k)_{H_{\tau_k \circ \tau}} =\\- \int_I \left (\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0\right)_{H_{\tau_k \circ \tau}}
\end{align*}

An application of integration by parts in time (see \cref{prop:Q}) yields the problem:

\begin{align*}
(Q^k, P^k) \in W^0(I, \tw{W}_{\tau_k \circ \tau})\times W^0(I, \tw{V}_{\tau_k \circ \tau}) \text{ with }\\
-\int_I ( Q^k_t, \delta W )_{H_{\tau_k \circ \tau}}+ (\nabla \delta W, \nabla Q^k)_{H_{\tau_k \circ \tau}} =\\ \int_I \left (\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta W\right)_{H_{\tau_k \circ \tau}}\\
-\int_I( P^k_t, \delta V_0)_{H_{\tau_k \circ \tau}} + ( \nabla \delta V_0, \nabla P^k)_{H_{\tau_k \circ \tau}} =\\- \int_I \left (\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} ,\delta V_0\right)_{H_{\tau_k \circ \tau}}
\end{align*}

But these are the weak formulations (cfr. \cref{thm:eq_pde}, \cref{pb:diri_ext}, \cref{pb:neu}) of the problems:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-Q^k_t-\Delta Q^k =\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} \\
Q^k(T)=0\\
\partial_\nu Q^k = 0 \text{ on } \Sigma_f\\
Q^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
, \quad &
\left\{\begin{matrix}
-P^k_t-\Delta P^k =-\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}-\bar{u}_\tau\circ \tau_k^{-1} \\
P^k(T)=0\\
P^k = 0 \text{ on } \Sigma_f\\
P^k = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}

Applying the time reversal $t\mapsto T -t$ (where $I = [0,T]$), these are a couple of standard heat equations for which we have available existence, uniqueness and stability results (see \cref{chap:parab_eq}, and \cref{prop:eq_form}).

By calling then $\pi^k = (Q^k \circ \tau^k,P^k \circ \tau^k)$ we conclude the proof.

\end{mproof}

We now turn to the verification of Gateaux differentiability of $J$, applying the techniques proposed in \cite{avg_adj}.

\begin{prop}[Averaged adjoint method for Gateaux derivatives]
\label{prop:adv_adj}

If $J'(\tau) \in \Te^*$ satisfies:

$$\lim_{k}\frac{G(k,u^0,\pi^k)-G(0,u^0,\pi^k)}{t_k}=J'(\tau)[\delta \te]$$

where $\delta\te_k = t_k\delta \te$ for $t_k\rightarrow 0$, then $J'(\tau)$ is the Gateaux derivative of $J$ at $\tau$.

\end{prop}

\begin{mproof}

We have $G(k,u^k,\pi^k)-G(k,u^0,\pi^k)  = \int_0^1 d_\phi G(k, su^k + (1-s)u^0,\pi^k)[u^k-u^0]ds = 0$ because $u^k-u^0 \in E$, and by absolute contintinuity and integrability of derivative as seen in \cref{prop:lagr}.

Moreover, calling $g_k = G(k,u^k,0)-G(0,u^0,0)$, we have:

\begin{itemize}
	\item $g_0 = 0$
	\item $g_k = J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau)$, thanks again to a change of variables
	\item $g_k = G(k,u^k,\pi^k)-G(0,u^0,\pi^k)$ thanks to $\pi^k \in F$ and the state equations (note, this is possible because $k,u^k$ appear, and $0,u^0$ appear, so that the indices don't mix)
\end{itemize}

And now, $J(\tau+\delta\te_k)-J(\tau) = J((\id+\delta\te_k \circ \tau^{-1})\circ \tau)-J(\tau) = g_k = G(k,u^k,\pi^k)-G(0,u^0,\pi^k) = G(k,u^k,\pi^k)-G(k,u^0,\pi^k)+G(k,u^0,\pi^k)-G(0,u^0,\pi^k) = G(k,u^0,\pi^k)-G(0,u^0,\pi^k)$.

\end{mproof}

\begin{prop}[Gateaux differentiability of $J$]
\label{prop:gateaux_diff}
Given $\tau \in \cT_a$, $J$ is Gateaux differentiable at $\tau$ with respect to the $W^{1,\infty}$ topology. The Gateaux differential is:


\begin{align*}
J'(\tau)[\delta \te] =\\ \int_I (w_t^\tau \dive(\delta \te\circ  \tau^{-1}), q^\tau )+ \int_I (A'(\delta\te \circ \tau^{-1})\nabla v^\tau, \nabla p^\tau)+\\
\int_I (v_t^\tau \dive(\delta \te\circ  \tau^{-1}), p^\tau )+ \int_I (A'(\delta\te \circ \tau^{-1})\nabla w^\tau, \nabla q^\tau)+\\
\frac{1}{2}\int_I\int_{\tau(U_r)}|v^\tau-w^\tau|^2\dive(\delta \te\circ  \tau^{-1})
\end{align*}

where $p^\tau$, $q^\tau$ solve:

\begin{align*}
\begin{matrix}
\left\{\begin{matrix}
-q^\tau_t-\Delta q^\tau =v^\tau-w^\tau\\
q^\tau(T)=0\\
\partial_\nu q^\tau = 0 \text{ on } \Sigma_f\\
q^\tau = 0 \text{ on } \Sigma_m
\end{matrix}\right., \quad & \left\{\begin{matrix}
-p^\tau_t-\Delta p^\tau = - v^\tau+ w^\tau \\
p^\tau(T)=0\\
p^\tau = 0 \text{ on } \Sigma_f \\
p^\tau = 0 \text{ on } \Sigma_m
\end{matrix}\right.
\end{matrix}
\end{align*}

and where $A'(\delta\te )= - D\delta \te -(D\delta\te)^t + \dive(\delta\te)I$.

\end{prop}

\begin{mproof}

\underline{The shape derivative is linear and bounded}

Linearity is immediate. For the boundedness:

\begin{align*}
|J'(\tau)[\delta \te]| \leq\\ \norm{\dive(\delta \te\circ  \tau^{-1})}_{L^\infty(\tau(U_r))}\left (\int_I( \norm{q_t^\tau}_{H_\tau}\norm{q^\tau}_{H_\tau}+ \norm{v_t^\tau}_{H_\tau}\norm{p^\tau}_{H_\tau})+\frac{1}{2}\norm{v^\tau-w^\tau}^2_{L^2(I,H_\tau)}\right )+\\
\left(\sum_{ij} \norm{(A'(\delta\te \circ \tau^{-1})_{ij}}_{L^\infty(\tau(U_r))}\right )\left (
\int_I \norm{\nabla v^\tau}_{H_\tau} \norm{\nabla p^\tau}_{H_\tau}+ \int_I \norm{\nabla w^\tau}_{H_\tau} \norm{\nabla q^\tau}_{H_\tau}\right )
\end{align*}

and then, for $C$ independent of $\delta \te$:

\begin{align*}
|J'(\tau)[\delta \te]| \leq\\ C \left ( \norm{\dive(\delta \te\circ  \tau^{-1})}_{L^\infty(\tau(U_r))}+\left(\sum_{ij} \norm{(A'(\delta\te \circ \tau^{-1})_{ij}}_{L^\infty(\tau(U_r))}\right )\right )\leq\\
\norm{\delta \te \circ \tau^{-1}}_{W^{1,\infty}(\mR^n;\mR^n)}\leq \\
C\norm{\delta \te }_{W^{1,\infty}(\mR^n;\mR^n)}
\end{align*}

where in the last step we applied point i) of lemme 2.2, \cite{murat}. This shows the boundedness.

\underline{Conclusion}

Assume $p^k \weakc p^0$ in $Q(I,\tw{V}_\tau)$ and $q^k \weakc q^0$ in $Q(I,\tw{W}_\tau)$.

Now, using that $u^0=(w^\tau, v_0^\tau)$:

\begin{align*}
G(k,u^0,\pi^k)-G(0,u^0,\pi^k) =\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2|\det(D\tau_k)|+\\
\int_I ( w_t^\tau |\det(D\tau_k)| , q^k)_{H_\tau}+ (A_{\tau_k}\nabla w^\tau, \nabla q^k)_{H_\tau} -\int_I(g,\tr_{U} q^k)_{L^2(\Gamma_f)} +\\ \int_I (v_t^\tau |\det(D\tau_k)|,p^k )_{H_\tau} + (A_{\tau_k} \nabla v^\tau, \nabla p^k)_{H_\tau} - \\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2-\\
\int_I ( w_t^\tau , q^k )_{H_\tau}+(\nabla w^\tau, \nabla q^k)_{H_\tau} +\int_I(g,\tr_{U} q^k)_{L^2(\Gamma_f)} -\\ \int_I (v_t^\tau,p^k )_{H_\tau} + ( \nabla v^\tau, \nabla p^k)_{H_\tau} \\
\end{align*}

Grouping some terms and cancelling the boundary integral:

\begin{align*}
G(k,u^0,\pi^k)-G(0,u^0,\pi^k) =\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2(|\det(D\tau_k)|-1)+\\
\int_I ( w_t^\tau (|\det(D\tau_k)| -1), q^k)_{H_\tau}+ ((A_{\tau_k}-I)\nabla w^\tau, \nabla q^k)_{H_\tau}+\\
\int_I (v_t^\tau (|\det(D\tau_k)|-1),p^k )_{H_\tau} + ((A_{\tau_k}-I) \nabla v^\tau, \nabla p^k)_{H_\tau} \\
\end{align*}

Now, the application $\delta \te \mapsto \id +\delta \te \circ \tau^{-1}$ is Fréchet differentiable at $\delta \te =0$, as a map of $\Te$ into $\cV^1$, with Fréchet derivative $\delta \te \circ \tau^{-1}$, which is linear and bounded by point i) of lemme 2.2, \cite{murat}. Note, we needed here $\tau \in \cT^1$.

Also, the maps $\delta \eta \mapsto |\det(D\eta)|$ and $\eta\mapsto (D\eta)^{-1}(D\eta)^{-t}|\det D\eta|$ are Fréchet differentiable at $\id$, from $\cV^1$ into $L^\infty(\mR^n;\mR)$ and $L^\infty(\mR^n;\mR^{n\times n})$, as stated in lemma 4.16, page 80 of \cite{lindemann}. Their Fréchet derivatives are $\dive (\beta)$ and $I-D\beta-(D\beta)^t$, respectively.

Therefore, composition with  $\delta \te  \mapsto \id+ \delta \te \circ \tau^{-1}$ yields two Fréchet differentiable maps, whose derivatives at $0$, in direction $\delta \te \in \Te$ are exactly:

\begin{itemize}
	\item $\dive(\delta \te \circ \tau^{-1})$
	\item $A'(\delta \te \circ \tau^{-1})$
\end{itemize} 

These maps are:

\begin{itemize}
	\item $\delta \te_k \mapsto |\det(D\tau_k)|$
	\item $\delta \te_k \mapsto A_{\tau_k}$
\end{itemize}

Therefore:

\begin{itemize}
	\item $|\det(D\tau_k)|-1 = |\det(D\tau_k)|-1 - t_k\dive(\delta \te \circ \tau^{-1})+t_k\dive(\delta \te \circ \tau^{-1}) = o^1_k + t_k\dive(\delta \te \circ \tau^{-1})$
	\item $A_{\tau_k}-I = A_{\tau_k}-I - t_k A'(\delta \te \circ \tau^{-1}) + t_k A'(\delta \te \circ \tau^{-1}) = o_k^2 + t_k A'(\delta \te \circ \tau^{-1}) $
\end{itemize}

where $o_1^k \in L^\infty(\mR^n;\mR)$ and $o^2_k \in L^\infty(\mR^n;\mR^{n\times n})$ being higher order terms, in $L^\infty$ and with respect to $t_k$.

We can then write $(G(k,u^0,\pi^k)-G(0,u^0,\pi^k))/t_k = a_k + o_k$.

Here:

\begin{align*}
a_k :=\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2\dive(\delta \te \circ \tau^{-1})+\\
\int_I ( w_t^\tau \dive(\delta \te \circ \tau^{-1}), q^k)_{H_\tau}+ (A'(\delta \te \circ \tau^{-1}) \nabla w^\tau, \nabla q^k)_{H_\tau}+\\
\int_I (v_t^\tau \dive(\delta \te \circ \tau^{-1}),p^k )_{H_\tau} + (A'(\delta \te \circ \tau^{-1})  \nabla v^\tau, \nabla p^k)_{H_\tau} \\
\end{align*}

Thanks to the assumed weak convergence, $a_k\rightarrow J'(\tau)[\delta \te]$.

So, we still have to show that:

\begin{align*}
o_k:=\\
\frac{1}{2}\int_I \int_{\tau(U_r)}|v^\tau-w^\tau|^2 o^1_k t_k^{-1}+\\
\int_I ( w_t^\tau o^1_kt_k^{-1}, q^k)_{H_\tau}+ (t_k^{-1}o^2_k\nabla w^\tau, \nabla q^k)_{H_\tau}+\\
\int_I (v_t^\tau o^1_k t_k^{-1},p^k )_{H_\tau} + (t_k^{-1}o^2_k \nabla v^\tau, \nabla p^k)_{H_\tau} 
\end{align*}

goes to zero. This is true because again we can write:

\begin{align*}
|o_k| \leq\\ \norm{ o^1_kt_k^{-1}}_{L^\infty(\tau(U_r))}\left (\int_I( \norm{v_t^\tau}_{H^\tau}\norm{p^k}_{H_\tau}+ \norm{v_t^\tau}_{H_\tau}\norm{p^k}_{H_\tau})+\frac{1}{2}\norm{v^\tau-w^\tau}^2_{L^2(I,H_\tau)}\right )+\\
\left(\sum_{ij} \norm{((t_k^{-1}o^2_k)_{ij}}_{L^\infty(\tau(U_r))}\right )\left (
\int_I \norm{\nabla v^\tau}_{H_\tau} \norm{\nabla p^k}_{H_\tau}+ \int_I \norm{\nabla w^\tau}_{H_\tau} \norm{\nabla q^k}_{H_\tau}\right )
\end{align*}

which goes to $0$, thanks to the boundedness of the averaged adjoint states, which stems from their weak convergence.

We assumed $p^k \weakc p^0$ in $Q(I,\tw{V}_\tau)$ and $q^k \weakc q^0$ in $Q(I,\tw{W}_\tau)$. We now prove these claims.

\underline{Weak convergence of states}

We show at first  $v_0^k \weakc v^0_0$ in $Q(I,\tw{V}_\tau)$ and $w^k \weakc w^0$ in $Q(I,\tw{W}_\tau)$.

We do this by showing a bound, uniform in $k$.

To do this, recall that $V_0^k:=v_0^k\circ \tau_k^{-1}$ and $W^k:=w^k\circ \tau_k^{-1}$ satisfy, as seen in \cref{thm:eq_pde}:

\begin{align*}
W^k \in Q_0(I, \tw{W}_{\tau_k\circ \tau}), V_0^k \in Q_0(I,\tw{V}_{\tau_k\circ \tau}) \\
\int_I  (W^k_t , Q)_{H_{\tau_k\circ \tau}}+ (\nabla W^k, \nabla Q)_{H_{\tau_k\circ \tau}} = \int_I(g,\tr_{{\tau_k\circ \tau}(U)} Q)_{L^2(\Gamma_f)}, \quad \forall Q \in Q^0(I, \tw{W}_{\tau_k\circ \tau}) \\
\int_I (V^k_{0t},P)_{H_{\tau_k\circ \tau}} + (\nabla V_0^k, \nabla P)_{H_{\tau_k\circ \tau}}= -\int_I(U_k',P)_{H_{\tau_k\circ \tau}}+(U^k, \nabla P)_{H_{\tau_k\circ \tau}}, \quad \forall P \in Q^0(I, \tw{V}_{\tau_k\circ \tau})
\end{align*}

where $U^k:=\bar{u}\circ \tau_k^{-1}$, where we used that pullbacks and time derivatives commute, see \cref{prop:change_boch}.

Thanks to \cref{prop:diri_wp} and \cref{prop:wp_neu} we obtain the stability estimates:

\begin{align*}
\norm{V^k}^2_{C([0;T],H_{\tau_k\circ \tau})}+\norm{V^k}_{L^2(I,H_{\tau_k\circ \tau})}^2+ \\\norm{\nabla V^k}_{L^2(I,H_{\tau_k\circ \tau})}^2 + \norm{(V^k)_t}^2_{L^2(I,H_{\tau_k\circ \tau})}\leq\\ C\norm{U^k}_{H^1(I,\tw{W}_{\tau_k\circ \tau})}^2\\
\norm{W^k}^2_{C([0;T],H_{\tau_k\circ \tau})}+\norm{W^k}_{L^2(I,H_{\tau_k\circ \tau})}^2+ \norm{\nabla W^k}_{L^2(I,H_{\tau_k\circ \tau})}^2 +\\ \norm{W^k_t}^2_{L^2(I,H_{\tau_k\circ \tau})}\leq \\C\norm{g}_{H^1(I,L^2(\Gamma_f))}^2
\end{align*}


where $C$ is independent of $k$.

%But $\norm{U^k}_{H^1(I,V_{T_k\circ T})}^2 = \norm{\bar{u}\circ T_k^{-1}}_{H^1(I,V_{T_k\circ T})}^2\leq N_k\norm{\bar{u}}_{H^1(I,V_{ T})}^2$ by \cref{lemma:bochner_Hk_map}, where $N_k:=\norm{\circ T_k}_{L(V_{T_k\circ T},V_{T}))}$.

Now, consider \cref{thm:change}. It says that for almost every time:

\begin{align*}
\norm{U^k}_{\tw{W}_{\tau_k\circ \tau}}\leq\\ \left ( 1+\norm{\det D\tau_k}_{L^\infty(\mR^n)}\right)^{1/2} \norm{(D\tau_k)^{-1}}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{\bar{u}}_{H^1(\tau(U_r));\mR^n)}
\end{align*}

and the same goes for the first derivative. 


%The term $( \norm{\det DT_k}_{L^\infty(\mR^n)})^{1/2}$ is bounded with respect to $k$ as we already saw, and with analogous reasonings, so is $ \norm{(DT_k)^{-1}}$, thanks to the Fréchet differentiability of $\delta \te_k \rightarrow  (DT_k)^{-1}$ established in lemme 4.3, page IV.8 \cite{murat}.

This bound is uniform on $k$ because of the continuity of the bound, with respect to $k$, as seen in 4.12, page IV.6, \cite{murat}.

We conclude that $\norm{U^k}_{H^1(I,\tw{W}_{\tau_k\circ \tau})}^2$ is bounded and we thus have that $W^k \in Q_0(I, \tw{W}_{\tau_k\circ \tau}), V_0^k \in Q_0(I,\tw{V}_{\tau_k\circ \tau})$ are bounded.

Now, for almost all times, using 4.11, page IV.6 of \cite{murat}, we obtain that, for instance:

\begin{align*}
\norm{v_0^k}_{\tw{W}_{ \tau}}\leq \\\left ( 1+\norm{\det (D\tau_k)^{-1}}_{L^\infty(\mR^n)}\right)^{1/2} \norm{D\tau_k}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{V_0^k}_{H^1(\tau_K(\tau(U_r)))}
\end{align*}

where we remember that $H^1_0$ was chosen to be normed with the full $H^1$ norm.

The same goes for $w^k$ and the first derivatives in time, yielding that $w^k \in Q_0(I, \tw{W}_{ \tau}), v_0^k \in Q_0(I,\tw{V}_{\tau})$ are bounded.

We thus have $w^k\weakc w^? \in Q_0(I, \tw{W}_{ \tau})$, $v_0^k \weakc v_0^? \in Q_0(I,\tw{V}_{\tau})$, in the weak topologies of, respectively, $Q(I, \tw{W}_{ \tau}), Q(I,W_{\tau})$, and modulo subsequences. The initial values are preserved becase $Q_0$ is closed and convex in the Hilbert space $Q$ (see \cref{prop:Q}). The closedness follows from the fact that the embedding into continuous function is linear bounded, and evaluation at $0$ is linear bounded from continuous functions.

We now prove that $w^?=w^0$, $v^?=v^0$, and this will yield the weak convergence of the whole sequence.

To prove e.g. that $v^?=v^0$, let us look at the weak formulations of $v_0^k$:

\begin{align*}
\int_I (v_{0t}^k,p |\det(D\tau_k)|)_{H_\tau} + (A_{\tau_k} \nabla v_0^k, \nabla p)_{H_\tau}+(\bar{u}',p|\det(D\tau_k)|)_{H_\tau}+(A_{\tau_k} \nabla \bar{u} , \nabla p)_{H_\tau} = 0
\end{align*}

for all $p \in Q_0(I,\tw{V}_{\tau})$.

Let's analyize the first term, which is $\int_I (v_{0t}^k,p |\det(D\tau_k)|)_{H_\tau} ) =(v_{0t}^k,p |\det(D\tau_k)|)_{L^2(I,H_\tau)}$.

We can write:

\begin{align*}
(v_{0t}^k,p |\det(D\tau_k)|)_{L^2(I,H_\tau)} =\\ (v_{0t}^k,p )_{L^2(I,H_\tau)}- (v_{0t}^k,p )_{L^2(I,H_\tau)} + (v_{0t}^k,p |\det(D\tau_k)|)_{L^2(I,H_\tau)} =\\ (v_{0t}^k,p )_{L^2(I,H_\tau)} + (v_{0t}^k,p (|\det(D\tau_k)|-1))_{L^2(I,H_\tau)}
\end{align*}

Because $p \in  Q(I,\tw{V}_{\tau})$, the first term converges to $(v_{0t}^?,p )_{L^2(I,H_\tau)}$, see \cref{prop:Q} for details on why we can write the time derivative of the limit. The other term can be estimated as follows:

\begin{align*}
|(v_{0t}^k,p (|\det(D\tau_k)|-1))_{L^2(I,H_\tau)}|\leq\\\norm{v_{0t}^k}_{L^2(I,H_\tau)}\norm{p (|\det(D\tau_k)|-1))}_{L^2(I,H_\tau)}\leq\norm{v_{0t}^k}_{L^2(I,H_\tau)}\norm{p }_{L^2(I,H_\tau)} \norm{|\det(D\tau_k)|-1}_{L^\infty}
\end{align*}

Where the first term in the product is bounded by the weak convergence property, and the last one goes to $0$ by continuity, see again 4.12, page IV.6 of \cite{murat}.

In a similar fashion for the other pieces, and by passing to the limit:
\begin{align*}
\int_I (v_{0t}^?,p)_{H_\tau} + (\nabla v_0^?, \nabla p)_{H_\tau}+(\bar{u}',p)_{H_\tau}+(\nabla \bar{u} , \nabla p)_{H_\tau} = 0
\end{align*}

By uniqueness, $v^?=v^0$.

\underline{Weak convergence of averages adjoint states}

So, $v_0^k \weakc v_0^0, w^k\weakc w^0$ in the sense of the $Q(I,\tw{V}_\tau)$ and $Q(I,\tw{W}_\tau)$ weak convergence.

We now claim that $p^k \weakc p^0, q^k\weakc q^0$, in a similar style as before. To do so, remember that $P^k:=p^k\circ \tau_k^{-1}$ and $Q^k:=q^k\circ \tau_k^{-1}$ solve:

\begin{align*}
-Q^k_t-\Delta Q^k =\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}+\bar{u}_\tau\circ \tau_k^{-1} \\
Q^k(T)=0\\
\partial_\nu Q^k = 0 \text{ on } \Sigma_f\\
Q^k = 0 \text{ on } \Sigma_m
\end{align*}

and

\begin{align*}
-P^k_t-\Delta P^k =-\frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}-\bar{u}_\tau\circ \tau_k^{-1} \\
P^k(T)=0\\
P^k = 0 \text{ on } \Sigma_m \sqcup \Sigma_f
\end{align*}

By \cref{thm:const_track}, we will obtain a bound in $Q$ of the tranported averaged adjoints as soon as we have a bound on $\ds \frac{v_0^k-w^k+v_0^0-w^0}{2}\circ \tau_k^{-1}$ in the $L^2(I,H)$ norm, and of $U^k:=\bar{u}_\tau\circ \tau_k^{-1}$. The latter was proven above.

So, by \cref{thm:change} and 4.12 of \cite{murat} at page IV.6, it suffices to have an $L^2(I,H)$ bound on $\ds \frac{v_0^k+w^k+v_0^0+w^0}{2}\circ \tau_k^{-1}\circ \tau_k = \frac{v_0^k+w^k+v_0^0+w^0}{2}$ which we have, since we just proved that $v_0^k, w^k$ are weakly convergent in e.g. $L^2(I,H)$.

We conclude that $Q^k,P^k$ are bounded in the $Q(I,\tw{W}_{\tau_k\circ \tau})$ and $Q(I,\tw{V}_{\tau_k\circ \tau})$ sense.

But what we want is a bound on $q^k, p^k$ in the $Q(I,\tw{W}_{ \tau})$ and $Q(I,\tw{V}_{ \tau})$ sense. This can be accomplished in exactly the same way as before.

We conclude that there exist $q^?, p^?$ in $Q^0(I,\tw{W}_{ \tau})$, $Q^0(I,\tw{V}_{ \tau})$, that are, modulo subsequences, the weak limits of $q^k, p^k$.

To show e.g. $q^?=q^0$ and conclude the convergence of the full sequence, we analyze the weak formulation of $q^k$, which reads, after going to the moving domain and applying integration by parts in time (see \cref{prop:Q}):

\begin{align*}
-\int_I \left (\frac{((v_0^k+\bar{u}_\tau - w^k)+(v_0^0+\bar{u}_\tau - w^0)}{2}\right )|\det(D\tau_k)|,\delta w)_{H_\tau}+\\
-\int_I (  q^k_t ,   \delta w |\det(D\tau_k)|)_{H_\tau}+ (A_{\tau_k}\nabla \delta w, \nabla q^k)_{H_\tau}
\end{align*}

for all $\delta w \in Q_0(I,\tw{W}_{ \tau})$.

We show the convergence of e.g. the member: $\int_I( v_0^k|\det(D\tau_k)|,\delta w)_{H_\tau}$. By splitting the scalar product as we saw above, we are left with checking that $\int_I (v_0^k,\delta w)_{H_\tau}\rightarrow  \int_I (v_0^0,\delta w)_{H_\tau}$, which is true, since we proved that $v_0^k \weakc v_0^0$ in $Q(I,\tw{V}_\tau)$. We conclude, upon passing to the limit, that:

\begin{align*}
-\int_I \left (\frac{((v_0^0+\bar{u}_\tau - w^0)+(v_0^0+\bar{u}_\tau - w^0)}{2}\right ),\delta w)_{H_\tau}+\\
-\int_I (  q^?_t ,   \delta w )_{H_\tau}+ (\nabla \delta w, \nabla q^?)_{H_\tau}
\end{align*}

which is satisfied also by $q^0$, therefore $q^? = q^0$ and we have weak convergence of the entire sequence.

\end{mproof}

\begin{obs}[Fréchet differentiability]
\mbox{}\\
Fréchet differentiability could be proved from the Gateaux differentiability of \cref{prop:gateaux_diff} after showing continuity of $\tau\mapsto dJ(\tau)$. Stronger smoothness assumptions on the transformations $\tau$ must however be made. 
Yet another way would be to apply implicit function theorems.
\end{obs}

\section{Star-shaped reparametrization}
\label{sec:star}
\textcolor{red}{You can add a generalization to a different star shaped reparametrization, if need be}

Here we reparametrize the problem assuming the domains $D, \Omega=\tau(\Omega_r)$ to be star-shaped with respect to the origin. We do this to justify the computer implementation of the solution algorithm. In particular, we define and analyze certain maps that convert functions on a sphere to radial deformation fields (see below for details), and based on those, detail the expression of the shape gradient of \cref{prop:gateaux_diff}. This is the result of \cref{prop:star_shaped_gradient}.

\begin{prop}[Star shaped boundary]
Let $f \in C(\mS)$, $f>0$. Define $\Omega_f:=\{x, |x|<f(\xh)\}\cup\{0\}$, where $\xh=x/|x|$. Then:
\begin{itemize}
\item $\Omega_f$ is open
\item $\Omega_f$ has boundary $\{x, |x|=f(\xh)\}$
\item $\Omega_f$ is a bounded Lipschitz domain
\end{itemize}
\end{prop}

\begin{figure}[H]
\centering
\includegraphics[width=0.4\columnwidth]{Images/RadialDisplacement.pdf}
\caption{Illustration of radial displacement}\label{fig:star}
\end{figure}

\begin{mproof}

For $x \in \partial \Omega_f$ (so, $x\neq 0$) we find $x_n, y_n \rightarrow x$ with $|x_n|<f(\widehat{x_n})$ and $|y_n|\geq f(\widehat{y_n})$. For large $n$ and by continuity, $|x| = f(\xh)$ and we have shown one inclusion.

For the reverse, and $x, |x|=f(\xh)$ (so, $x\neq 0$), we define $x_n = \frac{n}{n+1} x$ which satisfies $|x_n|<|x|=f(\xh)=f(\widehat{x_n})$, that is, $x_n \in \Omega_f$, and also $x_n\rightarrow x$. This shows that $x \in \partial \Omega_f$.

It is a bounded Lipschitz domain by lemma 2 at page 96 of \cite{burenkov}, and lemma 5 at page 151 also of \cite{burenkov}, a fact that was not discussed in \cite{deckelnick}. Note that the definition of Lipschitz domain of \cite{burenkov} is completely equivalent to that of \cite{bello} (and at least implies that of \cite{mclean}, \cite{grisvard}, \cite{leoni}, \cite{adams}, a fact which is needed in the sequel), by an application of the Lebesgue number lemma, whose statement can be found at e.g. page 179 of \cite{munkres}.

\end{mproof}

We now define maps relating a radial function to its correspondent a star-shaped domain. We choose $0<\eps <f_D \in W^{1,\infty}(\mS)$, to parametrize the non moving part of the optimization domain. The reference domain is taken to be $\Omega_{f_D}\setminus \overline{B}_\eps$, and we call $D:=\Omega_{f_D}$

\begin{prop}[$H_f, A_f$]
Let $\eps <f_D \in W^{1,\infty}(\mS)$ and $0<f \in W^{1,\infty}(\mS), f<f_D$, and define:
\begin{itemize}
	\item $H_f(x):=\ds \left\{\begin{matrix}
\frac{x}{\epsilon}f(\hat{x}) &  x\neq 0\\ 
0 & x=0
\end{matrix}\right. $, as a function $\mR^n\rightarrow \mR^n$
	\item $A_f(x):=\left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh$, as a function $\mR^n\setminus\{0\}\rightarrow \mR^n$
\end{itemize}

They enjoy the following properties:

\begin{enumerate}
%	\item $H_f:\mR^n \rightarrow \mR^n$, $A_f:\mR^n \rightarrow \mR^n$ is Lipschitz, $A_f: \overline{D}\setminus B_\eps\rightarrow \mR^n$ is Lipschitz too
	\item $H_f(B_\eps)=\Omega_f$, $H_f(\eps \mS) = \partial \Omega_f$
	\item $A_f(D\setminus \overline{B_\eps}) = D\setminus \overline{\Omega_f}$, $A_f(\partial D) = \id$, $A_f(\eps \mS) = \partial \Omega_f$
	\item $A_f=H_f$ on $\eps\mS$
	\item $H_f^{-1}(y):=\ds \left\{\begin{matrix}
\epsilon \frac{y}{f(\hat{y})} &  y\neq 0\\ 
0 & y=0
\end{matrix}\right. $, as a function $\mR^n\rightarrow \mR^n$
	\item $A_f^{-1}(y):=\left (  \eps+\frac{f_D(\yh)-\eps}{f_D(\yh)-f(\yh)}(|y|-f(\yh)) \right )\yh$, as a function $\overline{D}\setminus \Omega_f \rightarrow \overline{D}\setminus B_\eps$
\end{enumerate}

\end{prop}


\begin{figure}[H]
\centering
\includegraphics[width=0.7\columnwidth]{Images/A_f.pdf}
\caption{Illustration of the action of $A_f$}\label{fig:A_f}
\end{figure}

\begin{mproof}
All the properties are straightforward from the definitions. It helps to recognize that $A_f$ is just the linear map from the radial segment $[\eps, f_D(\xh)]$ to $[f(\xh), f_D(\xh)]$ and that $\overline{\Omega_{f_D}} \setminus \Omega_f = \{f(\xh)\leq|x|\leq f_D(\xh)\}$
\end{mproof}

They also satisfy a bi-Lipschitz condition.

\begin{prop}[Bi-Lipschitz condition]
We have that $A_f:  \overline{D}\setminus B_\eps\rightarrow \overline{D}\setminus \Omega_f $ is Lipschitz with Lipschitz inverse (bi-Lipschitz), and so is $H_f: \mR^n \rightarrow \mR^n$.
\end{prop}

\begin{mproof}

The second part of the proposition is contained in \cite{deckelnick} in a weaker for, we therefore proceed to prove all the statements.

\underline{$H_f$}

We can assume both $x,y\neq 0$. Then $|f(\xh)x-f(\yh)y|\leq |x||f(\xh)-f(\yh)|+f(\yh)|x-y|$. Employing direct and reverse triangle inequalities we get $|\xh-\yh|\leq \frac{2}{|x|}|x-y|$.

As $f$ is Lipschitz (see \cite{deckelnick}) we obtain:  $|f(\xh)x-f(\yh)y|\leq |x|C(f)\frac{2}{|x|}|x-y|+C(f)|x-y|$.

Now, $1/f$ is also Lipschitz and bounded, because $f>0$ and is continuous on a compact set. Thus the same proof shows the Lipschitz property also for $H_f^{-1}$.

\underline{$A_f$}

Call $A_f(x)=\left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh =:Q(x)\xh $. Because $|x|\geq\eps$, as before, we obtain $|A_f(x)-A_f(y)|\leq 2/\eps Q(x) |x-y|+|Q(x)-Q(y)|$, so that we need to show that $Q$ is bounded Lipschitz.

By continuity and compactness, $f_D(\xh)-\eps\geq \delta >0$ and boundedness follows. The Lipschitz property follows because $Q$ is sums of products of bounded Lipschitz functions. For instance, $f_D(\xh)$ is bounded and Lipschitz because $|x|\geq\eps$, as before, and so is $f_D(\xh)-\eps$. Is is a bounded Lipschitz function that is uniformly above $\delta$, so that its reciprocal is also a bounded Lipschitz function.

Analogous reasonings let us prove also the Lipschitz property of $A_f^{-1}$.

\end{mproof}

We now try to glue $H_f, A_f$ together and still obtain a bi-Lipschitz function. Even the Lipschitz property need not to hold in general, see page 7 of \cite{weaver} for a counterexample. We therefore proceed to the proof of this fact.

\begin{prop}[Gluing $H_f^{-1}, A_f^{-1}$]
\label{prop:gluing}
$H_f^{-1}, A_f^{-1}$, or also $A_f, H_f$ can be glued into a Lipschitz function $\overline{D}\rightarrow\overline{D}$.
\end{prop}
\begin{mproof}

Call $\tau_f^{-1}$ the gluing. It is Lipschitz $\overline{D}\rightarrow\overline{D}$ if and only if $\tau_f^{-1}\circ H_f$ is Lipschitz $H_f^{-1}(\overline{D})\rightarrow\mR^n$, because we proved that $H_f$ is bi-Lipschitz $\mR^n \rightarrow \mR^n$.

We are therefore left to prove that gluing Lipshitz function on $\mS$ produces a Lipschitz function, which would also yield the claim for $\tau_f$, the gluing of $A_f, H_f$. Note that by the preceding proposition, all the functions to be glued are Lipschitz and agree on their overlaps.

\underline{Gluing lemma for Lipschitz functions on $\mS$}

Let $A\supseteq \overline{B_\eps}$. Suppose $g:A\rightarrow\mR^n$ and $h:\overline{B_\eps}\rightarrow\mR^n$ are Lipschitz and agree on $\eps \mS$. Call $f$ their gluing.

For the proof we can assume that $x \in B_\eps$, $y \in A \setminus \overline{B_\eps}$.

Then, $|f(x)-f(y)|\leq |h(x)-h(\eps \yh)|+|g(\eps \yh)-g(y)|$.

We claim at first that $|y-\eps \yh|\leq  |x-y|$. To see this, choose $n:=\yh$. Then $|y-x|^2 \geq |(y-x)\cdot n n|^2$ by Pythagoras' theorem, so that $|y-x|\geq |(y-x)\cdot n| = |(y-\eps \yh)\cdot n + (\eps \yh -x)\cdot n|$. But $(y-\eps \yh)\cdot n=|y|-\eps \geq 0$, and $(\eps \yh -x)\cdot n = \eps - x\cdot n\geq 0 $ as $x\cdot n \leq |x|\leq \eps$.

Thus  $|y-x|\geq |(y-\eps \yh)\cdot n| + |(\eps \yh -x)\cdot n|\geq  |(y-\eps \yh)\cdot n|=|y-\eps \yh|$.

We also claim that $|x-\eps \yh|\leq |x-y|$. To do so, pick $n:=\frac{\eps\yh -x}{|\eps\yh-x|}$. By Pythagoras' theorem we obtain $|y-x|\geq |(y-x)\cdot n|=|(y-\eps \yh)\cdot n +(\eps \yh -x)\cdot n|$. The second summand is non-negative and for the first one, it is directly proportional to $(y-\eps \yh)\cdot(\eps \yh-x)=(|y|-\eps)(\eps-\yh\cdot x)\geq 0$. So, $|x-y|\geq |(\eps \yh -x)\cdot n|=|\eps \yh -x|$.

Thus $ |f(x)-f(y)|\leq C|x-y|$ as desired.


\end{mproof}

\begin{cor}[Radial to volumetric transformation]
\label{cor:star_shaped_transformation}
Let again $\eps <f_D \in W^{1,\infty}(\mS)$ and $0<f \in W^{1,\infty}(\mS), f<f_D$. Define:

\begin{itemize}
	\item $\ds \tau_f(x):=\left\{\begin{matrix}
 x & |x|\geq f_D(\xh)\\ 
 \left (  f(\xh)+\frac{f_D(\xh)-f(\xh)}{f_D(\xh)-\eps}(|x|-\eps) \right )\xh & \eps \leq |x| \leq f_D(\xh) \\ 
 \frac{x}{\epsilon}f(\hat{x}) & 0<|x|\leq \eps\\ 
 0 & |x|=0
\end{matrix}\right.$

	\item $\ds \tau_f^{-1}(y):=\left\{\begin{matrix}
 x & |y|\geq f_D(\yh)\\ 
 \left (  \eps+\frac{f_D(\yh)-\eps}{f_D(\yh)-f(\yh)}(|y|-f(\yh)) \right )\yh & f(\yh) \leq |y| \leq f_D(\yh) \\ 
 \epsilon \frac{y}{f(\hat{y})}& 0<|y|\leq f(\yh)\\ 
 0 & |y|=0
\end{matrix}\right.$
\end{itemize}


Then $\tau_f \in \cT$.
\end{cor}
\begin{mproof}

The final gluing on the border of $D$ yields a Lipschitz function: we can see this by taking $\id -\tau_f^{\pm 1}$, which is Lipschitz and $0$ on $\partial D$, so that we are considering the zero extension outside $D$ of a Lipschitz function, null on $\partial D$. This extension is Lipschitz.

\end{mproof}

Note that, as long as $f<f_D$, $\tau_f(B_\eps)$ will always be bounded Lipschitz.

We finally have a look at shape derivatives in this radial framework. The cost functional will be $j(q):=J(\tau_{\eps+q})$, where $0<q+\eps < f_D$. We are interested, for $h\in W^{1, \infty}(\mS)$, in the limits $$\lim_{t\rightarrow 0}\frac{j(q+th)-j(q)}{t}$$

But this is:

$$\lim_{t\rightarrow 0}\frac{J(\tau_{\eps+q+th})-J(\tau_{q+\eps})}{t}$$

Now, we derive the expression of a displacement field $V_h$, to connect this difference quotient to the already computed shape derivative, see also \cite{deckelnick}. The ansatz $\tau_{q+th}=(\id + tV_h\circ \tau_q^{-1})\circ \tau_q$ brings us to $V_h = \ds \frac{\tau_q+th-\tau_q}{t}$, and by some computations, we obtain: 

$$V_h(x) :=\left\{\begin{matrix}
 0 & |x|\geq f_D(\xh)\\ 
 h(\xh)\frac{f_D(\xh)-|x|}{f_D(\xh)-\eps}\xh & \eps \leq |x| \leq f_D(\xh) \\ 
 \frac{x}{\epsilon}h(\hat{x}) & 0<|x|\leq \eps\\ 
 0 & |x|=0
\end{matrix}\right.$$

This expression only depends on $h$ and is the gluing of Lipschitz functions, that are either $0$ at the gluing points, or such that the gluing points lie in $\eps\mS$. Note, this vector field is just moving $\eps \mS$ by $h$ and radially damping this movement to $0$ close to $\partial D$. We can therefore conclude:

\begin{prop}[Shape derivative, star shaped case]
\label{prop:star_shaped_gradient}
We have the following facts, for $h \in W^{1,\infty}(\mS)$, $0<q<f_D$, $q \in W^{1,\infty}(\mS)$:

\begin{itemize}
	\item $\tau_{q+th}=(\id + tV_h\circ \tau_q^{-1})\circ \tau_q$
	\item $V_h \in \Te$
	\item $j$ is Gateaux differentiable at every $0<q<f_D$, $q \in W^{1,\infty}(\mS)$, with $j'(q)[h] = J'(\tau_{\eps+q})[V_h]$
\end{itemize}

\end{prop}
\begin{mproof}

We only need to show that $h\mapsto V_j$ is linear bounded $W^{1,\infty}(\mS)\rightarrow \Te$. Linearity is immediate and for the boundedness: $\sup_x|V_h(x)| = \norm{h}_\infty$, and we only therefore need to bound the Lipschitz constant of $V_h$. 

We only need to restrict ourselves to $\overline{D}$, as extending to zero a Lipschitz function doesn't increase its Lipschitz constant.

The gluing lemma \cref{prop:gluing} shows that it is sufficient to bound the Lipschitz constants of the two branches, separately.

These bounds are respectively: $C(\eps)(\norm{h}_\infty + 2\norm{D_T h}_\infty)$ and $[2\eps^{-1}(\norm{D_T h}_\infty + \norm{h}_\infty)]C(f_D,\eps) + C(f_D,\eps)\norm{h}_\infty$, which concludes the proof.

\end{mproof}

\subsection{Smooth star-shaped domains}

To ensure that $U$ has the smoothness required to perform numerical analysis, we want to increase the regularity of $f$ and see an increase in the regularity of $\partial \Omega_f$.

\begin{prop}[Smooth radial function yields smooth star shaped domain]
\label{prop:Co_domain}
Let $f>0$ which is either $C^{1,1}(\mS)$ (that is, $C^1$ with all the components of $D_T f$ Lipschitz) or $C^2(\mS)$.  

Then, $\Omega_f$ has boundary of class $C^{1,1}$ or $C^2$.

\end{prop}

\begin{mproof}

In what follows we generically write $ C^o$, $o=1,1 $ or $o=2$.


\underline{A punctured diffeomorphism of class $C^o$}

We consider $H_f$, neglecting the $\eps$ factor. It has gradient (see \cite{deckelnick}) $D H_f(x) = f(\xh)I+\xh \otimes D_Tf(\xh)$, and  $D H_f^{-1}(y) =1/f(\yh)I-1/f(\yh)^2 \yh \otimes D_Tf(\yh)$. They are $C^o$ away from the origin. In particular $H_f$ is $C^o$  outside of $B_\delta(0)$, $\delta < 1$. $H_f(B_\delta)$ also contains a ball around the origin, and the complement contains $\Omega_f$.

We conclude that $H_f: \overline{B_\delta(0)}^c \rightarrow \overline{H_f(B_\delta(0))}^c$ is a $C^o$ diffeomorphism, where the right set is open by $H_f$ being a homeomorphism of $\mR^n$. The Lischitz regularity of the gradients follows from the Lipschitz and boundedness of every factor, and the fact that we are setting ourselves away from the origin. In particular, $D_T f$ is Lipschitz, therefore continuous, on the sphere, and so bounded too.

We have therefore obtained a homeomorphism $\mR^n \rightarrow \mR^n$, which is $C^o$ as $\overline{B_\delta(0)}^c \rightarrow \overline{H_f(B_\delta(0))}^c$, so, in a neighbourhood of $\partial \Omega_f$.

For simplicity let's refer to such maps as $C^o$ punctured diffeomorphisms for $\Omega_f$.

\underline{Punctured diffeomorphism and $C^o$ domains}

Let $\Omega$ be of class $C^o$ (always locally) and bounded. Assume we have $F$, a punctured diffeomorphism for $\Omega$, so, $F:\mR^n\rightarrow \mR^n$ is a homeomorphism, and $F: U\rightarrow F(U)$ is $C^o$, $\partial \Omega \cc U$. Then, by analyzing the composition of $F$ with (small enough) charts of $\Omega$ we see that $F(\Omega)$ is another $C^o$ domain (local sense). 

\underline{From diffeomorphisms to graphs}

Let $\Omega$ be any $C^o$ domain, $x\in \partial \Omega$. We obtain $A\ni x, B$ open, and $\phi: A\rightarrow B$ a $C^o$ diffeomorphism, with $\phi^{-1}(B\cap \mR^n_+)=A\cap \Omega$, and $\phi(x)=0$.

$\phi$ is a $C^1$ diffeomorphism, so $D\phi_n(x)\neq 0$, and we can assume $D\phi_n(x)$ to be proportional to $-e_n$ by a rotation of the axis.

Thus $\partial_n\phi_n(z)<0$ in some $B(x)\subseteq A$. $B(x)$ is chosen small that $\phi$ is Lipschitz on $B(x)$.

Apply the implicit function theorem to obtain $V',I$ open with $x \in V'\times I\subseteq B(x)$ and a function $\eta:V'\rightarrow I$ that is $C^o$ and Lipschtiz, with $\phi_n(z',z_n)=0 \iff z_n = \eta(z')$, for $z \in V'\times I$.

$V'$ is open around $x'$, so let's restrict it to a square centered at $x'$. Relabel $\eta$ as the restriction to this new $V'$ and restrict $I$ to be the connected component of $G$ hosting $\eta(V')$, which is now an interval, as continuous image of a connected set. Because $x_n \in I$, and by continuity, $V'$ can be shrunk such that $\eta(V')\cc J \cc I$ for some open interval $J$. 

All these shrinkings don't change the character of being the implicit function, i.e. $\eta$ still satisfies $\phi_n(z',z_n)=0 \iff z_n = \eta(z')$, for $z \in V'\times I$, and also,  $x \in V'\times I\subseteq B(x)$ and $\eta:V'\rightarrow I$ is still $C^o$ and Lipschitz.

Now, the choice of $B(x)$ makes $z_n\mapsto \phi(z',z_n)$ strictly decreasing, for $(z',z_n) \in B(x)$.  So, for $z \in V'\times I$, we have $\phi_n(z', z_n) = \phi_n(z)>0=\phi_n(z',\eta(z')) \iff z_n<\eta(z')$ (by basic properties of strictly decreasing functions).

But also, $\phi_n(z) >0 \iff \phi(z) \in B\cap \mR^n_+ \iff z \in \phi^{-1}(\mR^n_+\cap B)=A\cap \Omega$.

Therefore, $z \in V'\times I, z_n<\eta_n(z) \iff z \in V'\times I, \phi_n(z) >0 \iff z \in A\cap \Omega \cap (V'\times I) = (V'\times I)\cap \Omega$.

Summing up we have the following:

\begin{itemize}
	\item a square and an interval $V', I$ with $V'\times I \ni x$
	\item $\eta: V'\rightarrow I$, Lipschitz, of class $C^o$
	\item $\phi(V') \cc J \cc I$
	\item $z \in V'\times I, z_n<\eta_n(z) \iff z \in (V'\times I)\cap \Omega$
	\item (and consequently, $z \in V'\times I, z_n=\eta_n(z) \iff z \in (V'\times I)\cap \partial \Omega$)
\end{itemize}

\underline{Conclusion}

Let a radial function $f>0$ be of class $C^o$. Thanks to $H_f$, a punctured diffeomorphism of class $C^o$, we we have that $\partial \Omega_f$ is the image of $\eps\mS$, a domain of class $C^o$ as well, locally. So $\Omega_f $ is of class $C^o$ locally, in the sense of diffeomorphisms, and by what we showed, also in the sense of graphs.

So, for $x \in \partial \Omega_f$ we can find a change of coordinates and a parallelepiped $V = V'\times I$ with $\phi: V'\rightarrow I$, $\phi$ of class $C^o$ and also Lipschitz, and $V\cap 	\Omega_f = V\cap \{x_n<\phi(x')\}$. We have moreover that $\phi \in J \cc I$ for some open interval $J$. By a compactness argument, finitely many $V_j = V_j'\times (a_n^j, b_n^j) $ are necessary to cover $\partial \Omega_f$. 

So, we have $V_j \cap \Omega_f = V_j\cap \{x_n<\phi_j(x')\} = V\cap \{a_n^j<x_n<\phi_j(x'), x' \in V_j'\}$. Choose $d>0$ to be the minimum gap between $\phi_j$ and $I_j$. $d>0$ by the existence of $J_j \cc I_j$. We call $L$ the maximum Lipschitz constant of $\phi_j$. 

We have therefore a Lipschitz and $C^o$ domain in the style of \cite{burenkov}, which yields, modulo an application of the Lebesgue number lemma, a $C^o$ and Lipschitz domain in the style of \cite{grisvard}.

\underline{Remarks about the usage of the implicit function theorem}

Examining the proofs of the inverse and implicit function theorems as given e.g. at pages 310, 311 of \cite{gilardi2}, we see that solving $f=0$ for $f$ Lipschitz and $C^o$, yields a Lipschitz and $C^o$ implicit function.

\end{mproof}

\chapter{Discretization}

In this chapter we focus on giving justification to the numerical observations contained in \cref{chap:num_exp}. Linear finite elements are used to discretize the partial differential equations in space, whereas the implicit Euler or the Crank-Nicolson methods are used for advancing in time.

We account for the fact the non-discretized domain is smooth and the computational one is polygonal/polyhedral. 

We are not focusing here on optimization algorithms to solve the shape identification problem, nor on the specific domain parametrization. This will be done in \cref{chap:num_exp}.


As a summary of the discretization approach:

\begin{itemize}
	\item the PDEs are numerically solved on a polygonal/polyhedral approximation of the smooth domain $U$
	\item such approximation involves only knowing a finite number of points of $\partial U$, and not its entire parametrization
	\item only such nodal values of the boundary data is required (compatible, for instance, with the case where only finite number of measurements are realized)
	\item implicit Euler or Crank-Nicolson time steppings are adopted
	\item several optimal order error estimates are obtained
\end{itemize}

We remark that such time stepping schemes require a globally smooth solution, over time. To decrease such requirement, discontinuous Galerkin space-time methods can be adopted, see e.g. \cite{vexler}. The reason for this is that certain time integrals therein are not discretized in time, whereas the classical implicit Euler/Crank-Nicolson evaluate such quantities pointwise. The implicit Euler method can be in fact seen as a space-time method, with quadrature in time. More smoothness in time is therefore required, to treat this numerical quadrature.

We can reach such smoothness for the state equations, by requiring smooth data, and certain compatibility relations among them (see e.g. chapter 2 of \cite{lions}). Smoothness of the data alone is not enough: a regular solution is obtained, but only away from the starting time, where a singularity can develop (see e.g. the discussion in \cite{harbrecht}). The adjoint equations are however, in a certain sense, fixed by the particular cost functional we chose, and the state equation itself: unfortunately, for them, compatibility relations do not hold, in general.

In \cite{harbrecht}, they work with adjoint equations that have incompatible boundary data, and devise a non-standard time stepping scheme to deal with this. On the other hand, our choice of cost functional, makes it possible to obtain compatibility of order zero in the adjoint. This would be enough for a low order space-time method, but not for the chosen schemes. To obtain more compatibility, i.e., to modify the data that enters the adjoint equations, since we cannot modify the PDE solved by the states $u,v$, we can only tweak the cost functional. This is what we will do, by introduction of a suitable temporal weight in the cost functional of \cref{pb:shopt}. Such operation will yield compatibility of arbitrary order, at the price of partially modifying the nature of the shape optimization problem. See \cref{sec:o-t-d} for a more thorough discussion.

An in-depth presentation and analysis of the discretization algorithms for states and adjoints is discussed in \cref{chap:inh_fem}. In what follows we will build on the results therein.

As a last note, let us mention the two canonical ways, in the literature on optimal control, of discretizing a problem posed on an infinite-dimensional level:

\begin{itemize}
	\item optimize-then-discretize: the gradient of the cost functional is derived on the continuous level (see e.g. \cref{prop:gateaux_diff} in our case), and some adjoint states appear. Then, one proceeds with discretizing states and adjoints, and obtains an optimality system on the discrete level, amenable to numerical solution
	\item discretize-then-optimize: the states and cost function, i.e. the continuous problem (\cref{pb:pdes} and \cref{pb:shopt}) are discretized, to obtain an optimization problem posed on the discrete level. Finite dimensional optimality conditions can now be derived
\end{itemize}

In any case, one starts from an infinite-dimensional problem and obtains discrete optimality conditions, that can be employed for a numerical implementation. When the obtained discrete optimality system is the same, we say that the two strategies, optimize-then-discretize and discretize-them-optimize commute. With a diagram:

\[\begin{tikzcd}
	&&& \text{continuous optimality system} \\
	\text{continuous problem} &&&&&& \text{discrete optimality system}  \\
	&&& \text{discrete problem} 
	\arrow["{\text{optimization}}"', from=3-4, to=2-7]
	\arrow["{\text{discretization}}", from=1-4, to=2-7]
	\arrow["{\text{optimization}}", from=2-1, to=1-4]
	\arrow["{\text{discretization}}"', from=2-1, to=3-4]
\end{tikzcd}\]

Although not a trivial task, there are several benefits implied by realizing a commutative scheme, we refer to the introduction of \cite{liu} for a comparison between the two strategies, and a discussion of advantages and disadvantages of each. See also \cite{flaig}, in the context of parabolic optimal control.

We can show that optimization and discretization commute, when using the implicit Euler case. We strongly suspect that this conclusion can be extended also to Crank-Nicolson, thanks to the work of \cite{flaig}.

Now:

\begin{itemize}
	\item in \cref{sec:o-t-d}, the continuous states and adjoints are discretized and the error in doing so, is quantified. We are taking an optimize-then-discretize approach, and obtain optimal order estimates, optimal with respect to the approximation properties of the finite element spaces and time stepping schemes
	\item in \cref{sec:d-t-o_IE}, a discretize-then-optimize approach is adopted, just like in \cref{chap:num_exp}. A result on the convergence of the discrete shape gradient, to the continuous one, is presented, in the case the time-stepping is done by the implicit Euler method
	\item in \cref{sec:superconv}, we only discretize in space and show that a better result than in \cref{sec:d-t-o_IE} is available. This is then applied to the case of implicit Euler to obtain a fully discrete result
	

\end{itemize}

In what follows, $\lesssim$ stands for $\leq C$, with $C$ independent on time and space discretization parameters.

\section{Approximation of PDEs, optimize-then-discretize}
\label{sec:o-t-d}

Consider the state and adjoint equations as seen in \cref{pb:pdes} and \cref{prop:gateaux_diff}. Let us have a unified notation (just like in \cref{pb:mix}).

\begin{pb}[Unified notation for state and adjoint equations]
\label{pb:uni_state_adj}
State equations:

\begin{align*}
\left\{\begin{matrix}
u_t-\Delta u =0 & \text{ in } U\times (0,T)\\ 
u = u_D & \text{ on } \Gamma_D\times(0,T)\\ 
\partial_\nu u = u_N & \text{ on } \Gamma_N\times(0,T)\\ 
u(0) =0 & 
\end{matrix}\right.
\end{align*}

Adjoint equations:

\begin{align*}
\left\{\begin{matrix}
-a_t-\Delta a =\eta (v-w) & \text{ in } U\times (0,T)\\ 
a = 0 & \text{ on } \Gamma_D\times(0,T)\\ 
\partial_\nu a = 0 & \text{ on } \Gamma_N\times(0,T)\\ 
a(T) =0 & 
\end{matrix}\right.
\end{align*}

We intend that $u$ can be $v$, in which case $a$ is $p$, or $u$ is $w$ and then $a$ is $q$, so that the Dirichlet and Neumann boundaries are coherent between state and adjoint equation. Note that we added a temporal weighting function $\eta$ which we will later specify.

\end{pb}

We have dropped, for simplicity, all the references to the domain transformation. Let us discuss the presence of the temporal weight $\eta$. This is a function $\eta: [0,T] \rightarrow \mR$ which in the above problem, we wrote equal for both adjoint states. This is a slight abuse of notation, in fact, for $p$ and $q$ we should be writing $\eta$ and $-\eta$.

Its presence in the right hand side of the adjoint equation can be justified by modifying the energy function in \cref{pb:shopt} to be:

$$J_\eta(\tau) = \frac{1}{2} \int_I \eta \norm{v_\tau - w_\tau}_{H_\tau}^2$$

This modification is reasonable for a reasonable $\eta$ and its main purpose is to facilitate the analysis of the numerical discretization. In particular, we choose $\eta$ to be a smooth cut-off function that is positive in $(0,T)$ and $0$ in $[T, +\infty]$. Note that in case a solution to the "classical" problem exists, then it is also a solution to this new problem, and viceversa. In fact, $J_\eta(\tau)=0 \implies \eta \norm{v_\tau - w_\tau}_{H_\tau}^2=0 \implies v_\tau = w_\tau$. This equality holds on all $I=[0,T]$ by the time continuity of the states.

Modifying the final-time behaviour of the energy might have detrimental effects if the boundary data exhibts strong variations close to final time, which is physically implausible, given the physical nature of the partial differential equation. In fact, it is known that solutions to the heat equation tend to a steady state for long times, and we are only measuring the value of one such solution on the external boundary of $U$: we thus expect that in practice, this boundary data will not exhibit oscillatory behaviour for large times, and that the introduction of $\eta$ will not cause issues.

We now proceed to discretize states and adjoints using the scheme presented in \cref{pb:num_scheme} (the adjoint equation can be cast into a standard heat equation by time reversal). In short, finite elements are used in space, a finite difference time stepping, in time. If one chose an optimize-then-discretize approach this would be satisfactory (at least with regards to the numerical approximation of states and adjoints). However we will conduct experiments in a discretize-then-optimize setting, so that the upcoming results are only partially satisfactory.

The spatial discretization is done on a polygonal approxumation of $U$. We explicitly account for this, see the introductory discussion in \cref{chap:inh_fem}. Note, the next assumption is formulated as if $U$, $U_h$ were given, i.e. they are not deformations of initial reference domains. This will be remarked later on, too. 

Throughout, set $\theta=1$ to obtain the implicit Euler method, $\theta=1/2$ for the Crank-Nicolson method.

\begin{ass}[Hypothesis for the numerical discretization of \cref{pb:uni_state_adj} ]
\label{ass:num_discr_shopt}
\textcolor{white}{ }
\begin{enumerate}
	\item $\partial U \in C^2$ (for instance, the star shaped functions must be of class $C^2$), $U_h$ is polygonal/polyhedrak and $\partial U_h$ interpolates $\partial U$. The mesh family of $U_h$ must also be quasi-uniform \textcolor{red}{be precise}
	\item $u_D \in H^1(I, H^{2}(\Gamma_D)) \cap H^{1/\theta+1}(I,H^{3/2}(\Gamma_D))$, $u_N \in H^2(I,L^2(\Gamma_N)) \cap H^{1/\theta}(I, H^2(\Gamma_D))$
	\item $g_D(0)=0$ and $g_N^{(k)}(0), g_D^{(k+1)}(0)  = 0$ for $k=0,..., 1/\theta$
	\item $\eta^{(k)}(T)  = 0$ for $k=0,..., 1/\theta-1$, $\eta \geq 0$ and $\eta \in C^{\infty}([0,T];\mR)$
\end{enumerate}

\end{ass}

We have written $u_N, u_D, \Gamma_D, \Gamma_N$ to mantain a flexible notation. With reference to \cref{pb:pdes} this translates to:

\begin{itemize}
	\item state $v$: $u_D=f$ on $\Gamma_f$, $=0$ on $\Gamma_m$, $\Gamma_D = \partial U=\tau(U_r)$, $\Gamma_N=\emptyset$
	\item state $w$: $u_N=g$ on $\Gamma_f$, $u_D = 0$ on $\Gamma_m$, $\Gamma_D = \Gamma_m$ and $\Gamma_f = \Gamma_N$
\end{itemize}

Call now $h$ the maximum element size of the mesh of $U_h$, and $\delta t$ one of the $K$ uniform intervals $[t^k,t^{k+1}]$, $k=0,...,K-1$, into which $I$ is subdivided.

\begin{pb}[Numerical discretization of \cref{pb:uni_state_adj}]
\label{pb:num_scheme_recall}
Consider $g_{N,h}^k, g_{D,h}^k$ to be the Lagrange interpolant of $g_N(t^k), g_{D,h}^k$. For the state $u$ we adopt:

\begin{align*}
\left ( \frac{u_{h}^{k+1}-u_h^k}{\delta t}, v_h\right)_{L^2(\Omega_h)} + (\nabla(\theta u_h^{k+1}+(1-\theta)u^k_h), \nabla v_h)_{L^2(\Omega_h)} = (\theta g_{N,h}^{k+1} + (1 - \theta)g_{N,h}^{k} , v_h)_{L^2(\Gamma_{N_h})},\quad  1\leq k \leq K\\
u_h^{k+1}|_{\Gamma_{D_h}}=g_{D,h}^{k+1},\quad 1\leq k \leq K\\
u_h^0=0
\end{align*}

and $v_h \in S^1_{h,0,D_h}$. Here $\Gamma_{D_h}, \Gamma_{N_h}$ are the discrete counterparts of $\Gamma_{D}, \Gamma_{N}$, and $S^1_{h,0,D_h}$ is the linear finite element space on $U_h$, with the constraint of vanishing on $\Gamma_{D_h}$.

The same scheme is applied to the adjoint equations. We refrain from writing it fully, since we won't be using it in the implementation.
\end{pb}

We now state the error estimates for \cref{pb:uni_state_adj}. Before doing so, we remind that the continuous solution is defined on a smooth domain $U$, whereas the discretized solution on a polygonal/polyhedral approximation $U_h$. To compare e.g. $u$ and $u_h$ we must have a way of "lifting" $u_h$ to $U$ or viceversa. This procedure is possible and we denote it by $(\cdot)^l$: we thus compare $u: U\times I \rightarrow \mR$ and $u_h^l:U\times\{0,...,K\}\rightarrow \mR$. For details regarding the lifting action we refer to \cref{prop:lift}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\columnwidth]{Images/Lift.pdf}
\caption{Lifting action}\label{fig:lift}
\end{figure}


\begin{prop}[Optimize-then-discretize approximation of state and adjoint equations]
\label{prop:o-t-d}
Let \cref{ass:num_discr_shopt} be fulfilled. Then, for $0\leq k \leq K$:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(U)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(U)}^2} \lesssim h + (\delta t)^{1/\theta}\\
	\left | \int_I (\partial_t u , w_K)_{L^2(U)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(U)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(U))}
\end{align*}

and

\begin{align*}
	\norm{a(t^k)-(a_h^k)^l}_{L^2(U)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
	\sqrt{\delta t \sum_{k=1}^{K} \norm{(1-\theta)(a(t^{k}) - a_h^{k})^l) + \theta(a(t^{k-1}) - a_h^{k-1})^l)}_{H^1(U)}^2} \lesssim h + (\delta t)^{1/\theta}\\
	\left |- \int_I (\partial_t a , w_K)_{L^2(U)}-\delta t \sum_{k=1}^{K}\left ( \frac{(a^{k-1}_h)^l - (a_h^{k})^l}{\delta t} , w_{K,k}\right )_{L^2(U)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(U))}
\end{align*}

where $w_K$ is piecewise constant on the time discretization, and with values $w_{K,k}$, on $[t^k,t^{k+1}]$, that belong to $H^1_{0,D}(U)$ (i.e. it is $0$ on the Dirichlet boundary), and $\lesssim$ means $\leq C$, with $C\geq 0$ independent of $h$ and $\delta t$.

\end{prop}

Note, writing $H^1_{0,D}$ is flexible because the Dirichlet boundary varies between $v,w$. In fact, for $v$, $H^1_{0,D}=H^1_0$, whereas for $w$ we have $H^1_{0,D}=H^1_{0,m}=\{u \in H^1, u(\Gamma_m)=0\}$.

\begin{mproof}

We show the satisfaction of all the hypothesis necessary to obtain \cref{thm:fully_discr_est_par} (where we track from there all the necessary assumptions), and then bound the constants therein, uniformly with respect to the space/time discretization. We do this for $u$ at first, then for $v$. We do not track the dependency on the domain $U$. This is just a more detailed repetition of the proof of the more general result \cref{cor:actual_par_est}.

We note at first that in the star shaped setting, $\partial U \in C^2$ can be ensured by \cref{prop:Co_domain}.

\underline{Smoothness of $u$: \cref{ass:smoothness_par_discr} and  \cref{ass:basic_par_mix}}

We need to ensure that $u \in H^1(I,H^2(U))$. To do so we turn to \cref{thm:mix_reg}, which we apply with $k=1$. Hypothesis $1$ to $3$ suffice. 

\underline{Assumptions for spatial semidiscretization of $u$: \cref{ass:discr_reg}}

They are also satisfied by $1-3$.

\underline{Assumptions for full discretization of $u$: \cref{ass:full_discr_smoothness}}

The smoothness of the problem data is ensured by point $2$. We turn to the compatibility conditions of order $1,...,1/\theta$. The compatibility "residuals" $\delta_h^k(0)$ are all $0$ (see \cref{ass:full_discr_smoothness} for the notation) by hypothesis $3$.

\underline{Bounding the constants $A,B,C,D$ of $u$: \cref{thm:fully_discr_est_par}}

To bound $A,B$ uniformly with respect to $h$ we only need to note that the equation for $u$ has no source term. To bound $C$, this last fact, together with $\delta_h^k(0)$, $k=0,...,1/\theta$, suffices. $D=0$, in turn.

We now turn verify the same facts for the adjoint states $a$.

\underline{Smoothness of $a$}

We need to ensure that $a \in H^1(I,H^2(U))$. To apply \cref{thm:mix_reg} with $k=1$ we see that $\eta(T)(v(T)-w(T))$ should be zero on the Dirichlet boundary, which it is, given the fact that $\eta(T)=0$. We also need $v,w$ (so, generically, $u$), to be $H^1(I, L^2(U))$, which we have already checked (we even have $u \in H^1(I,H^2(U))$.  \cref{ass:basic_par_mix} is also easily verified.

\underline{Assumptions for spatial semidiscretization of $a$}

To fulfill \cref{ass:discr_reg} we see by the triangle inequality that $\norm{\eta(u-u_h^l)}_{L^2(U)}\lesssim C_u h^2$ would suffice, for a suitable $C_u$ (see \cref{ass:discr_reg} for the definition of $C_u$). Actually, given the properties of $\eta$, only $\norm{u-u_h^l}_{L^2(U)}\lesssim C_u h^2$ has to be asked. But the hypothesis we have verified for $u$ were sufficient for the conclusions of \cref{thm:semidiscrete_error_bound} to hold. We can therefore take $C_u = A = A(u)$, which is a constant in space and time, independent of $\delta t$ and $h$, as we saw before.

\underline{Assumptions for full discretization of $a$}

The compatibility conditions listed in \cref{ass:full_discr_smoothness} are satisfied as long as $\eta(T)=0$ in the case $\theta = 1$, and also $\eta'(T)=0$ in the case $\theta=1/2$. We also have $u_h \in H^{1/\theta}(I,S^1_h)$ by $2$.

\underline{Bounding the constants $A(a),B(a),C(a),D(a)$ of $a$}

This would be the last step to ensure the thesis of \cref{thm:fully_discr_est_par}, for $a$. Starting from $D(a)^2$, we see, thanks to the boundedness of $\eta$, that $D(a)^2 \lesssim \delta t \sum_{k=0}^{K-1}\norm{\theta(u_h(t^{k+1})-u_h^{k+1}) + (1-\theta)(u_h(t^k)-u_h^k)}^2_{L^2(U_h)}$. This $O(\delta t^{2/\theta})$ by \cref{prop:d_vd_sd} and the above reasonings ($D=D(u)=0$, $C=C(u)$ is bounded uniformly).

Moving on to $C(a)$. We see that there only remains to bound, by the triangle inequality, the already checked compatibility relations and the boundedness of $\eta$, the term $\ds \int_I\norm{u_h^{1/\theta}}_{-1,h}^2\lesssim \int_I\norm{u_h^{1/\theta}}_{L^2(U_h)}^2$. This can be done as above \cref{eqn:dd_est}.

To bound $A(a)$ (equivalently $B(a)$), we need to check the boundedness of $\ds \int_IC_{\eta(v-w)}^2 + \int_I \norm{\eta(v_h - w_h)}_{H^1(U_h)}^2$. In fact, we have chosen $\eta(v_h - w_h) \in S^1_h$ as a right hand side for the semidiscrete equation of $a_h$. A triangle inequality and basic energy estimates yield a bound for the second term. The definition of $C_{\eta(v-w)}$ comes directly from \cref{ass:discr_reg} and we see that, thanks to \cref{thm:semidiscrete_error_bound}, it is dominated by $A(v)+A(w)$, which we have already estimated.

\end{mproof}

\section{Approximation of shape gradient, discretize-then-optimize with implicit Euler}
\label{sec:d-t-o_IE}

In the numerical experiments (see \cref{chap:num_exp}) we adopt a discretize-then-optimize approach. When employing the implicit Euler method in time, we can see that optimization and discretization commute, as explained below. We are moreover able to quantify the error generated when substituting the continuous with the fully discretized shape gradient. 

A future line of research could be to extend such conclusions to the case of the Crank-Nicolson method, so as to fully justify the adopted algorithms in some of the numerical experiments we conducted. A promising direction would be to find a way to adapt the arguments of \cite{flaig}, at least to show commutativity of optimization and discretization. But for now, we assume $\theta = 1$ throughout.

We begin by defining the discretized problem, where we employ continuous and piecewise linear transformations $\tau_h$, that thus preserve the finite element spaces and the polygonal/polyhedral nature of the discrete reference domain $U_{r,h}$.

\begin{pb}[Discrete shape optimization problem]
\label{pb:discr_shopt}
Given a polygonal/polyhedral reference domain $U_{r,h}$ and transformations $\tau_h$ that are linear finite element vector fields that preserve the fixed boundary, we aim at solving:

$$\inf_{\tau_h }\frac{\delta t}{2}\sum_{k=1}^{K}\norm{v_h^k-w^k_h}_{L^2(\tau_h(U_{r,h}))}^2=:J_{h,\delta t}(\tau_h)$$


where $v_h^k, w^k_h$ are defined in \cref{pb:num_scheme_recall}, with $\theta=1$, and their dependence on $\tau_h$ is not highlited in the notation.

\end{pb}

At this level, for simplicity, but also for the sake of generality, we work with again with arbitrary vector fields in place of radial fields.

\begin{prop}[Discrete shape gradient]
\label{prop:discrete_shape_gradient}
The discrete shape gradient of \cref{pb:discr_shopt} is:

\begin{align*}
	J_{h,\delta t}'(\tau_h)[\delta \theta_h] =\\
	\delta t \sum_{k=1}^{K} \left (\frac{w_h^{k}-w_h^{k-1}}{\delta t}, \dive(\delta \theta_h \circ \tau_h^{-1}) q_h^{k-1} \right )_{L^2(\tau_h(U_{r,h}))} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h \circ \tau_h^{-1}) \nabla w_h^k, \nabla q_h^{k-1})_{L^2(\tau_h(U_{r,h}))}+\\
	\delta t \sum_{k=1}^{K} \left (\frac{v_h^{k}-v_h^{k-1}}{\delta t}, \dive(\delta \theta_h \circ \tau_h^{-1}) p_h^{k-1} \right )_{L^2(\tau_h(U_{r,h}))} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h \circ \tau_h^{-1}) \nabla v_h^k, \nabla p_h^{k-1})_{L^2(\tau_h(U_{r,h}))}+\\
	\frac{\delta t}{2} \sum_{k=1}^{K} \int_{\tau_h(U_{r,h})} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h \circ \tau_h^{-1})
\end{align*}

Again, we dropped the dependence of $v,w$ on $\tau_h$, for simplicity. Here, the discretized adjoint states satisfy:

\begin{pb}[]

\begin{align*}
	\left ( \frac{p_h^{k-1}-p_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla p_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} + \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	p_h^k = 0 \text{ on }  \tau_h (\partial U_{h,r}), \quad 1\leq k \leq K\\
	p_h^K=0 
\end{align*}

and 

\begin{align*}
	\left ( \frac{q_h^{k-1}-q_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla q_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} - \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	q_h^k = 0 \text{ on } \tau_h (\Gamma_{D_h,r}), \quad 1\leq k \leq K\\
	q_h^K=0 
\end{align*}

The test functions are zero on the entire boundary for the equation of $p_{h}^k$, and only on the moving boundary for $q_h^k$.

\end{pb}

\end{prop}

\begin{mproof}[Sketch of proof]

We give a sketch of a proof, only to justify the time indices that appear in the expressions of the adjoint equations. For a rigorous proof one could adopt the same techniques employed in the continuous case. For simplicity we decide here to make use of the method proposed in and \cite{lindemann2}, section 4 (or more generally, \cite{lindemann}), to which we refer, for additional details: it is worth noting that such method can be fully justified, and that we numerically verified the correctness of such derivation.

To this end, we form a discretized Lagrangian just like in \cref{prop:lagr}, were integrals are replaced by Riemann sums (evaluated at the end of the time sub-intervals), and derivatives by difference quotients.

Since we have $v_h^0=w_h^0=0$ we can slighlty simplify the procedure to obtain the discretized adjoints (that are exact on a discrete level): we only need to differentiate such Lagrangian by $v_h^k, w_h^k$, $k=1,...,K$. 

In doing so, we obtain the following scheme, for e.g. $p_h^k$:

\begin{align*}
	\left ( \frac{p_h^{k-1}-p_h^k}{\delta t}, v_h\right )_{L^2(\tau_h(U_{r,h}))} + (\nabla p_h^{k-1}, \nabla v_h )_{L^2(\tau_h(U_{r,h}))} + \eta(t^k)(v_h^k-w_h^k,v_h)_{L^2(\tau_h(U_{r,h}))} = 0, \quad 1\leq k \leq K\\
	p_h^k = 0 \text{ on } \partial \tau_h (U_{h,r}), \quad 1\leq k \leq K\\
	p_h^K=0 
\end{align*}

where we test by $v_h \in S^1_{h,0}$. For now, the time indices are only suggestive notation. However, note that by applying implicit Euler to the time reversed $p$, this is exactly the \cref{pb:num_scheme} applied to the equation of $p$, modulo a time shift in the right hand side: we thus obtain an implicit method, with an "explicit" right hand side $\eta(t^k)(v_h^k-w_h^k)$.

Therefore $p_h^k$ is an approximation of  $p(t^k)$, and we will later quantify this assertion.

Also note, it is important that $\tau_h$ is piecewise linear on the discretization, and continous, so that finite element functions remain finite element functions after an application of $\tau_h$, and the geometry remains of polygonal/polyhedral nature. See again \cite{lindemann2} for further details on this matter.

\end{mproof}

\begin{obs}[$\tau$ and $\tau_h$]
\label{obs:tau_vs_tau_h}
\mbox{}\\
Throughout the rest of the section, we won't try to take into account the fact that the reference domains $U_r$ and and $U_{r,h}$ are changing under the actions of $\tau$ and $\tau_h$. It means that the estimates are $\tau, \tau_h$ dependent. Therefore we will fix $U = \tau(U_r)$ and $U_h=\tau_h(U_{r,h})$ once and for all. \mbox{}\\


Remember that \cref{ass:num_discr_shopt} must hold, which implies a specific form of $\tau_h$, i.e. that it must interpolate $\tau$. We refrain from generalizing the estimate to more arbitrary $\tau_h$, and we note that our result may be a first step of a more general argument (just like in finite element error estimates, the error between exact and discretized solution is decomposed into two parts by the introduction of a suitable interpolant). \mbox{}\\

This is in any case a novelty with respect to e.g. \cite{paganini}, where similar estimates to the ones we are up to derive, and in which $H^2$ regularity is asked on non-convex polygonal domains. \mbox{}\\
\end{obs}

We now give a quantitative estimate on the approximation power of the discrete adjoints we just obtained. This is needed, because the scheme they satisfy is not exactly the implicit Euler treated in \cref{prop:o-t-d}.

\begin{prop}[Error estimates for adjoint states]
\label{prop:d-t-o_estimates}
The adjoints satisfy the same asymptotic, optimal order error estimates of \cref{prop:o-t-d}, under the same assumptions (with $\theta = 1$).
\end{prop}

\begin{mproof}
The proof is exactly that of \cref{prop:o-t-d}. The only difference comes from the fact that the right hand sides of the adjoints are not "correct", i.e. they are shifted by $\delta t$. But this is not an issue, as we shall now show. 

We see that we only need to show a bound of  $\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})u_h(t^{k-1})-\eta(t^k)u_h^{k}}^2_{L^2(U_h)}$, where $u$ denotes the generic state corresponding state to the generic adjoint $a$ (this is the same notation as in the proof of \cref{prop:o-t-d}), $U_h=\tau_h(U_{r,h})$.

Applying the triangle inequality and using again the proof of \cref{prop:o-t-d}, we see that we actually only need to bound the term:

\begin{align*}
\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})u_h(t^{k-1})-\eta(t^k)u_h^k}^2_{L^2(U_h)}\lesssim\\
\underbrace{\delta t \sum_{k=1}^{K}\norm{\eta(t^{k-1})(u_h(t^{k-1})-u_h(t^{k}))}^2_{L^2(U_h)}}_{\circled{1}}+\\
\underbrace{\delta t \sum_{k=1}^{K}\norm{(\eta(t^{k-1})-\eta(t^k))u_h(t^{k})}^2_{L^2(U_h)}}_{\circled{2}}+\\
\underbrace{\delta t \sum_{k=1}^{K}\norm{\eta(t^k)(u_h^k-u_h(t^k)))}^2_{L^2(U_h)}}_{\circled{3}}
\end{align*}

There holds $\ds  \circled{2} \leq \norm{\eta'}_\infty^2 \delta t^3 \sum_{k=1}^{K}\norm{u_h(t^{k})}^2_{L^2(U_h)}$. Call $\pi u_h := u_h(t^{k})$ for $t \in (t^k, t^{k+1})$. By \cref{lemma:pw_constant_appr} we see that, for $\delta t $ small enough, one has $\norm{\pi u_h}_{L^2(I, L^2(U_h))} \lesssim \delta t \norm{u_h'}_{L^2(I,L^2(U_h))}$. This yields:

\begin{align*}
	 \ds  \circled{2}\leq \norm{\eta'}_\infty^2 \delta t^3 \sum_{k=1}^{K}\norm{u_h(t^{k})}^2_{L^2(U_h)}  = \norm{\eta'}_\infty^2 \delta t^2 \int_I \norm{\pi_h u_h}^2_{L^2(U_h)}\\\lesssim \delta t^3 \norm{u_h'}_{L^2(I,L^2(U_h))}^2 \norm{\eta'}_\infty ^2
\end{align*}

On the other hand,  $\ds  \circled{1} \leq \norm{\eta}_\infty^2 \delta t \sum_{k=1}^{K}\norm{u_h(t^{k-1})-u_h(t^{k})}^2_{L^2(U_h)}$, and with a similar reasoning as in the proof of \cref{lemma:pw_constant_appr}, we conclude:

\begin{align*}
 \circled{1} \leq \norm{\eta}_\infty^2 \delta t \sum_{k=1}^{K} \delta t \int_{I_k}\norm{u_h'}_{L^2(I_k , L^2(U_h))}^2 
\end{align*}

In both cases, $\norm{u_h'}_{L^2(I,L^2(U_h))}^2$ can be bounded uniformly with respect to $h$ (and $\delta t$), by energy estimates (see e.g. \cref{cor:L2_deriv_est}).

Note, it is clear from this estimate that a very steep $\eta$ will yield higher discretization errors.

Finally, by \cref{prop:d_vd_sd} (which we can apply by \cref{ass:num_discr_shopt}), we obtain $\ds \circled{3} \lesssim (h^2+\delta t)\norm{\eta}_\infty^2 $.

%This $O(\delta t^{2/\theta})$ by \cref{prop:d_vd_sd} and the above reasonings ($D=D(u)=0$, $C=C(u)$ is bounded uniformly).

\end{mproof}

\begin{obs}[Optimization and discretization commute]
\mbox{}\\
Optimization and discretization commute, in the case of $\theta=1$. In fact, we could have started from the continuous states and adjoint (see \cref{pb:pdes} and \cref{prop:gateaux_diff}), applied the scheme of \cref{pb:num_scheme_recall} to the states and the perturbed implicit Euler method of \cref{prop:discrete_shape_gradient} for the adjoints (which is a "legitimate" scheme, as we have just shown in \cref{prop:d-t-o_estimates}) to obtain exactly the same discrete quantities (states and adjoints).\mbox{}\\
With a diagram:

\[\begin{tikzcd}
	&&& \text{\cref{prop:gateaux_diff}} \\
	\text{\cref{pb:shopt}} &&&&&& \text{\cref{prop:discrete_shape_gradient}}  \\
	&&& \text{\cref{pb:discr_shopt}} 
	\arrow["{\text{optimization}}"', from=3-4, to=2-7]
	\arrow["{\text{discretization}}", from=1-4, to=2-7]
	\arrow["{\text{optimization}}", from=2-1, to=1-4]
	\arrow["{\text{discretization}}"', from=2-1, to=3-4]
\end{tikzcd}\]


\end{obs}


Before studying how well the discrete gradient approximates the continuous gradient, we need some additional error bounds for the state discretization. This is not strictly necessary: we do so to relax the smoothness requirements on the deformation field $\delta \theta$ in the upcoming arguments. This however entails assuming stronger compatibility relations for the state equations. From the physical point of view, this is not an issue: the state equations, unlike the adjoint ones, coming from a physical process, should naturally satisfy such compatibility. 

The following proposition is proven in this section, applied to our concrete (state) equations. The proof also applies to the general case, of course, under suitable assumptions.

\begin{prop}[Another bound on the state discretization]
\label{prop:another_bound}
There holds, under \cref{ass:num_discr_shopt}, the following error estimates:

\begin{align*}
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}\lesssim h + \delta t
\end{align*}

\end{prop}

\begin{mproof}
We again apply a separation into semidiscretization in space, and then full discretization, and adopt the notation $u$ to represent either one of the two state variables.

\underline{Estimating $Q_h^k$ in the $L^2$ norm}

Going to the proof of \cref{prop:d_vd_sd}, let us bound $Q_h^k$ in the stronger $L^2$ norm. There holds (also see \cite{quarteroni}, page 388):

\begin{align*}
	Q_h^k = -\frac{1}{\delta t}\int_{I_k}(s-t^k)u''_h(s)ds
\end{align*}

From here, $\norm{Q_h^k}_{L^2(U_h)}^2\leq \delta t \norm{u_h''}_{L^2(I_k,{L^2(U_h)})}^2$, by an application of the Cauchy-Schwarz inequality. 

Therefore, $\delta t \sum_{k=0}^{K-1} \norm{Q_h^k}_{L^2(U_h)}^2\leq \delta t^2 \norm{u_h''}_{L^2(I,{L^2(U_h)})}^2$. The latter norm can be bounded uniformly on $h$, thanks to \cref{ass:num_discr_shopt} and the reasoning of \cref{thm:reg_time}. Note, we need here the stronger compatibility condition that $\delta_h'(0)$ is bounded in $H^1$, see \cref{prop:d_vd_sd} for the notation. In the current concrete case, $\delta_h'(0) = 0$ and this is thus not an issue.

\underline{Semidiscrete bound}

Consider \cref{eqn:discr_err}, where we remind that $e_h^k = u_h^k-u_h(t^k)$. We can test it by $\ds \frac{e_h^{k+1}-e_h^k}{\delta t}$ to obtain:

\begin{align*}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, \frac{e_{h}^{k+1}-e_h^k}{\delta t}\right)_{L^2(U_h)} + a_h \left (e_h^{k+1}, \frac{e_{h}^{k+1}-e_h^k}{\delta t} \right ) = \left ( Q_h^k,\frac{e_{h}^{k+1}-e_h^k}{\delta t}\right)_{L^2(U_h)}
\end{align*}

Hence, employing Young's and Cauchy-Schwarz' inequalities, we find:

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2 + \frac{1}{2\delta t}(\norm{\nabla e_h^{k+1}}^2_{L^2(U_h)} - \norm{\nabla e_h^k}^2_{L^2(U_h)})\leq  \norm{Q_h^k}_{L^2(U_h)} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}
\end{align*}

Because $e_h^0=0$ we get:

\begin{align*}
\delta t \sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2 \leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{L^2(U_h)}^2}\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2}
\end{align*}

This means that:

\begin{align*}
\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(U_h)}^2} \leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{L^2(U_h)}^2} \lesssim \delta t
\end{align*}

where we used the first part of the proof.

\underline{Fully discrete bound}

We have, denoting with $(\cdot)^l$ the lifting of finite element functions defined in \cref{prop:G_h}, and using \cref{prop:lift} itself:

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2\lesssim\\
	\delta t \sum_{k=0}^{K-1} \norm{\frac{e(t^{k+1})-e(t^k)}{\delta t}}_{L^2(U)}^2 +  \delta t \sum_{k=0}^{K-1} \norm{\frac{e_h^{k+1}-e_h^{k}}{\delta t}}_{L^2(U_h)}^2
\end{align*}

The second term on the right is $O(\delta t^2)$ by above, so that we need to concentrate only on the first one, where $e=u-u_h^l$. But by a suitable modification of Lemma 3.2 of \cite{lshou}, we can reason as follows:

\begin{align*}
\delta t \sum_{k=0}^{K-1} \norm{\frac{e(t^{k+1})-e(t^k)}{\delta t}}_{L^2(U)}^2 = \delta t \sum_{k=0}^{K-1} \norm{\frac{1}{\delta t}\int_{I_k}e'}_{L^2(U)}^2\lesssim \norm{e'}_{L^2(I,L^2(U))}^2\lesssim h^2
\end{align*}

by \cref{cor:L2_deriv_est} and \cref{ass:num_discr_shopt}.

\end{mproof}

\begin{thm}[Fully discrete estimate for shape gradients, implicit Euler case]
\label{thm:ie_shape_grad_est}
Let  $U$ be fixed and $U_h$ as in \cref{ass:num_discr_shopt}. The same assumption must hold. Let $\delta \te \in W^{1,\infty}(U)$ and $\delta \te_h$ be a vector valued finite element function of $S^1_h=S^1_h(U_h)$. There exists a constant $\gamma$ that depends on $U$, the shape regularity and quasi-uniformity of the meshes, independent of $h, \delta t$, such that, for $h,\delta t$ small enough, we have:

\begin{align*}
|dJ(	U)[\delta \te]-dJ_{h,\delta t}(U_h)[\delta \te_h]|\leq \gamma\left [ (h+\delta t)(\norm{\delta \te}_{W^{1,\infty}(U)}+\norm{\delta \te_h}_{W^{1,\infty}(U_h)}) + \norm{\delta \te - \delta \te_h^l}_{W^{1,\infty}(U)}\right ]
\end{align*}

where the notation $dJ(U)[\delta \te]:=dJ(\tau)[\delta \te\circ \tau]$, if $U=\tau(U_r)$, is to emphasize that the dependence on $\tau$ is not tracked.
Analogously $dJ_{h,\delta t}(U_h)[\delta \te]:=dJ_{h,\delta t}(\tau_h)[\delta \te_h\circ \tau]$, with $U_h = \tau_h(U_{r,h})$ and a suitable $\tau_h$ that(linearly) interpolates $\tau$ on the spatial discretization nodes.

\end{thm}
\begin{mproof}

\underline{Forewarning}

As we have already mentioned in \cref{obs:tau_vs_tau_h}, we consider $U, U_h$ to be frozen in our estimate, and we assume $U_h$ to be interpolating $U$, as in \cref{ass:num_discr_shopt}. For simplicity, we are also considering $\delta \theta$ and $\delta \theta_h$ to be defined on the moving domain. Therefore, the quantities to be compared become, after simplifying the notation, and employing \cref{prop:gateaux_diff} and \cref{prop:discrete_shape_gradient}:

\begin{align*}
	\delta t \sum_{k=1}^{K} \left (\frac{w_h^{k}-w_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) q_h^{k-1} \right )_{L^2(U_h)} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla w_h^k, \nabla q_h^{k-1})_{L^2(U_h)}+\\
	\delta t \sum_{k=1}^{K} \left (\frac{v_h^{k}-v_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) p_h^{k-1} \right )_{L^2(U_h)} + \delta t \sum_{k=1}^{K} (A'(\delta \theta_h) \nabla v_h^k, \nabla p_h^{k-1})_{L^2(U_h)}+\\
	\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h )\\
\end{align*}

and

\begin{align*}
	\int_I (w_t \dive(\delta \te), q)_{L^2(U)}+ \int_I (A'(\delta\te )\nabla v, \nabla p)_{L^2(U)}+\\
\int_I (v_t\dive(\delta \te), p)_{L^2(U)}+ \int_I (A'(\delta\te )\nabla w, \nabla q)_{L^2(U)}+\\
\frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te)
\end{align*}

To make a fair comparison we also need to have $\delta \te $ and $\delta \te_h$ to be somewhat related. We will discuss in the end some possible choices.

\underline{Splitting into pieces}

We separately bound the five pieces, which, if we again recover the notation $u, a$ to indicate a state and its correspondent adjoint (so, $u=v \iff a = p$ or $u=w \iff a = q$), means to find bounds just for the following three quantities:

\begin{align*}
	\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}  - \int_I (u_t , \dive(\delta \te) a)_{L^2(U)}
\end{align*}

\begin{align*}
	\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)}
\end{align*}

\begin{align*}
	\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te)
\end{align*}

\underline{Derivatives: rewriting}

Denote again by $\pi a = a(t^k)$ on $(t^k,t^{k+1})$. Then:

\begin{align*}
	\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}  - \int_I (u_t , \dive(\delta \te) a)_{L^2(U)} = \\
	\underbrace{- \int_I (u_t , \dive(\delta \te) (a -\pi a))_{L^2(U)}}_{\circled{1}}+ \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)} - \int_I (u_t , \dive(\delta \te) \pi a)_{L^2(U)}}_{\circled{R1}}
\end{align*}

Now:

\begin{align*}
	\circled{R1} = \delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)} - \delta t \sum_{k=1}^{K}\left (\frac{u(t^{k})-u(t^{k-1})}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}=\\
\underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u(t^{k})-u(t^{k-1})}{\delta t} -\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}}_{\circled{2}}+\\ \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te)  a(t^{k-1})\right )_{L^2(U)}}_{\circled{R2}} 
\end{align*}

Lastly:

\begin{align*}
	\circled{R2} = \underbrace{\delta t \sum_{k=1}^{K} \left (\frac{u_h^{k}-u_h^{k-1}}{\delta t}, \dive(\delta \theta_h ) a_h^{k-1} \right )_{L^2(U_h)}
		- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te_h^l)  a_h^{k-1,l}\right )_{L^2(U)} }_{\circled{3}}+ \\
	\underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , (\dive(\delta \te) - \dive(\delta \te_h^l)  )a_h^{k-1,l}\right )_{L^2(U)}}_{\circled{4}} + \\
	\underbrace{- \delta t \sum_{k=1}^{K}\left (\frac{u^{k,l}_h-u^{k-1,l}_h}{\delta t} , \dive(\delta \te) \left(a(t^{k-1})-a_h^{k-1,l}\right)\right )_{L^2(U)}}_{\circled{5}}
\end{align*}

\underline{Derivatives: estimation}

We start with $\circled{1},\circled{2},\circled{5}$.

We have, by the Cauchy-Schwarz inequality and \cref{lemma:pw_constant_appr}:

\begin{align*}
\left |\circled{1}\right|\leq \delta t \norm{\dive(\delta \te)}_{L^\infty(U)}\norm{u_t}_{L^2(I,L^2(U))}\norm{a'}_{L^2(I,L^2(U))}\lesssim \delta t \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

Then, using again the Cauchy-Schwarz inequality:

\begin{align*}
\left |\circled{2}\right|\leq \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t \sum_{k=0}^{K-1} \norm{a(t^k)}^2_{L^2(U)}}\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\frac{u(t^{k+1})-u(t^k)}{\delta t} - \frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}
\end{align*}

Employing \cref{prop:another_bound} at first, and \cref{lemma:pw_constant_appr} afterwards:

\begin{align*}
\left |\circled{2}\right|\lesssim (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\sum_{k=0}^{K-1} \int_{I_k}\norm{a(t^k)}^2_{L^2(U)}}\lesssim (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)} \norm{a'}_{L^2(I,L^2(U))}\lesssim  (h+\delta t) \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

Note, this is where we used \cref{prop:another_bound}. One could alternatively assume higher differentiability for $\theta$ and proceed with \cref{prop:o-t-d}.

Then:

\begin{align*}
	\left |\circled{5}\right|\leq  \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t\sum_{k=0}^{K-1} \norm{\frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}\sqrt{\delta t\sum_{k=0}^{K-1} \norm{a(t^{k})-a_h^{k,l}}_{L^2(U)}^2}
\end{align*}

Thanks to \cref{prop:d-t-o_estimates} we can write:

\begin{align*}
	\left |\circled{5}\right|\lesssim (h^2+\delta t)  \norm{\dive(\delta \te)}_{L^\infty(U)} \sqrt{\delta t\sum_{k=0}^{K-1} \norm{\frac{u_h^{k+1,l}-u_h^{k, l}}{\delta t}}_{L^2(U)}^2}
\end{align*}

Using \cref{prop:another_bound} and the last step of its proof:

\begin{align*}
	\left |\circled{5}\right|\lesssim (h^2+\delta t)  \norm{\dive(\delta \te)}_{L^\infty(U)}
\end{align*}

And with similar reasonings:
\begin{align*}
	\left |\circled{4}\right|\lesssim \norm{\dive(\delta \te) - \dive(\delta \te_h^l)}_{L^\infty(U)}
\end{align*}

Member $\circled{3}$ can be bound with the help of \cref{prop:lin_appr}.

\underline{Gradients: rewriting}

We have:

\begin{align*}
	\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)} = \\
	\underbrace{\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)}- \int_I (A'(\delta\te )\nabla\tilde{\pi}u, \nabla \pi a)_{L^2(U)}}_{\circled{R3}} + \\\underbrace{- \int_I (A'(\delta\te )\nabla u, \nabla (a-\pi a))_{L^2(U)}}_{\circled{6}}\underbrace{- \int_I (A'(\delta\te )\nabla (u - \tilde{\pi}u), \nabla \pi a)_{L^2(U)}}_{\circled{7}} 
\end{align*}

Continuing the splitting:

\begin{align*}
\circled{R3} = \delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla u(t^{k}) , \nabla a(t^{k-1}))_{L^2(U)} = \\
\underbrace{\delta t \sum_{k=1}^{K} (A'(\delta \theta_h ) \nabla u_h^k, \nabla a_h^{k-1})_{L^2(U_h)} - \delta t \sum_{k=1}^{K} (A'(\delta\te_h^l )\nabla u_h^{k,l} , \nabla a_h^{k-1,l})_{L^2(U)}}_{\circled{8}}+\\
- \underbrace{\delta t \sum_{k=1}^{K} ((A'(\delta \te) - A'(\delta\te_h^l ))\nabla u_h^{k,l} , \nabla a_h^{k-1,l})_{L^2(U)}}_{\circled{9}}+\\
- \underbrace{\delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla (u(t^{k})-u_h^{k,l}) , \nabla a(t^{k-1}))_{L^2(U)}}_{\circled{10}}+\\
- \underbrace{\delta t \sum_{k=1}^{K} (A'(\delta\te )\nabla u_h^{k,l} , \nabla (a(t^{k-1}) -a_h^{k-1,l}))_{L^2(U)}}_{\circled{11}}
\end{align*}
\underline{Gradients: estimation}

The terms $\circled{10}, \circled{11}$ can be estimated in a common way. We only need to make sure that $\ds \delta t \sum_{k=1}^{K} \norm{\nabla u_h^{k,l}}_{L^2(U)}^2 $ is bounded uniformly (true by \cref{prop:o-t-d}, \cref{lemma:pw_constant_appr} and the smoothness of $u$, ensured by \cref{ass:num_discr_shopt}), and also that $\ds \delta t \sum_{k=1}^{K} \norm{\nabla a(t^{k-1})}_{L^2(U)}^2$ is uniformly bounded (true by \cref{lemma:pw_constant_appr} and the smoothness of $a$, ensured by \cref{ass:num_discr_shopt}). Then an application of the Cauchy-Schwarz inequality, \cref{prop:d-t-o_estimates} and \cref{prop:o-t-d} yield:

\begin{align*}
	\left | \circled{10} \right |, \left |\circled{11}\right | \lesssim (h+\delta t) \norm{A'(\delta \te)}_{L^\infty(U)}
\end{align*}

Similarly:

\begin{align*}
	\left | \circled{9} \right | \lesssim (h+\delta t) \norm{A'(\delta \te_h^l)-A'(\delta \te)}_{L^\infty(U)}
\end{align*}

and the term $\circled{8}$ follows directly from \cref{prop:lin_appr}.

\underline{Cost functions: estimation}

We are missing a bound on: 

\begin{align*}
	\circled{J}:=\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te) = \\
	\underbrace{\frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{1}{2}\int_I\int_{U}\eta |v-w|^2\dive(\delta \te_h^l)}_{\circled{R4}}+\\
	-\underbrace{ \frac{1}{2}\int_I\int_{U}\eta |v-w|^2(\dive(\delta \te) - \dive(\delta \te_h^l))}_{\circled{12}}
\end{align*}

We find:

\begin{align*}
	\left | \circled{12} \right | \lesssim \norm{\dive(\delta \te) - \dive(\delta \te_h^l)}_{L^\infty(U)}
\end{align*}

whereas:

\begin{align*}
\circled{R4} =\underbrace{ \frac{\delta t}{2} \sum_{k=1}^{K} \int_{U_h} \eta(t^k)|v_h^k-w_h^k|^2  \dive(\delta \theta_h ) - \frac{\delta t}{2} \sum_{k=1}^{K}\int_{U} \eta(t^k) |v_h^{k,l}-w_h^{k,l}|^2\dive(\delta \te_h^l)}_{\circled{13}}+\\
\underbrace{\frac{\delta t}{2} \sum_{k=1}^{K}\int_{U} \eta(t^k) (|v_h^{k,l}-w_h^{k,l}|^2- |v(t^k)-w(t^k)|^2)\dive(\delta \te_h^l)}_{\circled{14}}+\\
\underbrace{\frac{1}{2}\int_I\int_{U}\tilde{\pi} \eta (|\tilde{\pi} v-\tilde{\pi} w|^2-|v-w|^2)\dive(\delta \te_h^l)}_{\circled{15}}+\\
\underbrace{\frac{1}{2}\int_I\int_{U}(\tilde{\pi} \eta - \eta) |v-w|^2\dive(\delta \te_h^l)}_{\circled{16}}
\end{align*}

For $\circled{16}$ we can use the fact that that $\norm{\eta -\tilde{\pi} \eta}_\infty\leq \delta t \norm{\eta'}_\infty$ to ensure that:

\begin{align*}
	\left | \circled{16} \right |\lesssim \delta t \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

Similarly, also by applying the Cauchy-Schwarz' inequality and \cref{lemma:pw_constant_appr}:

\begin{align*}
	\left | \circled{15} \right |\lesssim  \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)} (\norm{v-\tilde{\pi} v}_{L^2(I,L^2(U))}+\norm{w-\tilde{\pi} w}_{L^2(I,L^2(U))})\lesssim \delta t \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

The Cauchy-Schwarz' inequality also yields:
\begin{align*}
	\left | \circled{14} \right | \lesssim \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}(E_v+E_w)(S_v+S_w)
\end{align*}

where $\ds E_u = \sqrt{\delta t \sum_{k=1}^{K}\norm{u(t^k)-u_h^{k,l}}_{L^2(U)}^2}$ and $\ds S_u = \sqrt{\delta t \sum_{k=1}^{K}\norm{u(t^k)+u_h^{k,l}}_{L^2(U)}^2} $.

Through \cref{prop:o-t-d} we find $E_u \lesssim \delta t + h^2$, whereas \cref{prop:o-t-d} combined with \cref{lemma:pw_constant_appr} yield $S_u \lesssim 1$, so that:

\begin{align*}
	\left | \circled{14} \right | \lesssim (\delta t + h^2)\norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}


Similarly, and reasoning as in \cref{prop:lin_appr}, we can also see that:

\begin{align*}
	\left | \circled{13} \right | \lesssim h \norm{\dive(\delta \te_h^l)}_{L^\infty(U_h)}
\end{align*}

This concludes the proof.

\end{mproof}

Upon choosing $\delta \te = \delta \te_h^l$ we easily obtain the following corollary.

\begin{cor}

With the same hypothesis and notation of \cref{thm:ie_shape_grad_est}:

\begin{align*}
|dJ(	U)[\delta \te_h^l]-dJ_{h,\delta t}(U_h)[\delta \te_h]|\leq \gamma (h+\delta t)\norm{\delta \te_h}_{W^{1,\infty}(U_h)}
\end{align*}

\end{cor}

With this, similar estimates to those in \cite{paganini} were derived, in a slightly different context: in a time-dependent setting, and a precise handling of the geometry error. However, in \cite{paganini}, order $2$ estimates (in space) are obtained instead: this is because the deformation field $\delta \te$ is assumed to have an additional order of differentiability, so that certain duality techniques may be employed. Such a result doesn't fully explain why superconvergence happens in the context of just $W^{1,\infty}$ displacements. It is however a strong hint for the realization of such phenomenon, which is indeed observable in practice (see again the experiments in \cite{paganini}). In the next section we obtain similar superconvergence estimates, in our setting.


\section{Approximation of shape gradient, superconvergence for spatial semidiscretization}
\label{sec:superconv}

We now show that for smooth displacement fields $\delta \te$ that vanish in a neighbourhood of the fixed boundary, a superconvergence result for the shape gradient is available, in the spirit of \cite{paganini}. Such "compact support" assumption is not very strong in our setting: admissible displacements must already be zero at the fixed boundary, so as to yield a transformation that preserves $\Gamma_f$.

This result, in turn, is shown initially only for the spatial semidiscretization, which however suggests that such a result may be available also in the fully discrete case. We are able to give a positive answer for the implicit Euler scheme.

The difference with the estimates of \cite{paganini} lies in the fact that we are explicitly taking into account the geometry discrepancy $U \neq U_h$ (in the special case that $U_h$ interpolates $U$), apart from the time dependent setting we are in.

Such estimates, as noted in \cite{paganini}, don't seem to be so easily obtainable for displacements $\delta \te \in W^{1,\infty}$ only.

\textcolor{red}{Introduce and derive semidiscrete shape gradient}

\begin{thm}[Superconvergence result for shape gradients, spatially semidiscrete case]
\label{thm:superconvergence_sd}
Let $U$ be fixed and $U_h$ as in \cref{ass:num_discr_shopt}. Let \cref{ass:num_discr_shopt} itself hold, $\delta \te \in W^{2,\infty}(U)$, with $D\delta \te=0$ on the fixed boundary $\Gamma_f$. There exists a constant $\gamma$ that depends on $U$, the shape regularity and quasi-uniformity of the meshes, but independent of $h$, such that, for $h$ small enough, we have:

\begin{align*}
	\left |dJ(U)[\delta \te] - dJ_h(U_h)[\delta \te^{-l}] \right|\leq \gamma  h^2 \norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

where the notation for the shape gradients is analogous to that in \cref{thm:ie_shape_grad_est}.

\end{thm}

\begin{mproof}
The proof is similar to that of \cref{thm:ie_shape_grad_est}: we compare "derivative" terms, "gradient" terms and "cost function" terms, and use \cref{prop:lin_appr}, apart from the semidiscretization error estimates for the partial differential equations, to obtain an overall $O(h^2)$ term. We indicate $\delta \te^{-l}=:\delta \te_h$.

\underline{Derivatives}

We recover the notation $u\rightarrow$ generic state ($v$ or $w$), $a\rightarrow$ adjoint state of $u$.

We have:

\begin{align*}
	\int_I(u',a\dive(\delta \te))_{L^2(U)}-\int_I (u_h',a_h\dive(\delta \te_h))_{L^2(U_h)}=\\
	\underbrace{\int_I((u-u_h^l)',a\dive(\delta \te))_{L^2(U)}}_{\circled{1}}+\\
	\underbrace{\int_I((u_h')^l, (a-a_h^l)\dive(\delta \te))_{L^2(U)}}_{\circled{2}}+\\
	\underbrace{\int_I((u_h')^l, a_h^l\dive(\delta \te))_{L^2(U)}-\int_I (u_h',a_h\dive(\delta \te_h))_{L^2(U_h)}}_{\circled{3}}
\end{align*}

We apply \cref{cor:L2_deriv_est} to $\circled{1}$, a thing which we can do, as \cref{ass:num_discr_shopt} and by the reasonings of \cref{prop:o-t-d}, to obtain:

\begin{align*}
	\left | \circled{1} \right | \lesssim h^2\norm{\dive{\delta \theta}}_{L^\infty(U)}
\end{align*}

It is crucial here that $\te$ has two weak derivatives, so that $a\te$ is a test function, as required by \cref{cor:L2_deriv_est}. 

On the other hand, employing \cref{thm:semidiscrete_error_bound}, \cref{prop:lift} and suitable energy estimates to $u_h'$ (which are avaliable by \cref{ass:full_discr_smoothness}), we come as well to:

\begin{align*}
	\left | \circled{2} \right | \lesssim h^2\norm{\dive{\delta \theta}}_{L^\infty(U)}
\end{align*}

Employing \cref{prop:lin_appr}, and \cref{prop:lift}, we find:

\begin{align*}
	\left | \circled{3} \right |\lesssim  h^2 \norm{u_h'}_{L^2(I,H^1(U_h))}\norm{a_h}_{L^2(I,H^1(U_h))}\norm{\delta \te}_{W^{1,\infty}(U)} \lesssim  h^2 \norm{\delta \te}_{W^{1,\infty}(U)}
\end{align*}

\underline{Gradients}

We perform a suitable splitting:

\begin{align*}
	\int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)}-\int_I (A'(\delta\te_h )\nabla u_h, \nabla a_h)_{L^2(U_h)} = \\
	\underbrace{\int_I (A'(\delta\te )\nabla u, \nabla a)_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla u^{-l}, \nabla a^{-l})_{L^2(U_h)}}_{\circled{4}}+\\
	\underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla a_h^l)_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla (u_h - u^{-l}), \nabla a_h)_{L^2(U_h)}}_{\circled{5}}+\\
	\underbrace{\int_I (A'(\delta\te )\nabla u, \nabla (a_h^l-a))_{L^2(U)} - \int_I (A'(\delta\te_h )\nabla u^{-l}, \nabla (a_h-a^{-l}))_{L^2(U_h)}}_{\circled{6}}+\\
	- \underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla (a_h^l-a))_{L^2(U)}}_{\circled{7}}+\\
	- \underbrace{\int_I (A'(\delta\te )\nabla u, \nabla (a_h^l-a))_{L^2(U)}}_{\circled{8}}+\\
	- \underbrace{\int_I (A'(\delta\te )\nabla (u_h^l-u), \nabla a)_{L^2(U)}}_{\circled{9}}
\end{align*}

We refer directly to \cref{prop:lin_appr} to show that $\ds |\circled{4}|\lesssim h^2\norm{\delta \te}_{W^{1,\infty}(U)}$. We also obtain, by additionally invoking \cref{prop:lift} and suitable energy estimates:

\begin{align*}
	\left | \circled{5} \right |, \left | \circled{6} \right |\lesssim h \norm{\delta \te}_{W^{1,\infty}(U)} \norm{u_h^l-u}_{L^2(I,H^1(U))},  h \norm{\delta \te}_{W^{1,\infty}(U)} \norm{a_h^l-a}_{L^2(I,H^1(U))}\lesssim h^2 \norm{\delta \te}_{W^{1,\infty}(U)}
\end{align*}

having used \cref{thm:semidiscrete_error_bound} in the last step. The same \cref{thm:semidiscrete_error_bound} is sufficient to conclude the bound $\ds \left | \circled{7} \right | \lesssim h^2 \norm{\delta \te}_{W^{1,\infty}(U)}$. The remaining terms are treated in the same way, we thus focus on $\circled{9}$. Using integration by parts \cref{thm:ibp}, the assumption on $D\delta \te$ and the fact that $u, u^l_h=0$ on the moving boundary $\Gamma_m$, we obtain:

\begin{align*}
	\left |\circled{9} \right |= \left |\int_I(\dive(A'(\delta \te)\nabla a), u_h^l-u)_{L^2(U)}\right |\lesssim h^2 \norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

where we used again \cref{thm:semidiscrete_error_bound}.

\underline{Cost function}

There holds:

\begin{align*}
	\int_I \int_U \eta |v-w|^2 \dive(\delta \te) - \int_I \int_{U_h} \eta |v_h-w_h|^2\dive(\delta \te_h)=\\
	\int_I\int_U\eta((v-v_h^l)-(w-w_h^l))((v+v_h^l)-(w+w_h^l))\dive(\delta \te) + \int_I\int_U\eta(v_h^l-w_h^l)^2\dive(\delta \te)-\int_I\int_{U_h}\eta (v_h-w_h)^2\dive(\delta \te_h)
\end{align*}

The first term is $\lesssim h^2\norm{\delta \te}_{W^{1,\infty}(U)}$ thanks to the Cauchy-Schwarz inequality and \cref{thm:semidiscrete_error_bound}, the second one because of \cref{prop:lin_appr}. This concludes the proof.

\end{mproof}

As a corollary, we can derive the same result as in \cref{thm:ie_shape_grad_est}, but with a better order of convergence in space.

\begin{cor}[Fully discrete superconvergence result]
With the same assumptions and notation of \cref{thm:superconvergence_sd} and in the discretize-then-optimize framework of \cref{sec:d-t-o_IE}, we can conclude:  

\begin{align*}
	\left |dJ(U)[\delta \te] - dJ_{h,\delta t}(U_h)[\delta \te^{-l}] \right|\leq \gamma  (h^2 + \delta t)\norm{\delta \te}_{W^{2,\infty}(U)}
\end{align*}

\end{cor}
\begin{mproof}[Sketch of a proof]
The proof applies the same techniques as in \cref{thm:superconvergence_sd}, for what concerns the error committed by a time discretization.

The overall argument is overall more transparent: it amounts to inserting $dJ_h$ between $dJ$ and $dJ_{h,\delta t}$. Two pieces must then be estimated, and the first is exactly $O(h^2)$ by  \cref{thm:ie_shape_grad_est}.

The second one is $\ds dJ_h(U)[\delta \te^{-l}] - dJ_{h,\delta t}(U_h)[\delta \te^{-l}]$. Of this member, we give an appropriate splitting, where every piece is $O(\delta t)$ by the same arguments as in  \cref{thm:ie_shape_grad_est}. Let us recover the unified notation of \ref{pb:uni_state_adj}. Then:

\begin{align*}
	\int_I\int_{U_h}u_h'a_h\dive(\delta \te^{-l})-\delta t \sum_{k=1}^K \int_{U_h} \frac{u_h^k-u_h^{k-1}}{\delta t}a_h^k \dive(\delta \te^{-l})  =\\
	\int_I\int_{U_h}u_h'(a_h-\pi a_h)\dive(\delta \te^{-l})+\\
	\delta t \sum_{k=1}^K\int_{U_h}\frac{u_h(t^k)-u_h(t^{k-1})}{\delta t}(a_h(t^k)-a_h^k)\dive(\delta \te^{-l})+\\
	\delta t \sum_{k=1}^K \int_{U_h} \left (\frac{u_h(t^k)-u_h(t^{k-1})}{\delta t}-\frac{u_h^k-u_h^{k-1}}{\delta t}\right )a_h^k \dive(\delta \te^{-l})
\end{align*}

and:

\begin{align*}
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla u_h)\nabla a_h - \delta t \sum_{k=1}^K (A'(\delta \te^{-l})\nabla u_h^k)\nabla a_h^{k-1} =  \\
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla (u_h-\tilde{\pi} u_h)\nabla a_h + \\
	\int_I \int_{U_h} (A'(\delta \te^{-l})\nabla \tilde{\pi} u_h ) \nabla (a_h - \pi a_h) +\\
	\delta t \sum_{k=1}^K \int_{U_h} (A'(\delta \te^{-l})\nabla u_h(t^k) ) \nabla( a_h(t^{k-1})-a_h^{k-1}) +\\
	\delta t \sum_{k=1}^K \int_{U_h} (A'(\delta \te^{-l})\nabla (u_h(t^k)-u_h^k ) \nabla a_h^{k-1}
\end{align*}

Finally:

\begin{align*}
	\frac{1}{2} \int_I \int_{U_h} \eta |v_h-w_h|^2\dive(\delta \te^{-l}) - \frac{1}{2} \sum_{k=1}^K \int_{U_h}\eta(t^k)(v_h^k-w_h^k)^2\dive(\delta \te^{-l}) = \\
	\frac{1}{2} \int_I \int_{U_h} (\eta-\tilde{\pi}\eta) |v_h-w_h|^2\dive(\delta \te^{-l})+\\
	\frac{1}{2} \int_I \int_{U_h} \tilde{\pi} \eta (|v_h-w_h|^2 - |\tilde{\pi} v_h-\tilde{\pi}w_h|^2)\dive(\delta \te^{-l})+\\
	\frac{1}{2} \sum_{k=1}^K \int_{U_h}\eta(t^k)((v_h(t^k)-w_h(t^k))^2-(v_h^k-w_h^k)^2)\dive(\delta \te^{-l})
\end{align*}

Each of the pieces above is $O(\delta t)$, so that the conclusion follows.

\end{mproof}

\chapter{Implementation}
\label{chap:num_exp}

We now turn to discussing our implementation and to verifying some of the results that were previosly shown:

\begin{itemize}
	\item \cref{sec:implementation} is devoted to the illustration of the computer implementation of the shape optimization problem, \cref{pb:diri}
	\item in \cref{sec:experiments} some numerical experiments are reported, and the results are discussed and analyzed. We also verify the error estimates for the shape gradients
\end{itemize}

\section{Algorithmic set-up}
\label{sec:implementation}

We wrote our code in Python, making heavy use of the FEniCS package (\cite{fenics}). This is the main tool to simulate the partial differential equations. One of the reasons for choosing FEniCS is the compatibility with dolfin-adjoint, an automatic differentiation toolbox that "derives the discrete adjoint and tangent linear models from a forward model written in the Python interface to FEniCS" (see \cite{dolfin-adjoint_1}, \cite{dolfin-adjoint_2} and \cite{dolfin-adjoint_3}). That is, we only needed to code the "forward model" (cost functional and partial differential equations), and the gradients, that are exact on the discrete level, would be automatically derived for us by dolfin-adjoint. The correctness of the gradients was also checked through comparison with \cref{prop:discrete_shape_gradient} and through Taylor tests. In addition, for the shape optimization part, we made use of Moola, "a set of optimisation algorithms specifically designed for PDE-constrained optimisation problems" (see \href{https://github.com/funsim/moola}{here}). GMSH (\cite{gmsh}) was used for the meshing.

The shape identification problem \cref{pb:shid} lends itself very well to debugging and numerical experiments, as one can build analytical solutions and then analyize whether that is recovered by the optimization process. One can for instance artificially create the "optimal" inclusion $\Omega_e$ and come up with e.g. Neumann measurements $g$, simulate the heat equation for $w$ (see \cref{pb:pdes}) and then obtain the correct Dirichlet data $f$. Starting then from an initial guess for the inclusion and making use of $g,f$, optimization can be started: $\Omega_e$ should be recovered.

Before delving into more details, here is an overview of the different components of the shape optimization code:
\begin{enumerate}
	\item meshing the reference domain
	\item transforming the reference domain to the "optimal domain" $\Omega_e$
	\item simulating the heat equation on $\Omega_e$ with artificial Neumann data $g$, to obtain the synthetic Dirichlet data $f$
	\item running the optimization routines with $f,g$ as data
\end{enumerate}

Let us now discuss more thoroughly some of the above components.

\underline{Meshing}

We want to remark that in the meshing procedure, we started from a smooth shape modeled in GMSH, and then triangulated it into a mesh, whose boundary nodes lie on the boundary of the smooth shape, as is required in e.g. \cref{ass:num_discr_shopt} and \cref{chap:inh_fem}. Instead of choosing a base mesh and then performing (uniform) refinements on it, we loaded a sequence of meshes with increasingly finer mesh widths: after a uniform refinement, not all discrete boundary nodes need to be again on the smooth boundary. One would need to correct for this, and to do so, one would need to know a parametrization of the entire boundary. We avoided this, as we tried to use the least possible knowledge of the smooth boundary.

\begin{figure}[H]
\centering
\includegraphics[width=0.75\columnwidth]{Images/UniformRefinement.pdf}
\caption{Problems with uniform refinements}\label{fig:uniform_refinement}
\end{figure}

\underline{Star-shaped parametrization}

For simplicity, we assume that the computational domain can only undergo radial displacements of the form given in \cref{cor:star_shaped_transformation}. This is realized as follows. The reference domain is fixed to be a triangular meshing of $D\setminus \overline{B_\epsilon(0)}=:U_r$, which induces the space of linear finite elements $S^1_h$, as we have denoted it in e.g. \cref{chap:inh_fem}. Consider another meshing of the unit sphere $\mS$, potentially independent of the previous one, to allow some flexibility, inducing (surface) linear finite elements $B^1_{\tilde{h}}$. Our control, i.e. our optimization variable, will be a function $ q_{\tilde{h}} \in B^1_{\tilde{h}}$, and we would be solving:

\begin{align*}
	\min_{q_{\tilde{h}} \in B^1_{\tilde{h}}} J_{h,\delta t}(\tau_{\eps+q_{\tilde{h}}}) = J_{h,\delta t }(\id  + V_{q_{\tilde{h}}})
\end{align*}

with $V_{q_{\tilde{h}}}$ being the replacement vector field described in  \cref{cor:star_shaped_transformation}. The issue with this formulation is that  $V_{q_{\tilde{h}}}$ doesn't preserve the polygonal/polyhedral nature of the volume meshes. Therefore, we actually implement:

\begin{align*}
	\min_{q_{\tilde{h}} \in B^1_{\tilde{h}}}J_{h,\delta t }(\id  + I_h V_{q_{\tilde{h}}})
\end{align*}

where $I_h$ means Lagrange interpolation onto piecewise linears. The transformation $q_{\tilde{h}} \mapsto I_h V_{q_{\tilde{h}}}$ is implemented in a custom block in dolfin-adjoint.

\underline{Synthetic data}

As previously mentioned, to obtain the needed boundary data to perform shape optimization, we simulate the heat equation for $w$ on the exact computational domain $\Omega_{e,h}$. Because we are in a "volumetric" setting, we give the Neumann data and obtain the Dirichlet nodal values. The discrete Neumann trace need not to have an easy boundary expression, plus, we found the doing otherwise to be more complicated from a code point of view, at least with the tools at our disposal.

Using the same discretization parameters to generate the synthetic data, and then perform shape optimization, will result in committing an "inverse crime" (see \cite{wirgin}). To avoid this, there are two possibilities: either some noise is added to the synthetic data, or different computational models must be employed in synthesis and inversion/optimization. We experiment with both options, and in particular, for the second, we synthethize the data with a finer discretization than during the optimization process. We mention that in \cite{harbrecht}, synthesis and inversion are performed by solving integral equations of different kinds, but on the same discretization. The authors also add noise to the synthetic data.  

\underline{Finite elements}

We are adopting, as already mentioned, linear finite elements, for simplicity, but also computational efficiency. The framework of \cref{chap:inh_fem} can be however potentially adapted to accommodate isoparametric elements, see the works of e.g. \cite{edelmann}, \cite{elliott}, \cite{ranner}. Isoparametric elements elements are necessary, when adopting higher order basis functions, in order to preserve optimal accuracy (see section 4.4 of \cite{strang} for a discussion on this). The version of FEniCS we are using (2019.1) doesn't provide support for curved geometries, and the latest release FEniCSx is not yet interfaced with dolfin-adjoint. Alternatively, Firedrake could be employed, which has compatibility with dolfin-adjoint, although we felt it to be not flexible enough with the transfering of functions between non conforming meshes, something we needed to at several places throughout our code.

This in constrast to \cite{harbrecht}, where the authors employ order $2$ isoparametric elements (in the context of the boundary element method). This is a major difference with \cite{harbrecht}, quadratic boundary elements opposed to linear finite elements, in out case.

The motivation for this is that the analysis of \cite{paganini}, which we partially repeated in our setting, suggests that the volume form of the shape gradient is more accurate a boundary form. 

The main drawback of adopting a distributed setting is the added computational cost: the entire domain must be meshed, and the solution computed on interior nodes too.

\underline{Optimization}

As previously mentioned, we make use of the package Moola. This is because of its capabilities to natively handle optimization with respect to custom scalar products, and we found this to be especially important in our case, see \cref{sec:experiments} for a justification.

We mostly experimented with an L-BFGS algorithm, and with a modified Newton's method. We implemented the latter following the observations contained in \cite{eppler}, a work centered around a very similar shape optimization problem to ours, in an attempt to alleviate some spurious artifacts we observed, and attributed to the ill-posedness of the shape identification problem. We will soon discuss these in \cref{sec:experiments}.

With regards to the temporal weight (see \cref{sec:o-t-d} for details), we chose $\eta(t) = \exp\{-a/(t-T)^2\}$, with a suitable $a>0$ ($a=0.05$ in our runs). $\eta$ roughly looks like this:

\begin{figure}[H]
\centering
\includegraphics[width=0.5\columnwidth]{Images/Eta.pdf}
\caption{The temporal weight $\eta$}\label{fig:eta}
\end{figure}

\section{Experiments}
\label{sec:experiments}

\subsection{Shape optimization results}

For simplicity we work in two dimensions and with $D:=B_1(0)$, $\Omega_r = B_{0.5}(0)$, so that $U_r$ is an annulus centered at the origin.

\subsection{Estimates for the shape gradients}

\tred{hessian in L-BFGS}

\chapter{Conclusion}

\begin{appendices}

\appendix
\chapter{Functional spaces}
\section{Sobolev spaces}

\begin{thm}[Integration by parts]
\label{thm:ibp}
Let $\Omega$ be a bounded Lipschitz domain. Let $1<p<\infty$ and $f,g \in W^{1,p}(\Omega), W^{1,q}(\Omega)$, $q=p'$. Then:

$$\int_\Omega f \partial_i g = -\int_\Omega g \partial_i f+\int_{\partial \Omega} \tr u \nu_i d\pazocal{H}^{n-1}$$
\end{thm}
\begin{mproof}

This follows from \cite{leoni}, theorem 18.1 at page 592, where $g$ needs to be $C^1_c(\mR^n)$. But \cite{adams}, theorem 3.18 at page 54, says that (thanks to the smoothness of the boundary) the set of the restriction of such functions is dense in $W^{1,q}(\Omega)$, so that we can conclude by a density argument \textcolor{red}{\href{https://www.math.kit.edu/iana2/lehre/sobolevspaces2021s/media/lec15.pdf}{developed here}}.

\end{mproof}

\begin{lemma}
$f \in L^\infty(\Omega; \mR^N) \iff f_i \in L^\infty$, and two equivalent norms are $\norm{f}_a:=\norm{|f|}_\infty$, $\norm{f}_b:=\max_i\norm{f_i}_\infty$, for $|\cdot |$ any finite dimensional norm.
\end{lemma}
\begin{mproof}

We choose $|\cdot |=|\cdot|_1$.

Consider $f_n \in X_a = \{[f], f: \Omega \rightarrow \mR^n \text{ measurable }, \norm{f}_a\}$, Cauchy. Then every component is Cauchy in the scalar $L^\infty$, so that $f_n^i \rightarrow f^i $ in $L^\infty$. The limit $f$ is in $X_a$ because the functions $|f_i|$ are essentially bounded, and so is $|f|$. 

Then $\norm{f_n-f}_a\leq \norm{f_n-f_m}_a+\sum_i\norm{f_m^i-f^i}_\infty$ for all $n,m$. Choose $m\geq n$ with $\norm{f_m^i-f^i}\leq 1/(Nn)$ and conclude $X_a$ is Banach.

We know from \cite{leoni}, theorem B.88 at page 671, and page 669, we know that $X_b = \{[f], f: \Omega \rightarrow \mR^n \text{ measurable }, \norm{f}_b\}$ is Banach.

Moreover $X_a=X_b$ as sets, so that the thesis follows.


%We have that $\norm{f}_\infty = \sup_{\Omega\setminus X}f$ for all $X$ null sets on which $f \leq \norm{f}_\infty$ on $\Omega \setminus X$.
%
%In fact, that  $\norm{f}_\infty \geq \sup_{\Omega\setminus X}f$ is clear, whereas suppose there is $\epsilon >0$ with $\norm{f}_\infty -\epsilon \geq f$ on $\Omega \setminus X$. Then we contradict the definition of essential supremum and therefore $\norm{f}_\infty = \sup_{\Omega\setminus X}f$.
%
%Next up: for some $X,Y \subseteq \Omega$ of measure $0$, $f,g\leq \norm{f}_\infty, \norm{g}_\infty$ in $\Omega\setminus X, \Omega \setminus Y$, therefore, for some $N$ of null measure, $f,g\leq \norm{f}_\infty, \norm{g}_\infty$ in $\Omega \setminus N$. Therefore, $\norm{f}_\infty = \sup_{\Omega \setminus N}f, \norm{g}_\infty = \sup_{\Omega \setminus N}g$. 
%
%Therefore $ \max(\norm{f}_\infty, \norm{g}_\infty) = \max(\sup_{\Omega \setminus N}f,  \sup_{\Omega \setminus N}g) = \sup_{\Omega\setminus N}\max(f,g)$.
%
%So, $N$ is a null set and $\max(f,g)\leq \max(\norm{f}_\infty, \norm{g}_\infty)$, which by the reasoning of before.
%
%

\end{mproof}

\begin{prop}[Characterization of $W^{1,\infty}$]
\label{prop:lip}
Let $\Omega$ be a bounded Lipschitz domain, or $\mathbb{R}^n$. Then $W^{1,\infty}(\Omega) = C^{0,1}\cap L^\infty(\Omega)$.

This means that $u\in W^{1,\infty}(\Omega)$ if and only if $u$ has a (unique) representative that is bounded, Lipschitz continuous. Weak and classical derivatives coincide a.e.
\end{prop}
\begin{mproof}

%\underline{ACL characterization}
%
%Let $\Omega$ be just a domain.
%
%Consider a line $\gamma$ intersecting $\Omega$. Then, the intersection is a disjoint union of open segments $\gamma_i$. We say $u\in AC_\gamma(\Omega)$ if and only if $u$ is $AC[a,b]$ for every $[a,b]\cc\eta_i$ for all $i$, for almost all lines $\eta$ parallel to $\gamma$ and intersecting $\Omega$.
%
%We say $u \in ACL(\Omega)$ if $u$ is $AC_{e_i}(\Omega)$ for all coordinate axis $e_i$. We also call $BL(\Omega)$ the set of $u$ with a representative $\tilde{u}$, with $\tilde{u}\in ACL(\Omega), \tilde{u}, \nabla \tilde{u} \in L^\infty$, $\nabla u$ being the classical (a.e.) gradient.
%
%We have the following result (see \cite{kufner}, page 276, theorem 5.6.5.): $u \in W^{1,\infty}(\Omega)$ if and only if $u$ has a representative $\tilde{u} \in BL(\Omega)$. Classical and weak derivatives then coincide a.e..

\underline{Extension}

In the case $\Omega$ is bounded Lipschitz, then $\Omega$ is an extension domain for $W^{1,\infty}(\Omega)$, meaning that there is $E: W^{1,\infty}(\Omega)\rightarrow W^{1,\infty}(\mathbb{R}^n)$ linear bounded with $Eu=u$ a.e. on $\Omega$ (see \cite{leoni}, theorem 13.17 at page 425, 13.13 at page 424, and definition 9.57 at page 273).

\underline{The proof}

Let $u \in  W^{1,\infty}(\Omega)$. By \cite{leoni}, 11.50 at page 339, because $\Omega$ is an extension domain, we obtain that $u$ has a representative $\bar{u}$ that is bounded Lipschitz. Let $\phi \in C_c^\infty(\Omega)$. By The Kirszbraun theorem (see e.g. \cite{kirszbraun}), we can extend $\bar{u}$ to a Lipschitz function $e$ on $\mathbb{R}^n$. Then, for a large enough cube $Q$ containing $\Omega$, $\ds \int_\Omega\bar{u}\partial_i\phi = \int_Q e \partial_i \phi  = -\int_Q \partial_i e \phi $, by Fubini's theorem and integration by parts for AC functions.

Because $e=\bar{u}$	on $\Omega$, we conclude $\ds \int_\Omega\bar{u}\partial_i\phi =-\int_{\Omega} \partial_i \bar{u} \phi $, so that $\nabla \bar{u} = \nabla u$ almost everywhere.

Conversely, let $u$ be bounded Lipschitz. The above reasoning shows that $u$ has essentially bounded weak derivatives equal to the a.e. classical derivatives.

\end{mproof}

\begin{cor}[$W^{k,\infty}=C^{k,1}_B$]
\label{prop:lipk}
For a bounded Lipschitz domain $\Omega$, or for $\Omega = \mR^n$, then $W^{k,\infty}=C^{k,1}_B$ ($C^{k,1}$ bounded functions with bounded classical derivatives up to order $k+1$).
\end{cor}
\begin{mproof}

We have already proved the case $k=1$. We prove, for instance, the case $k=2$. Then, $u \in W^{k,2} \implies u, \partial_i u \in W^{k,1}$ (\cite{leoni}, 11.7 at page 321), so that by \cref{prop:lip}, we find bounded Lipschitz $h, g_i$ with $u=h$ a.e., $\partial_i u = \partial_i h$ a.e., $g_i = \partial_i u$ a.e..

Therefore $h$ is continuous, with continuous weak derivatives $g_i$, which implies that $h \in C^1(\Omega)$ (see \textcolor{red}{\href{https://math.stackexchange.com/questions/497708/is-a-continuous-function-with-continuous-weak-derivatives-of-class-c1}{here} and \href{https://math.stackexchange.com/questions/1787716/u-continuous-and-the-weak-derivative-du-continuous-rightarrow-u-in-c1}{here}}).

Now, $\partial_i h =g_i$ a.e., so everywhere, so that:

\begin{itemize}
\item $h$ is bounded Lipschitz and $C^1$
\item $\partial_i h$ are bounded Lipschitz
\end{itemize}

%Therefore, for $\phi \in C_c^\infty(\Omega)$ we get $\ds -\int_\Omega u \phi_{,i}\ds = \int_\Omega \partial_i u\phi =  \int_\Omega g_i \phi$.
%
%Pick a cube $Q = [-M,M]^n$, $\Omega \cc Q$. So, upon extending in a bounded Lipschitz manner $g_i$ to $G_i$ with $G_i(\partial Q)=0$ (see \cite{kirszbraun} and multiply by a suitable cut-off function), and $\phi$ to $0$, we get $\ds ...=\int_\Omega G_i \phi$. Call $h_i^x(t)=G_i(...,x_{i-1},t,x_{i+1},...)$ which is $AC[-M,M]$. Because $\eta_i^x(s):= \int_{-M}^s h_i^x(z)dz$ is $AC[-M,M]$ too because $h_i^x$ is bounded, and $h_i^x(t) =  \eta_i^{x'}(t)$. Employing then Fubini:
%
%\begin{align*}
%...= \int_{-M}^M... \int_{-M}^M \int_{-M}^M G_i(...,x_{i-1},x_i,x_{i+1},...)\phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n  \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M h_i^x(x_i) \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^{x'}(x_i)  \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= \int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^{x'}(x_i)  \phi dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= -\int_{-M}^M... \int_{-M}^M \int_{-M}^M \eta_i^x(x_i)  \phi_{,i} dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%=- \int_{-M}^M... \int_{-M}^M \int_{-M}^M \int_{-M}^{x_i} G_i(...,x_{i-1},z,x_{i+1},...) dz\phi_{,i} dx_i dx_1...dx_{i-1}dx_{i+1}...dx_n \\
%= -\int_Q k_i\phi_{,i}
%\end{align*}
%
%where in the last passage we have used again Fubini and the fact that 
%
%$$k_i(x):=\int_{-M}^{x_i} G_i(...,x_{i-1},z,x_{i+1},...) dz$$
%
% is measurable and bounded on $Q$.

\end{mproof}

\section{Bochner spaces}

Here are some useful results about Bochner spaces.

\begin{prop}[Bochner integral and bounded operators]
\label{prop:bochner_bound}
Let $X,Y$ be separable Banach, let $T \in L(X,T)$ be a linear bounded operator. For $f \in L^1(I,X)$ define $Tf (t):= T(f(t))$. Then $Tf \in L^1(I,Y)$ with $T\int_I f = \int_I Tf$.
\end{prop}
\begin{mproof}

First of all, a clarification on the definition. What is really happening is that from the time equivalence class $f$, we select a $g$, and then $Tf(t):=T(g(t))$. $Tf$ is then the equivalence class of $t\mapsto Tf(t)$. The definition is well posed, because $g_1(t)=g_2(t)\implies T(g_1(t))=T(g_2(t))$.

Let $f_n$ be simple, $f_n\rightarrow f $ a.e., with $\lim_n \int_I f_n = \int_I f$ and $\norm{f_n}_X \leq C \norm{f}_X$ (see page 6, and corollary 2.7 at page 8 of \cite{kreuter}).

\underline{Measurability}

For almost all $t$, $T(f_n(t)) \rightarrow T(f(t))=Tf(t)$ in $Y$, so that $Tf$ is measurable (strongly).

\underline{Integrability}

By the assumptions, $\norm{Tf_n}\leq \norm{T}\norm{f_n}\leq C\norm{f}\in L^1(I)$, so that by dominated convergence (corollary 2.6 of \cite{kreuter}) $Tf$ is integrable too. Thus $\int_T Tf = \lim_n \int_I  Tf_n = \lim_n T\int_I  f_n$, because $f_n$ is simple. And now, by the choice of $f_n$, $\int_T Tf = \lim_n T\int_I  f_n = T \lim_n \int_I  f_n = T \int_I f$.

\end{mproof}

\begin{prop}	[Derivations and bounded operators]
\label{lemma:bochner_Hk_map}
As before, let $X,Y$ be separable Banach, let $T \in L(X,T)$ be a linear bounded operator.

For $k\geq 0$, $f \in H^k(I,X)\implies Tf \in H^k(I,Y)$, with weak derivatives $\partial_{t^i}Tf = T\partial_{t^i}f$, $0\leq i \leq k$.

The map $f \mapsto Tf$, $H^k(I,X)\rightarrow H^k(I,Y)$ is linear, and bounded by $\norm{T}$.
\end{prop}
\begin{mproof}
The case $k=0$ is proved above.

We prove now that $\partial_{t^i}Tf = T\partial_{t^i}f$ for $i=1$. Note that $T\partial_t f \in L^2(I,Y)$, which qualifies as weak derivative.

In fact, for $\phi \in C_c^\infty(I)$, we have $\int_I \phi T\partial_i f = \int_I T(\phi\partial_t f) = T \int_I\phi\partial_t f = -T\int_I\phi'f=-\int_I\phi'Tf$.

Higher weak derivatives are treated analogously and the rest of the claims follow from the time stationarity of $T$ and by $\norm{\partial_{t^i}Tf}=\norm{T\partial_{t^i}f}\leq \norm{T}\norm{\partial_{t^i}f}$.

\end{mproof}

\begin{prop}[Continuous representatives]
\label{prop:cts_repr}
Let $X$ be separable Banach. $f \in L^1(I,X)$ has at most a continuous representative on $[0,T]$.
\end{prop}
\begin{mproof}
Assume there exists two such continuous representatives, so that we get a function $\delta: [0,T] \rightarrow X$ that is zero almost everywhere and continuous. Hence, $[0,T] \ni t \mapsto \norm{\delta(t)}$ is continuous in $\mR$ and zero a.e., so that it must be zero everywhere.
\end{mproof}

%\begin{prop}[Weak derivatives and Gelfand triples]
%\label{prop:sob_implies_W}
%Let $H\subseteq V$ be separable Hilbert spaces, $H$ densely embedded in $V$.
%
%Then $y \in L^2(I,V)\cap H^1(I,H) \subseteq W(I,V)$.
%\end{prop}
%\begin{mproof}
%We note that $V$ is Hilbert separable, so, reflexive Banach and separable, so that $V^*$ is separable too. Then, call $i$ the embedding $H \emb V^*$.
%
%For $\phi \in C^\infty_c(I)$ we obtain $\int_I i(y_t)\phi=\int_I i(y_t\phi)= i \left ( \int_I y_t\phi \right )$ by \cref{prop:bochner_bound}. Therefore $\int_I i(y_t)\phi=-i \left ( \int_I y\phi' \right ) =\int_I i(y)\phi'  $ , proving that $y \in W(I,V)$.
%
%\end{mproof}

We now check that a vector valued test function has weak derivatives of all orders.

\begin{prop}[Weak derivatives of test functions]
\label{prop:weak_class}
Let $\phi \in C^1([0,T],X)$, for $X$ separable Banach. It means that the limit of the difference quotients exists for all points of $I$, that $t\mapsto \phi(t), \phi'(t)$ are continuous, and that they can be continuously extended to $[0,T]$.

Then these classical derivatives coincide a.e. with the weak derivatives of $u$.

\end{prop}
\begin{mproof}


We rely on proposition 3.8 of \cite{kreuter} at page 26.

\underline{Absolute continuity}

Consider $\epsilon >0$. Divide $[a,b] \cc (0,T)$ into a uniform partition $t_i$. By theorem 6 at page 146 of \cite{mvt}, we get that $\ds \norm{\phi(t_i)-\phi(t_{i-1})}_X \leq (t_i-t_{i-1})\norm{\phi(\xi_i)}_X\leq (b-a) \norm{\phi'}_{\infty}/n$, and by choosing $n$ small enough, we conclude that $\phi$ is (locally) absolutely continuous.

\underline{Weak derivative}

Therefore, $\phi$ is locally $AC$, differentialble everywhere and $\phi'$ is bounded, so that $\phi \in H^1(I,X)$ and weak and classical derivatives coincide. 

\end{mproof}

And now, introduce a time dependent version of the trace operator which is useful for our computations.

\begin{defn}[Time dependent trace]
Let $\Omega$ be a bounded Lipschitz domain. For $k\geq 0$ we define $\tr: H^k(I,H^1(\Omega))\rightarrow H^k(I, H^{1/2} (\partial \Omega))$ by $\tr(u)(t):=\tr(u(t))$
\end{defn}

Below are some properties of this operator.

\begin{prop}[Properties of trace operator]
\label{prop:trace}
The trace operator just defined:
\begin{enumerate}
\item is well posed
\item is linear bounded
\item admits a linear bounded right inverse, for instance, $E(g)(t):=E(g(t))$ (for $E$ a right inverse of the static trace)
\item $\tr$ and $E$, in the case of $k \in \mathbb{N}_0$, coincide (in the time a.e. sense) for the case $l\geq k$
\item for $k\geq 1$, $\tr u(0)=0 \iff u(0)=0$ (in the sense of continuous representatives)
\item it coincides with the trace treated for instance in \cite{lions}
\end{enumerate}
\end{prop}
\begin{mproof}

\underline{Proof of the proposition}

We recall that the trace operator is bounded surjective onto $H^{1/2}(\partial \Omega)$, with a right inverse $E$ (see theorem 3.37 at page 102 of \cite{mclean}).

The first three points are consequences of this fact and of \cref{prop:bochner_bound}.

The fourth property follows by the definition of $\tr, E$ and the fact that $H^l\subseteq H^k$, for $k\leq l$.

Let now $k\geq 1$. We know that $H^1, H^{1/2}$ are separable and Banach (the latter is separable because the continuos image of $H^1$ separable, and Banach (see \cite{grisvard}, page 20). Therefore, by \cite{evans}, theorem 2 of page 286, we obtain the embeddings $H^k(I,H^1)\emb C([0,T],H^1)$ and the same goes for $H^k(I,H^{1/2})$. The embedding is $U$, the unique continuous representative of a certain time equivalence class (\cref{prop:cts_repr}). We also introduce brackets to indicate equivalence classes in time, so, $u = [Uu]$.

We want to prove $(Uu)(0)=0 \iff U(\tr u)(0)=0$. But we have $[t \mapsto U(\tr u )(t)]=tru:=[t \mapsto \tr((Uu)(t))]$. So, $U(\tr u )(t)=\tr((Uu)(t))$ for all $t\in[0,T]$ by continuity. 

For the last point, let $k=0$. We have:

\begin{enumerate}
\item $H^1(\Omega)\cap C^1(\overline{\Omega})$ is dense in $H^1(\Omega)$ (see \cite{adams}, theorem 3.18 at page 54, where being $\Omega$ bounded Lipschitz is important)
\item functions $\sum_{i\leq m} \phi_i(t)f_i$ for $\phi_i \in C_c^\infty(I), f_i \in H^1(\Omega)\cap C^1(\overline{\Omega})$ are dense in $L^2(I,H^1)$ (see \cite{hinze}, page 39, lemma 1.9)
\end{enumerate}

It follows by the third point that $C^1(\overline{\Omega\times I})$ is dense in $L^2(I,H^1)$, so that $u\mapsto u|_{I\times \partial \Omega}$ admits a unique extension by continuity to $L^2(I,H^1)$, so that this definition of trace coincides with the one from the literature in the case of the space $H^{1,0}:=L^2(I,H^1)$ (see \cite{lions}, theorem 4.1), we expand this argument below.

\underline{Proof of leftover facts}

We call $C^k(\overline{\Omega}):=\{u \in C^k(\Omega) \text{ with }\partial_\alpha f \text{ extendable by continuity to } \overline{\Omega} \}$. 

Consider $u(x,t):=\phi(t)v(x)$, for $\phi \in C^1([0,T]), v \in C^1(\overline{\Omega})$. Then, it has partial derivatives $u_t = \phi_t v, u_i = \phi u_i$. $u$ and all its partial derivatives are continuous on $I\times \Omega$, meaning that $u \in C^1(\Omega \times I)$.

Moreover, $u, u_i, u_t \in C([0,T], C(\overline{\Omega}))$. We claim $ C([0,T], C(\overline{\Omega})) = C(\overline{\Omega\times I})$. In fact, one direction is trivial, and so, let $f \in C([0,T], C(\overline{\Omega})) = C(\overline{\Omega})$. Fix $(t,x) \in \overline{\Omega\times I}$. Then, $|f(s,y)-f(t,x)|\leq |f(t,y)-f(t,x)|+|f(t,y)-f(s,y)|\leq  |f(t,y)-f(t,x)|+\norm{f(t, \cdot)-f(s,\cdot)}_{\infty}$. If now $s$ is close to $t$, and $y$ is close to $x$, then $|f(s,y)-f(t,x)|$ is small.

This shows $u, u_i, u_t \in C([0,T], C(\overline{\Omega})) \in C(\overline{\Omega\times I}) $, i.e. $u \in C^1(\overline{Q\times I})$.

To conclude, let $u \in L^2(I,H^1)$. Approximate $u$ by $u_k:=\sum_{i\leq m_k} \phi_i^k(t)f_i^k$ as in point 2, and approximate $f_i^k$ by suitable $g_i^k \in H^1(\Omega)\cap C^1(\overline{\Omega})$, to obtain $u_k:=\sum_{i\leq m_k} \phi_i^k(t)g_i^k$

Then $\norm{u-w_k}_{L^2(I,H^1)}\leq \norm{u_k-w_k}_{L^2(I,H^1)}+\norm{u_k-u}_{L^2(I,H^1)}$. We only need to estimate $ \norm{u_k-w_k}_{L^2(I,H^1)}\leq\ds  T \sum_{i\leq m_k} \norm{\phi_i^k}_\infty\norm{f_i^k-g_i^k}_{H^1}$. By the first point, $\norm{f_i^k-g_i^k}_{H^1}$ can be made as small as it is necessary to conclude.

\underline{Last remarks}

Again with reference to \cite{lions}, consider the anisotropic spaces $H^{r,s}:=L^2(I,H^r)\cap H^s(I,L^2)$. We restrict to the case $r = 1$, $s\geq 0$. Denote the traces $\tr_s$ defined in theorem 4.1, mapping $H^{1,s}(\Omega \times I)\rightarrow H^{1/2, s/2}(\partial \Omega \times I)$. For $\partial \Omega$ Lipschitz this theorem is still valid, as $1/2\leq 1$, see the discussion above lemma 2.4 in \cite{costabel}. As stated in \cite{lions}, $\tr_s$ is an extension of  $u\mapsto u|_{I\times \partial \Omega}$, defined on the dense suspace $C^\infty(\overline{Q\times I})$ of $H^{1,s}$ (that this space is dense can be proved as in lemma 2.22 of \cite{costabel}). So, let $C^\infty(\overline{Q\times I})\ni u_n \rightarrow_{H^{r,s}} u \in H^{1,s}$.
 
We have $\tr_s u_n = \tr_0 u_n$. Then, $u_n \rightarrow_{H^{1,s}} u$, $u_n \rightarrow_{H^{1,0}} u$, so that $\tr_s u_n \rightarrow_{H^{1/2,s/2}}\tr_s u$ (hence $\tr_0 u_n \rightarrow_{H^{1/2,0}}\tr_s u$) and $\tr_0 u_n  \rightarrow_{H^{1/2,0}} \tr_\sigma u$.

Thus $\tr_0 u = \tr_s u$.

Using what we derived before, we can conclude the characterization of the traces in the anisotropic settign define 

\end{mproof}

And now some sanity checks in the case of Gelfand triples. 

\begin{prop}[Sanity checks for Gelfand triples]
\label{prop:sanity}

Consider the following Gelfand triples (the diagram commutes):

\[\begin{tikzcd}
	{V} &&& {V^*} \\
	& H & {H^*} \\
	{W} &&& {W^*}
	\arrow["c", hook, from=3-1, to=1-1]
	\arrow["a", hook, from=1-1, to=2-2]
	\arrow["b"', hook, from=3-1, to=2-2]
	\arrow["{a^*}", hook, from=2-3, to=1-4]
	\arrow["r", from=2-2, to=2-3]
	\arrow["{b^*}"', hook, from=2-3, to=3-4]
	\arrow["{c^*}", hook, from=1-4, to=3-4]
\end{tikzcd}\]

Here $W\subseteq V \subseteq H$ are all separable Hilbert spaces, $a,b,c$ the trivial injections, $r$ the Riesz isomorphism of $H$. We denote by $i_V$ the Gelfand triple embedding $V\emb V^*$, so, $i_V=a^*ra$.

Then:

\begin{enumerate}
	\item $H^1(I,V)\subseteq W(I,V)$ with continuous embedding. The $W(I,V)$ derivative of $u \in H^1(I,V)$ is $i_V u_t$.
	\item for $u \in W(I,W)$ with $(i_W u)'\in L^2(I,H)$ (i.e. $(i_W u)_t = b^*r h$ for $h$ in $L^2(I,H)$) we obtain $u \in W(I,V)$ (i.e. $cu \in W(I,V)$), with derivative $(i_V cu)'=a^*r h$, so that also $(i_V cu)' \in L^2(I,H)$. It also holds $(i_V cu)'|_W = (i_W u)'$. $h$ is also the weak derivative $L^2(I,H)$ of $bu$.
	\item let $u, v \in W(I,V)$ with $u-v \in W$. Then $u-v \in W(I,W)$ with derivative $(i_W(u-v))'=(i_V u)'|_W-(i_V v)'|_W$.
\end{enumerate}

\end{prop}
\begin{mproof}

We use several times that time integrals and bounded linear static operators commute, see \cref{prop:bochner_bound}. $\phi$ denotes $\phi \in C^\infty_c(I)$.

\underline{First point}

We need to check that $a^* r a u \in H^1(I, V^*)$. This follows from \cref{lemma:bochner_Hk_map}, so that $(a^* r a u)_t = a^* r a u_t$.

\underline{Second point}

At first we claim that $h$ is a weak derivative of $bu \in L^2(I,H)$. In fact, $b^* r \int_I bu \phi' = \int_I (i_W u)\phi' = \ind{\mind{u \in W(I,W)}} =-\int_I(i_Wu)'\phi=-\int_I b^*r h\phi = b^*r (-\int_I h \phi)$. By density (definition of Gelfand triple), $b^*$ is injective, $r$ is too, and thus $\int_I bu \phi' = -\int_I h \phi$, which shows that $bu$ has weak derivative $h$, in the $H^1(I,H)$ sense.

And now $\int_I i_V c u \phi'= \int_I a^*racu \phi' = a^*r\int_I bu\phi' = \ind{by what we just proved}=-a^*r \int_I h \phi$, proving that $(i_V cu)'=a^*r h$.

Morevoer $(i_V cu)'|_W = c^*a^*r h=b^*rh=\ind{assumption} = (i_W u)'$.

\underline{Third point}

We check the derivative. We have $\int_i i_W(u-v)\phi' =\ind{\mind{u-v \in W\subseteq V}} = \int_I b^* r a (u-v) = c^*\int_I(i_Vu - i_Vv)\phi' = -\int c^*((i_V u)'- (i_V v)')\phi$.

\end{mproof}

\subsection{Some approximation properties}

\begin{lemma}[Piecewise constant approximation]
\label{lemma:pw_constant_appr}
Let $X$ be a separable Banach space, and $u \in H^1(I,X)$. Discretize $I$ into uniform subintervals $I_k:=[t^k,t^{k+1}]$ of width $\delta t$. Call $\pi u \in L^2(I,X)$ the function $\pi u(t)=u(t^{k})$, for $t \in (t^k,t^{k+1})$.

Then, $\norm{u-\pi u}_{L^2(I,X)}\leq C \delta t \norm{u'}_{L^2(I,X)}$, for $C=1/\sqrt{2}$.


The same holds for $\tilde{\pi}u(t) = u(t^{k+1})$ for $t \in (t^k,t^{k+1})$.

\end{lemma}

\begin{mproof}
There holds $\ds \int_{I_k}\norm{\pi u - u(t)}_X^2 dt = \int_{I_k} \norm{\int_{t^k}^{t} u'(s)ds}_X^2 dt\leq \int_{I_k}\left ( \int_{t^k}^{t} \norm{u'(s)}_X ds \right )^2 dt$. 

By Hölder's inequality we then see that $ \ds \int_{I_k}\norm{\pi u - u(t)}_X^2 dt \leq  \int_{I_k} \norm{u'(s)}_X^2 ds  \int_{I_k}(t-t^k)dt = \frac{\delta t ^2}{2} \norm{u'}_{L^2(I_k,X)}^2$. The result follows after summation.
\end{mproof}

\chapter{Parabolic equations}
\label{chap:parab_eq}

\section{Abstract theory}

\begin{ass}[Basic assumption for parabolic problems]
\label{ass:basic_par}

Let $V\subseteq H$ be real separable Hilbert spaces, $V$ dense in $H$. Then $H\hookrightarrow V^*$ is also dense, as stated in \cite{trol} at page 147. This embedding is $H \ni f \mapsto (f, \cdot )_H$. We thus obtain a Gelfand triple, and we have $W(I,V)\subseteq C(I,H)$.

Let $A:V\rightarrow V^* $ be linear bounded, $u \in W(I;V)$, $f \in L^2(I,V^*)$ and $u_0 \in H$.

We also assume that $\langle Av, v \rangle_{V^*,V}+ \lambda \HN{v}^2\geq \alpha \VN{v}^2$ for $\lambda \geq 0, \alpha >0$.
\end{ass}

We are interested in the following problem:

\begin{pb}[Abstract parabolic equation]
\label{eqn:general_parabolic}
\begin{align}
	u_t+Au=f \text{ in }V^* \text{ and for a.e. } t \in (0,T)\\
	u(0)=u_0
\end{align}
\end{pb}

\begin{thm}[Basic well posedness of \cref{eqn:general_parabolic}]
\label{thm:well_pos_parabolic}
Under \cref{ass:basic_par}, \cref{eqn:general_parabolic} has a unique solution $u$. Moreover $u$ satisfies the energy estimate:
\begin{equation}
	\label{eqn:en_est}
	\norm{u}_{W(I,V)} + \norm{u}_{C([0,T],H)}\leq c(\lambda, \alpha, \VSN{A}, T)(\HN{u_0}+\norm{f}_{L^2(I,V^*)})
\end{equation} 
\end{thm}
\begin{mproof}
See \cite{gilardi} at page 19, theorem 26.
\end{mproof}

We can also obtain additional regularity. Here are further assumptions to make this possible.

\begin{ass}[Assumptions for additional regularity]
\label{ass:reg_par}
We assume $u_0 \in V$, $f = f_1+f_2 \in L^2(I,H)+H^1(I,V^*)$. We also need $A$ to be symmetric (i.e. $\langle Au,v \rangle_{V^*,V} = \langle Av,u \rangle_{V^*,V}$).
\end{ass}

\begin{thm}[Regularity of time derivative]
\label{thm:reg_time}
Suppose \cref{ass:basic_par} and \cref{ass:reg_par}. Then $u_t \in L^2(I, H)$ with the estimate:
\begin{align}
	\norm{u}_{W(I,V)} + \norm{u}_{C(I,H)} + \norm{u_t}_{L^2(I,H)} \leq\\ c(\lambda, \alpha, \VSN{A}, T)(\VN{u_0}+\norm{f_1}_{L^2(I,H)} + \norm{f_2}_{H^1(I,V^*)})
\end{align}

That $u_t \in L^2(I, H)$ means precisely that there is $h \in L^2(I,H)$ with $a^* r h = (i_V u)'$, with the notation introduced in \cref{prop:sanity}.

\end{thm}
\begin{mproof}
We refer to page 26 of \cite{gilardi}, theorem 28, and only prove the necessary modifications.

\underline{Product rule for $A$}

We have 

\begin{align*}
\int_0^t \langle Au_n,u_n' \rangle_{V^*,V} = \sum_{k,l\leq n} \langle Aw^n_k,w^n_l \rangle_{V^*,V} \int_0^t g_k^n g_l^{n '} = \\
\sum_{k,l\leq n} \langle Aw^n_k,w^n_l \rangle_{V^*,V} \left (-\int_0^t g_k^{n'} g_l^n + g_k^n(t) g_l^n(t)-g_k^n(0) g_l^n(0) \right )
\end{align*}

By linearity at first and then symmetry we get:

\begin{align*}
	= \langle Au_n,u_n \rangle_{V^*,V}(t)-\langle Au_n,u_n \rangle_{V^*,V}(0)-\int_0^t\langle Au_n',u_n \rangle_{V^*,V}=\\
	= \langle Au_n,u_n \rangle_{V^*,V}(t)-\langle Au_n,u_n \rangle_{V^*,V}(0)-\int_0^t\langle Au_n,u_n' \rangle_{V^*,V}
\end{align*}

so that:

\begin{align*}
	\int_0^t \langle Au_n,u_n' \rangle_{V^*,V} = \frac{1}{2}\left( \langle Au_n,u_n \rangle_{V^*,V}(t)-\langle Au_n,u_n' \rangle_{V^*,V}(0) \right )
\end{align*}

\underline{Estimate for right hand side}

We have:

\begin{align*}
	\int_0^t \langle f_2,u_n' \rangle_{V^*,V} = \sum_{k\leq n}\int_0^tg_k^{n'}\langle f_2,w_k^n \rangle_{V^*,V}
\end{align*}

By the smoothness of $f_2$ we have that $t \mapsto \langle f_2(t),w_k^n \rangle_{V^*,V}$ is $H^1(0,T)$, in particular $AC[0,t]$, so that we can integrate by parts:

\begin{align*}
	 = - \sum_{k\leq n}\int_0^tg_k^{n}\langle f_2',w_k^n \rangle_{V^*,V} + \sum_{k\leq n} g_k^{n}(t)\langle f_2(t),w_k^n \rangle_{V^*,V} - \sum_{k\leq n} g_k^{n}(0)\langle f_2(0),w_k^n \rangle_{V^*,V} = \\
	 -\int_0^t \langle f_2',u_n \rangle_{V^*,V} + \langle f_2,u_n \rangle_{V^*,V}(t)-\langle f_2,u_n \rangle_{V^*,V}(0)
\end{align*}

Here we have used \cref{lemma:bochner_Hk_map} to take the derivative inside the bracket.

Note that by the smoothness of $f_2$, we can write, for instance, $\langle f_2,u_n \rangle_{V^*,V}(0) = \langle f_2(0),u_n \rangle_{V^*,V}$.

\tred{NB: here I need $f_2(0) \in V$ probably, but I'm not yet using the compatibility condition!}.

Going to the absolute values:

\begin{align*}
	\left | \int_0^t \langle f_2,u_n' \rangle_{V^*,V}\right | \leq 
	\int_0^T |\langle f_2',u_n \rangle_{V^*,V}|+ \VSN{f_2(t)}\VN{u_n(t)}+\VSN{f_2(0)}\VN{u_n(0)} \leq \\
	\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{\alpha}{4}\VN{u_n(t)}^2 +\\
	+ \frac{4}{\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+ \frac{1}{2}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1}{2}\VN{u_{n0}}^2
\end{align*}

Now, $u_n$ converges weakly in $L^2(I,V)$ by estimate (59) of \cite{gilardi} and thus $\frac{1}{2}\norm{u_n}_{L^2(I,V)}$ is bounded. The term $\frac{\alpha}{4}\VN{u_n(t)}$ can be pulled to the left hand side, $u_{0n}$ is $V$ convergent hence bounded. Therefore as in \cite{gilardi} we are able to conclude that $u_n'$ is bounded in $L^2(I,H)$. We want to conclude $u_t \in L^2(I,H)$. We know for sure that $\langle u_m',w_j\rangle_{V^*,V}=\langle f-Au_m,w_j\rangle_{V^*,V}$, so that muliplication by a test function and integration yields $\int_I \langle u_m',w_j\phi\rangle_{V^*,V}=\int_I \langle f-Au_m,w_j\phi\rangle_{V^*,V}$. Because $u_m\rightharpoonup u$ in $L^2(I,V)$ we observe that, by \cref{prop:bochner_bound} applied on $A \in L(V,V^*)$, it holds $\int_I \langle u_m',w_j\phi\rangle_{V^*,V}\rightarrow \int_I \langle u',w_j\phi\rangle_{V^*,V}$.

What's more, is that $u_m' \rightharpoonup h$ in $L^2(I,H)$, so that $\int_I \langle h ,w_j\rangle_{V^*,V}\phi = \int_I \langle u',w_j\rangle_{V^*,V}\phi$. It means that for almost all $t$, $\langle h ,w_j\rangle_{V^*,V} = \langle u',w_j\rangle_{V^*,V}$. And now we can really say that $u' \in L^2(I,H)$, which even more precisely means $(i_Vu)' = a^* r h$ almost everywhere.

We also obtain that $u_t$ is bounded by $c(\alpha)(\norm{f_2}_{L^\infty(I,V^*)}+\norm{f_2}_{L^2(I,V^*)}+\VN{u_0}+\norm{u}_{L^2(I,V)})$.

Note that, by \cite{evans}, theorem 2 of page 286, we can estimate $\norm{f_2}_{L^\infty(I,V^*)}$ by $c(T)\norm{f_2}_{H^1(I,V^*)}$, so that the claim for the time derivative $u_t$ is proven.

\end{mproof}

For the case where $H=L^2$, $H^1\supseteq V\supseteq H^1_0$,  $f_2|_{H^1_0}=0$ we have even more regularity available.

\begin{thm}[Additional regularity]
\label{thm:par_reg}
Suppose \cref{ass:basic_par} and \cref{ass:reg_par}. 

Let additionally $H=L^2$, $H^1\supseteq V\supseteq H^1_0$,  $f_2|_{H^1_0}=0$. Then $Au|_{H^1_0}$ extends to $\overline{Au_{H^1_0}} \in L^2(I,H)$ with:
\begin{align}
	\norm{u}_{W(I,V)} + \norm{u}_{C([0,T],H)} + \norm{u_t}_{L^2(I,H)} +\norm{\overline{Au|_{H^1_0}}}_{L^2(I,H)}\leq\\ c(\lambda, \alpha, \VSN{A}, T)(\VN{u_0}+\norm{f_1}_{L^2(I,H)} + \norm{f_2}_{H^1(I,V^*)})
\end{align}

Moreover $u_t+\overline{Au_{H^1_0}}=f_1$ in $L^2(0,T,L^2)\cong L^2(Q)$ and $\overline{Au|_{H^1_0}}=Au$ on $H^1_0$.

\end{thm}
\begin{mproof}

For $v \in H^1_0$ we get $ \langle Au,v \rangle_{V^*,V} =  \langle f_1-u_t,v \rangle_{V^*,V} = ( f_1-u_t,v )_H$, for almost all $t \in (0,T)$. From here we conclude that $Au(t)$ extends for a.a. $t$ to an element of $H$ with $(\overline{Au}-f_1+u_t,v)_{L^2}=0$ for all $v \in H^1_0$, almost all $t$. By density, $\overline{Au}-f_1+u_t=0$ in $H$ for almost all $t$, so that $\overline{Au}=f_1-u_t$ in $L^2(0,T,L^2)\cong L^2(Q)$.

This isometric isomorphism is stated in \cite{trol}, page 144. 

\end{mproof}

For our applications we also need to track the constants more precisely, which is accomplished in the next proposition.

\begin{prop}[Tracking the costants]
\label{thm:const_track}
With \cref{ass:basic_par} there holds:
\begin{align}
\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq \exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})\\
\norm{u'}_{L^2(I,V^*)}\leq \norm{A}_{L(V,V^*)}\alpha^{-1/2}\sqrt{\exp(2\lambda T)}\HN{u_0} +\\\left (\norm{A}_{L(V,V^*)}\alpha^{-1}\sqrt{\exp(2\lambda T)}+1\right ) \norm{f}_{L^2(I,V^*)}
\end{align}

With additionally \cref{ass:reg_par} we obtain:

\begin{align}
C\norm{u'}^2_{L^2(I,H)}\leq 
(1+(1+C_0)\alpha^{-1})\norm{f_2}_{H^1(I,V^*)}^2+\\
(1+\norm{A}_{L(V,V^*)})\VN{u_{0}}^2+C_0\HN{u_0}^2+\\
\norm{f_1}_{L^2(I,H)}^2+C_0\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}
\end{align}

with $C>0$ a number independent of the problem.

Here $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$.

\end{prop}
\begin{mproof}

\underline{No regularity}

From page 21 of \cite{gilardi} we obtain that $\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq \exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})$. \textcolor{red}{NOTA BENE, this is slightly wrong, i.e. a 2 is missing from the left hand side}.

In particular, $\sqrt{\alpha}\norm{u}_{L^2(I,V)}\leq 	\sqrt{\exp(2\lambda T)}(\HN{u_0}+\alpha^{-1/2}\norm{f}_{L^2(I,V^*)})$, or $\norm{u}_{L^2(I,V)}\leq 	\alpha^{-1/2}\sqrt{\exp(2\lambda T)}(\HN{u_0}+\alpha^{-1/2}\norm{f}_{L^2(I,V^*)})$.

Moreover $\norm{u'}_{L^2(I,V^*)}\leq \norm{Au}_{L^2(I,V^*)}+\norm{f}_{L^2(I,V^*)}\leq \norm{A}\norm{u}_{L^2(I,V)}+\norm{f}_{L^2(I,V^*)}$.

All in all, we obtain:

$$\norm{u}^2_{C([0;T],H)}+\alpha\norm{u}_{L^2(I,V)}^2\leq \exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f}^2_{L^2(I,V^*)})$$

and:

$$\norm{u'}_{L^2(I,V^*)}\leq \norm{A}_{L(V,V^*)}	\alpha^{-1/2}\sqrt{\exp(2\lambda T)}(\HN{u_0}+\alpha^{-1/2}\norm{f}_{L^2(I,V^*)})+\norm{f}_{L^2(I,V^*)}$$

\underline{More regularity}

We tie back to page 25 of \cite{gilardi}. In particular:

\begin{align*}
\int_0^t\HN{u_n'}^2+\int_0^t\langle A u_n, u_n'\rangle_{V^*,V}=\int_0^t(f_1,u_n')_H+\int_0^t \langle f_2, u_n'\rangle_{V^*,V}
\end{align*}

%Now, taking $u_{n0}$ to be the orthogonal projection of $u_0$ onto $V_n$ with the scalar product of $V$, we can assume $\VN{u_{n0}}\leq\VN{u_0}$.

Then:
\begin{align*}
\int_0^t\langle A u_n, u_n'\rangle_{V^*,V}\geq \frac{\alpha}{2}\VN{u_n(t)}^2-\frac{\lambda}{2}\HN{u_n(t)}^2-\frac{\norm{A}}{2}\VN{u_{n0}}
\end{align*}

whereas, as in the proof of \cref{thm:reg_time}:
\begin{align*}
	\left | \int_0^t \langle f_2,u_n' \rangle_{V^*,V}\right | \leq
	\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{\alpha}{4}\VN{u_n(t)}^2 +\\
	+ \frac{4}{\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+ \frac{1}{2}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1}{2}\VN{u_{n0}}^2
\end{align*}

Also:
\begin{align*}
\int_0^t(f_1,u_n')_H\leq \frac{1}{2}\norm{f_1}_{L^2(I,H)}^2+\frac{1}{2}\int_0^t\HN{u_n'}^2
\end{align*}

Putting all together:

\begin{align*}
\int_0^t\HN{u_n'}^2+\frac{\alpha}{2}\VN{u_n(t)}^2-\frac{\lambda}{2}\HN{u_n(t)}^2-\frac{\norm{A}}{2}\VN{u_{n0}} \\
\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{\alpha}{4}\VN{u_n(t)}^2 +\\
+ \frac{4}{\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+ \frac{1}{2}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1}{2}\VN{u_{n0}}^2+\\
+ \frac{1}{2}\norm{f_1}_{L^2(I,H)}^2+\frac{1}{2}\int_0^t\HN{u_n'}^2
\end{align*}

which brings us to:

\begin{align}
\label{eqn:weak_der_bound}
\frac{1}{2}\int_0^t\HN{u_n'}^2+\frac{\alpha}{4}\VN{u_n(t)}^2-\frac{\lambda}{2}\HN{u_n(t)}^2\leq \\
\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 +\\
+ \frac{8+\alpha}{2\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1+\norm{A}}{2}\VN{u_{n0}}^2+\\
+\frac{1}{2}\norm{f_1}_{L^2(I,H)}^2
\end{align}

and thus, because norms are lower semicontinuous and because we have weak convergence of the time derivative, and $V$-strong convergence of the initial data:

\begin{align*}
\frac{1}{2}\int_0^T\HN{u'}^2\leq 
\frac{1}{2}\norm{f_2'}_{L^2(I,V^*)}^2 
+ \frac{8+\alpha}{2\alpha}\norm{f_2}_{L^\infty(I,V^*)}^2+\frac{1+\norm{A}}{2}\VN{u_{0}}^2+
\frac{1}{2}\norm{f_1}_{L^2(I,H)}^2+\\
\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )
\end{align*}

Using a purely numeric constant $C$  without dependences on the problem we can write:

\begin{align*}
\int_0^T\HN{u'}^2\leq 
\norm{f_2'}_{L^2(I,V^*)}^2+C(1+\alpha^{-1})\norm{f_2}_{L^\infty(I,V^*)}^2+C(1+\norm{A})\VN{u_{0}}^2+\norm{f_1}_{L^2(I,H)}^2+\\
C\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )
\end{align*}


For the last term, employing the exact argument as in the first part of the proof:

\begin{align}
\label{eqn:limsup}
\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )\leq\\
2^{-1}\max(1,\lambda)\max(1,\alpha^{-1}) \text{limsup}_n \left ( \norm{u_n}_{C([0,T],H)}^2 + {\alpha}\norm{u_n}_{L^2(I,V)}^2 \right )\leq\\
2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)(\HN{u_0}^2+\alpha^{-1}\norm{f_1+f_2}^2_{L^2(I,V^*)}) \leq \\
2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)(\HN{u_0}^2+2\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}+2\alpha^{-1}\norm{f_2}^2_{L^2(I,V^*)}) \leq \\
C C_0(\HN{u_0}^2+\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}+\alpha^{-1}\norm{f_2}^2_{L^2(I,V^*)})
\end{align}


where $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$ and $C$ is a purely numeric constant without dependences on the problem.

Therefore:

\begin{align*}
C\int_0^T\HN{u'}^2\leq 
\norm{f_2'}_{L^2(I,V^*)}^2+(1+\alpha^{-1})\norm{f_2}_{L^\infty(I,V^*)}^2+(1+\norm{A})\VN{u_{0}}^2+\norm{f_1}_{L^2(I,H)}^2+\\
C_0(\HN{u_0}^2+\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}+\alpha^{-1}\norm{f_2}^2_{L^2(I,V^*)})
\end{align*}


The embedding $H^1(I,V^*)\emb C([0,T],V^*)$ has norm that only depends on $T$, which follows from the equality $f_2(t)=f_2(s)+\int_s^tf_2'$, for $0\leq s \leq t \leq T$, a bound being $1+T$.

Thus:

\begin{align*}
C\int_0^T\HN{u'}^2\leq 
(1+(1+C_0)\alpha^{-1})\norm{f_2}_{H^1(I,V^*)}^2+\\
(1+\norm{A})\VN{u_{0}}^2+C_0\HN{u_0}^2+\\
\norm{f_1}_{L^2(I,H)}^2+C_0\alpha^{-1}\norm{f_1}^2_{L^2(I,V^*)}
\end{align*}


\end{mproof}


Proving higher time regularity under additional compatibility assumptions and smoothness of the data can alternatively be done as follows.

\begin{prop}[Higher time regularity]
\label{prop:time_reg}

Let $k\geq 1$. Suppose $f \in H^k(I, V^*)$, together with:

\begin{itemize}
	\item $g_j:=f^{(j-1)}(0)-Ag_{j-1} \in H$, for $j = k$
	\item $g_{j-1} \in V$ for $1\leq j\leq k$
\end{itemize}

where $g_0 = u_0$.

Then, there holds, for $1\leq j\leq k$:

\begin{align*}
\left\{\begin{matrix}
u^{(j+1)}+Au^{(j)} = f^{(j)}
\\
u^{(j)}(0) = f^{(j-1)}(0) - Ag_{j-1}
\end{matrix}\right.
\end{align*}

In particular $u \in H^k(I,V)$, and $u^{(k+1)} \in L^2(I,V^*)$. One can prove, with the help of \cref{thm:well_pos_parabolic}, a-priori estimates on these successive derivatives.


\end{prop}

\begin{mproof}

See \cite{wloka}, theorem 27.2, page 406. The proof is a simplification of his argument, since our operator $A$ is for simplicity, independent in time. We also prove the proposition for the lowest order of differentiation, being the extension to higher derivatives  tractable with equal arguments.

Consider the problem:

\begin{align*}
	v_t + Av = f'\\
	v(0) = f(0) - Au (0)
\end{align*}

By assumption, $f(0) - Au (0) \in H$, and $f' \in L^2(I,V^*)$, so that, by \cref{thm:well_pos_parabolic} we obtain $v \in W(I;V)$.

Define $w(t):=u(0) + \ds \int_0^tv(s)ds$, an absolutely continuous $V$-valued function, being $u(0) \in V$ by assumption. We have $w_t = v$, so that $w \in H^1(I,V)$. We show that $w = u$.

Integrating the equation of $v$ we obtain, with equalities holding in $V^*$, that:

\begin{align*}
	w_t(t) = v(t) = \int_0^t f' -\int_0^t Av + v(0) = \\
	f(t) - f(0) + f(0) - Au(0) - \int_0^t A(w_t) = \\
	f(t) - f(0) + f(0) - Au(0) - Aw (t) + Au(0) = f(t) - Aw(t)
\end{align*}

Therefore, $w$ solves the same equation as $u$ and thus, $w=u$. From here we obtain both $u \in H^1(I,V)$, together with $u_{tt} = w_{tt} = v_t \in L^2(I,V^*)$, and the equation:

\begin{align*}
	u_{tt} + Au_t = f'\\
	u_t(0) = f(0) - Au (0)
\end{align*}

\end{mproof}

% This proposition assumes the same compatibility of that above, for k=1, and it is far more complicated.

%Under slightly different assumptions we can prove similar results, for $k=1$.
%
%\begin{ass}[Even more assumptions for even more regularity]
%\label{ass:zero_comp}
%We make the hypothesis $u_0=0$, which is the only case that is of interest for us, together with $A$ symmetric. Moreover, we require that the source term is a generic $f\in H^1(I,V^*)$ (in particular, the split $f=f_1 +f_2 \in L^2(I,H)+H^1(I,V^*)$ is not sufficient anymore), so that it is continuous  (\cite{evans}, page 286, theorem 2), and we can therefore ask the additional condition $f(0) \in H$.
%\end{ass}
%
%
%\begin{prop}[More smoothness from zero-order compatibility]
%Let \cref{ass:basic_par} and \cref{ass:zero_comp} hold. Then $u \in H^1(I,V)$ (in particular, $u \in C([0,T];V)$), and  $u' \in L^\infty(I,H)$ with the estimates:
%
%\begin{align*}
%\norm{u'}^2_{L^\infty(I,H)} \leq \exp(2\lambda T) \left (  \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2\right )
%\end{align*}
%
%and:
%
%\begin{align*}
%\int_0^T \VN{u'}^2 \leq  \frac{1}{\alpha } \HN{f(0)}^2 + C_1\norm{f}_{H^1(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha^2}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%with $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$, $C$ is a purely numeric constant without dependences on the problem, $C_1:=\alpha^{-2} + 4 \lambda C C_0 \alpha^{-2} + 2\lambda\alpha ^{-1} $.
%
%There also holds $u'' \in L^2(I,V^*)$ and:
%
%\end{prop}
%
%\begin{mproof}
%
%We consider again the functions $u_n$ as defined in \cite{gilardi}, page 22, equation (54).
%
%Thanks to the smoothness of $u_n$ and $f$, which are both $H^1$ in time, we can conclude that $u_n \in H^2(I,V_n)$, due to a bootstrapping argument from equation (56) of \cite{gilardi}.
%
%So, upon differentiation, we get that $\langle u_n'', v_n\rangle_{V^*,V} + \langle A u_n', v_n\rangle_{V^*,V} = \langle f', v_n \rangle_{V^*,V}$ for almost every $t$ (actually, for all $t$). Anyhow, thanks to the smoothness of $u_n'$, we can substitute it as $v_n \in V_n$ and integrate from $0$ to $t$ to obtain:
%
%\begin{align*}
%\int_0^t \langle u_n'', u_n'\rangle_{V^*,V} + \int_0^t\langle A u_n',u_n'\rangle_{V^*,V} = \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Equivalently, being $u_n'(t) \in H$, we can write:
%
%\begin{align*}
%\int_0^t (u_n'', u_n')_H + \int_0^t\langle A u_n',u_n'\rangle_{V^*,V} = \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Using the assumptions on $A$:
%
%\begin{align*}
%\int_0^t (u_n'', u_n')_H + \alpha \int_0^t \VN{u_n'}^2 - \lambda \int_0^t \HN{u_n'}^2 \leq \int_0^t \langle f', u_n' \rangle_{V^*,V}
%\end{align*}
%
%Therefore:
%
%\begin{align*}
%\frac{1}{2} \HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \frac{1}{2} \HN{u_n'(0)}^2+ \lambda \int_0^t \HN{u_n'}^2 +\frac{1}{2\alpha} \int_0^t \VSN{ f'}^2+ \frac{\alpha}{2}\int_0^t \VN{u_n'}^2
%\end{align*}
%
%We need to estimate the $H$ norm of $u_n'(0)$, for which the compatibility condition on $f(0)$ is essential.
%
%In fact, because the ODE for $u_n$ held a.e., and now that $u_n' \in H^1(I,V)$, the ODE holds for all times and we can conclude that $(u_n'(0),u_n'(0))_H + \langle A u_n(0), u_n'(0)\rangle_{V^*,V} = ( f(0), u_n'(0))_H$. Here comes in handy the fact that $u_0=0$, so that $u_n(0)=0$ too and therefore $\HN{u_n'(0)}^2  \leq 2^{-1}\HN{f(0)}^2 + 2^{-1} \HN{u_n'(0)}^2$ and therefore, $\HN{u_n'(0)}^2\leq \HN{f(0)}$.
%
%With this bound:
%
%\begin{align*}
%\HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \HN{f(0)}^2+ 2\lambda \int_0^t \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%\underline{The $L^\infty$ estimate}
%
%Gronwall's lemma (in the form of \cite{gilardi} at page 19) yields:
%
%\begin{align*}
%\HN{u_n'(t)}^2 \leq \exp(2\lambda T) \left (  \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2\right )
%\end{align*}
%
%This alone doesn't show that $u'\in L^\infty(I,H)$, but if this was true, and is $u_n'(t)\rightarrow_H u'(t)$ for a.e. $t$ modulo subsequences, then this would yield the required estimate on the norm.
%
%Now, $u_n, u_n' \rightharpoonup_H u, u'$ (where $u'$ is the $L^2(I,H)$ representative of the derivative of $u$ in the distributional sense, see the proof of \cref{thm:reg_time}). This is true modulo a common subsequence
%
%%, but since we also know the boundedness of $u_n, u_n' $ in $L^2(I,H)$ (cfr the proof of \cref{thm:reg_time} and page 23 of \cite{gilardi}), we conclude the convergence of the full sequences.
%
%Because $u_n', u'$ are the $L^2(I,H)$ sense derivatives of $u_n, u$ (thanks to the injectivity of $H^* \emb V^*$), then, by the compactness theorem 2.1 at page 271 of \cite{navier_stokes} with $X_0=X=X_1=H$ we conclude that $u_n \rightarrow u$ strongly in $L^2(I,H)$. Thanks to proposition 2.13 at page 10 of \cite{kreuter}, $u_n\rightarrow_H u$ for a.e. $t$, modulo a further subsequence.
%
%The bound shown above implies that $u' \in L^\infty(I,H)$ as we wished. 
%
%\underline{$u' \in L^2(I,V)$}
%
%
%We know:
%
%
%\begin{align*}
%\HN{u_n'(t)}^2 + \alpha \int_0^t \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2+ 2\lambda \int_0^t \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%so that:
%
%
%\begin{align*}
%\alpha \int_0^T \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2+ 2\lambda \int_0^T \HN{u_n'}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2
%\end{align*}
%
%But the proof of \cref{thm:const_track} says (cfr. \cref{eqn:weak_der_bound}):
%
%\begin{align*}
%\frac{1}{2}\int_0^t\HN{u_n'}^2+\frac{\alpha}{4}\VN{u_n(t)}^2\leq \\
%\frac{\lambda}{2}\HN{u_n(t)}^2 + \frac{1}{2}\norm{f'}_{L^2(I,V^*)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 + \frac{8+\alpha}{2\alpha}\norm{f}_{L^\infty(I,V^*)}^2\\
%\end{align*}
%
%In particular:
%
%\begin{align*}
%2\lambda\int_0^T\HN{u_n'}^2\leq \\
%4 \lambda \left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2\\
%\end{align*}
%
%so that:
%
%\begin{align*}
%\alpha \int_0^T \VN{u_n'}^2 \leq \frac{1}{2} \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2+\\
%4 \lambda \left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%As we have already seen (or as it is explained at page 23 of \cite{gilardi}), the term in the brackets is bounded above.
%
%%Now, remember that $u_n$ was bounded in $L^2(I,V)$, and that any weakly convergent subsequence would solve the parabolic problem. Thus, $u_n \rightharpoonup u$ in $L^2(I,V)$ (cfr. page 23 in \cite{gilardi}).
%
%Morevoer, we showed in the proof of \cref{thm:reg_time} that $u_n'$ is bounded in $L^2(I,H)$, and that any weakly convergent subsequence would reach $u'$, thus yielding the weak convergence of the full sequence.
%
%
%Also we now have that $u_n'$ is bounded in $L^2(I,V)$, thus admitting a weakly convergent subsequence to $w$, in $L^2(I,V)$. Because it is implied the weak convergence in $L^2(I,H)$, to $w$, we obtain that $w=u' $. Reiterating the argument and thanks to the boundedness of the full sequence, the full sequence must converge weakly in $L^2(I,V)$ to $u'$.
%
%By lower semicontinuity of the norm:
%
%\begin{align*}
%\alpha \int_0^T \VN{u'}^2 \leq \HN{f(0)}^2 +\frac{1}{\alpha} \int_0^T \VSN{ f'}^2+\\
%4 \lambda \limsup_n\left (\frac{\lambda}{2} \norm{u_n}^2_{C([0,T];H)} + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )+ 2\lambda \norm{f'}_{L^2(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%Remembering \cref{eqn:limsup}:
%
%\begin{align*}
%\text{limsup}_n \left ( \frac{\lambda}{2}\norm{u_n}_{C([0,T],H)}^2 + \frac{1}{2}\norm{u_n}_{L^2(I,V)}^2 \right )\leq\\
%C C_0 \alpha^{-1}\norm{f}^2_{L^2(I,V^*)}
%\end{align*}
%
%
%where $C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$ and $C$ is a purely numeric constant without dependences on the problem, so that:
%
%\begin{align*}
%\int_0^T \VN{u'}^2 \leq \\ \frac{1}{\alpha } \HN{f(0)}^2 + C_1\norm{f}_{H^1(I,V^*)}^2  + 2\lambda\frac{8+\alpha}{\alpha^2}\norm{f}_{L^\infty(I,V^*)}^2
%\end{align*}
%
%for $C_1:=\alpha^{-2} + 4 \lambda C C_0 \alpha^{-2} + 2\lambda\alpha ^{-1} $.
%
%Because the embedding $H\emb V$ is injective, $u'$ is also the weak derivative, $L^2(I,V)$ sense, of $u \in L^2(I,V)$, so that $u \in H^1(I,V)$. And thus, thanks to theorem 2 at page 286 of \cite{evans}, we obtain $u \in C([0,T]; V)$.
%
%\end{mproof}

\section{Application to inhomogeneous parabolic problems}

\subsection{Inhomogeneous Dirichlet problem}
\label{subs:inh_diri}

We make the following assumption.

\begin{ass}[Assumptions for \cref{pb:diri}]
\label{ass:diri}
We assume $\Omega \cc D $ to be bounded Lipschitz domains, so that $U:=D\setminus \Omega$ is bounded Lipschitz too and  the trace operator is bounded surjective onto $H^{1/2}(\partial U)$, with a right inverse $E$ (see theorem 3.37 at page 102 of \cite{mclean}). For such a choice we also have $H^1_0=H^1\cap \text{ker }\tr$, see \cite{leoni}, page 595, theorem 18.7.

Moreover, we select $f \in H^1(I, H^{1/2}(\Gamma_f))$, $f(0)=0$.
\end{ass}

Note that, given a bounded extension operator $E: H^{1/2}(\partial U) \rightarrow H^1(U)$, we obtain by \cref{lemma:bochner_Hk_map} that $Ef \in H^1(I, H^1(U))$. We have defined $\tr u (t):= tr(u(t))$ and analogously $Eu(t):=E(u(t))$ (see \cref{prop:trace}).

Call $H=L^2(U)$, $V=\{ v \in H^1(U), \tr u = 0 \text{ on } \Gamma_m\}=:H^1_{0,m}$. $V$ is a closed subspace of $H^1$, which is Hilbert separable, hence also Hilbert separable. We norm it with the full $H^1$ norm. Because $H^1_0(U)$ is dense in $H$, so is $V$ and we obtain a Gelfand triple. That $V$ is a closed subspace of $H^1$ follows from the observation that if $u_n\rightarrow u$ in the $V$ norm, then $\tr u_n \rightarrow \tr u$ in $L^2(\partial U)$. We can take an almost everywhere pointwise convergent sequence, so that $\tr u_n \rightarrow \tr u$ a.e., and by the fact that $\Gamma_m$ has positive Hausdorff measure, we conclude $\tr u = 0$ on $\Gamma_m$.

We define $A:= H^1 \rightarrow H^{1*}$ by $(Au)v:=\int_u\nabla u \nabla v$. This operator can be the recast to $V\rightarrow H^{-1}$ and $V\rightarrow V^*$.

The problem under consideration is the following. For $U = D\setminus \Omega$ we have:

\begin{pb}[Inhomogeneous heat equation, Dirichlet conditions]
\label{pb:diri}
\begin{align}
u_t - \Delta u = 0 \text{ in } (0,T)\times U\\
u(\Sigma_f)=f\\
u(\Sigma_m)=0\\
u(0)=0
\end{align}

By this we mean:

\begin{align}
u \in W(I,H^1_{0,m}) \\
u_t|_{H^{-1}} + A u = 0 \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
\tr u = f \text{ on } \Sigma_f\\
u(0)=0
\end{align}

\end{pb}

\begin{thm}[Well posedness and regularity for \cref{pb:diri}]
\label{prop:diri_wp}
Given \cref{ass:diri}, the solution $u$ to \cref{pb:diri} is unique with $u_t \in L^2(I,H)$. 

%The uniqueness holds in more generally in $L^2(I,V)\cap H^1(I, H^{-1})$.

The problem is equivalent to:

\begin{pb}[Equivalent formulation with extension]
\label{pb:diri_ext}
\begin{align}
u_0 \in W(I,H^1_0) \\
u_0' + A u_0 = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
u_0(0)=0
\end{align}
\end{pb}

with $\bar{u}$ any given $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. This means that $u$ solves \cref{pb:diri} $\implies$ $u-\bar{u}$ solves \cref{pb:diri_ext}, and if $u_0(\bar{u})$ solves  \cref{pb:diri_ext}, then $\bar{u}+u_0(\bar{u})$ solves \cref{pb:diri}.

Furthermore: 

\begin{align}
\norm{u}^2_{C([0;T],H)}+\norm{u}_{L^2(I,H)}^2+ \norm{\nabla u}_{L^2(I,H)}^2 + \norm{u'}^2_{L^2(I,H)}\leq C(T)\norm{\bar{u}}_{H^1(I,V)}^2
\end{align}

with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.

\end{thm}
\begin{mproof}

\underline{Extension of the boundary data}

Let $\bar{u}\in H^1(I,H^1_{0,m}(U))$ be such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. We can choose for instance $E\tilde{f}$, see \cref{prop:trace}, where $\tilde{f}=0$ on $\Sigma_m$, $\tilde{f}=f$ on $\Sigma_f$. $\tilde{f} \in H^1(I,H^{1/2}(\partial U))$, because $\Gamma_f$ and $\Gamma_m$ have positive distance (see the definition of the norm in \cite{grisvard}, page 20).  

\underline{Reformulation (first part)}

Consider the following commutative diagram, where $V = H^1_{0,m}$, $W=H^1_0$:

\[\begin{tikzcd}
	{H^1_{0,m}} &&& {(H^1_{0,m})^*} \\
	& H & {H^*} \\
	{H^1_0} &&& {H^{-1}}
	\arrow["c", hook, from=3-1, to=1-1]
	\arrow["a", hook, from=1-1, to=2-2]
	\arrow["b"', hook, from=3-1, to=2-2]
	\arrow["{a^*}", hook, from=2-3, to=1-4]
	\arrow["r", from=2-2, to=2-3]
	\arrow["{b^*}"', hook, from=2-3, to=3-4]
	\arrow["{c^*}", hook, from=1-4, to=3-4]
\end{tikzcd}\]

Here, $a,b,c$ are the trivial injections, $r$ the Riesz isomorphism $h\mapsto(h,\cdot)_H$. 

Now $(i_W (u-\bar{u}) )'+A(u - \bar{u}) = (i_Vu)'|_{H^{-1}}-(i_V\bar{u})'|_{H^{-1}}+Au - A\bar{u} = \ind{\cref{prop:sanity}}  = (i_Vu)'|_{H^{-1}}-(i_V\bar{u}_t)|_{H^{-1}}+Au - A\bar{u} = -(i_V\bar{u}_t)|_{H^{-1}}- A\bar{u}$ if $u$ solves \cref{pb:diri}, where $\bar{u}_t$ is the weak derivative of $\bar{u}$ in the $H^1(I,V)$ sense. Call $u_0 = u-\bar{u}$. By again \cref{prop:sanity}, $u_0 \in W(I,H^1_0)$.

%That $\tr E \tilde{f}=\tilde{f}$ is easily seen for a.a. $t$, and by \cref{lemma:bochner_Hk_map}, we get $\bar{u} \in H^1(I,H^1_c(U))$. The last result could be applied since $H^{1/2}(\partial U)$ is the continuous image of a separable space, hence it is separable, and it is also Banach (again by \cite{grisvard}, page 20).
%
%
%The initial value of $\bar{u}$ is null. To see this, we know that the unique time-continuous representative $U\tilde{f}$ of $\tilde{f}$ (\cite{evans}, page 286, theorem 2, and \cref{prop:cts_repr}) satisfies $\lim_{t\rightarrow 0^+}U\tilde{f}(t)=0$, the limit being in $H^{1/2}(\partial U)$. We also know that $\bar{u}$ has a unique continuous representative $U\bar{u}$ by similar arguments, and $U\bar{u}(t) \rightarrow U\bar{u}(0)$ for $t\rightarrow 0^+$. Now, $ [U\tilde{f}] = \tilde{f} = \tr \bar{u} =[ \tr U\bar{u} ]$, where the square brackets are equivalence classes in time. Thus $U\tilde{f} =  \tr U\bar{u}$ for all $t$, and thus $\tr U\bar{u}\rightarrow 0$ for small times. Applying $E$ we get $U\bar{u}\rightarrow 0$ which is what we wanted to show.

This motivates us to consider the problem: 

\begin{align}
u_0 \in W(I,H^1_0) \\
u_0' + A u_0 = -(f_1+f_2) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) \\
u_0(0)=0
\end{align}

Here, $f_1:=(i_V\bar{u}_t)|_{H^{-1}}=c^*a^*ra\bar{u}_t = b^*r (a\bar{u}_t) \in L^2(I,H)$.

Moreover, $A \in L(V, H^{-1})$, so, by \cref{lemma:bochner_Hk_map}, $f_2:=A\bar{u} \in H^1(I, H^{-1})$.

\underline{Existence}

By \cref{thm:par_reg} we get a solution of the above problem with $u_0' \in L^2(I, H)$.

And now, let $u:=\bar{u}+c u_0 =\bar{u}+ u_0 $. We claim it is a solution. The initial and boundary conditions are surely satisfied. We check it is in $W(I,V)$ and is satisfies the partial differential equation.

By \cref{prop:sanity}, we have both $\bar{u}, c u_0 \in W(I,V)$. The derivative of $\bar{u}$ becomes $i_V \bar{u}_t$, see \cref{prop:sanity}. Therefore $(i_V(\bar{u}+c u_0))'|_{H^1_0} = c^* (i_V(\bar{u}+c u_0))' = c^*i_V \bar{u}_t + c^*i_V(c u_0)' = b^*r (a\bar{u}_t) + i_W(u_0)'$ by \cref{prop:sanity}.

Using the pde of $u_0$, $... = b^*r (a\bar{u}_t) - Au_0 -f_1 -f_2 = -A(u_0+\bar{u})$.

\underline{Uniqueness}

For two solutions $u_1, u_2$ of $\cref{pb:diri}$ we can form $d:=u_1-u_2\in W(I,H^1_0)$ by \cref{prop:sanity}. Clearly, $d(0)=0$. Moreover, $(i_{H^1_0} d)' = \ind{\cref{prop:sanity}}=(i_V u_1)'|_{H^1_0}-(i_V u_2)'|_{H^1_0} = A(u_1-u_2)$.

By uniqueness stated in \cref{thm:well_pos_parabolic} we obtain $d=0$ in $L^2(I,H)$, so that the solution is unique and doesn't depend on the choice of the extension of the Dirichlet datum.

\underline{Reformulation (part 2)}

Therefore $u=\bar{u}+u_0$ above is the unique solution of \cref{pb:diri}. So, given any $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$, we can construct $u_0$ as above and get $u=\bar{u}+u_0$ solving \cref{pb:diri}.

Viceversa, let $u$ solve \cref{pb:diri}. Call $u_0 = u- \bar{u}$. Then, as seen above, $u_0 \in W(I,H^1_0)$ and $(i_V (u-\bar{u}) )'|_{H^{-1}}+A(u - \bar{u}) = (i_Vu)'|_{H^{-1}}-(i_V\bar{u})'|_{H^{-1}}+Au - A\bar{u} = \ind{\cref{prop:sanity}}  = (i_Vu)'|_{H^{-1}}-(i_V\bar{u}_t)|_{H^{-1}}+Au - A\bar{u} = -(i_V\bar{u}_t)|_{H^{-1}}- A\bar{u}$ if $u$ solves \cref{pb:diri}, where $\bar{u}_t$ is the weak derivative of $\bar{u}$ in the $H^1(I,V)$ sense. Call $u_0 = u-\bar{u}$. By again \cref{prop:sanity}, $(i_W (u-\bar{u}) )'+A(u - \bar{u}) = (i_Vu)'|_{H^{-1}}-(i_V\bar{u})'|_{H^{-1}}+Au - A\bar{u} = (i_Vu)'|_{H^{-1}}-(i_V\bar{u}_t)|_{H^{-1}}+Au - A\bar{u} = -(i_V\bar{u}_t)|_{H^{-1}}- A\bar{u} = -b^*r(a\bar{u}_t)-A\bar{u}$. Moreover, $u_0(0)=0$, so that $u_0$ solves \cref{pb:diri_ext}.

%\begin{itemize}
%\item $u_0 \in L^2(I,H^1_0)$
%\item $u_0' \in L^2(I,V^*)+L^2(I,H)\subseteq L^2(I,H^{-1})$
%\item $u_0(0)=0$ in $H$
%\item $u_0$ solves $u_0' + A u_0 = -((\bar{u}',\cdot)_H+\langle A \bar{u},\cdot\rangle_{H^{-1},H^1_0})$
%\end{itemize}

\underline{Regularity}

Let $u=\bar{u}+u_0$ be the unique solution, as before, of \cref{pb:diri}. From \cref{prop:sanity} we know $(i_V(\bar{u}))'=i_V(\bar{u}_t)=a^*r(a\bar{u}_t)$, and $i_V(cu_0)'=a^*r (u_0')$, for $u_0' \in L^2(I,H)$ the representative of $(i_W(u_0))'$, equivalently, the weak derivative of $u_0$ in the $H^1(I,H)$ sense. It follows that $(i_Vu)' = a^*r(a\bar{u}_t+u_0')$, proving the additional time smoothness claim.

\underline{Stability}

Let $\bar{u}\in H^1(I,H^1_{0,m}(U))$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$. Consider $u_0$. Then, by \cref{thm:const_track}:


\begin{align*}
\norm{u_0}^2_{C([0;T],H)}+\alpha\norm{u_0}_{L^2(I,H^1_0)}^2\leq \exp(2\lambda T)\alpha^{-1}\norm{(\bar{u}',\cdot)_H+ A \bar{u}}^2_{L^2(I,H^{-1})}
\end{align*}

\begin{align*}
C\norm{u_0'}^2_{L^2(I,H)}\leq 
(1+(1+C_0)\alpha^{-1})\norm{A \bar{u}}^2_{H^1(I, H^{-1})}+\\
\norm{(\bar{u}',\cdot)_H}_{L^2(I,H)}^2+C_0\alpha^{-1}\norm{(\bar{u}',\cdot)_H}^2_{L^2(I,H^{-1})}
\end{align*}

$C_0 = \ds 2^{-1}\max(1,\lambda)\max(1,\alpha^{-1})\exp(2\lambda T)$.

We norm $H^1_0$ with the full $H^1$ norm too. Then:
\begin{align*}
\norm{(\bar{u}',\cdot)_H+ A \bar{u}}_{L^2(I,H^{-1})}\leq \\
\sup_{\norm{v}_{L^2(I,H^{1}_0)}=1}\norm{\bar{u}'}_{L^2(I,H)}\norm{v}_{L^2(I,H)}+\norm{\nabla \bar{u}}_{L^2(I,H)}\norm{\nabla v}_{L^2(I,H)}\leq \\C(\norm{\bar{u}'}_{L^2(I,H)}+\norm{\nabla \bar{u}}_{L^2(I,H)})
\end{align*}

By \cref{lemma:bochner_Hk_map}, $\norm{A \bar{u}}_{H^1(I, H^{-1})}\leq \norm{A}_{L(V,H^{-1})}\norm{\bar{u}}_{H^1(I,V)}$ (we could apply it since $H^{-1}$ is separable, as a dual of a reflexive Banach space).

Finally, $\norm{(\bar{u}',\cdot)_H}^2_{L^2(I,H^{-1})}\leq \norm{\bar{u}'}_{L^2(I,H)}^2$.

We can then say:

\begin{align*}
\norm{u_0}^2_{C([0;T],H)}+C\alpha\norm{u_0}_{L^2(I,H^1_0)}^2\leq \exp(2\lambda T)\alpha^{-1}\norm{\bar{u}}^2_{H^1(I,V)}\\
C\norm{u_0'}^2_{L^2(I,H)}\leq 
((1+(1+C_0)\alpha^{-1})\norm{A}_{L(V,H^{-1})}^2 +1 +C_0\alpha^{-1})\norm{\bar{u}}^2_{H^1(I,V)}
\end{align*}

Now, $\langle Av, v\rangle_{H^{-1}, H^1_0} + 1\cdot  \HN{v}^2 = 1\cdot \norm{v}_{H^1_0}^2$, so that $\alpha=\lambda=1$. Moreover, $\langle Au, v\rangle_{H^{-1}, H^1_0}\leq \VN{u}\norm{v}_{H^1_0}$, i.e. $\norm{A}_{L(V,H^{-1})}\leq 1$.

Therefore $\norm{u_0}^2_{C([0;T],H)}+\norm{u_0}_{L^2(I,H^1_0)}^2 + \norm{u_0'}^2_{L^2(I,H)}\leq C(T)\norm{\bar{u}}_{H^1(I,V)}^2$ with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.

Now, let's analyse the norms of $\bar{u}$. Because $\bar{u}\in H^1(I,V)$, then, $\bar{u} \in C([0,T],V)\emb C([0,T],H)$, where the embedding is non-expansive by the choice of the norm of $V$. Therefore $\norm{\bar{u}}_{C([0;T],H)}\leq \norm{\bar{u}}_{C([0;T],V)}\leq (1+T)\norm{\bar{u}}_{H^1(I,V)}$. We can therefore conclude that $\norm{u}^2_{C([0;T],H)}+\norm{u}_{L^2(I,H^1_0)}^2 + \norm{u'}^2_{L^2(I,H)}\leq C(T)\norm{\bar{u}}_{H^1(I,V)}^2$ with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.

\end{mproof}

\subsection{Inhomogeneous Neumann-Dirichlet problem}

We make the following assumption.

\begin{ass}[Assumptions for \cref{pb:diri}]
\label{ass:neu}
We keep \cref{ass:diri} (apart from the Dirichlet datum). We consired $g \in H^1(I, L^2(\Gamma_f))$, $g(0)=0$.
\end{ass}

Again, call $H=L^2(U)$, $V=\{ v \in H^1(U), \tr u = 0 \text{ on } \Gamma_m\}=:H^1_{0,m}$. $H,V$ induce a Gelfand triple as seen before. 


The problem under consideration is:

\begin{pb}[Inhomogeneous heat equation, Neumann conditions]
\label{pb:neu}
\begin{align}
u_t - \Delta u = 0 \text{ in } (0,T)\times U\\
\partial_\nu u(\Sigma_f)=g\\
u(\Sigma_m)=0\\
u(0)=0
\end{align}

By this we mean:

\begin{align}
u \in W(I,H^1_{0,m}) \\
u_t + A u = G \text{ in } V^* \text{ and for a.e. } t \in (0,T) \\
u(0)=0
\end{align}

where $\langle G(t), v \rangle_{V^*,V}:=\int_{\Gamma_f} g(t)\tr v d\sigma$, $\sigma$ the $1$-codimensional Hausdorff measure, and $A$ was introduced before in $L(V,H^{-1})$.

\end{pb}

By \cref{lemma:bochner_Hk_map}, $G \in H^1(I,V^*)$. In fact, define $T: L^2(\Sigma_f)\rightarrow V^*$ by $\langle Tg,v \rangle_{V^*,V}:=\int_{\Gamma_f} g\tr v d\sigma$. Then, $\langle Tg,v \rangle_{V^*,V} \leq \norm{g}_{L^2(\Gamma_f)} \VN{v}$ by trace theory. Now, $G(t)=Tg(t)$.

Moreover, $\langle A v, v \rangle_{V^*,V}+ 1 \cdot \HN{v} = 1\cdot \norm{V}$, so that we can immediately conclude:

\begin{thm}[Well posedness and regularity for \cref{pb:neu}]
\label{prop:wp_neu}
Given \cref{ass:neu}, the solution $u$ to \cref{pb:neu} is unique with $u_t \in L^2(I,H)$.

Furthermore: 

\begin{align}
\norm{u}^2_{C([0;T],H)}+\norm{u}_{L^2(I,H)}^2+ \norm{\nabla u}_{L^2(I,H)}^2 + \norm{u'}^2_{L^2(I,H)}\leq C(T)\norm{g}_{H^1(I,L^2(\Gamma_f))}^2
\end{align}

with $C>1$, only dependent on $T$, smoothly, exploding for large $T$.
\end{thm}
\begin{mproof}

It is an application of \cref{thm:well_pos_parabolic}, \cref{thm:reg_time} and \cref{thm:const_track}.
\end{mproof}

\subsection{Space-time regularity for a more general problem}

Here, we build on the results of the last subsections, and prove higher spatial and time regularity, under suitable smoothness assumptions.

The overall problem, comprehensive of both \cref{pb:diri} and \cref{pb:neu}, is:

\begin{pb}[Inhomogeneous heat equation, general case]
\label{pb:mix}
\begin{align*}
u_t - \Delta u = f \text{ in } (0,T)\times U\\
\partial_\nu u(\Sigma_N)=g_N\\
u(\Sigma_D)=g_D\\
u(0)=u_0
\end{align*}

Calling $V:=H^1_{0,m}(U)$ (see \cref{ass:neu}), and $H=L^2(U)$, we mean:

\begin{align*}
u \in W(I,H^1) \\
u_t + A u = f + G \text{ in the sense of } V^* \text{ and for a.e. } t \in (0,T) \\
\tr u =g_D \text{ on } \Sigma_D\\
u(0)=u_0
\end{align*}

where $\langle G(t), v \rangle_{V^*,V}:=\int_{\Gamma_N} g(t)\tr v d\sigma$, $\sigma$ the $1$-codimensional Hausdorff measure.

\end{pb}

\textcolor{red}{Remove the comment below}

Note, for the regular case, we will be discussing only a homogeneous initial condition. This will suffice for our purposes. A generalization would entail handling more complicated compatibility conditions, see \cite{lions}, chapter 2. Also note that the requirements imposed on the data below, are only sufficient, to ensure the desired regularity.

\begin{ass}[Basic assumption for \cref{pb:mix}]
\label{ass:basic_par_mix}
\textcolor{white}{ }
\begin{enumerate}
	\item $u_0 \in H^1(U)$
	\item $\Omega \cc D$ are bounded Lipschitz domains
	\item $A: H^1 \rightarrow (H^1)^*$, $(Au)v = \int_U \nabla u \nabla v$
	\item $g_D \in H^1(I, H^{1/2}(\Gamma_D))$. Here $\Gamma_D\neq \emptyset$ is either $\partial U, \partial D $ or $\partial \Omega$, with $g_D(0) = u_0$ on $\Gamma_D$
	\item $g_N \in H^1(I, L^2(\Gamma_N))$, where $\Gamma_N = \partial U \setminus \Gamma_D$
	\item $f \in L^2(I, H)$
\end{enumerate}
\end{ass}

\begin{ass}[Time regularity assumption for \cref{pb:mix}]
\label{ass:time_reg_mix}

Let $k\geq 1$. 

Consider $G_D \in H^1(U)$ solving:
$$
\left\{\begin{matrix}
-\Delta G_D(t) = 0 & \text{ in } U\\ 
G_D(t) = g_D(t) & \text{ on } \Gamma_D\\ 
G_D(t) = 0 & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

We ask, aside from \cref{ass:basic_par_mix}:

\textcolor{red}{Make it more general, and hide the fact that this won't work unless I consider more general theories of compatibility conditions. In particular, just put the conditions in terms of the derivatives of $u$ at initial time}

\begin{enumerate}
%	\item $\partial U \in C^{1,1}$
	\item $u_0=0$
	\item $g_D \in H^{k+1}(I, H^{1/2}(\Gamma_D))$
	\item $g_N \in H^{k}(I, L^2(\Gamma_N))$
	\item $f \in H^k(I, H)$
	\item $g_N^{(j)}(0)=0$, for $j = 0,...,k-1$
	\item $f^{(j-1)}(0) - G_D^{(j)}(0) + \sum_{l=1}^{j-1}(-1)^l A^l f^{(j-l-1)}(0)  \in V$, for $j=0,...,k-1$ ( for $j=0$ it is read $g_D(0)=0$, which we already assumed)
	\item $\sum_{j=1}^{k-1}(-1)^jA^j(f^{(k-j-1)}(0))\in H$ (remember that $A: V\rightarrow V^*$, so that $Af \neq -\Delta f$, in general)
%	\item $A^lf^{(j-l-1)}(0) \in V$, for $j=1,...,k-1$ and for $l=1,...,j$, and $f^{(j-1)}(0)\in H^1(U)$ with $f^{(j-1)}(0) = g_D^{(j)}(0)$ on $\Gamma_D$, for $j = 1, ..., k-1$ (\textcolor{red}{also wrong})
\end{enumerate}
\end{ass}

\begin{ass}[Additional time regularity assumptions]
\label{ass:add_time_reg_mix}
Apart from \cref{ass:basic_par_mix} and \cref{ass:time_reg_mix}, suppose that, for $k\geq 1$, there holds:

\begin{itemize}
	\item $g_N \in H^{k+1}(I, L^2(\Gamma_N))$
	\item $f^{(k-1)}(0) - G_D^{(k)}(0) + \sum_{l=1}^{k-1}(-1)^l A^l f^{(k-l-1)}(0)  \in V$
\end{itemize} 
\end{ass}


\begin{ass}[Spatial regularity assumptions]
\label{ass:space_reg_mix}
Let \cref{ass:basic_par_mix} for $k=0$, and also \cref{ass:time_reg_mix} and \cref{ass:add_time_reg_mix} hold for $k\geq 1$. Further assume:

\begin{itemize}
	\item $\partial U \in C^{1,1}$
	\item $g_D \in H^k(I,H^{3/2}(\Gamma_D))$
	\item $g_N \in H^k(I,H^{1/2}(\Gamma_N))$
\end{itemize}

\end{ass}


\begin{thm}[Regularity results for \cref{pb:mix}]
\label{thm:mix_reg}

Under \cref{ass:basic_par_mix}:

\begin{itemize}
	\item there exists a unique $u \in W(I,H^1(U))$ solution to \cref{pb:mix}
	\item for such $u$ there holds $u' \in L^2(I,L^2(U))$ with:
	\begin{align*}
	\norm{u}^2_{L^2(I,H)}+\norm{\nabla u}^2_{L^2(I,H)} + \norm{u'}^2_{L^2(I,H)} \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))}   + C(U) \norm{g_D}^2_{H^1(I,H^{1/2}(\Gamma_D))} + \norm{u_0}^2_{H^1(U)}\right )
\end{align*}
\end{itemize}

Under \cref{ass:time_reg_mix} have that $u \in H^k(I,V)\cap ( H^{k+1}(I,V) + H^{k+1}(I,V^*))$.


Under \cref{ass:add_time_reg_mix}, $u^{k+1} \in H^1(I,H)$, or $u \in H^{(k+1)}(I,H)$, and, for $1\leq j \leq k$:

\begin{align*}
	\left\{\begin{matrix}
(u^{(j+1)},v)_H + (\nabla u^{(j)}, \nabla v)_H = ( f^{(j)}, v)_H + (g_N^{(j)}, v)_{L^2(\Gamma_N)} \\
u^{(j)}(0) = f^{(j-1)}(0) - G_D^{(j)}(0) + \sum_{l=1}^{j-1}(-1)^l A^l f^{(j-l-1)}(0)   \in V \\
\tr u^{(j)}(\Sigma_D) = g_D^{(j)}
\end{matrix}\right.
\end{align*}


Finally, if \cref{ass:space_reg_mix} holds, then $u \in H^{k}(I,H^2(U)) \cap H^{k+1}(I,H)$.

\end{thm}

\begin{mproof}

\underline{Well-posedness, stability}

Existence and uniqueness follow with similar arguments as in the previous subsections.

In particular, $u=G_D + \delta$, where $G_D$ is (for a.e. $t$), a e.g. harmonic extension of $g_D$:
$$
\left\{\begin{matrix}
-\Delta G_D(t) = 0 & \text{ in } U\\ 
G_D(t) = g_D(t) & \text{ on } \Gamma_D\\ 
G_D(t) = 0 & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

Using the results of trace theory we know, in particular, that $G_D \in H^1(U)$ with $\norm{G_D}_{H^1}\leq C(U) \norm{g_D}_{H^{1/2}(U)}$.

$\delta \in W(I,V) \cap H^1(I,H)$ is the solution to:

$$
\left\{\begin{matrix}
(\delta_t,v)_H + (\nabla \delta, \nabla v)_H = (f - \partial_t G_D,v)_H + (g_N,v)_{L^2(\Gamma_N)} \text{ for all } v \in V\\ 
\delta(0) = u_0 - G_D(0) \in V
\end{matrix}\right.
$$

Note that $G_D(0)$ makes sense, being $g_D \in C([0,T], H^{1/2}(\Gamma_D))$ and $g_D \mapsto G_D$ is linear bounded, so that we can apply \cref{lemma:bochner_Hk_map}.

We can therefore deduce the estimate:

\begin{align*}
	\norm{u}^2_{L^2(I,H)}+\norm{\nabla u}^2_{L^2(I,H)} + \norm{u'}^2_{L^2(I,H)} \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))}  + \norm{G_D}^2_{H^1(I,H^1(U))}\right )  \leq \\
	C(T)\left (  \norm{f}_{L^2(I,H)}^2 +  \norm{g_N}^2_{H^1(I,L^2(\Gamma_N))} + C(U) \norm{g_D}^2_{H^1(I,H^{1/2}(\Gamma_D))} + \norm{u_0}^2_{H^1(U)}\right )
\end{align*}

\underline{Regularity: compatibility relations}
%
%We note that for $\partial U$ this smooth we can apply the trace theory stated in theorem 1.5.1.2, page 38, \cite{grisvard}. 
%
%We can therefore solve the problem: 
%
%$$
%\left\{\begin{matrix}
%-\Delta G_N(t) = 0 & \text{ in } U\\ 
%\partial_\nu G_N(t) = g_N(t) & \text{ on } \Gamma_D\\ 
%G_N(t) = 0 & \text{ on } \Gamma_D
%\end{matrix}\right.
%$$
%
%and obtain $G_N \in H^2(U)$, with $\norm{G_N}_{H^2(U)}\leq C(U) \norm{g_N}_{H^{1/2}(\Gamma_N)}$ (see also the regularity results in chapter 2 of \cite{grisvard}).
%
%Therefore, for $v \in H^1_c(U)$ (which means that $v=0$ on $\Gamma_D$):
%
%\begin{align*}
%	\int_{\Gamma_N} g_N v d\sigma = \int_{\Gamma_N} \partial_\nu G_N v d\sigma = \int_U v \Delta G_N + \int_U \nabla G_N \nabla v = \int_U \nabla G_N \nabla v
%\end{align*}
%
%Calling $\gamma := \delta - G_N$ we conclude that:
%
%$$
%\left\{\begin{matrix}
%(\gamma_t,v)_H + (\nabla \gamma, \nabla v)_H = (f-\partial_t G_D - \partial_t G_N, v)_H \\
%\gamma(0) = u_0 - G_D(0) - G_N(0) \in V
%\end{matrix}\right.
%$$
%
%where the initial condition holds because $G_N=0$ on $\Gamma_D$.

$F:=(f-\partial_t G_D, \cdot)_H + (g_N, \tr(\cdot))_{L^2(\Gamma_N)}$ is, thanks to the smoothness assumptions, in $H^k(I,V^*)$. We apply \cref{prop:time_reg}, to the problem:

$$
\left\{\begin{matrix}
(\delta_t,v)_H + (\nabla \delta, \nabla v)_H = (F, v)_H \\
\delta(0) = \delta_0 \in V
\end{matrix}\right.
$$

for $\delta_0 = - G_D(0)$.

We check its hypothesis, for $k\geq 1$.

In particular $F^{(k-1)} = (f^{(k-1)} - G^{(k)}_D, \cdot)_H +(g_N^{(k-1)}, \tr(\cdot))_{L^2(\Gamma_N)}$.

Because $f\in H^k(I,H)$, and $g_N, G_D \in  H^{k+1}(I,H^{1/2}(\Gamma_D)), H^{k+1}(I,H^1(U))$, we can define $F^{(k-1)}(0)$, which is $F^{(k-1)}(0) = (f^{(k-1)}(0) - G^{(k)}_D (0), \cdot)_H +(g_N^{(k-1)}(0), \tr(\cdot))_{L^2(\Gamma_N)}$. As $g_N^{(k-1)}(0) = 0$, we get:

\begin{align*}
	F^{(k-1)}(0) = (f^{(k-1)}(0) - G^{(k)}_D (0), \cdot)_H
\end{align*}

We now compute the terms $g_k$.

We have $g_k = \sum_{j=0}^{k-1}(-1)^j A^j F^{(k-j-1)}(0) + (-1)^k A^k( - G_D(0))$, $g_0 = -G_D(0)$.


Note, $AG_D(v) = (\nabla G_D, \nabla v )=0$ for $v \in V$. Therefore, $A^jG_D(0)=0$ and we get to $g_k = \sum_{j=0}^{k-1}(-1)^j A^j F^{(k-j-1)}(0)$, $k \geq 1$.

Let's start to check that $g_k \in H$. To do so, note that for $j=0, ..., k-1$ we have that $A^j F^{(k-j-1)}(0) = A^j f^{(k-j-1)}(0)  -A^j G^{(k-j)}_D (0)$.

So, for $j=0$: $A^j F^{(k-j-1)}(0) = f^{(k-1)}(0)  - G^{(k)}_D (0)$, whereas for $j\geq1$: $A^j F^{(k-j-1)}(0) = A^jf^{(k-j-1)}(0)  -A^{j-1} A G^{(k-j)}_D (0)$.

Because $f \in H^k(I,H), G_D \in H^{k+1}(I, H^1(U))$, the term for $j=0$ is in $H$.

For $j\geq1$. Note that, by calling $h: H^{1/2}(\Gamma_D)\rightarrow H^1(U)$ the operator $g_D\mapsto G_D$, thanks to the assumption $g_D \in H^{k+1}(I, H^{1/2}(\Gamma_D))$ and to \cref{lemma:bochner_Hk_map}, we have $\partial_{t^k} h g_D = h \partial_{t^k} g_D$, so that $A G^{(j)}_D = 0$, for all $t$ and all $j\leq k$. Therefore $A^{j-1} A G^{(k-j)}_D (0)=0$ for $j\geq 1$ without other assumptions, and we have to ask for $ \sum_{j=1}^{k-1}(-1)^j A^j F^{(k-j-1)}(0) = \sum_{j=1}^{k-1}(-1)^jA^j(f^{(k-j-1)}(0))\in H$.

It now remains to ask that $g_j \in V$ for $j=1,...,k-1$.

We have $g_j = \sum_{l=0}^{j-1}(-1)^l A^l F^{(j-l-1)}(0)$, for $j=1,...,k-1$, and, as seen before, $AG_D^{(j-l)}=0$, so that we must ensure:

\begin{align*}
	f^{(j-1)}(0) - G_D^{(j)}(0) + \sum_{l=1}^{j-1}(-1)^l A^l f^{(j-l-1)}(0)  \in V
\end{align*}

\underline{Regularity: time smoothness}

So, \cref{prop:time_reg} ensures then that $\delta \in H^k(I,V)$, $\delta^{(k+1)} \in L^2(I,V^*)$. Because we $G_D \in H^{k+1}(I,H^1(U))$ we obtain that $u = G_D + \delta$ is in $H^{k+1}(I,H^1(U)) + H^{k+1}(I,V^*)$ and in $H^k(I,H^{1}(U))$.

\underline{Regularity: time smoothness again}

By \cref{prop:time_reg} we also have:

\begin{align*}
\left\{\begin{matrix}
\langle \partial_t \delta^{(k)},v\rangle_{V^*,V} + (\nabla \delta^{(k)}, \nabla v)_H = \langle F^{(k)}, v\rangle_{V^*,V} \\
\delta^{(k)}(0) = g_k \in H
\end{matrix}\right.
\end{align*}

We ask for $g_k \in V$.

The right hand side $F^{(k)} = (f^{(k)} - G^{(k+1)}_D, \cdot)_H +(g_N^{(k)}, \tr(\cdot))_{L^2(\Gamma_N)}$ is now an element of $L^2(I,H) + H^1(I,V^*)$, meaning that we can apply \cref{thm:reg_time} to obtain $\delta \in H^{k+1}(I,H)$. 

With analogous reasoning to \cref{prop:diri_wp} we conclude that $u \in H^{(k+1)}(I,H)$, and, for $1\leq j \leq k$:

\begin{align*}
	\left\{\begin{matrix}
(u^{(j+1)},v)_H + (\nabla u^{(j)}, \nabla v)_H = ( f^{(j)}, v)_H + (g_N^{(j)}, v)_{L^2(\Gamma_N)} \\
u^{(j)}(0) = g_k + G_D^{(j)}(0)  \in V \\
\tr u^{(j)}(\Sigma_D) = g_D^{(j)}
\end{matrix}\right.
\end{align*}

\underline{Spatial regularity}

This last equation reads, for a.e. $t \in (0,T)$:

\begin{align*}
\left\{\begin{matrix}
(\nabla u^{(j)}, \nabla v)_H = ( f^{(j)} - u^{(j+1)}, v)_H + (g_N^{(j)}, v)_{L^2(\Gamma_N)} \\
\tr u^{(j)}(\Sigma_D) = g_D^{(j)}
\end{matrix}\right.
\end{align*}

which is the variational counterpart to:

\begin{align*}
\left\{\begin{matrix}
- \Delta  u^{(j)} = f^{(j)} - u^{(j+1)} \\
u^{(k)}(\Gamma_D) = g_D^{(k)} \\
\partial_\nu u^{(j)}(\Gamma_N) = g_N^{(j)}
\end{matrix}\right.
\end{align*}

This holds for $0\leq j \leq k$.

$H^2$ regularity results that can be found in chapter 2 of \cite{grisvard} let us conclude the proof.

\end{mproof}

\textcolor{red}{An application of this, please}

\section{Reformulation of parabolic equations}

We just saw that the two parabolic equations of interest can be recasted into the problem of finding $u\in W(I,V)$, $u(0)=0$, $u_t+Au=f$ for a.e. $t$ in $V^*$, with notation from preceding sections.

In particular, $f \in L^2(I, V^*)$ and so is $Au$ (because $A\in L(V,V^*)$, and by \cref{lemma:bochner_Hk_map}).

Call then $E(u):=u_t+Au-f \in L^2(I,V^*)$ and $W_0(I,V)$ the $W(I,V)$ functions with zero initial value. Then, the differential equation reads $\langle E(u)(t),v\rangle_{V^*,V}=0$ for all $v\in V$, for a.a. $t$, equivalently, $E(u)=0$ for a.a. $t$. Thus, we are interested in the abstract problem:

\begin{pb}[Even more abstract parabolic equation]
\label{pb:more_abstr_par}
Given a function $E: W(I,V)\rightarrow L^2(I,V^*)$, find $u\in W_0(I,V)$, such that $E(u)=0$ for a.a. $t$.
\end{pb}
 
We can view $L^2(I,V^*)\cong L^2(I,V)^*$.

Hence $\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=\int_I \langle E(u)(t),v(t) \rangle_{V^*,V} dt$ (see \cite{hinze}, theorem 1.31 at page 39).

\color{black}


We are now ready to restrict both state and adjoint space.

\begin{defn}[$Q(I,V)$]
\label{def:Q}
We define $Q(I,V)=H^{1,1}=L^2(I,V)\cap H^1(I,H)$, with the norm $\norm{v}_Q^2=\norm{v}_{L^2(I,V)}^2 + \norm{v_t}_{L^2(I,H)}^2$.
\end{defn}

\begin{prop}[Properties of $Q$]
\label{prop:Q}
There holds:
\begin{itemize}
	\item $Q=Q(I,V)$ is Hilbert with $(v,w)_{L^2(I,V)} + (v_t,w_t)_{L^2(I,H)}$ 
	\item $Q(I,V)$ is dense in $L^2(I,V)$
	\item $Q(I,V)\emb C([0,T],H)$
	\item $Q_0(I,V)$ is dense in $L^2(I,V)$, $Q_0(I,V)$ the space of $Q(I,V)$ function with zero initial value
	\item $Q(I,V) = W(I,V)\cap H^1(I,H)$, $Q_0(I,V) =  W_0(I,V)\cap H^1(I,H)$ as sets. There holds that the $W(I,V)$ derivative is represented by the $H^1(I,H)$ derivative and $\langle u', v\rangle_{V^*,V} = (u',v)_H$, with the suitable interpretations of $u'$ (on the left, we have $i_V(u)'$, $i_V$ the Gelfand triple embedding; on the right we have $u$, seen in $H$, and then weakly differentiated in the $H^1(I,H)$ sense)
	\item integration by parts in time holds: $\int_I(v_t,w)_H = -\int_I(w_t,v)_H +(v(T),w(T))_H-(v(0),w(0))_H$
	\item if $q_n$ is bounded in $Q(I,V)$, then there exists a weakly convergent subsequence $q_k$ such that $q_k\weakc q$ in $L^2(I,H)$, $\partial_i q_k\weakc \partial_i q$ in $L^2(I,H)$ and $q_k'\weakc q'$ in $L^2(I,H)$
\end{itemize}
\end{prop}
\begin{mproof}

\underline{Completeness}

We have the inclusions $L^2(I,H)\subseteq L^2(I,V)\cap H^1(I,H)\subseteq H^1(I,V)$.

If $q_n$ is Cauchy in $Q$, then it is Cauchy in the individual norms of $ L^2(I,V), H^1(I,H)$, so that $q_n$ convergens to two limits, one in $L^2(I,V)$ and one in $H^1(I,H)$. The convergence is common in $L^2(I,H)$, which implies that the two limits coincide at $q \in Q(I,V)$. The convergence in $Q(I,V)$ of $q_n$ to $Q$ follows from the individual convergences of $q_n, \nabla q_n, q_{nt}$ in $ L^2(I,H), L^2(I,H),L^2(I,H)$.

\underline{Density}

We have $C_c^\infty(I,V) \subseteq Q(I,V) \subseteq L^2(I,V)$. The first inclusion holds because of \cref{prop:weak_class}, so that $C_c^\infty(I,V)\subseteq H^1(I,V)$. Moreover $H^1(I,V)\subseteq  Q(I,V) $ trivially, where the $H^1(I,H)$ derivative is the $H^1(I,V)$ derivative. $C_c^\infty(I,V)$ is dense in $ L^2(I,V)$ by \cite{hinze}, page 39, lemma 1.9.

\underline{Continuity}

Follows from the embedding $H^1(I,H)\emb C([0,T],H)$, as seen in \cite{evans}, theorem 2 of page 286.

\underline{More density}

We can therefore speak of initial values. In particular,  $C_c^\infty(I,V) \subseteq Q_0(I,V)\subseteq L^2(I,V)$, and as before, the density result follows.

\underline{Relationship with $W(I,V)$}

Consider the chain:

\[\begin{tikzcd}
	V & H & {H^*} & {V^*}
	\arrow["a", hook, from=1-1, to=1-2]
	\arrow["r", from=1-2, to=1-3]
	\arrow["{a^*}", hook, from=1-3, to=1-4]
\end{tikzcd}\]

where $a$ is the trivial embedding and $r$ the Riesz isomorphism.

We claim that for $v \in Q(I,V)$, then $(a^*ra v)' = a^*r (av)'$, where $av \in H^1(I,H)$. In fact, for $\phi \in C^\infty_c(I)$, we get $\int_I a^*ra v \phi' = \ind{\cref{prop:bochner_bound}} = a^*r\int_I av\phi' = -a^*r\int_I(av)'\phi =-\int_I a^*r(av)' \phi$.

Now, let $u \in W(I,V)$, with $(a^*ra u)' = a^*r h$, $h \in L^2(I,H)$. Then $ a^*r \int_I h \phi = \ind{\cref{prop:bochner_bound}} = \int_I a^*r h \phi  = \int_I (a^*ra u)' \phi =  a^*r (-\int au \phi')$.

We know that $a^*$ is injective and so is $r$, so that $ \int_I h \phi  = -\int_I au \phi'$ as we wanted.

\underline{Integration by parts}

We note that for $v,w \in Q(I,V)\subseteq W(I,V)$, we have $\int_I \langle (a^*ra v)', w\rangle_{V^*,V} = \int_I \langle a^*r(a v)', w\rangle_{V^*,V} = \int_I((a v)', aw)_H$. We can now apply theorem 3.11 at page 148 of \cite{trol} to conclude that  $\int_I(v_t,w)_H = -\int_I((aw)_t,av)_H +((av)(T),(aw)(T))_H-((av)(0),(aw)(0))_H$

\underline{Weak convergence}

At first we note that $\partial_i, \partial_t$ are linear bounded operators from $Q(I,V)$ to $L^2(I,H)$.

Remember that in any case, $V$ is a closed subspace of $H^1$. Then, $\partial_i : V\rightarrow H$ is linear and bounded, because $V$ is bounded by the full $H^1$ norm, as we declared already.

Therefore, by \cref{lemma:bochner_Hk_map}, $\partial_i$ extends to a linear bounded map from $L^2(I,V)$ to $L^2(I,H)$, therefore, to a linear bounded map on $Q(I,V)	$, in the sense of:

\[\begin{tikzcd}
	{Q(I,V)} & {L^2(I,V)} & {L^2(I,H)}
	\arrow["i", hook, from=1-1, to=1-2]
	\arrow["{\partial_i}", from=1-2, to=1-3]
\end{tikzcd}\]

Because $q_n$ is bounded in the Hilbert space $Q(I,V)$, it has a weakly convergent subsequence $q_k\weakc q \in Q(I,V)$. Therefore, $\partial_i (i(q_k))\weakc \partial_i (i(q))$ in $L^2(I,H)$. By the Hilbert space property of $L^2(I,H)$ we conclude that $(\partial_i q_k,p)_{L^2(I,H)}\rightarrow (\partial_i q,p)_{L^2(I,H)}$ for all $p \in L^2(I,H)$.

For the time derivative we can draw a similar diagram:

\[\begin{tikzcd}
	{Q(I,V)} & {H^1(I,H)} & {L^2(I,H)}
	\arrow["j", hook, from=1-1, to=1-2]
	\arrow["{\partial_t}", from=1-2, to=1-3]
\end{tikzcd}\]

We therefore obtain $(\partial_t q_k,p)_{L^2(I,H)}\rightarrow (\partial_t q,p)_{L^2(I,H)}$ for all $p \in L^2(I,H)$.

The convergence $(q_k,p)_{L^2(I,H)}\rightarrow (q,p)_{L^2(I,H)}$ for all $p \in L^2(I,H)$ follows analogously.

\end{mproof}

We can therefore restrict the testing space.

\begin{prop}[Equivalent testing]
\label{prop:eq_test}
Let $E: W(I,V)\rightarrow L^2(I,V^*)$, and $u\in W_0(I,V)$.

Then:

\begin{align*}
E(u)=0 \\
\iff \\
\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=0 \quad \forall v \in L^2(I,V)\\
\iff \\
\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=0 \quad \forall v \in W^0(I,V)\\
\iff \\
\langle E(u), v\rangle_{L^2(I,V)^*, L^2(I,V)}=0 \quad \forall v \in Q^0(I,V)
\end{align*}

\end{prop}


We have also seen that with smoothness assumption on data (\cref{ass:diri} and \cref{ass:neu}) we obtain that the solutions of \cref{pb:diri}, \cref{pb:neu} have $Q_0(I,V)$ smoothness. 

We can therefore formulate the two partial differential equations directly on $Q_0(I,V)$ as follows.

\begin{align*}
w \in W_0(I, H^1_{0,m}),\bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)\\
w' + A w = (g,\cdot)_{L^2(\Gamma_f)} \text{ in }H^{1*}_{0,m} \text{ and for a.e. } t \in (0,T) \\
v_0' + A v_0 = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) 
\end{align*}

with $\bar{u}$ any given $\bar{u}\in H^1(I,H^1_{0,m})$ such that $\tr \bar{u} =f$ on $\Sigma_f$, and with $\bar{u}(0)=0$.

We are working under \cref{ass:diri}, \cref{ass:neu}.

Thanks to \cref{prop:eq_form}, this is equivalent to:

\begin{align*}
w \in W_0(I, H^1_{0,m}), \bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0) \\
\int_I \langle w' , q\rangle_{H^{1*}_{0,m},H^1_{0,m}}+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I \langle v_0',p\rangle_{H^{-1},H^1_0} + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

By regularity, see \cref{prop:diri_wp}, \cref{prop:wp_neu}, and thanks to \cref{prop:Q} this implies:
\begin{align*}
w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) \\
\int_I ( w' , q)_H+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I (v_0',p)_H + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

where now the derivatives are in the $H^1(I,H)$ sense. Indeed we have proved in \cref{prop:Q} that $u \in W(I,V)$ with $L^2(I,H)$ derivative, is actually $Q(I,V)$, with weak derivative in the $H^1(I,H)$ sense equal to the $L^2(I,H)$ representative of $u'$ in the $W(I,V)$ sense. There, we also proved the representation of the duality bracket.

Conversely, a solution $w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) $ to the above problem satisfies $w \in W_0(I, H^1_{0,m}), \bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)$, see \cref{prop:Q}, and the proof of \cref{prop:diri_wp} . And by \cref{prop:Q} we can get to:

\begin{align*}
w \in W_0(I, H^1_{0,m}), \bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0) \\
\int_I \langle w' , q\rangle_{H^{1*}_{0,m},H^1_{0,m}}+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I \langle v_0',p\rangle_{H^{-1},H^1_0} + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

By \cref{prop:eq_test} we obtain back:

\begin{align*}
w \in W_0(I, H^1_{0,m}),\bar{u}+v_0 \in W_0(I,H^1_{0,m}), v_0 \in W_0(I,H^1_0)\\
w' + A w = (g,\cdot)_{L^2(\Gamma_f)} \text{ in }H^{1*}_{0,m} \text{ and for a.e. } t \in (0,T) \\
v_0' + A v_0 = -((\bar{u}',\cdot)_H+A \bar{u}) \text{ in }H^{-1} \text{ and for a.e. } t \in (0,T) 
\end{align*}

Therefore:

\begin{prop}[Equivalent formulation]
\label{prop:eq_form}

Under \cref{ass:diri}, \cref{ass:neu}, \cref{pb:diri}, \cref{pb:neu} can be equivalently formulated as:

\begin{align*}
w \in Q_0(I, H^1_{0,m}), \bar{u}+v_0 \in Q_0(I,H^1_{0,m}), v_0 \in Q_0(I,H^1_0) \\
\int_I ( w' , q)_H+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_{0,m}) \\
\int_I (v_0',p)_H + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

Existence, uniqueness and stability proved already in  \cref{prop:diri_wp}, \cref{prop:wp_neu} carry over to this new formulation.

\end{prop}

\chapter{Domains transformations}

\section{Transforming domains}

\begin{prop}[Measurability of composition]
\label{prop:circ_wd}

Define $\pazocal{M}:=\{\tau: \mR^n \rightarrow \mR^n \text{ Lebesgue measurable } \}/\sim$, the quotient being the almost everywhere equal relation (according to the Lebesgue measure).

Consider also $U$ from $\pazocal M_c :=\{\tau: \mR^n \rightarrow \mR^n \text{ continuous } \}/\sim$, the application "unique continuous representative", and $\pazocal{M}_{BL} :=\{\tau: \mR^n \rightarrow \mR^n \text{ Lipschitz homeomorphism} \}/\sim \subseteq \pazocal{M}_c$.

We can then define $\circ:  \pazocal{M} \times \pazocal{M}_{BL}, \pazocal{M}_c \times \pazocal{M} \rightarrow \pazocal{M}$ by, respectively, $[f]\circ g := [f\circ U(g)], f \circ [g]:= [U(f)\circ g]$. These definitions are well posed.

\end{prop}
\begin{mproof}

\underline{$\pazocal{M}_c$}

$U(f)$ is Borel measurable, so the preimage of a Borel set is Borel measurable, and $g$ is Lebesgue measurable, so his preimage of such Borel set is Lebesgue measurable (\textcolor{red}{see \href{https://math.stackexchange.com/questions/283443/is-composition-of-measurable-functions-measurable}{here} for the different notions of measurability}).

This shows that $U(f)\circ g$ is measurable.

To complete the well posedness, if $h=g$ a.e., then clearly $U(f)\circ g= U(f)\circ  h$ a.e..

\underline{$\pazocal{M}_{BL}$}

Consider $f\circ U(g)$. We need to prove it is measurable and that is only depends on $[f]$.

For the measurability: the preimage of a Borel set, by $f$, is Lebesgue measurable $L$. $U(g)$ has a Lipschitz inverse, which will map this set to a Lebesgue set. Indeed, $L = B \cup N$, with $B$ Borel and $N$ Lebesgue measurable and null (\textcolor{red}{see \href{https://math.stackexchange.com/questions/3420145/lebesgue-measurable-set-union-of-borel-set-and-null-set}{here}}). Image and unions commute, so, $U(g)^{-1}(L) = U(g)^{-1}(B) \cup U(g)^{-1}(N)$. The first set is Lebesgue measurable by measurability of $U(g)$, the second one is null, because Lipschitz maps map null sets into null sets, see 9.54 at page 271 of \cite{leoni}. 

%Suppose $f,g \in [f]$. Then $f=g$ everywhere but on the null set $E$. Because $\psi \in \cT^1$ we know that $U(\psi)$ is a Lipschitz homeomorphism, so that $U(\psi)^{-1}(E)$ has zero measure by the lemma of Vitali. For the same reason, the composition is measurable, see \cite{murat}, remarque 2.2, page II-7.

\end{mproof}


Throughout, $D$ is a bounded Lipschitz domain. We define as in \cite{murat} the following spaces of transformations:

\begin{defn}[Spaces of transformations]
We define:
\begin{itemize}	
	\item $\cV^k=\{\tau \in \pazocal{M}, \tau-\id \in W^{k,\infty}(\mR^n,\mR^n)\}$, $k\geq 1$
%	\item $\circ: \cV^1 \times \cV^1 \rightarrow \cV^1$ and $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow W^{1,\infty}(\mR^n,\mR^n)$ by $\tau_1\circ\tau_2 = [U(\tau_1)\circ \tau]$, for any $[\tau]=\tau_2$, $[]$ being an equivalence class according to $\sim$.
	\item $\cT^k=\{\tau \in \cV^k \text{ with an } \eta \in \cV^k, \tau \circ \eta = \eta \circ \tau = \id\}$. Any such $\eta$ is unique, we denote it by $\tau^{-1}$ and we have that $U(\tau)$ is a Lipschitz homeomorphism with $U(\tau^{-1})=U(\tau)^{-1}$
\end{itemize} 
\end{defn}

\begin{obs}[A technicality]
 \mbox{}\\
Technically, in the original definition of \cite{murat}, $\tau$ need not to be a continuous function, although this is suggested e.g. in remarque 2.1 at page II-4.  \mbox{}\\

Going to equivalence classes of $\tau$ makes the identification with continuous functions more precise, as we now show.  \mbox{}\\

\underline{One implication} \mbox{}\\

Let $\tau: \mR^n\rightarrow\mR^n$ with $[\tau-\id] \in W^{k,\infty}$. Then $\tau$ is equal a.e. to a (Lebesgue) measurable function, hence also (Lebesgue) measurable, and thus $[\tau] \in \cV^k$ as we have defined it (\textcolor{red}{this is proved \href{https://heil.math.gatech.edu/6337/spring11/section3.4.pdf}{here}; note that $\{g\neq f\}$ is measurable as the Lebesgue measure is complete}). \mbox{}\\

Now, suppose $\tau$ is a bijection, and $[\tau^{-1}-\id] \in W^{k,\infty}$ too. Then $\tau = \id + g = G, \tau^{-1} = \id + h = H$ almost everywhere. Here, $G,H$ are at least Lipschitz.
But then $\tau \circ H = \id $ a.e., and since $H$ is Lipschitz, we can conclude also $G\circ H = \id$ a.e., so, everywhere. With a symmetric reasoning, we are lead to $G=H^{-1}$, so that $G$ is bi-Lipschitz. \mbox{}\\

Thus, $[\tau]\circ [\tau^{-1}]:=[U(\tau)\circ U(\tau^{-1})] = [G\circ G^{-1}] = \id$ and an analogous reasoning leads to $[\tau] \in \cT^k$ as we have defined it. \mbox{}\\

\underline{The other implication} \mbox{}\\

It is immediate for $\cV^k$ and for $\cT^k$, in the equivalence class of $\tau \in \cT^k$ there is a unique $U(\tau)$ at least bi-Lipschitz, hence invertible, with $[U(\tau)]=\tau$. \mbox{}\\

This shows that:

\begin{enumerate}
\item $\{\tau: \mR^n\rightarrow\mR^n$ with $[\tau-\id] \in W^{k,\infty}\} / \sim = \cV^k$
\item $\{\tau: \mR^n\rightarrow\mR^n$ bijection with $[\tau^{\pm 1}-\id] \in W^{k,\infty}\}/\sim = \cT^k$
\end{enumerate}

\end{obs}

We need to check the well-posedness of $\circ$.

\begin{prop}
\label{prop:circ_wd_V}
$\circ: \cV^1 \times \cV^1 \rightarrow \cV^1$ and $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow W^{1,\infty}(\mR^n,\mR^n)$ are well defined.
\end{prop}
\begin{mproof}

We start by $\circ:W^{1,\infty}(\mR^n,\mR^n) \times \cV^1 \rightarrow \cV^1$. We have $\te\circ \tau =[ U(\te)\circ U(\tau)]$ for instance (see \cref{prop:circ_wd}); the latter is a bounded Lipschitz map, so it remains in $W^{1,\infty}$.

For the second claim, just write $\eta \circ \tau -\id = (\eta - \id)\circ \tau + \tau -\id$ and use the first part. 

\end{mproof}


\begin{prop}[Chain rule for $k=1$]
\label{prop:chain}
Let $f \in W^{1,\infty}(\mR^n,\mR^n)$ or $\cV^1$, together with $\psi \in \cT^1$.  Then:

\begin{itemize}

\item $f \circ \psi$ has essentially bounded weak derivatives, and $D(f \circ \psi) = Df \circ \psi D\psi$. The equality holds a.e. also for the classical derivatives.

\item  $D(\psi^{-1}) = (D\psi)^{-1} \circ \psi^{-1}$, where $(D(\psi^{-1}))^{-1}:=[(DU(\psi^{-1}))^{-1}]$, the representative being a.e. invertible. The equality holds a.e. also for the classical derivatives.

\item $|\det(D\psi)|$ is an essentially bounded measurable function with $|\det(D\psi)|\geq \delta>0$ a.e.. 
\end{itemize} 

\end{prop}
\begin{mproof}

\underline{Weak derivatives}

We notice that $f \circ \phi$ has a unique Lipschitz representative, that is $U(f)\circ U(\phi)$. The desired formula follows as in \cite{murat}, lemme 2.1 at page II-6, for the classical derivatives, because Lipschitz function are almost everywhere differentiable by the Rademacher theorem (\tred{see \href{https://abel.math.harvard.edu/archive/212b_spring_05/handouts/Rademacher.pdf}{here}}). The chain rule holds for functions differentiable only at one point. 

% (or from \cite{ziemer}, page 53, theorem 2.2.2 in the case of left composition by $ W^{1,\infty}(\mR^n,\mR^n)$ vector fields) (	\tred{this needs the Rademacher theorem, see \href{https://abel.math.harvard.edu/archive/212b_spring_05/handouts/Rademacher.pdf}{here}. The set of differentiability is measurable, see \cite{leoni}, 9.17}).

Now, to identify the weak derivatives:

\begin{itemize}
	\item $U(f)$ is Lipschitz, so that $DU(f)$, the classical derivative, is also the weak derivative $Df$ (note that $f$ need not to be essentially bounded to state this). The latter is a measurable function, as a.e. limit of difference quotients.
%	\item $DU(f)\circ U(\psi)$,  as pointed out in \cite{murat}, remarque 2.2, page II-7, is measurable. It is also essentially bounded.
	\item $DU(f)\circ U(\psi)$, is measurable, see \cref{prop:circ_wd}. It is also essentially bounded.
	\item By \cref{prop:circ_wd} we observe that $DU(f)\circ U(\psi)$ represents $Df \circ \psi$
	\item $D\psi = [DU(\psi)]$ as seen above
	\item the product of equivalence classes is always defined as the product of their representatives
\end{itemize}

Therefore $ Df \circ \psi D\psi = [DU(f)\circ U(\psi) DU(\psi)]$.

And now, because $f \circ \phi$ is Lipschitz, it has weak derivatives, $D(f \circ \phi)$, equal to the classical derivatives $DU(f\circ \phi) = D (U(f)\circ U(\psi)) = DU(f)\circ U(\psi) DU(\psi)$, where the last equality holds a.e., as mentioned at the beginning of the proof.

This let us conclude the first claim.

\underline{Inverse Jacobian}

For the second one, put $f = \psi^{-1}$. Then, for the classical derivatives, $I = DU(\psi)\circ U(\psi)^{-1} DU(\psi^{-1})$ a.e., so that both $DU(\psi)\circ U(\psi)^{-1}, DU((\psi)^{-1})$ are invertible as matrices, a.e.. 

\underline{Determinant}

We have defined $|\det(D\psi)|:=[|\det DU(\psi)|]$, see \cref{prop:circ_wd}. The claim follows as in lemme 4.2, pag. IV-7 of \cite{murat}, and because $\det$ is a polynomial of essentially bounded functions.

\end{mproof}

We go on to define the space of admissible transformations.

\begin{defn}[Admissible transformations]
\label{def:adm}
We define $\Theta:=\{\theta \in W^{1,\infty}(\mR^n,\mR^n) \text{ with } \theta=0 \text{ on } \mR^n \setminus D\}$, a Banach subspace of $ W^{1,\infty}(\mR^n,\mR^n)$.


We also define $\cT:=\{\tau \in \cT^1, \tau^{\pm 1}|_{\mR^n\setminus D}=\id\}$. 

\end{defn}

\begin{prop}[Some group properties of $\cT$]
\label{prop:group}
Let $\eta, \tau \in \cT, \te \in \Te$. Then:

\begin{itemize}
	\item $\eta \circ \tau \in \cT$
	\item $\te \circ \tau \in \Te$
	\item $\id$ is the neutral element
	\item $\eta^{-1} \in \cT$
\end{itemize}

\end{prop}
\begin{mproof}

%\underline{Stability under composition (regularity)}
%
%We start by showing that $\tau \circ \eta |_D \in W^{2,\infty}$.
%
%%By $\tau \in \cV^1$, we sure have that $\tau \circ \eta \in \cV^1$ by \cref{prop:circ_wd_V}. So, 
%
%$U(\tau)\circ U(\eta)$, is a bounded Lipschitz function. Morevoer $ D(U(\tau)\circ U(\eta)) = D(U(\tau))\circ U(\eta) DU(\eta) $ everywhere in $D$, because $\eta, \tau$ happen to be in $W^{2,\infty}(D)$, so that $U(\eta), U(\tau) \in C^{1,1}(D)$, see \cref{prop:lip}.
%
%This is a product of a bounded Lipschitz function and a bounded Lipschitz function, so it is also bounded Lipschitz. Therefore, $D(U(\tau)\circ U(\eta))\in C^{0,1}(D)$ and thus $U(\tau)\circ U(\eta) \in C^{1,1}_B(D)$, so that by $\cref{prop:lipk}$, $[U(\tau)\circ U(\eta)|_D] = \tau \circ \eta|_D \in W^{2,\infty}(D)$.
%
%This same proof shows that for $\te \in \Te$, $\tau \in \cT$, $\te \circ \tau \in \Te$, because $\te \circ \tau$ was already a $W^{1,\infty}$ function by \cref{prop:circ_wd}, and because $\tau$ fixes $\mR^n \setminus D$.

\underline{Stability under inversion}

It is trivial, because the definition of $\cT$ is symmetric with respect to inversion.

\underline{Stability under composition ($\cT^1$)}

$\eta \circ \tau$ is surely in $\cV^1$ by \cref{prop:circ_wd}. Now, by the above point, $\tau^{-1} \circ \eta^{-1}$ is in $\cV^1$ too, and the composition yields: $(\eta \circ \tau)\circ (\tau^{-1} \circ \eta^{-1}) = [U(\eta)\circ U(\tau)]\circ [(U\tau)^{-1} \circ (U\eta)^{-1}] = \id$.

\end{mproof}

\begin{prop}[Small perturbations of $\cT$]
\label{prop:ptb_id}
Let $\te \in \Te$ with small enough $\norm{\te}_{W^{1,\infty}(\mR^n;\mR^n)}$. Then, $\id+\te\in \cT$.

Let $\delta \te \in \Te$ with small enough $\norm{\delta\te}_{W^{1,\infty}(\mR^n;\mR^n)}$, and $\tau \in \cT$. Then, $\tau + \delta \te\in \cT$.

\end{prop}
\begin{mproof}

\underline{Perturbation of identity}

We only need to check the properties of the inverse map.

$U(\tau)^{-1}$ exists and is Lipschitz, see the proof of lemme 2.4 of \cite{murat}, page II-16. We can therefore define $\tau^{-1}$ and we obtain that it is $\cV^1$. So, $\tau \in \cT^1$. The fact that $\tau = \id$ outside of $D$ automatically implies $\tau^{-1}=\id$ outside of $D$, which can be seen more precisely by going to the smooth representatives of $\tau, \tau^{-1}$.

%Moreover, $D\tau$ is a function in $W^{1,\infty}(D;\mR^{n\times n})$. Because of the Banach algebra properties listed in proposition 2.1 of \cite{murat}, page II-5 (which apply to $D$, just by extending $W^{1,\infty}(D)$ functions to $0$), the theorem of Neumann series holds (for $D\te$!), and by the assumptions on the norm of $\te$ we observe that $D\te$ has a small norm $W^{1,\infty}(D;\mR^{n\times n})$: by $D\tau   = I + D\te$ , we conclude that there is $ S \in W^{1,\infty}(D;\mR^{n\times n})$ with $SD\tau = D\tau S = I$, in the sense of matrix multiplication.
%
%This shows $(D\tau)^{-1} \in W^{1,\infty}(D;\mR^{n\times n})$.
%
%Because $\tau \in \cT^1$, we have from \cref{prop:chain}, that $D\tau^{-1} = (D\tau)^{-1}\circ \tau^{-1}$, so that $D\tau^{-1} $ is the composition of a $W^{1,\infty}(D;\mR^{n\times n})$ by a $\cT$ function. This implies that $\tau^{-1}$ is $W^{2,\infty}(D)$, because $\tau^{-1}$ maps $D$ into $D$.

\underline{Perturbation, not of identity}

We solve the equation $\tau + \delta \te =\eta \circ \tau$, i.e., we define $\eta:=\id + \delta \te \circ \tau^{-1}$. Because $\tau^{-1} \in \cT$ and $\delta \te \in \Te$ we observe that $\delta \te \circ \tau^{-1} \in \Te $, thanks to \cref{prop:group}.

We only need to prove that $\delta \te \circ \tau^{-1}$ is small, and then use the first part. 

But by \cref{prop:chain} this follows immediately. One can alternatively apply point i) of lemme 2.2, \cite{murat}.

\end{mproof}

\begin{thm}{Small perturbations of identity, Lipschitz property}
\label{thm:ptb_id_lip}
Let $U\cc D$ be Lipschitz bounded. There exists $0<C(U)<1$ such that, for $\tau \in W^{1,\infty}(\mR^n;\mR^n)$ and $\norm{\tau - \id}_{W^{1,\infty}(\mR^n;\mR^n)}\leq C(U)$, then $T(U)$ is also bounded Lipschitz, where $T$ is $U(\tau)$, the unique Lipschitz continuous representative of $\tau$ (see \cref{prop:lip}).

This result can be applied to, e.g., $\tau \in \cT$ which is a small perturbation of identity in the $W^{1,\infty}$ topology.
\end{thm}

\begin{mproof}
It is done in \cite{bello}, lemma 3, page 629.
\end{mproof}

%\begin{prop}[Gateaux differentiability]
%Consider $J:\cT \rightarrow E$ for $E$ some Banach space.
%
%Let $\tau \in \cT$. Then:
%
%$$ \forall \delta\te \in \Te \text{ exists } \lim_{t\rightarrow 0}\frac{J(\tau + t \delta\te)-J(\tau)}{t} \iff  \forall \delta\te \in \Te  \text{ exists }\lim_{t\rightarrow 0}\frac{J((\id +t \delta \te)\circ \tau)-J(\tau)}{t}$$
%
%In case of existence, we have:
%
%$$ \lim_{t\rightarrow 0}\frac{J((\id +t \delta \te)\circ \tau)-J(\tau)}{t} = \lim_{t\rightarrow 0}\frac{J(\tau + t \delta \te\circ \tau)-J(\tau)}{t}$$
%
%Note that $\id + t \delta \te \in \cT$ for small $t$.
%
%\end{prop}
%
%\begin{mproof}
%
%It suffices to show that $\Te \circ \tau = \Te$.
%
%In fact, $\delta \te \circ \tau \in \Te$ for $\te \in \Te$, as we verified in \cref{prop:group}. Using the same result, $\tau^{-1} \in \cT$, $(\delta \te \circ \tau ) \circ \tau^{-1}  \in \Te$ and $(\delta \te \circ \tau ) \circ \tau^{-1} = [U(\delta \te)\circ U(\tau)]\circ[U(\tau)^{-1}] = [(U(\delta \te)\circ U(\tau))\circ(U(\tau)^{-1})]=\delta \te$.
%
%\end{mproof}
%

\section{Transforming Sobolev spaces}

\begin{thm}[Change of variables]
\label{thm:change}

Let $U$ be open and $T = U(\tau)$ for $\tau \in \cT^1$, and let $p \in [ 1,\infty]$. Then:

\begin{enumerate}
	\item $f \in L^p(T(U)) \iff f\circ T \in L^p(U)$ and there holds, for $f \in L^p(T(U))$:
	$$ \norm{f}_{L^p(T(Q))}\leq \left ( \norm{\det DT}_{L^\infty(\mR^n)}\right)^{1/p} \norm{f\circ T}_{L^p(Q)}$$
	\item $f \in W^{1,p}(T(U)) \iff f\circ T \in W^{1,p}(U)$ and there holds, for $f\in W^{1,p}(T(U))$:
	$$Df \circ T = (Df)^{-t}D(f\circ T)$$
	$$ \norm{Df}_{L^p(T(Q);\mR^n)}\leq \left ( \norm{\det DT}_{L^\infty(\mR^n)}\right)^{1/p} \norm{(DT)^{-1}}_{L^\infty(\mR^n;\mR^{n\times n})}\norm{D(f\circ T)}_{L^p(Q;\mR^n)}$$
	\item \tred{add the rest of this proposition}
	\item if $p \in (1, \infty)$, $f \in W^{1,p}_0(T(U)) \iff f\circ T \in W^{1,p}_0(U)$
	\item therefore, composition by $T$ is a linear isomorphism between $W^{k,p}(T(U))\rightarrow W^{k,p}(U)$ for $k=0,1$, and between $W^{1,p}_0(T(U))\rightarrow W^{1,p}_0(U)$ for $k=0,1$, $p \in (1, \infty)$
	\item for $D$ a bounded Lipschitz domain and $\cT, \Te$ defined before, we get, for $f \in H^1(D)$, that $\tr f = \tr(f\circ T)$
	\item if moreover, $\Omega, T(\Omega) \cc D$ are also bounded Lipschitz domains, letting $U:=D\setminus \Omega$, another bounded Lipschitz domain, for $f \in H^1(T(U))$ and $\tr_{T(U)} f =0 $ on $ \partial T(\Omega) $, then $\tr_{U} f\circ T=0$ on $\partial \Omega$ and $\tr_{T(U)} f = \tr_{U} f\circ T$ on $\partial D$
	\item so, $\circ T$ is a linear isomorphism of $H^1_{0,m}(U)$ and $H^1_{0,m}(T(U))$ ($H^1_{0,m}$ is defined in \cref{subs:inh_diri} as $\{u \in H^1, u(\Gamma_m)=0$)
\end{enumerate}

\end{thm}

\begin{mproof}

We need to prove only the last points, for the other are proved in \cite{murat}, pages IV.4, IV.5, IV.6.

\underline{Static strace}

To do so, let $f_n \in C(\overline{D})\cap H^1(D)$ converging in $H^1(D)$ to $f$. By point 4, we have $f_n \circ T\rightarrow f\circ T$ in $H^1(D)$ (rememeber, $T(D)=D$ by invertibility of $T$ and the fact that $T(x)=x$ outside of $D$). Therefore we have:

$$\tr f \leftarrow_{L^2(\partial D)}\tr(f_n) = f_n|_{\partial D} = (f_n\circ T)|_{\partial D}= \tr(f_n \circ T)\rightarrow_{L^2(\partial D)} \tr(f \circ T)$$

\underline{Zero moving trace}

First of all, as $T$ is a homeomorphism of $\mR^{n}$, $TU=D\setminus T(\Omega)$, $T\partial U = \partial D \sqcup \partial \Omega$, $T\partial \Omega = \partial T \Omega$.

Now, an application of \cref{thm:ibp} yields that the extension to $0$ in $T\Omega$ of $f$, call it $\bar{f}$, is $H^1(D)$, with $\partial_i \bar{f}=\partial_i f$ in $TU$, $0$ in $T(\Omega)$.

We claim that $\tr_D \bar{f} = \tr_{T(U)} f|_{\partial D}$. In fact, approximate $\bar{f}$ by restrictions to $D$ of $C^\infty_c(\mR^n)$ functions $f_n$ (see theorem 3.18 of \cite{adams}, page 54), which also approximate $f$ on ${T(U)}$, by the observation that $\norm{f_n|_{T(U)}}_{H^1({T(U)})}\leq \norm{f_n|_D}_{H^1(D)}$. Then:

$$\tr_{T(U)}( f_n|_{T(U)})|_{\partial D} = (f_n|_{T(U)})|_{\partial {T(U)}}|_{\partial D} = f_n|_{\partial D} = \tr_D ( f_n|_D ) $$

Now, by what we observed before, $\tr_{T(U)}( f_n|_{T(U)})\rightarrow \tr_{T(U)}(f) $ in $L^2(\partial {T(U)})$, so that $\tr_{T(U)}( f_n|_{T(U)})|_{\partial D} \rightarrow \tr_{T(U)}( f)|_{\partial D}$. On the other hand $\tr_D ( f_n|_D ) \rightarrow \tr_D \bar{f}$, which yields the claim.

Using this: $ \tr_{T(U)}( f)|_{\partial D} = \tr_D \bar{f} = \ind{point 5} = \tr_D(\bar{f}\circ T) = \tr_D(\overline{f \circ T}) = \tr_U (f\circ T)|_{\partial D}$, where we used that $\bar{f}\circ T$ is zero in $T^{-1}T\Omega = \Omega$ (because again $T$ maps null sets into null sets), so it is the zero extension $\overline{f \circ T}$ of $f\circ T$, and applied the same reasoning as above to conclude $\tr_D(\overline{f \circ T}) = \tr_U (f\circ T)|_{\partial D}$. Both $\bar{f}\circ T$ and $f\circ T$ are $H^1$ functions by point 2.

We can now also say that $\tr_U f\circ T=0 $ on $\partial \Omega$.

%In fact, let $\phi \in C^\infty_c(D)$. Then $ \int_D \bar{f}\circ T \phi_{,i} = \int_U  f\circ T \phi_{,i} = \ind{using \cref{thm:ibp}} = \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma -\int_U \partial_i(f\circ T)\phi =  \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma -\int_D \partial_i(\bar{f}\circ T)\phi  =  \int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma +\int_D \bar{f}\circ T \phi_{,i}  $.
%
%It follows that $\int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma = 0$ for all $\phi \in C^\infty_c(D)$. Let now $\phi_n \in C^\infty_c(\mR^n)$ approximate $f\circ T$ in $H^1(U)$ as seen above. Choose a cut-off function $\eta$ that is $1$ in a small neighbourhood of $ \Omega$ and $0$ in the complement of $D$ and a small neighbourhood of $\partial_D$. Then $\eta \phi_n$ is in $C^\infty_c(D)$ and:

$$(\eta \phi_n)|_{\partial \Omega} = \tr_U( \phi_n|_U)_{\partial \Omega} \rightarrow \tr_U(f \circ T)_{\partial \Omega}$$
%
%the limit being in $L^2(\partial \Omega)$. Because  $\eta \phi_n$ is in $C^\infty_c(D)$ we can choose it $\phi$ in $\int_{\partial \Omega}\tr_U(f\circ T) \phi \nu_i d\sigma = 0$, yielding:
%
%$$\int_{\partial \Omega}\tr_U(f\circ T) \phi_n \eta \nu_i d\sigma = 0$$ 
%
%This implies, thanks to the boundedness and measurability of $\nu_i$, that:
%
%$$\int_{\partial \Omega}\tr_U(f\circ T)^2\nu_i d\sigma = 0$$

\underline{Multiplication by a $W^{1,\infty}$ function}

We claim that, for $\psi \in W^{1,\infty}(\mR^n;\mR)$ and $f \in H^1(U)$, then $f\psi$ has the same trace as $f$ as long as $\psi = 1$ in a neighbourhood of $\partial U$.

Note that $f\psi \in H^1(U)$ still. Now: approximate $f$ by restriction of test functions $f_n$. Then $f_n \psi$ is $C(\overline{U})\cap H^1(U)$ (thanks also to \cref{prop:lipk}), so that $\tr_U(f_n\psi) = \tr_U(f_n)$. Because $f_n \psi \rightarrow f \psi$ is $H^1(U)$ the claim is valid.

This last convergence follows from $\norm{(f_n-f)\psi}_{L^2}\leq \norm{(f_n-f)}_{L^2}\norm{\psi}_{L^\infty}$, the chain rule $\partial_i(f_n\psi)=\partial_i f_n \psi + \partial_i \psi f_n$ (see \textcolor{red}{corollary 4.1.18 \href{https://www.math.stonybrook.edu/~joa/PUBLICATIONS/SOBOLEV.pdf}{here}}) and again $\norm{\partial_i(f_n-f)\psi}_{L^2}\leq \norm{\partial_i(f_n-f)}_{L^2}\norm{\psi}_{L^\infty}$, $\norm{(f_n-f)\partial_i\psi}_{L^2}\leq \norm{(f_n-f)}_{L^2}\norm{\partial_i\psi}_{L^\infty}$.

\underline{Reducing to a function of $0$ trace}

Let $\eta$ be a smooth cut-off function which is $1$ close to $\partial D$ and $0$ close to $\partial T\Omega$, $\beta=0$ close to $\partial D$ and $1$ close to $\partial T\Omega$. This can be accomplished by e.g. building a suitable partition of unity of the compact sets $\partial \Omega$ and $\partial D$. (\textcolor{red}{can I do this? Yes, see bachelor's thesis, take $K =\partial \Omega$ etc. Also, be careful with all of these equalities...}).

%Then $\beta + \eta = 1$ on $\partial T(U)$ and thus $\tr_{T(U)} f = \tr_{T(U)} (f(\eta+\beta)) = \tr_{T(U)} f\eta+\tr_{T(U)} f\beta$.

$f\beta$ has zero trace, as it can be verified by approximating $f$ by smooth functions again: 

$$\tr_{T(U)} f\beta \leftarrow_{L^2(\partial T(U))} \tr_{T(U)} f_n \beta $$

where the latter quantity is $\tr_{T(U)} f_n $ on $\partial T(U)$ and $0$ on $\partial D$. By restricting the convergence  to first $\partial D$ and then to $\partial T(U)$, and using almost everywhere convergent subsequences, we conclude that $\tr_{T(U)} f \beta = \tr_{T(U)} f $ on $\partial T(U)$ and  $\tr_{T(U)} f \beta = 0 $ on $\partial D$, i.e.  $f\beta$ has zero trace.

%The same argument yields that $\tr_{T(U)} f \eta = \tr_{T(U)} f $ on $\partial D$ and  $\tr_{T(U)} f \eta = 0 $ on $\partial T(U)$.
%
%Hence $\tr_{T(U)} f |_{\partial T(U)}= \tr_{T(U)} f\beta |_{\partial T(U)}$, with $f\beta$ of zero trace on $T(U)$. 

\underline{Domain transformation}

But zero trace functions in $H^1(T(U))$, since $T(U)$ is assumed to be bounded Lipschitz, are exactly the functions $H^1_0(T(U))$ (theorem 18.7 at page 595 of \cite{leoni}).

By then point 4, $(f\beta)\circ T \in H^1_0(U)$.

Because $T$ is bi-Lipschitz, we can write $(f\beta)\circ T = f \circ T \beta \circ T$ almost everywhere.

We have that $\beta \circ T +  \eta \circ T$ is $W^{1,\infty}$ and $1$ near $\partial U$. 

So, $\tr_U f\circ T = \tr_U f\circ T(\beta \circ T +  \eta \circ T) = \tr_U (f\circ T\beta \circ T) + \tr_U (f\circ T  \eta \circ T)$.

Approximate $f\circ T$ by $g_n$ smooth as seen above.  Then, $\tr_U (g_n \eta \circ T)$ is $0$ on $\partial \Omega$ and $\tr_U g_n$ on $\partial D$. By selecting an almost everywhere convergent subsequence, we conclude $\tr_U (f\circ T \eta \circ T) = 0$ on $\partial \Omega$. 

Hence  $\tr_U f\circ T|_{\partial \Omega} = tr_U f\circ T(\beta \circ T)|_{\partial \Omega} = 0$.

\end{mproof}

%We need to define the pullback of functionals. 
%
%\begin{ass}[Defining pullbacks]
%\label{ass:pull}
%
%Throughout, $\Omega\cc D$ is another bounded Lipschitz domain, and we assume $\tau \in \cT$ preserves this property, i.e., that $T (\Omega) $ is also bounded Lipschitz, $T=U(\tau)$.
%
%We denote by $V$ either $H^1_0(U)$ or $H^1_c(U)$ (see \cref{subs:inh_diri} for the definition of this space, and by $V_T$ either  $H^1_0(T(U))$ or $H^1_c(T(U))$.
%\end{ass}
%
%\begin{prop}[Pullback]
%\label{prop:pull}
%
%Under \cref{ass:pull}, let $F \in V_T^*$. We define $F\circ T \in V^*$ by:
%
%$$\langle F, v\rangle_{V^*_T,V_T} = \langle F\circ T , |\det(DT)| v\circ T\rangle_{V^*,V}$$
%
%The definition is well posed.
%
%Moreover:
%\begin{itemize}
%\item the maps $V\rightarrow V$, $w\mapsto w|\det(DT)|$, and $S_T: V_T\rightarrow V$, $v \mapsto |\det(DT)| v\circ T$ are linear isomorphisms
%\item taking pullbacks, seen as a map $P_T: V_T^*\rightarrow V^*$, is linear and bounded
%\item we have $P_T = S_T^{-*}$, so that taking pullbacks is also a linear isomorphism
%
%\end{itemize}
%
%
%\end{prop}
%\begin{mproof}
%
%\underline{Existence by density}
%
%Let $H_T \ni f_n \rightarrow F$ in $V_T^*$, possible by density of $H_T=L^2(T(U))$ in $V_T^*$.
%
%By \cref{thm:change} we observe that $g_n:=f_n\circ T \in H$ is Cauchy in $V^*$. In fact:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V}  = \int_U (g_n-g_m)w =\ind{change of variables} = \\
%\int_{T(U)} (f_n-f_m)w\circ T^{-1} |\det(D(T^{-1}))| = \\
%\langle f_n-f_m ,  w\circ T^{-1} |\det(D(T^{-1}))| \rangle_{V^*_T,V_T} 
%\end{align*}
%
%We have to prove that $w\circ T^{-1} |\det(D(T^{-1}))| \in V_T$. We start by showing that $|\det(D(T^{-1}))| \in W^{1,\infty}(D)$. Because $\tau \in \cT$, then $\det(D(T^{-1}))\in W^{1,\infty}(D)$, as a product of $W^{1,\infty}(D)$ functions, because we have $\tau^{-1}|_D \in W^{2,\infty}(D)$ (i.e. a product of bounded Lipschitz functions, hence, still bounded Lipschitz, see \cref{prop:lip}). And now, the absolute value of a $W^{1,\infty}(D)$ function, is still $W^{1,\infty}(D)$, because the absolute value preserve the Lipschitz continuity, and the boundedness.
%
%Also, $W^{1,\infty}\subseteq H^1$, so that $w\circ T^{-1} |\det(D(T^{-1}))| \in H^1(T(U))$. For the traces, we know by \cref{thm:change} that $w\circ T^{-1} \in V_T$. Suppose e.g. that $\tr(w\circ T^{-1})=0$ on $\partial T(U)$. Approximate $w\circ T^{-1}$ by $v_n$ smooth to conclude that  $\tr (w\circ T^{-1} |\det(D(T^{-1}))|) = \tr(w\circ T^{-1})\cdot  |\det(D(T^{-1}))|$. Here we have used that a $C^{0,1}_B$ function can be extended by continuity to the boundary, in view of its uniform continuity. This shows that $w\circ T^{-1} |\det(D(T^{-1}))| \in V_T$.
%
%Thus:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V} \leq \\
%\norm{f_n-f_m }_{V^*_T}\norm{  w\circ T^{-1} |\det(D(T^{-1}))| }_{V_T} 
%\end{align*}
%
%Call $d:=|\det(D(T^{-1}))| \in W^{1,\infty}(D)$. By the product rule we get $\norm{D( w\circ T^{-1} d)}_{L^2(T(U))}^2\leq \sum_i \left( \norm{d}_{L^\infty(D)}^2 +\norm{\partial_i d}_{L^\infty(D)}^2\right )^2 \norm{D(w\circ T^{-1})}_{V_T}^2$, which means that:
%
%\begin{align*}
%\langle g_n-g_m ,  w \rangle_{V^*,V} \leq \\
%C(T)\norm{f_n-f_m }_{V^*_T}\norm{w\circ T^{-1} }_{V_T} \leq\\
%C(T)\norm{f_n-f_m }_{V^*_T}\norm{w}_{V}
%\end{align*}
%
%where we used \cref{thm:change} in the last passage. Hence also $g_n$ is Cauchy in the Banach space $V^*$ and we can thus conclude the existence of $G \in V^*$ such that $g_n\rightarrow G$ in $V^*$.
%
%And now:
%
%\begin{align*}
%\langle f,  v \rangle_{V^*_T,V_T} = \lim \langle f_n,  v \rangle_{V^*_T,V_T} = \\
%\lim( f_n,v)_{H_T} =\ind{change of variables} =\\
%\lim( g_n,v\circ T |\det(DT)|)_{H} = \\
%\lim\langle g_n, v\circ T |\det(DT)| \rangle_{V^*,V} = \\
%\langle G, v\circ T |\det(DT)| \rangle_{V^*,V}
%\end{align*}
%
%where we used the fact that $v\circ T |\det(DT)| \in V_T$, in complete analogy with the above reasonings.
%
%\underline{Well posedness}
%
%So, $\langle F,  v \rangle_{V^*_T,V_T} = \langle G, v\circ T |\det(DT)| \rangle_{V^*,V}$.
%
%$|\det(DT)|$ is represented by $d \in C^{0,1}_B(D)$. In \cref{prop:chain} we saw $C\geq d\geq \delta >0$ almost everywhere in $\mR^n$. The inequality holds everywhere on $D$, by continuity of $d$. Then $1/d$ is bounded and Lipschitz, as we can verify by:
%
%$$\left | \frac{1}{d(x)}-\frac{1}{d(y)}\right |=\left| \frac{d(x)-d(y)}{d(x)d(y)}\right |\leq \delta^{-2}C|x-y|$$
%
%Therefore, multiplication by $d$ is a bijection of $V$ (a linear isomorphism actually, we already proved the boundedness, and the boundedness of the inverse follows from the bounded inverse theorem).
%
%Assume there exists another $G_2$ satisfying $\langle F,  v \rangle_{V^*_T,V_T} = \langle G_2, v\circ T |\det(DT)| \rangle_{V^*,V}$.
%
%Then  $\langle G_2-G, v\circ T |\det(DT)| \rangle_{V^*,V} = 0$ for all $v \in V_T$. Because $\circ T$ is another bijection, we can conclude  $\langle G_2-G, w \rangle_{V^*,V} = 0$ for all $w \in V$, which yields the uniqueness.
%
%\underline{Boundedness}
%
%Also, $S_T: V_T \rightarrow V$ defined by $S_Tv = |\det(DT)|v\circ T$ is a linear isomorphism, as a composition of linear isomorphism (see also \cref{prop:chain}). 
%
%Therefore:
%
%$$\langle F, v\rangle_{V^*_T,V_T} = \langle F\circ T , S_Tv\rangle_{V^*,V} =  \langle S_T^*(F\circ T), v\rangle_{V^*,V}$$
%
%This shows that $S_T^{-*}F=F\circ T = P_T F$, and this concludes the proof.
%		
%%Now, $w\circ T^{-1} \in V_T$ by \cref{thm:change}. We can also say that $|w \circ T^{-1} |\in V_T$, with $\norm{|w \circ T^{-1}|}_{V_T}\leq \norm{w \circ T^{-1}}_{V_T}$ (\tred{see \href{https://math.stackexchange.com/questions/2578760/if-u-in-h1-omega-then-u-in-h1-omega}{here} for the bound on the gradient, or \href{https://www.math.ucdavis.edu/~hunter/pdes/ch3.pdf}{here, prop. 3.22}}).
%%
%%In fact, absolute value preserves zero traces. To see this, suppose that $\tr f = 0$ on $\partial \Omega$. Then, as in the proof of \cref{thm:change}, $\tr |f| |_{\partial \Omega} = \tr(|f|\beta)|_{\partial \Omega}$, $\beta$ smooth, $1$ close to $\partial \Omega$ and $0$ close to $\partial D$. Approximating $|f_n|$ by smooth functions we see that: $\tr(|f|\beta)$
%
%\end{mproof}

\section{Transforming Bochner spaces}

\begin{prop}[Isomorphism between $Q$ spaces]
\label{prop:change_boch}

$$\circ T : Q(I,V_T)\rightarrow Q(I,V)$$

is a linear isomorphism, and so is:

$$\circ T : Q_0(I,V_T)\rightarrow Q_0(I,V)$$

In particular, $(u\circ T)' = u'\circ T$ (under suitable identifications, see the proof).

\end{prop}

\begin{mproof}

\underline{Existence of derivative}

Consider the following commutative diagram:

\[\begin{tikzcd}
	{V_T} & {H_T} & {H_T^*} & {V^*_T} \\
	V & H & {H^*} & {V^*}
	\arrow["{a_T}", hook, from=1-1, to=1-2]
	\arrow["{r_T}", from=1-2, to=1-3]
	\arrow["{a_T^*}", hook, from=1-3, to=1-4]
	\arrow["r", from=2-2, to=2-3]
	\arrow["a^*", hook, from=2-3, to=2-4]
	\arrow["a", hook, from=2-1, to=2-2]
	\arrow["{\circ T_H=:t_V}"', from=1-1, to=2-1]
	\arrow["{\circ T_H=:t_H}", from=1-2, to=2-2]
\end{tikzcd}\]

We know that $f\in Q(I,V_T)$ satisfies $a_Tf \in H^1(I,H_T)$. Therefore, by \cref{lemma:bochner_Hk_map}, $t_H a_T f =a t_V f \in H^1(I,H)$, and $t_v  \in L^2(I,V)$, so that $t_V : Q(I,V_T)\rightarrow Q(I,V)$ is well defined.

\underline{Boundedness}

We have that $t_V: V_T \rightarrow V$ is linear bounded, so that $t_V: L^2(I,V_T)\rightarrow L^2(I,V)$ is also linear and bounded. Still by \cref{lemma:bochner_Hk_map}, we have $(a t_V f )' = (t_H a_T f)' = t_H(a_T f)'$.

Thus $\norm{t_V f}_{L^2(I, V)}\leq C(T) \norm{f}_{L^2(I, V_T)}$, together with $\norm{(a t_V f )'}_{L^2(I, H)}\leq C(T) \norm{(a_T f)'}_{L^2(I, H_T)}$.

By noting that $(t_V)^{-1} = (\circ T)^{-1} $ is bijective, and by the bounded inverse theorem:

$$\circ T : Q(I,V_T)\rightarrow Q(I,V)$$

is a linear isomorphism.

\underline{Zero initial value}

Consider $at_V f$. It has a unique $C([0,T],H)$ representative, $U(at_V f)$. Also, $a_T f$ has a unique continuous representative $U(a_T f)$. Now, $at_V f = t_H a_T f$, so that $[U(at_V f)] = [t_H U(a_T f)]$. By continuity, $U(at_V f) = t_H U(a_T f)$ on $[0,T]$ and thus, whenever $U(a_T f)(0)=0$, so is $U(at_V f)$, informally, also $t_Vf (0) =0$. 

So, $t_V(Q_0(I,V_T))\subseteq Q_0(I,V)$.

$(t_V)^{-1} = (\circ T)^{-1}$ and we can conclude that  $t_V^{-1}(Q_0(I,V))\subseteq Q_0(I,V_T)$.

\end{mproof}


\section{Transforming partial differential equations}

We consider again the two parabolic equations of interest, namely, \cref{pb:diri} and \cref{pb:neu}.

We continue from \cref{prop:eq_form}.

\begin{align*}
w \in Q_0(I, H^1_{0,m}), v_0 \in Q_0(I,H^1_0) \\
\int_I ( w' , q)_H+ (\nabla w, \nabla q)_H = \int_I(g,\tr q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, H^1_c) \\
\int_I (v_0',p)_H + (\nabla v_0, \nabla p)_H= -\int_I(\bar{u}',p)_H+(\nabla \bar{u}, \nabla p)_H, \quad \forall p \in Q^0(I, H^1_0) 
\end{align*}

We are working under the assumption:

\begin{ass}
\label{ass:pull}

We have $T=U(\tau), \tau \in \cT$, $U\cc D$ bounded Lipschitz domains and we also assume that $T(U)$ is bounded Lipschitz.
\end{ass}

Suppose the problem is formulated on $T(U)$. To ease the notation, call $H^1_{0,m}(T(U))=\tw{W}_T, H^1_{0,m}(U)=\tw{W}, H^1_0(U)=\tw{V}$ and analogously for the other spaces.

We write the problem as:

\begin{align*}
w^T \in Q_0(I, \tw{W}_T), v_0^T \in Q_0(I,\tw{V}_T) \\
\int_I  (w^T_t , q)_{H_T}+ (\nabla w^T, \nabla q^T)_{H_T} = \int_I(g,\tr_{T(U)} q^T)_{L^2(\Gamma_f)}, \quad \forall q^T \in Q^0(I, \tw{W}) \\
\int_I (v^T_{0t},p)_{H_T} + (\nabla v_0^T, \nabla p^T)_{H_T}= -\int_I(\bar{u}',p^T)_{H_T}+(\nabla \bar{u}, \nabla p^T)_{H_T}, \quad \forall p^T \in Q^0(I, \tw{V}_T)
\end{align*}

Applying a change of variables, we get equivalently:

\begin{align*}
w^T \in Q_0(I, \tw{W}_T), v_0^T \in Q_0(I,\tw{V}_T) \\
\int_I (w^T_t\circ T, q^T\circ T |\det(DT)|)_H+ (A_T\nabla (w^T\circ T), \nabla( q^T\circ T))_{H} =\\ \int_I(g,\tr_{T(U)} q^T)_{L^2(\Gamma_f)}, \quad \forall q^T \in Q^0(I, \tw{W}_T) \\
\int_I(v_{0t}^T\circ T,p^T\circ T |\det(DT)|)_H + (A_T \nabla (v_0^T\circ T), \nabla( p^T\circ T))_{H}=\\ -\int_I((\bar{u}')\circ T,p^T\circ T |\det(DT)|)_{H}+(A_T \nabla (\bar{u} \circ T), \nabla (p^T\circ T))_{H}, \quad \forall p^T \in Q^0(I, \tw{V}_T)
\end{align*}

Here $A_T = |\det(DT)|DT^{-1}(DT)^{-t}$.

Now, we note that:

\begin{itemize}
	\item $\tr_{T(U)} q = \tr_U(q\circ T)$ on $\Sigma_f$ by \cref{thm:change}
	\item $w_t^T\circ T = (w^T\circ T)_t$ by the proof of \cref{prop:change_boch} and analogously for $v_0$
	\item by \cref{prop:change_boch},$\circ T$ is a bijection between $Q^0(I,\tw{W}_T)$ and $Q^0(I,\tw{W})$ and analogously for $\tw{V}$
	\item $\bar{u} \in H^1(I,\tw{W}_T)$ and that $\bar{u}'$ denoted the weak derivative in the $H^1(I,\tw{W}_T)$ sense, so that \cref{prop:bochner_bound} yields $\bar{u}\circ T \in H^1(I,\tw{W})$ and $(\bar{u}\circ T )' = \bar{u}'\circ T $
\end{itemize}

We therefore get, equivalently:

\begin{align*}
w^T \in Q_0(I, \tw{W}_T), v_0^T \in Q_0(I,\tw{V}_T) \\
\int_I ( (w^T\circ T)_t , q |\det(DT)|)_H+ (A_T\nabla (w^T\circ T), \nabla q)_{H} =\\ \int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( (v_0^T\circ T)_t,p |\det(DT)|)_H + (A_T \nabla (v_0^T\circ T), \nabla p)_{H}=\\ -\int_I((\bar{u}\circ T)',p|\det(DT)|)_{H}+(A_T \nabla (\bar{u} \circ T), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}

and by \cref{prop:change_boch}, we also get $w^T\circ T \in Q_0(I,\tw{W}), v_0^T\circ T \in Q_0(I,\tw{V})$.

%\tred{Note, here one could absorb $\det$ into the test functions, complicate the PDE but get rid of the time coefficients. From here one could prove a continuity result for the states and then get Fréchet differentiability from Gateaux differentiability}.

On the other hand, consider:

\begin{align*}
w \in Q_0(I, \tw{W}), v_0 \in Q_0(I,\tw{V}) \\
\int_I ( w_t , q |\det(DT)|)_H+ (A_T\nabla w, \nabla q)_{H} =\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( v_{0t},p |\det(DT)|)_H + (A_T \nabla v_0, \nabla p)_{H}=\\ -\int_I((\bar{u}\circ T)',p|\det(DT)|)_{H}+(A_T \nabla (\bar{u} \circ T), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}

Then, we note the following:

\begin{itemize}
	\item by \cref{prop:change_boch}, $w\circ T^{-1} \in Q_0(I, \tw{W}_T), v_0\circ T^{-1} \in Q_0(I,\tw{V}_T) $, and as seen above, $((w\circ T^{-1})\circ T)_t = (w\circ T^{-1})_t\circ T$ and the same goes for $v_0\circ T^{-1}$
\end{itemize}

Therefore we obtain, equivalently:

\begin{align*}
w\circ T^{-1} \in Q_0(I, \tw{W}_T), v_0\circ T^{-1} \in Q_0(I,\tw{V}_T) \\
\int_I ((w\circ T^{-1})_t , q^T)_{H_T}+ (\nabla (w\circ T^{-1}), \nabla q^T)_{H_T} = \\\int_I(g,\tr_{T(U)} q^T)_{L^2(\Gamma_f)}, \quad \forall q^T \in Q^0(I, \tw{W}_T) \\
\int_I ((v_0\circ T^{-1})_t,p^T)_{H_T} + (\nabla (v_0\circ T^{-1}), \nabla p^T)_{H_T}= \\-\int_I(\bar{u}',p^T)_{H_T}+(\nabla \bar{u}, \nabla p^T)_{H_T}, \quad \forall p^T \in Q^0(I, \tw{V}_T)
\end{align*}

and $w\circ T^{-1} \in Q_0(I, \tw{W}_T), v_0\circ T^{-1} \in Q_0(I,\tw{V}_T)$.

These findings can be summarized as follows.

\begin{thm}[Equivalent formulations with transported domain]
\label{thm:eq_pde}

Let \cref{ass:diri}, \cref{ass:neu}, \cref{ass:pull} hold.

Consider the following problems, where again, $T$ is the unique Lipschitz representative of $\tau \in \cT$.

\begin{pb}[Joint parabolic problem, moving domain]
\label{pb:joint_mov}
\begin{align*}
w^T \in Q_0(I, \tw{W}_T), v_0^T \in Q_0(I,\tw{V}_T) \\
\int_I  (w^T_t , q^T)_{H_T}+ (\nabla w^T, \nabla q^T)_{H_T} = \int_I(g,\tr_{T(U)} q^T)_{L^2(\Gamma_f)}, \quad \forall q^T \in Q^0(I, \tw{W}_T) \\
\int_I (v^T_{0t},p^T)_{H_T} + (\nabla v_0^T, \nabla p^T)_{H_T}= -\int_I(\bar{u}',p^T)_{H_T}+(\nabla \bar{u}, \nabla p^T)_{H_T}, \quad \forall p^T \in Q^0(I, \tw{V}_T)
\end{align*}
\end{pb}

\begin{pb}[Joint parabolic problem, reference domain]
\label{pb:joint_ref}
\begin{align*}
w \in Q_0(I, \tw{W}), v_0 \in Q_0(I,\tw{V}) \\
\int_I ( w_t , q |\det(DT)|)_H+ (A_T\nabla w, \nabla q)_{H} =\int_I(g,\tr_{U} q)_{L^2(\Gamma_f)}, \quad \forall q \in Q^0(I, \tw{W}) \\
\int_I ( v_{0t},p |\det(DT)|)_H + (A_T \nabla v_0, \nabla p)_{H}=\\ -\int_I((\bar{u}\circ T)',p|\det(DT)|)_{H}+(A_T \nabla (\bar{u} \circ T), \nabla p)_{H}, \quad \forall p \in Q^0(I, \tw{V})
\end{align*}
\end{pb}

We have the following:

\begin{itemize}
	\item consider $w^T \in Q_0(I, \tw{W}_T), v_0^T \in Q_0(I,\tw{V}_T)$. They solve \cref{pb:joint_mov} $\iff$ $w^T\circ T , v_0^T\circ T $ solve \cref{pb:joint_ref}
	\item consider $w \in Q_0(I, \tw{W}), v_0^T \in Q_0(I,\tw{V})$. They solve \cref{pb:joint_ref} $\iff$ $w\circ T^{-1}, v_0\circ T^{-1}$ solve \cref{pb:joint_mov} 

\end{itemize}

Here, $A_T:=  (DT)^{-1}(DT)^{-t}|\det(DT)|$.

\end{thm}

\chapter{Inhomogenous FEM on smooth domains}
\label{chap:inh_fem}
Handling smooth geometries in finite element analysis is not a trivial task. On one hand, finite element discretization is naturally done on polygonal/polyhedral domains, whereas the solution smoothness required to obtain optimal order error estimates, can only be achieved with a smooth boundary (or more generally, when $U$ is convex, which it isn't, in our case). An apparent contradiction therefore arises, and many authors simply conduct theoretical analysis on the polyhedral domains, but assuming enough smoothness of the solutions (this is the contradiction of "polygonal smooth" domains, mentioned in \cite{tiihonen}): an example of this in a setting close to ours, is contained in \cite{paganini}. 

There are few different ways to go about this dilemma, many of them are only a partially satisfactory answer to the problem. For instance, finite elements formulated directly on arbitrarily curved simplices have been studied, see \cite{zlamal}. This requires complete knowledge of the (curved) boundary of the computational domain. Optimal order estimates are also observed in \cite{bramble}. Their techniques work with smooth and rough data, but also require complete knowledge of a parametrization of the boundary, and are not easily extendable to a dimension higher than $2$. Interestingly, shape optimization techniques can be applied to analyze the discrepancy between discrete and smooth geometry in the solution process, see \cite{tiihonen}: the techniques therein presented only yield optimal order estimates in the $H^1$ norm.

The presence of Dirichlet boundary conditions further complicates the analysis. The Dirichlet values might be imposed strongly, i.e. enforced at the boundary nodes, or weakly (see e.g. \cite{chiba} for the elliptic case, or, more generally, the discussion in \cite{chouly}, and that in \cite{benner} for the parabolic case). The latter solution is viable only if one can extend to the whole volume the boundary data.

We chose the approach that was the least intrusive possible with regards to the exact geometry and data: it only requires the knowledge of the smooth domain and boundary data at some points of the smooth boundary. It is straightforward to implement, both from a meshing point of view and from a finite element code point of view. Standard meshing tools can be used without modification, GMSH being our choice (\cite{gmsh}), and powerful finite element libraries can be directly used to simulate the partial differential equations, we used Fenics (\cite{fenics}).

In short, the discrete solution is computed on a polygonal/polyhedral approximation $\Omega_h$ of the smooth domain $\Omega$, where the nodes of $\partial \Omega_h$ lie on $\partial \Omega$, and the Dirichlet conditions are imposed strongly. The boundary data is substituted by its Langrange interpolant, thus requiring its knowledge only on the boundary nodes of $\partial \Omega_h$.

The drawback is that we require "unnatural" smoothness to the boundary data, because we evaluate it pointwise ("unnatural" is compared to he hypothesis necessary to obtain $H^2$ regularity in the elliptic case, i.e. $H^{1/2}$ smoothness for Neumann data and $H^{3/2}$ smoothness for Dirichlet data: we will require both to be $H^2$ on the boundary). Such surplus of smoothness is however present in virtually all other works that analyze the change in geometry in detail. Strong imposition of Dirichlet boundary conditions, on the other hand, may not me the best solution for all PDEs, see e.g. \cite{hughes}.

The approach we took is based on the work of \cite{elliott}, \cite{ranner}, \cite{bernardi} and \cite{edelmann}.

We mention that one might alternatively solve the PDEs resulting from shape optimization, on the reference domain, rather than on the moving domain. This however complicates the variational formulation, and in the case of more difficult equations (more than a Poisson, or a heat equation in our case), already existing high performance solvers may be unavailable.

\textcolor{red}{	please make precise the mesh assumptions}

\section{Elliptic problems}

We consider a finite element method for approximating problems of the following form.

\begin{ass}[Basic assumptions for elliptic problems]
\label{ass:inh_ell}
Consider $\Omega \subseteq \mR^n$, $n=2,3$, with $C^2$ boundary, and data $f \in L^2(\Omega), g_D \in H^{3/2}(\Gamma_D), g_N \in H^{1/2}(\Gamma_N)$, where $\Gamma_D \sqcup \Gamma_N = \partial \Omega$ and $\overline{\Gamma_D}\cap \overline{\Gamma_N}=\emptyset$. We assume $\Gamma_D$ to be non-empty.

\end{ass}

\begin{pb}[Inhomogeneous elliptic problem]
\label{pb:inh_elliptic}

Under \cref{ass:inh_ell}, the problem is:

$$
\left\{\begin{matrix}
-\Delta u + k u = f & \text{ on } \Omega \\ 
u = g_D & \text{ on } \Gamma_D \\ 
\partial_\nu u = g_N & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

where $k \geq 0$ is a constant.

By this we mean to find $u \in H^1(\Omega)$ with:

$$a(u,v) = l(v), \text{ for all } v \in H^1_{0,D}$$

where $a(u,v) =\ds \int_{\Omega}\nabla u \nabla v + k \int_{\Omega} u  v$, and $l(v) = \ds\int_{\Omega}f v + \int_{\Gamma_N} g_{N}v$ and $H^1_{0,D}$ is the space of all $H^1$ functions with vanishing trace on $\Gamma_D$.

\textcolor{red}{Add existence, uniqueness, regularity}

\end{pb}

%4.1, for an explanation), ?? TODO

We define a polygonal/polyhedral meshing $\Omega_h$ (open) of $\Omega$, which has boundary nodes on $\partial \Omega$. We denote by $\Gamma_{D_h}, \Gamma_{N_h}$ the discrete Dirichlet and Neumann boundaries, and by $S^1_{h,0,D_h} $ the space of piecewise linear lagrangian FEM $S^1_h$ which are zero on $\Gamma_{D_h}$.

We collect some useful tools to relate $\Omega$ and $\Omega_h$.

\begin{prop}[Deformation into smooth boundary]
\label{prop:G_h}
Assume we have a quasi-uniform mesh. There exists, for $h$ small enough, $G_h: \overline{\Omega_h} \rightarrow \overline{\Omega}$ satisfying:

\begin{itemize}
	\item $G_h|_T = \id$ on interior simplices $T$ (those with at most one node on $\partial \Omega$)
	\item $G_h(\partial \Omega_h) = \partial \Omega$, $G_h|_e=p$, where $e$ is an edge/face of $\partial \Omega_h$ and $p$ is the closest point operator to $\partial \Omega$ (so that $G_h|_{\partial \Omega_h}$ coincides with the boundary lift in Definition 4.12 of \cite{elliott})
	\item $G_h$ is bi-Lipschitz, with $\norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}\lesssim h$, and $\norm{|\det(DG_h)|-1}_{L^\infty(\Omega_h)}\lesssim h$
	\item given $G_h(K)$, all the facets are at least $C^1$ smooth
	\item $G_h|_T$ is of class $C^1(T)$ for all closed simplices $T$ composing $\Omega_h$
\end{itemize}

\end{prop}
\begin{mproof}

\textcolor{red}{This proof is lacking a bound on the quasiconvexity constant and the fact that $G_h$ is surjective}

See section 4.1 of \cite{elliott} for the first two points, which follow from the definition of $G_h$. See also Lemma 8.16 of \cite{ranner}.

The last one is contained in Lemma 8.12, \cite{ranner}. We give more detail for the third and fourth points \textcolor{red}{which is not addressed in \cite{ranner}, \cite{elliott}}.

\underline{$G_h$ is a bi-Lipschitz homeomorphism}

We first note that $G_h|_K$ agrees with $G_h|_{K'}$ for $K\cap K' \neq \emptyset$. Therefore $G_h$ is continuous on $\overline{\Omega_h}$.

Then, we also note that $G_h$ has $DG_h \in L^\infty(\Omega_h)$ as weak derivative, where the gradient is defined element-wise. To see this, pick $\phi \in C^\infty_c(\Omega_h)$.

Then, applying \cref{thm:ibp}:
$$\int_{\Omega_h} G_h \partial_i \phi = \sum_K \int_{\partial K}G_h|_{K} \phi \nu_{K,i}  - \int_{\Omega_h}\partial_i G_h \phi$$

The first integral on the right is zero, because $G_h$ is continuous, the normal on the same interior facet is equal of opposite sign when referred to the two parent simplices it belongs to, and because $\phi=0$ on exterior facets.

Thus, $G_h \in W^{1,\infty}(\Omega_h)$, and Lemma 8.12 of \cite{ranner} shows that $\norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}\lesssim h$. Thanks to \cref{prop:lip}, we obtain that $G_h$ has a bounded Lipschitz representative, i.e., $G_h$ is bounded and Lipschitz on $\Omega_h$.Then $G_h$ is Lipschitz on all of $\overline{\Omega_h}$, and $\text{Lip}(\id -G_h) \lesssim  \norm{\id -G_h}_{W^{1,\infty}(\Omega_h)}$. (\textcolor{red}{This is not trivial: one could use quasiconvexity a sin Heinonen, and then bound the quasiconvexity constant uniformly})

So, $G_h$ is a Lipschitz perturbation of identity, on $\overline{\Omega_h}$.  An application of the reverse triangle inequality also shows that $|G_h(x)-G_h(y)|\geq (1-\text{Lip}(G_h))|x-y|$, which shows that $G_h$ is bijective (for small $h$), with a Lipschitz inverse.

%By compactness arguments, we see that it is a closed map $\overline{\Omega_h}\rightarrow\overline{\Omega}$.


\underline{Smooth facets of curved simplex}

From the last point we know that $G_h$ is of class $C^1$ when restricted to $K$, a closed simplex. By Whitney's extension theorem on simplices (see \cite{whitney}) we can conclude that $G_h|_K$ extends to a $C^1$ function on a neighbourhood of $K$. This extension is injective on $K$ as we saw before, and by Lemma 8.16 of \cite{ranner} (the determinant of $G_h$ is small), it has invertible jacobian on $K$. An application of a global version of the inverse function theorem (see e.g. \cite{pollack}, chapter 1 \textcolor{red}{and wikipedia}) yields that $G_h$ extends to a $C^1$ diffeomorphism around $K$, so that the smoothness of $\partial K$ follows.

\end{mproof}

Given $G_h$, we can define pullbacks and pushforwards of functions defined on $\Omega$ or $\Omega_h$.


\begin{prop}[Lift]
\label{prop:lift}
We define, for $u: \Omega \rightarrow \mR$, $u^{-l}:=u\circ G_h : \Omega_h \rightarrow \mR$, and analogously for $u_h: \Omega_h \rightarrow \mR$ we define $u_h^l:=u_h\circ G_h^{-1}$. We also need the mesh to be quasi-uniform (see proposition 4.7 of \cite{elliott}).

There holds:

\begin{itemize}
	\item if $v\in H^m(Q)$ if and only if $v^{-l} \in H^m(G_h(Q))$, for $m=0,1$, and $Q\subseteq \Omega_h$ open
%	\item for $v_h \in S^1_{h}$, we have $v_h^l \in H^1(\Omega)$
	\item for $v_h \in S^1_{h,0,D_h}$, we have $v_h^l \in H^1(\Omega)$, with zero trace on $\Gamma_D$ 
	\item for $v_h  \in S^1_h$, one has the following norm equivalences, which don't depend on $h$:
	\begin{enumerate}
		\item $\norm{v_h}_{L^2(\partial \Omega_h)} \sim \norm{v_h^l}_{L^2(\partial \Omega)}$
		\item $\norm{v_h}_{L^2( \Omega_h)} \sim \norm{v_h^l}_{L^2( \Omega)}$
		\item $\norm{\nabla v_h}_{L^2( \Omega_h)} \sim \norm{\nabla v_h^l}_{L^2( \Omega)}$
	\end{enumerate}
	\item consequently, the lifting operator $S^{1}_{h,0,D_h}\rightarrow H^k_{0,D}(\Omega)$ is bounded, for the $L^2$ norms if $k=0$, and $H^1$ norms if $k=1$ 
	
\end{itemize}

\end{prop}

\begin{mproof}

The first point follows by the fact that $G_h$ is bi-Lipschitz, see \cref{prop:G_h}, and theorem 11.53 of \cite{leoni}.

%We refer to \cite{bernardi} for the first point, to Lemma 2.3. This is applicable as $G_h(T)$ is a curved simplex of class $C^1$ in the notation of \cite{bernardi}, and this fact is guaranteed by lemma 8.13 and by following example 2 of \cite{bernardi}.
%
%The lifted $v_h$ mantains continuity at the edges, so that $v_h^l$ is in $H^1(\Omega)$ by an application of the divergence theorem on every (possibly curved) simplex $T^l$ composing $\Omega$.
%
%For the zero trace property, given that $v_h^l \in H^1(\Omega)\cap C(\overline{\Omega})$, we use $G_h(\partial \Gamma_{D_h}) = \partial \Gamma_D$.

The second point follows by applying the arguments about conformity outlined in section 5 of \cite{bernardi}. Following Example 2 therein, we discover that we can apply proposition and corollary 5.1.

The last point can be found in \cite{elliott}, see e.g proposition 4.9 and 4.13.
%
%\underline{First point}
%
%
%
%For an element $T$ (which we assume to be closed), it is stated in \cite{ranner}, lemma 8.12, page 1791, that $G_h|_T$ is a $C^2(T)$. $v^{-l}$ is measurable being the gluing of element-wise measurable functions.

\end{mproof}

Now, define $f_h \in S^1_h, g_{N,h} \in S^1_h(\Gamma_{N_h})$ to be any finite element approximations of $f, g_N$. Note, here $S^1_h(\Gamma_{N_h})$ means the usual piecewise linear FEM space over  $\Gamma_{N_h}$.

We can now define the discrete approximation of \cref{pb:inh_elliptic}.

\begin{pb}[FEM approximation of \cref{pb:inh_elliptic}]
We find $u_h \in S^1_h$ with $u_h(p)=g_D(p)$ for all $p$ external nodes of $\partial \Omega_h$, and solving:

$$a_h(u_h,v_h) = l_h(v_h), \text{ for all } v_h \in S^1_{h,0,D_h}$$

where $a_h(u_h,v_h) =\ds \int_{\Omega_h}\nabla u_h \nabla v_h + k \int_{\Omega_h} u_h  v_h$, and $l_h(v_h) =\ds \int_{\Omega_h}f_h v_h + \int_{\Gamma_{N_h}} g_{h,N}v_h$


\textcolor{red}{Add existence, uniqueness, connection with FEniCS}

\end{pb}

Note, we assumed $g_D \in H^{3/2}(\partial \Omega)$. Thanks to the $C^2$ smoothness of $\partial \Omega$ we can apply theorem 1.5.1.2 of \cite{grisvard} and obtain a $G \in H^2(\Omega)$ with $\tr_2 G = g_D$. Here $\tr_2$ denotes the trace operator from $H^2(\Omega)$. By Sobolev embeddings, $G \in C(\overline{\Omega})$. 

Now, we can pick $G_k \in C^\infty(\overline{\Omega})\cap H^2(\Omega)$ converging in $H^2(\Omega)$ to $G$. We can do so by \cite{adams}, theorem 3.18 at page 54. Then: $G_k|_{\partial \Omega}= \tr_2 G_k \rightarrow \tr_2 G = g_D$, and by $H^2(\Omega)\emb C(\overline{\Omega})$ we obtain $G|_{\partial \Omega} = g_D$, so that $g_D$ is continuous in both $n=2,3$ and so we can define its pointwise interpolation.

Alternatively we could have used Sobolev embeddings on manifolds to arrive to the same conclusion.

\begin{prop}[Interpolation on curved domains]
\label{prop:interp_curv}
Let $u \in H^2(\Omega)$, let $g \in H^2(\partial \Omega)$.

Let $u\in H^2(\Omega)$ and define $\Pi_c u = (\Pi_h u )^l$, where $\Pi_h$ is the usual pointwise Lagrange interpolator on $S^1_h$.

We can also define $\Pi_c g $ for $g \in H^2(\partial \Omega)$ in the same fashion.

It follows that:

\begin{itemize}
	\item $\norm{u-\Pi_c u}_{L^2(\Omega)} + h \norm{u-\Pi_c u}_{H^1(\Omega)}\lesssim h^2\norm{u}_{H^2(\Omega)}$
	\item $\norm{g-\Pi_c g}_{L^2(\partial \Omega)} + h \norm{g-\Pi_c g}_{H^1(\partial \Omega)}\lesssim h^2\norm{g}_{H^2(\partial \Omega)}$
\end{itemize}
Here $a \lesssim b$ means $a \leq Cb$ for $C\geq 0$ not depending on $h$.
\end{prop}

\begin{mproof}
See proposition 5.4 of \cite{elliott}.
\end{mproof}

\begin{prop}[Approximation of linear and bilinear forms]
\label{prop:lin_appr}
Let $v_h, w_h \in S^1_h$, $v,w \in H^2(\Omega)$, $\delta \te_h \in (S^1_h)^d$ ($d$ is the dimension of $\Omega$), $\delta \te \in W^{1,\infty}(\Omega;\mR^d)$. Then:

\begin{enumerate}
	\item $\ds \left | \int_\Omega v_h^lw_h^l - \int_{\Omega_h}v_hw_h\right |\lesssim h \norm{v_h}_{L^2(\Omega_h)}\norm{w_h}_{L^2(\Omega_h)}$
	\item $\ds \left | \int_\Omega v_h^lw_h^l - \int_{\Omega_h}v_hw_h\right |\lesssim h^2 \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)}$
	\item $\ds \left | \int_{\partial \Omega} v_h^lw_h^l - \int_{\partial \Omega_h}v_hw_h\right |\lesssim h^2 \norm{v_h}_{L^2(\partial \Omega_h)}\norm{w_h}_{L^2(\partial \Omega_h)}$
	\item $\ds \left | \int_\Omega \nabla v_h^l\nabla w_h^l - \int_{\Omega_h}\nabla v_h\nabla w_h\right |\lesssim h \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)}$
	\item $\ds \left | \int_\Omega \nabla v\nabla w - \int_{\Omega_h}\nabla v^{-l}\nabla w^{-l}\right |\lesssim h^2 \norm{v}_{H^2(\Omega)}\norm{w}_{H^2(\Omega)}$
	\item $\ds \left | \int_\Omega v_h^lw_h^l \dive(\delta  \te_h^l) - \int_{\Omega_h}v_h w_h \dive(\delta \te_h)\right |\lesssim h \norm{v_h}_{L^2(\Omega_h)}\norm{w_h}_{L^2(\Omega_h)} \norm{\dive(\delta \te_h)}_{L^\infty(\Omega_h)}$
	\item $\ds \left | \int_\Omega (A'(\delta	\te_h^l)\nabla v_h^l)\nabla w_h^l - \int_{\Omega_h}(A'(\delta	\te_h)\nabla v_h)\nabla w_h\right |\lesssim h \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)}\norm{D\delta \te_h}_{L^\infty(\Omega_h)}$
	\item $\ds \left | \int_\Omega v_h^l w_h^l \dive(\delta  \te_h^l) - \int_{\Omega_h}v_h w_h \dive(\delta \te_h)\right |\lesssim h^2 \norm{v_h}_{H^1(\Omega_h)}\norm{w_h}_{H^1(\Omega_h)} \norm{\dive(\delta \te_h)}_{L^\infty(\Omega_h)}$
\end{enumerate}
\end{prop}

\begin{mproof}
See \cite{edelmann}, and in particular, for the third point, Lemma 5.6 of \cite{kovacs}. Only the last two points are not already present in the literature.

\underline{Proof of $6, 8$}

We can reason as in section 6 of \cite{elliott}. To this end, we perform integration by parts:

\begin{align*}
	\int_{\Omega_h}v_h w_h \dive(\delta \te_h) = \int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l)(D(G_h^{-1}))^{-1})|\det(D(G_h^{-1}))|=\\
	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l)(D((G_h^{-1}))^{-1} - \id))|\det(D(G_h^{-1}))|+\\
	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l))(|\det(D(G_h^{-1}))|-1)+\\
	\int_{\Omega}v_h^l w_h^l \tr(D(\delta \te_h^l))
\end{align*}

The conclusion now follows from \cref{prop:G_h} and the fact that, for square matrices $A,B$, we have $|\tr(AB)|\leq \norm{A}_F\norm{B}_F$, and $\norm{\cdot }_F$ is the Frobenius norm.

By noting that the first and second integrals are zero on the interior elements, and upon using the "narrow band" inequality Lemma 6.3, \cite{elliott}, as suggested in  Lemma 6.4 of \cite{elliott}, we are able to also conclude that $8$ must hold.

\underline{Proof of $7, 9$}

It is very similar to the previous ones. The only peculiarity is the appearance of a term like $A'(\delta \te_h)\circ G_h^{-1} - A'(\delta \te_h^l)$. This is estimated, in the $L^\infty$ norm, as follows:

\begin{align*}
	\norm{A'(\delta \te_h)\circ G_h^{-1} - A'(\delta \te_h^l)}_{L^\infty(\Omega_h)}\leq\\
	2\norm{D(\delta \te_h^l)(D(G_h^{-1}))^{-1} - D(\delta \te_h^l)}_{L^\infty(\Omega_h)}+\\
	\norm{\tr(D(\delta \te_h^l)(D((G_h^{-1}))^{-1} - \id))}_{L^\infty(\Omega_h)}
\end{align*}

and we can now use \cref{prop:G_h} to conclude.

\end{mproof}

\begin{thm}[$H^1$ estimate]
\label{thm:H1_est_ell}
For $h$ small enough, we have $\norm{u-u_h^l}_{H^1(\Omega)} \lesssim h + \norm{f-f_h^l}_{L^2(\Omega)}+ \norm{g_N-g_{h,N}^l}_{L^2(\Gamma_N)}$
\end{thm}
\begin{mproof}

We partially follow the structure of the arguments in \cite{edelmann}, making some simplifications, and modifications to adapt them to our case.

\underline{Conclusion}

$\norm{u-u_h^l}_{H^1(\Omega)}\leq \norm{u-\Pi_c u }_{H^1(\Omega)}+\norm{\Pi_c u-u_h^l}_{H^1(\Omega)}$. The interpolation estimates \cref{prop:interp_curv} allow us to worry only about the second term. It is  $\norm{(\Pi_h u-u_h)^l}_{H^1(\Omega)}\lesssim \norm{\Pi_h u-u_h}_{H^1(\Omega_h)}$ by \cref{prop:lift}. We estimate the latter quantity, calling $e_h := u_h - \Pi_h u$, which is zero on $\Gamma_{D_h}$.

\underline{Defect, $e_h$ and $u$}

Let $d_h \in S^1_{h,0,D_h}$ be the unique solution to $a_h(d_h,v_h)=l_h(v_h)-a_h(\Pi_h u,v_h)$, $v_h \in S^1_{h,0,D_h}$.

Using $0 = l_h(v_h)-a_h(u_h,v_h)$, $v_h \in S^1_{h,0,D_h}$, we come to $a_h(d_h-e_h,v_h)=0$,  $v_h \in S^1_{h,0,D_h}$. Testing with $d_h-e_h=0$ on $\Gamma_{D_h}$ and using the connectedness of $\Omega_h$, we conclude that $e_h=d_h$.

Moreover, by \cref{prop:lift}, we have $v_h^l \in H^1_{0,D}$, so that $a(u,v_h^l) = l(v_h^l)$ and thus :

$$a_h(e_h,v_h) = l_h(v_h)-l(v_h^l) + a(u,v_h^l)-a_h(\Pi_h u, v_h)$$

\underline{Estimation of $e_h$}

The form $a_h$ is $H^1$ coercive, $h-$uniformly. This we show by the following estimate, $C$ not depending on $h$:

\begin{align*}
a_h(v_h,v_h) = a(v_h^l,v_h^l) + a_h(v_h,v_h) - a(v_h^l,v_h^l)\\
\geq C\norm{v_h^l}_{H^1(\Omega)}^2 - |a_h(v_h,v_h) - a(v_h^l,v_h^l)|\\
\geq C\norm{v_h}_{H^1(\Omega_h)}^2 -C h \norm{v_h^l}_{H^1(\Omega)}^2\\
\geq C(1-h)\norm{v_h}_{H^1(\Omega_h)}^2
\end{align*} 

We used, in order:
\begin{itemize}
	\item  the $h-$uniform coercivity of $a$ (descending from the Poincaré inequality in which functions vanish only on part of the boundary, $\Gamma_D$, see e.g. lemma 1 of \cite{dorfler})
	\item \cref{prop:lift} on $\norm{v_h^l}_{H^1(\Omega)}^2$
	\item proposition 4.6 of \cite{edelmann}
\end{itemize}

Therefore $\norm{e_h}^2_{H^1(\Omega_h)}\lesssim a_h(e_h,e_h) = l_h(e_h)-l(e_h^l) + a(u,e_h^l)-a_h(\Pi_h u, e_h)$, where we can test by $e_h=0$ on $\Gamma_{D_h}$.

This last term is estimated exactly as in proposition 5.5 of \cite{edelmann}. In particular, we make use of th $H^2$ regularity of $u$, and we extend $g_{N,h}, g_N$ to zero, on $\Gamma_{D_h}, \Gamma_D$

\end{mproof}


Note, the assumption of non-emptiness of the Dirichlet boundary is not strictly necessary, and can be removed, when $k>0$. In this case, we have to modify the above arguments because $a$ is not coercive anymore, but this is possible by consider a slightly different defect equation, where an $L^2$ scalar product is added.


For an $L^2$ error estimate we apply the Aubin-Nitsche trick, following \cite{fairweather} and \cite{edelmann}.

\begin{thm}[$L^2$ estimate]
\label{thm:L2_est_ell}
Assume either that $f \in H^1(\Omega)$ or that $\norm{f^l_h}_{H^1(\Omega)}\lesssim \norm{f}_{L^2(\Omega)}$. Then, for $h$ small enough, we have $\norm{u-u_h^l}_{L^2(\Omega)}\lesssim h^2 + \norm{f-f_h^l}_{L^2(\Omega)}+ \norm{g_N-g_{h,N}^l}_{L^2(\Gamma_N)} + \norm{g_D - \Pi_c g_D}_{L^2(\Gamma_D)} + A$, where $A = 0$ if  $\norm{f^l_h}_{H^1(\Omega)}\lesssim \norm{f}_{L^2(\Omega)}$ and $A = h^2\norm{f-f_h^l}_{H^1(\Omega)}$ otherwise.
\end{thm}

\begin{mproof}

Define $e:=u-u_h^l$ (whose boundary values at $\Gamma_D$ are not necessarily $0$!), and $z$ solving the dual problem:

$$
\left\{\begin{matrix}
-\Delta z + k z = e & \text{ on } \Omega \\ 
z = 0 & \text{ on } \Gamma_D \\ 
\partial_\nu z = 0 & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

This problem possesses $H^2$ regularity, so that we can write, after multiplying both sides by $e \in H^1$ (thanks to \cref{prop:lift}):

$$\norm{e}^2_{L^2(\Omega)} = a(z,e) - \int_{\partial \Omega} e \partial_\nu z  $$

Using that $z \in H^2$ we have that $\partial_\nu z=0$ on $\Gamma_N$, together with the estimate $\norm{z}_{H^2(\Omega)}\lesssim \norm{e}_{L^2(\Omega)}$ (\textcolor{red}{check!! It's done at page 92 of Grisvard}) and thus:

\begin{align*}
\norm{e}^2_{L^2(\Omega)} = a(z,e) +\norm{e}_{L^2(\Gamma_D)}\norm{ \partial_\nu z}_{L^2(\partial \Omega)} \\
\leq a(z,e) + C \norm{e}_{L^2(\Gamma_D)}\norm{e}_{L^2( \Omega)}
\end{align*}

Only $ a(z,e)$ remains to be estimated, and this is done in the proof of theorem 5.3 of \cite{edelmann}, and in remark 5.6.

\end{mproof}

\begin{cor}[Actual estimates]
By assuming $f,g_N, g_D$ in $H^2$ we conclude $\norm{u-u_h^l}_{H^1(\Omega)} \lesssim h$,$ \norm{u-u_h^l}_{L^2(\Omega)} \lesssim h^2$.
\end{cor}

\begin{mproof}
It suffices to take $f_h:=\Pi_h f$, $g_{N,h} = \Pi_h g$ and employ \cref{prop:interp_curv}.
\end{mproof}

Unfortunately the smoothness assumptions to obtain optimal order of convergence are quite strict. However, the advantage of this approach is that it is straightforward to implement, and works in both dimensions $n=2,3$.

If one is concerned with just $H^1$ error estimates, without taking numerical integration into account, we can relax the requirements on $f$. Incidentally, how we are about to choose $f$, is more in line with the implementation of FEniCS.

\begin{prop}[$H^1$ estimate with rougher $f$]
We choose $f_h=f $ on $\Omega \cap \Omega_h$ and $0$ otherwise, assuming $f \in H^1(\Omega)$. Then we obtain, for $h$ small enough, $\norm{u-u_h^l}_{H^1(\Omega)} \lesssim h + \norm{g_N-g_{h,N}^l}_{L^2(\Gamma_N)}$
\end{prop}
\begin{mproof}

Analysing the proof of proposition 5.5 in \cite{edelmann} we see that we only need to prove that $\ds \left | \int_\Omega f v_h^l - \int_{\Omega_h}f_h v_h \right |\lesssim h \norm{v_h^l}_{H^1(\Omega)} $, for $v_h \in S^1_{h,0,D_h}$.

We can rewrite the difference as follows:

\begin{align*}
\int_\Omega f v_h^l - \int_{\Omega_h}f_h v_h   =\\
\int_{\Omega \cap \Omega_h} f v_h^l - \int_{\Omega_h \cap \Omega} f_h v_h  + \int_{\Omega \setminus \Omega_h} f v_h^l - \int_{\Omega_h \setminus \Omega} f_h v_h  =\\
\int_{\Omega \cap \Omega_h} f v_h^l - \int_{\Omega_h \cap \Omega} f_h v_h  + \int_{\Omega \setminus \Omega_h} f v_h^l = \\
\int_{\Omega \cap \Omega_h^\partial} f (v_h^l - v_h)  + \int_{\Omega \setminus \Omega_h} f v_h^l
\end{align*}

where we used that $f=0$ outside of $\Omega$, that $f=f_h$ in $\Omega \cap \Omega_h$ and that $v_h^l=v_h$ for all simplices with at most one node on $\partial \Omega$ (by the definition of $G_h$). The set of all the other (straight) simplices is denoted by $\Omega_h^\partial$.

For the first integral we have that for $h$ small enough, \textcolor{red}{$\Omega \setminus \Omega_h \subseteq N_{ch^2}$} (see \cite{tiihonen} for this), for $N_\delta :=\{ x \in \Omega, 0 <\text{dist}(x,\partial \Omega) < \delta\}$.

Using the assumption $f 	\in H^1(\Omega)$, together with Lemma 4.10 of \cite{elliott}, we conclude that:

\begin{align*}
\left | \int_{\Omega \setminus \Omega_h} f v_h^l \right | \leq \norm{f}_{L^2(N_\delta)} \norm{v_h^l}_{L^2(N_\delta)} \lesssim \delta \norm{f}_{H^1(\Omega)} \norm{v_h^l}_{H^1(\Omega)}
\end{align*} 

To control the other integral, we note that \textcolor{red}{$\Omega \cap \Omega_h^\partial \subseteq N_h$}, also for $h$ small enough. Then:

\begin{align*}
\left | \int_{\Omega \cap \Omega_h^\partial} f (v_h^l - v_h) \right | \leq \norm{f}_{L^2(N_h)}( \norm{v_h^l}_{L^2(N_h)} + \norm{v_h}_{L^2(\Omega \cap \Omega_h^\partial)})\\ \lesssim h^{1/2} \norm{f}_{H^1(\Omega)} ( h^{1/2}\norm{v_h^l}_{H^1(\Omega)}+ \norm{v_h}_{L^2(\Omega \cap \Omega_h^\partial)})
\end{align*} 

But $\norm{v_h}_{L^2(\Omega \cap \Omega_h^\partial)} \leq \norm{v_h}_{L^2(\Omega_h^\partial)} \lesssim \norm{v_h^l}_{L^2(G_h(\Omega_h^\partial))}$, the last inequality resulting upon a change of variables applied elementwise, and an application of (4.10b) from \cite{elliott} to estimate the appearing determinant.

Because \textcolor{red}{$G_h(\Omega_h^\partial)\subseteq N_h$ (this is said in lemma 8.24 of 9, see edelmann)}, the proof is concluded.

\end{mproof}

This same strategy brings us to an optimal $L^2$ error estimate, too.

\begin{prop}[$L^2$ estimate with rougher $f$]
\label{prop:rough_L2_est_ell}
We choose $f_h=f $ on $\Omega \cap \Omega_h$ and $0$ otherwise, assuming $f \in H^1(\Omega)$. Then we obtain, for $h$ small enough, we have $\norm{u-u_h^l}_{L^2(\Omega)}\lesssim h^{2} + \norm{g_N-g_{h,N}^l}_{L^2(\Gamma_N)} + \norm{g_D - \Pi_c g_D}_{L^2(\Gamma_D)}$.
\end{prop}

\begin{mproof}
Analyizing the proof of the $L^2$ estimate, and of theorem 5.3 in \cite{edelmann}, we see that we only need to prove that $\ds \left | \int_\Omega f \Pi_c z - \int_{\Omega_h}f_h \Pi_h z \right |\lesssim h^2 \norm{e}_{L^2(\Omega)} $.

Just like before, we arrive at:

\begin{align*}
\int_\Omega f \Pi_c z - \int_{\Omega_h}f_h \Pi_h z   =\int_{\Omega \cap \Omega_h^\partial} f (\Pi_c z - \Pi_h z )  + \int_{\Omega \setminus \Omega_h} f \Pi_c z 
\end{align*}

Here, \cref{prop:interp_curv} lets us estimate $\norm{\Pi_c z}_{H^1(\Omega)}\lesssim \norm{z}_{H^2(\Omega)}$, for $h$ small, so that, just like in the previous proof, and using the $H^2$ regularity of $z$:

\begin{align*}
\left |\int_{\Omega \setminus \Omega_h} f \Pi_c z  \right | \lesssim h^2 \norm{f}_{H^1(\Omega)} \norm{z}_{H^2(\Omega)}\lesssim h^2 \norm{f}_{H^1(\Omega)} \norm{e}_{L^2(\Omega)}
\end{align*} 

Now, $\Omega$ is smooth enough for the existence of a bounded extension operator $E : H^2(\Omega) \rightarrow H^2(\mR^n)$ (see \cite{leoni}, theorem 13.17 at page 425, 13.13 at page 424, and definition 9.57 at page 273). Therefore:

\begin{align*}
\left | \int_{\Omega \cap \Omega_h^\partial} f (\Pi_c z - \Pi_h z )  \right |  \lesssim h^{1/2} \norm{f}_{H^1(\Omega)} \norm{\Pi_c z - \Pi_h z}_{L^2(\Omega \cap \Omega_h^\partial)}
\end{align*} 

But $\norm{\Pi_c z - \Pi_h z}_{L^2(\Omega \cap \Omega_h^\partial)} \leq \norm{\Pi_c z - z}_{L^2(\Omega)} +  \norm{Ez - \Pi_h Ez}_{L^2(\Omega_h)}$.

By \cref{prop:interp_curv} and by theorem 3.1.6 of \cite{ciarlet}, with constants independent of $h$, we obtain $\norm{\Pi_c z - \Pi_h z}_{L^2(\Omega \cap \Omega_h^\partial)}  \leq C h^2(\norm{z}_{H^2(\Omega)} + \norm{Ez}_{H^2(\Omega_h)})\leq Ch^2(\norm{z}_{H^2(\Omega)} + \norm{Ez}_{H^2(\mR^n)})\lesssim h^2 \norm{z}_{H^2(\Omega)} \leq h^2  \norm{e}_{L^2(\Omega)}$.

Hence $\ds \left | \int_{\Omega \cap \Omega_h^\partial} f (\Pi_c z - \Pi_h z )  \right |  \lesssim h^{5/2}\norm{e}_{L^2(\Omega)} $ and the proof is concluded.

\end{mproof}

Summing up, here are the assumptions we used to obtain optimal order estimates.

\begin{ass}[Assumptions for optimal order estimates]
On top of \cref{ass:inh_ell} we have assumed:
\begin{itemize}
	\item quasi-uniformity of the mesh
	\item $h$ small enough (all the estimates are asymptotic)
	\item $g_D, g_N \in H^2$
	\item $f \in H^1$
\end{itemize}
\end{ass}

\section{Parabolic problems}

\subsection{Semidiscrete estimates}

We partly build upon the previous section, to deal with problems of the following form.

\textcolor{red}{Add a more precise reference to the triangulation, quasi uniformity...}

\begin{pb}[Inhomogeneous parabolic problem]
\label{pb:inh_parabolic}

With reference to \cref{pb:mix}, we define:

$$
\left\{\begin{matrix}
\partial_t u-\Delta u = f & \text{ on } \Omega \times I \\ 
u = g_D & \text{ on } \Gamma_D \times I\\ 
\partial_\nu u = g_N & \text{ on } \Gamma_N \times I \\
u(0) =  u_0
\end{matrix}\right.
$$

We ask \cref{ass:basic_par_mix}.

\end{pb}

We provide a semidiscrete estimate, in the sense that only space is discretized. To do so we follow a classical argument involving the use of Ritz projections, see \cite{thomee} in e.g. theorem 1.2. To deal with the polygonal/polyhedral domain approximation we adapt some arguments contained in \cite{ranner}, where parabolic problems are treated on moving domains, but with homogeneous boundary conditions. The inhomogeneous Dirichlet boundary conditions require special care.

We start indeed from the Ritz projection, by keeping the same notation as in the last section for the lift.

Throughout this section, $\lesssim$ means $\leq C $, for $C$ independent of both the discretization parameter $h$, and time.

\begin{defn}[Inhomogeneous Ritz projection]
Consider $z \in H^2(\Omega)$. We define $R_h z \in S^1_h$ by:

$$a_h(R_h z , v_h) = a(z, v_h^l), v_h \in S^1_{h,0,D_h}$$
$$R_h z = \Pi_h z \text{ on } \partial \Omega_h$$

We denote $R_c z := (R_h z)^l$.

\end{defn}

Here are some useful properties of such projection.

\begin{prop}[Properties of the Ritz projection]
\label{prop:ritz}
The following facts hold true about $R_h$, where we assume that $h$ is small enough:

\begin{enumerate}
	\item $R_h$ is well defined
	\item $R_h$ is continuous, uniformly in $h$, from $H^2(\Omega)$, to $S^1_h$, i.e., $\norm{R_hz}_{H^1(\Omega_h)}\lesssim \norm{z}_{H^2(\Omega)}$
	\item $\norm{R_c z - z}_{H^1(\Omega)}\lesssim h\norm{z}_{H^2(\Omega)}$
	\item $\norm{R_c z - z}_{L^2(\Omega)}\lesssim h^2 \norm{z}_{H^2(\Omega)} + \norm{z-\Pi_c z}_{L^2(\Gamma_D)}$
	\item for $z \in H^1(I,H^2(\Omega))$, $R_c \frac{d}{dt} = \frac{d}{dt} R_c$ and we can therefore use the above properties also for $z_t$
\end{enumerate}

\end{prop}

\begin{mproof}

\underline{Well posedness and stability}

Consider $\delta_h := R_h z - \Pi_h z$. Then, $a_h(\delta_h , v_h) = a(z, v_h^l) - a_h(\Pi_h z, v_h), v_h \in S^1_{h,0,D_h}$, $\delta_h = 0$ on $\Gamma_{D_h}$.

The right hand side is a bounded functional on $S^1_h$, also by \cref{prop:lift}, and $a_h$ is ($h$-uniformly) coercive on $S^1_{h,0,D_h}$ by the proof of \cref{thm:H1_est_ell}.

Therefore, $\delta_h$ exists, and we see that $\delta_h+\Pi_h z$ satisfies the equation for $R_hz$. Defining $R_h z := \delta_h + \Pi_h z$ is a well posed operation, since we can check that $R_h z$ doesn't depend on the (discrete) extension of $\Pi_h z|_{\Gamma }$: if we had two candidates $R^ihz$, $i=1,2$, we could form a difference, $0$ on $\Gamma_{D_h}$, that would qualify as a test function in both variational formulations. Coercivity of $a_h$ would then yield $R_h^1=R_h^2$.

Now, for the stability.

By uniform coercivity and the definition of $R_h$: $\norm{R_h z}_{H^1(\Omega_h)}^2 \lesssim a_h(R_h z, R_h z) = a_h(\delta_h,R_h z) + a_h(\Pi_h z, R_h z)$, so that $\norm{R_h z}_{H^1(\Omega_h)} \lesssim \norm{\delta_h }_{H^1(\Omega_h)} + \norm{\Pi_h z }_{H^1(\Omega_h)}$.

For the second term.

Employing \cref{prop:lift} $\norm{\Pi_h z }_{H^1(\Omega_h)}\lesssim \norm{\Pi_c z }_{H^1(\Omega)} \leq \norm{\Pi_c z -z }_{H^1(\Omega)}+\norm{z }_{H^1(\Omega)} \lesssim (1+h)\norm{z}_{H^2(\Omega)}$, where in the last step we used \cref{prop:interp_curv}.

For the first term, we know that $ \norm{\delta_h }_{H^1(\Omega_h)}^2 \lesssim a_h(\delta_h, \delta_h) =  a(z, \delta_h^l) - a_h(\Pi_h z, \delta_h)$. We can insert a $0$ term: $ \norm{\delta_h }_{H^1(\Omega_h)}^2 \lesssim a(z-\Pi_c z, \delta_h^l) + a(\Pi_c z, \delta_h^l) - a_h(\Pi_h z, \delta_h)$ and use \cref{prop:interp_curv}, \cref{prop:lift} and \cref{prop:lin_appr}, to get:

$$ \norm{\delta_h }_{H^1(\Omega_h)}^2 \lesssim h \norm{z}_{H^2(\Omega)}\norm{\delta_h}_{H^1(\Omega_h)} + h\norm{\Pi_h z}_{H^1(\Omega_h)}\norm{\delta_h}_{H^1(\Omega_h)}$$

For the second term, we obtain, for $h$ small, that $\norm{\delta_h }_{H^1(\Omega_h)} \lesssim \norm{z}_{H^2(\Omega)}$, and the stability is shown.

\underline{Error bounds}

We start from the $H^1$ error bound.

We follow \cite{ranner} closely here, adapting the proof of Lemma 3.8 at page 1720, where in particular we make sure that $H^2$ stability of $R_h$ is sufficient, instead of the stronger $H^1$ stability they use. We are also using a slightly different bilinear form and function spaces.

Calling $F_h(v):=a(z-R_cz, v)$ for $v \in H^1$, we readily obtain:
$$|F_h(v_h^l)|\lesssim h \norm{v_h^l}_{H^1(\Omega)}\norm{z}_{H^2(\Omega)}$$

For $\eta \in H^2(\Omega)$ we instead have:
$$|F_h(\eta)|\lesssim \left ( h^2 \norm{z}_{H^2(\Omega)}+ h \norm{z-R_cz}_{H^1(\Omega)}\right)\norm{\eta}_{H^2(\Omega)}$$

The above estimates are shown in detail in \cite{ranner}.

Using again the same arguments of \cite{ranner} we come to:
$$\norm{z-R_cz}^2_{H^1(\Omega)}\lesssim h \norm{z-R_cz}_{H^1(\Omega)} \norm{z}_{H^2(\Omega)} + h \norm{z}_{H^2(\Omega)}(h\norm{z}_{H^2(\Omega)}+\norm{z-R_cz}_{H^1(\Omega)})$$

Appying Young's inequality brings us finally to:
$$\norm{z-R_cz}_{H^1(\Omega)}\lesssim h \norm{z}_{H^2(\Omega)} $$

For the $L^2$ error bound, we apply a variant of the Aubin-Nitsche trick. Call $e:= z - R_c z \in H^1(\Omega)$ (this holds by \cref{prop:lift}), and define $w$, just like in \cref{thm:L2_est_ell}, by:

$$
\left\{\begin{matrix}
-\Delta w = e & \text{ on } \Omega \\ 
w = 0 & \text{ on } \Gamma_D \\ 
\partial_\nu w = 0 & \text{ on } \Gamma_N 
\end{matrix}\right.
$$

As in the proof of \cref{thm:L2_est_ell}:

$$\norm{e}^2_{L^2(\Omega)} = a(w,e) - \int_{\partial \Omega} e \partial_\nu w  $$

and:

\begin{align*}
\norm{e}^2_{L^2(\Omega)} \leq a(w,e) + C \norm{e}_{L^2(\Gamma_D)}\norm{e}_{L^2( \Omega)} = F_h(w) + C \norm{e}_{L^2(\Gamma_D)}\norm{e}_{L^2( \Omega)}
\end{align*}

For the first term we can employ the estimates derived at the beginning and the $H^1$ error norm, so as to obtain:
$$|F_h(w)|\lesssim h^2\norm{z}_{H^2(\Omega)}\norm{w}_{H^2(\Omega)}$$

Using $H^2$ regularity for $w$ we are able to conclude:
$$\norm{z-R_c z}_{L^2(\Omega)}\lesssim h^2\norm{z}_{H^2(\Omega)} + \norm{z-\Pi_c z}_{L^2(\Gamma_D)} $$

\underline{Commutation with time derivative}

Follows from \cref{lemma:bochner_Hk_map}, and the fact that $R_c$ is linear and bounded. The latter is true as lifting a finite element function is a linear bounded map, see \cref{prop:lift}.

\end{mproof}

\begin{ass}[Smoothness requirement on continuous solution]
\label{ass:smoothness_par_discr}

We assume that $u \in H^1(I, H^2(\Omega))$.
\end{ass}

Note, for the parabolic problems arising from shape optimization as we can see in \cref{chap:cts_shape_opt}, we can get away with asking particular smoothness and compatibility assumptions on the problem data, see \textcolor{red}{SOME FUTURE CHAPTER} and \cref{thm:mix_reg}. For more general problems with non-null initial conditions, a finer analysis is most likely necessary.

We now can attempt an error estimate for \cref{pb:inh_parabolic}, for the following spatial semidiscrete formulation.

\begin{pb}[Spatially semidiscrete approximation of \cref{pb:inh_parabolic}]
\label{pb:inh_parabolic_discr}
We look for $u_h \in H^1(I, S^1_h)$ satisfying: 
$$(\partial_t u_h, v_h)_{L^2(\Omega_h)} + a_h(u_h, v_h) = (f_h, v_h)_{L^2(\Omega_h)} + (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})}, v_h \in S^1_{h,0,D_h}, a.e. t$$
$$u_h=g_{D,h}\text{ for a.e. }t \text{,  on } \Gamma_{D_h}$$
$$u_h(0)=u_{0h}$$

We are making the following assumptions on the data:

\begin{ass}[Assumptions for the spatial semidiscretization]
\label{ass:discr_reg}
\textcolor{white}{ }
\begin{itemize}
	\item $\partial \Omega \in C^2$
	\item $g_N \in L^2(I,H^2(\Omega))$, so that $g_{N,h}:=\Pi_h g_N \in L^2(I, S^1_h(\Gamma_{N_h}))$
	\item $g_D \in H^1(I, H^{2}(\Gamma_D))$, so that, with reference to \cref{prop:trace}, we have $G_D:=Eg_D \in H^1(I,H^2(\Omega))$ and therefore (see \cref{lemma:bochner_Hk_map}), there holds	 $G_{D,h}:=\Pi_h G_D \in H^1(I, S^1_h)$ and $g_{D,h}:=G_{D,h}|_{\Gamma_{D_h}} \in H^1(I, S^1_h(\Gamma_{D_h}))$ (note, $g_{D,h} = \Pi_h g_D$)
	\item $f \in L^2(I,L^2(\Omega))$ and $f_h \in L^2(I, S^1_h)$, with error bound  $\norm{f-f_h^l}_{L^2(\Omega_h)}\lesssim C_f h^2$, for a.e. $t$, $C_f$ independent of $h$ and belonging to $L^2(I)$.
	\item $u_0\in H^2(\Omega$), with the compatibility condition $u_{0} = g_{D}(0)$ on $\Gamma_{D}$, and $u_{0h}:=\Pi_h u_0$
\end{itemize}

(note that these assumptions can be relaxed for proving the well posedness of the scheme, and other choices of the discrete data might be possible. They become important when proving error bounds, so that we assume them right away. In particular, one could choose $f_h=\Pi_h f$, for $f\in L^2(U, H^2(\Omega))$ and obtain the same results).

\end{ass}

\end{pb}

\begin{prop}[Well posedness of \cref{pb:inh_parabolic_discr}]
\label{prop:wp_discr_par}
There exists a unique solution to \cref{pb:inh_parabolic_discr}, and this satisfies the stability estimate, holding for small enough $h$:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)}  + \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} + \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D)))} + \norm{u_{0}}_{H^2(\Omega)}
\end{align*}

We remember that $\lesssim$ stands for $\leq C$, $C\geq 0$ independent of $h$ and $t$.

\end{prop}

\begin{mproof}

\underline{Existence}

A function $\delta_h \in H^1(I, S^1_{h,0,D_h})$ can be written as $\delta_h=\sum_j d_{hj}(t)v_{hj}$, for the usual finite element basis $\{v_{hj}\}_j$ of $S^1_{h,0,D_h}$. We employ the splitting technique $\delta_h = u_h - G_{D,h}$. By testing with the equation of \cref{pb:inh_parabolic_discr} with the basis functions $v_{hj}$ we obtain the problem:
\begin{align}
\label{eqn:ode}
	M_h d_h'(t)+A_hd_h(t)= F_h(t), \text{ a.e. } t\\
	d_h(0) = d_{h,0}	
\end{align}

Here, $M_{h,ij} = (v_{hi}, v_{hj})_{L^2(\Omega_h)}, A_{h,ij} = a(v_{hi}, v_{hj})$ are the so called mass and stiffness matrices, both invertible, with respect to the nodal basis of $S^1_{h,0,D_h}$. We also have $F_{h,j}(t):= - (\partial_t G_{D,h}, v_{hj})_{L^2(\Omega_h)} - a_h(G_{D,h}, v_{hj}) + (f_h, v_{hj})_{L^2(\Omega_h)} + (g_{N,h}, v_{hj})_{L^2(\Gamma_{N_h})}$, together with $d_{h,0}:= u_{0h} - G_{D,h}$, in the sense of the non-Dirichlet nodal values (we are able to come to this problem thanks to the assumed compatibility between $u_{0h}, g_{D,h}$).

Thanks to the smoothness assumptions on the data, we have that $F$ has $L^2(I)$ entries.

Hence, by basic theory of ordinary differential equations (theorem 3.4 of \cite{odes}, for instance), we conclude the existence (and uniqueness) of $d \in H^1(I)$ solving the problem above. The function $u_h:=\sum_j d_j(t)v_{hj} + G_{D,h}$ is therefore a solution to the original problem. 

\underline{Uniqueness by energy estimates}

Uniqueness (and hence, independence on the particular extension $G_{D,h}$) follows by proving an energy estimate at first. In fact, let $e:=u_h^1-u_h^2$ be the difference of two solutions. It satisfies:

$$(\partial_t e_h, v_h)_{L^2(\Omega_h)} + a_h(e_h, v_h) = 0 , v_h \in S^1_{h,0,D_h}, a.e. t$$
$$e_h=0 \text{ for a.e. }t \text{,  on } \Gamma_{D_h}$$
$$e_h(0)=0$$

We can test the equation by $e_h$, use that $a_h(v_h,v_h) = \norm{v_h}_{H^1(\Omega_h)}^2-\norm{v_h}_{L^2(\Omega_h)}^2$, that $e_h(0)=0$ and Gronwall's lemma to conclude the desired uniqueness.

\underline{Stability}

Following \cite{gilardi}, page 20, 21, we can prove, for $\delta_h$, that:

\begin{align*}
	\norm{\delta_h}_{C([0,T],L^2(\Omega_h))} + \norm{\delta_h}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)} + \norm{g_{N,h}}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}}_{H^1(I,H^1(\Omega_h)))} + \norm{u_{0h}}_{L^2(\Omega_h)}
\end{align*}

so that, by triangle inequality:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)} + \norm{g_{N,h}}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}}_{H^1(I,H^1(\Omega_h)))}+\norm{u_{0h}}_{L^2(\Omega_h)}
\end{align*}

Now, thanks to \cref{ass:discr_reg}:

\begin{itemize}
%	\item $\norm{f_h}_{L^2(I,L^2(\Omega_h))}^2\lesssim \int_I C_f^2$ (here we use the same arguments as in \cref{prop:rough_L2_est_ell})
	\item $\norm{g_{N,h}}_{L^2(I,L^2(\Gamma_{N_h}))} \lesssim \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} $ (here is suffices to use \cref{prop:interp_curv}))
	\item because the Lagrange interpolator is linear bounded $H^2(\Omega)\rightarrow S^1_h$ there holds, by \cref{prop:interp_curv}: $\partial_t G_{D,h}=\Pi_h \partial_t G_D$, so that $\norm{\partial_t G_{D,h}}_{H^1(\Omega_h)} = \norm{\Pi_h \partial_t G_D}_{H^1(\Omega_h)} \lesssim \norm{\partial_t G_D}_{H^2(\Omega))}$, where we used \cref{prop:interp_curv} and \cref{prop:lift}. Thanks to the properties of $G_D$, and the fact that the extension $E$ of \cref{prop:trace} commutes with $\Pi_h$ (by \cref{lemma:bochner_Hk_map}), there holds $\norm{\partial_t G_{D,h}}_{H^1(\Omega_h)}\lesssim \norm{\partial_t g_D}_{H^{3/2}(\Gamma_D)}$. With analogous reasonings we can conclude that $\norm{G_{D,h}}_{H^1(I,H^1(\Omega_h)))}\lesssim \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D))}$
	\item similarly, $\norm{u_{0h}}_{L^2(\Omega_h)}\lesssim \norm{u_{0}}_{H^2(\Omega)}$
\end{itemize}

All in all:

\begin{align*}
	\norm{u_h}_{C([0,T],L^2(\Omega_h))} + \norm{u_h}_{L^2(I,H^1(\Omega_h))}\lesssim \norm{f_h}_{L^2(I,(S^1_{h,0,D_h})^*)} + \norm{g_{N}}_{L^2(I,H^2(\Gamma_{N}))} + \norm{g_D}_{H^1(I,H^{3/2}(\Gamma_D)))} + \norm{u_{0}}_{H^2(\Omega})
\end{align*}

\end{mproof}

\begin{thm}[Semidiscrete error bound]
\label{thm:semidiscrete_error_bound}
There holds:

\begin{align*}
	 \norm{u(t)-u_h^l(t)}_{L^2(\Omega)}^2 + h^{2}\int_0^T\norm{u-u_h^l}^2_{H^1(\Omega)} \lesssim\\
	 h^4A^2
\end{align*}

where $A^2:= \ds \norm{u}_{H^1(I,H^2(\Omega))}^2 + \norm{g_D}_{H^1(I,H^2(\Gamma_D))}^2 + \norm{u_0}_{H^2(\Omega)}^2 +  \int_0^T C_f^2+ \int_0^T \norm{f_h}_{H^1(\Omega_h)}^2 + \int_0^T  \norm{g_N}_{H^2(\Gamma_N)}^2 $.

For this to hold, \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix} must be fulfilled.

\end{thm}

\begin{mproof}

Also here, we adapt the argument from \cite{ranner}, in particular, those of pages 1727, 1728, 1729, which are modifications of standard techniques that can be traced in e.g. \cite{thomee}, theorem 1.2. We make it clear where one could use other approximations of the data, provided that they enjoy similar properties.

\underline{Error split}

We want to bound $e:=u-u_h = u-R_cu +R_c u -u_h^l =: \rho + \theta_h^l$. We already have the needed bounds on $\rho$ by \cref{prop:ritz}.

\underline{An equation for $\theta_h$}

Consider then $\theta_h := R_h u -u_h$. Is is an element of $H^1(I,S^1_{h,0,D_h})$ (i.e. it is $0$ on the Dirichlet boundary), making it a suitable test function: this is the primary reason to impose boundary conditions on $R_h$.

So, we have, for $v_h \in S^1_{h,0,D_h}$:

\begin{align*}
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} + a_h(R_h u, v_h) = \ind{definition of Ritz projection}=\\
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} + a(u, v_h^l) =\\
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t u, v_h^l)_{L^2(\Omega)} + (f, v_h^l)_{L^2(\Omega)} + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} 
\end{align*}

Adding the equation for $u_h$ we obtain:

\begin{align*}
(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h) = 
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t u, v_h^l)_{L^2(\Omega)}\\ + (f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}\\ + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} 
\end{align*}

Adding and subtracting $(\partial_t R_cu, v_h^l)_{L^2(\Omega)}$:


\begin{align}
\label{eqn:theta}
(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h) = 
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t R_c u , v_h^l)_{L^2(\Omega)}\\
- (\partial_t \rho, v_h^l)_{L^2(\Omega)}\\ + (f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}\\ + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} 
\end{align}

This means that we can estimate the right hand sides of the above equation to quantify the size of $\theta_h$.

\underline{Estimating the size of $\theta_h$: right hand sides}

By \cref{lemma:bochner_Hk_map} we can write $\partial_t R_h u = R_h \partial_t u, \partial_t R_c u = (R_h \partial_t u)^l$.

Hence, $|(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t R_c u , v_h^l)_{L^2(\Omega)}|\lesssim h^2 \norm{\partial_t u}_{H^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)}$, where we used \cref{prop:lin_appr}, and \cref{prop:ritz}.

Similarly, we have $\partial_t \rho = \partial_t u - R_c\partial_t u$.

Thus $| (\partial_t \rho, v_h^l)_{L^2(\Omega)}|\lesssim h^2 \norm{\partial_t u}_{H^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)} + \norm{\partial_t(g_D - g_{D,h}) }_{L^2(\Gamma_D)}\norm{v_h}_{H^1(\Omega_h)}$ by \cref{prop:ritz}. By the choice of $g_{D,h}$ and by \cref{prop:interp_curv}, $| (\partial_t \rho, v_h^l)_{L^2(\Omega)}|\lesssim h^2 (\norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)})\norm{v_h}_{H^1(\Omega_h)}$.

Moreover:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\leq\\
	|(g_{N} - g_{N,h}^l, v_h^l)_{L^2(\Gamma_{N})}| + |(g_{N,h}^l, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |
\end{align*}

By \cref{prop:lin_appr} and trace theorems there holds:

%$|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N,h})} |\lesssim h^2$:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\lesssim\\
	\norm{g_{N} - g_{N,h}^l}_{L^2(\Gamma_{N})}\norm{v_h^l}_{H^1(\Omega)} + h^2\norm{g_{N,h}}_{L^2(\Gamma_{N_h})} \norm{v_h}_{H^1(\Omega_h )}
\end{align*}

Using the choice of $g_{N,h}$ and also \cref{prop:interp_curv}, \cref{prop:lift}, we obtain:

\begin{align*}
	|(g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} |\lesssim 	h^2 \norm{g_N}_{H^2(\Gamma_N)}\norm{v_h}_{H^1(\Omega_h)}
\end{align*}

Analogously:

\begin{align*}
	|(f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}|\lesssim\\
	\norm{f-f_h^l}_{L^2(\Omega)}\norm{v_h}_{H^1(\Omega_h)} + h^2 \norm{f_h}_{H^1(\Omega_h)}\norm{v_h}_{H^1(\Omega_h)}\lesssim (C_f + \norm{f_h}_{H^1(\Omega_h)}) h^2 \norm{v_h}_{H^1(\Omega_h)}
\end{align*}

We used throughout \cref{ass:discr_reg}.

Calling $E_h(v_h):=(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h)$, we discovered that:

\begin{align}
\label{eqn:theta_residual}
	|E_h(v_h)|\lesssim h^2 \norm{v_h}_{H^1(\Omega_h)} (C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} )
\end{align}

\underline{Estimating the size of $\theta_h$: energy estimate}

By the equation of $\theta_h$, and by the possibility of testing with $v_h = \theta_h$ itself, we obtain:

\begin{align*}
	\frac{1}{2} \frac{d}{dt} \norm{\theta_h}_{L^2(\Omega_h)}^2 + \norm{\theta_h}^2_{H^1(\Omega_h)} - \norm{\theta_h}^2_{L^2(\Omega_h)} = E_h(\theta_h)
\end{align*}

Hence:

\begin{align*}
	\frac{1}{2} \frac{d}{dt} \norm{\theta_h}_{L^2(\Omega_h)}^2 + \norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim \norm{\theta_h}^2_{L^2(\Omega_h)}  + Qh^2\norm{\theta_h}_{H^1(\Omega_h)}
\end{align*}

Here we called $Q:=C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)}$.

By Young's inequality:

\begin{align*}
	\frac{1}{2} \frac{d}{dt} \norm{\theta_h}_{L^2(\Omega_h)}^2 + \norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim \norm{\theta_h}^2_{L^2(\Omega_h)}  + 2Q^2h^4 + \frac{1}{2}\norm{\theta_h}_{H^1(\Omega_h)}^2
\end{align*}

Re-arranging:

\begin{align*}
	\frac{1}{2} \frac{d}{dt} \norm{\theta_h}_{L^2(\Omega_h)}^2 + \frac{1}{2}\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim \norm{\theta_h}^2_{L^2(\Omega_h)}  + 2Q^2h^4
\end{align*}

We now integrate from $0$ to $t$:

\begin{align*}
	\frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2}\int_0^t\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim 2\int_0^t\frac{1}{2}\norm{\theta_h}^2_{L^2(\Omega_h)}  + 2h^4 \int_0^t Q^2 + \frac{1}{2} \norm{\theta_h(0)}_{L^2(\Omega_h)}^2
\end{align*}

Adding non-negative terms on the right hand side yields:

\begin{align*}
	\frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2}\int_0^t\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim 2\left (\int_0^t\frac{1}{2}\norm{\theta_h}^2_{L^2(\Omega_h)} + \int_0^t\frac{1}{2}\int_0^s\norm{\theta_h}^2_{H^1(\Omega_h)}dsdt\right) + 2h^4 \int_0^t Q^2 \\+ \frac{1}{2} \norm{\theta_h(0)}_{L^2(\Omega_h)}^2
\end{align*}

Gronwall's inequality (25, page 19 of \cite{gilardi}) now yields:

\begin{align*}
	\norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \int_0^t\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim  e^{2t } \left ( 4h^4\int_0^t Q^2 + \norm{\theta_h(0)}_{L^2(\Omega_h)}^2 \right)
\end{align*}

Therefore, for all $t \in [0,T]$ we have:

\begin{align}
\label{eqn:theta_energy}
	\norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \int_0^T\norm{\theta_h}^2_{H^1(\Omega_h)} \lesssim 8h^4\int_0^T Q^2 + 2\norm{\theta_h(0)}_{L^2(\Omega_h)}^2
\end{align}

We can apply also \cref{prop:lift} to obtain an estimate in spaces that don't depend on $h$:


\begin{align*}
	\norm{\theta_h^l(t)}_{L^2(\Omega)}^2 + \int_0^T\norm{\theta_h^l}^2_{H^1(\Omega)} \lesssim h^4\int_0^T Q^2 + \norm{\theta_h^l(0)}_{L^2(\Omega)}^2
\end{align*}

\underline{Conclusion}

We have, for $e=u-u_h^l$ (and $h<1$, at least), that:

\begin{align*}
	\norm{e(t)}_{L^2(\Omega)}^2 + h^2\int_0^T\norm{e}^2_{H^1(\Omega)} \lesssim\\
	\norm{\rho(t)}_{L^2(\Omega)}^2 + h^2\int_0^T\norm{\rho}^2_{H^1(\Omega)} 	+ \norm{\theta_h^l(t)}_{L^2(\Omega)}^2 + \int_0^T\norm{\theta_h^l}^2_{H^1(\Omega)} \lesssim \ind{\cref{prop:ritz}} \\
	 h^4 \norm{u(t)}_{H^2(\Omega)}^2 + h^4\norm{g_D(t)}_{L^2(\Gamma_D)}^2 + h^2h^2\int_0^T\norm{u}^2_{H^2(\Omega)} +  h^4\int_0^T Q^2 + \norm{\theta_h^l(0)}_{L^2(\Omega)}^2
\end{align*}

A triangle inequality applied to $\norm{\theta_h^l(0)}_{L^2(\Omega)}^2$, an application of \cref{prop:ritz} and the definition of $Q$ bring us to:


\begin{align*}
	 h^{-4}\norm{e(t)}_{L^2(\Omega)}^2 + h^{-2}\int_0^T\norm{e}^2_{H^1(\Omega)} \lesssim\\
	  \norm{u(t)}_{H^2(\Omega)}^2 + \norm{g_D(t)}_{L^2(\Gamma_D)}^2 + \int_0^T\norm{u}^2_{H^2(\Omega)} + \norm{u_0}_{H^2(\Omega)}^2 \\
	 +  \int_0^T C_f^2 + \int_0^T \norm{f_h}_{H^1(\Omega_h)}^2+  \int_0^T  \norm{g_N}_{H^2(\Gamma_N)}^2 +\int_0^T \norm{\partial_t u}_{H^2(\Omega)}^2 + \int_0^T\norm{ \partial_t g_D}_{H^2(\Gamma_D)}^2
\end{align*}

This means that:

\begin{align*}
	 h^{-4}\norm{e(t)}_{L^2(\Omega)}^2 + h^{-2}\int_0^T\norm{e}^2_{H^1(\Omega)} \lesssim\\
	 \norm{u}_{H^1(I,H^2(\Omega))}^2 + \norm{g_D}_{H^1(I,H^2(\Gamma_D))}^2 + \norm{u_0}_{H^2(\Omega)}^2 +  \int_0^T C_f^2+ \int_0^T \norm{f_h}_{H^1(\Omega_h)}^2 +  \int_0^T  \norm{g_N}_{H^2(\Gamma_N)}^2
\end{align*}

\end{mproof}

We can also prove convergence of the derivatives in a rather strong norm.

\begin{cor}[Refined error estimate]
\label{cor:L2_deriv_est}
Apart from \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix}, further assume that $g_{N}\in H^1(I, H^2(\Gamma_N))$. Then, for all $t \in (0,T)$:

\begin{align*}
	\int_0^T\norm{\partial_tu - (\partial_t u_h)^l}^2_{L^2(\Omega)} + \norm{u(t)-u_h^l(t)}_{H^1(\Omega)}^2 \lesssim h^2 B^2
\end{align*}


where $B:=\ds \norm{u}_{H^1(I,H^2(\Omega))}^2 + \norm{g_D}_{H^1(I,H^2(\Gamma_D))}^2 +  \int_0^T C_f^2+  \norm{f_h}_{L^2(I,L^2(\Omega_h))}^2 +\norm{g_N}_{H^1(H^2(\Gamma_N))}^2+\norm{u_0}_{H^2(\Omega)}^2$.

\end{cor}

\begin{mproof}

We employ again the error decomposition $e = \rho + \theta_h^l$.

%\underline{Isomorphism between $H^1$ spaces}
%
%We show that there exists an isomorphism $H^1(\Omega) \rightarrow H^1(\Omega_h)$ that has norms independent of $h$ (for small $h$).
%
%To do so, note that $H^1_T(\Omega_h) = H^1(\Omega_h)$ and $H^1_B(\Omega)=H^1(\Omega)$, where the subscript $B$ means "broken". For a definition of broken Sobolev space, see (4.18), page 1737, \cite{ranner}. The equivalence is proven in lemma 4.20, page 1738. 
%
%The lifting map induces the desired isomorphism between broken spaces, hence, between unbroken spaces, see proposition 8.14, page 1792, \cite{ranner}, where we can also deduce that the norms of such isomorphism can be bounded by numbers that don't depend on $h$.

\underline{Another estimate for $\theta_h$}

Consider again \cref{eqn:theta}:

\begin{align*}
(\partial_t \theta_h , v_h)_{L^2(\Omega_h)} + a_h(\theta_h, v_h) = 
(\partial_t R_h u , v_h)_{L^2(\Omega_h)} - (\partial_t R_c u , v_h^l)_{L^2(\Omega)}\\
- (\partial_t \rho, v_h^l)_{L^2(\Omega)}\\ + (f, v_h^l)_{L^2(\Omega)} - (f_h, v_h)_{L^2(\Omega_h)}\\ + (g_{N}, v_h^l)_{L^2(\Gamma_{N})} - (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})} 
\end{align*}

We intend to test by $\partial_t \theta_h \in L^2(I,S^1_{h,0,D_h})$. This is possible also by the reasonings in \cite{hinze}, (1.61), page 42. Integrate from $0$ to $t$ to obtain:

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \left ( a_h(\theta_h(t), \theta_h(t)) - a_h(\theta_h(0), \theta_h(0))\right ) = 
\int_0^t(\partial_t R_h u , \partial_t\theta_h)_{L^2(\Omega_h)} - \int_0^t(\partial_t R_c u , \partial_t\theta_h^l)_{L^2(\Omega)}\\
- \int_0^t(\partial_t \rho, \partial_t\theta_h^l)_{L^2(\Omega)}\\ + \int_0^t(f, \partial_t\theta_h^l)_{L^2(\Omega)} - \int_0^t(f_h, \partial_t\theta_h)_{L^2(\Omega_h)}\\ + \int_0^t(g_{N}, \partial_t\theta_h^l)_{L^2(\Gamma_{N})} - \int_0^t(g_{N,h}, \partial_t\theta_h)_{L^2(\Gamma_{N_h})} 
\end{align*}

Estimating the left hand side:

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \norm{\theta_h(t)}^2_{H^1(\Omega_h)} \leq  \frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2} \norm{\theta_h(0)}_{H^1(\Omega_h)}^2\\
+\int_0^t(\partial_t R_h u , \partial_t\theta_h)_{L^2(\Omega_h)} - \int_0^t(\partial_t R_c u , \partial_t\theta_h^l)_{L^2(\Omega)}\\
- \int_0^t(\partial_t \rho, \partial_t\theta_h^l)_{L^2(\Omega)}\\ + \int_0^t(f, \partial_t\theta_h^l)_{L^2(\Omega)} - \int_0^t(f_h, \partial_t\theta_h)_{L^2(\Omega_h)}\\ + \int_0^t(g_{N}, \partial_t\theta_h^l)_{L^2(\Gamma_{N})} - \int_0^t(g_{N,h}, \partial_t\theta_h)_{L^2(\Gamma_{N_h})} 
\end{align*}

For the terms with $g_N, g_{N,h}$ we integrate by parts and find:

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \norm{\theta_h(t)}_{H^1(\Omega_h)}^2 \leq  \frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2} \norm{\theta_h(0)}_{H^1(\Omega_h)}^2\\
+\int_0^t(\partial_t R_h u , \partial_t\theta_h)_{L^2(\Omega_h)} - \int_0^t(\partial_t R_c u , \partial_t\theta_h^l)_{L^2(\Omega)}\\
- \int_0^t(\partial_t \rho, \partial_t\theta_h^l)_{L^2(\Omega)}\\ + \int_0^t(f, \partial_t\theta_h^l)_{L^2(\Omega)} - \int_0^t(f_h, \partial_t\theta_h)_{L^2(\Omega_h)}\\ 
-\int_0^t( \partial_t g_{N},\theta_h^l)_{L^2(\Gamma_{N})} + \int_0^t( \partial_t g_{N,h},\theta_h)_{L^2(\Gamma_{N_h})}\\
+ (g_{N}(t) ,\theta_h^l(t))_{L^2(\Gamma_{N})} - ( g_{N,h}(t),\theta_h(t))_{L^2(\Gamma_{N_h})}\\
-(g_{N}(0) ,\theta_h^l(0))_{L^2(\Gamma_{N})} + ( g_{N,h}(0),\theta_h(0))_{L^2(\Gamma_{N_h})}
\end{align*}

For the right hand side, estimating every piece but the first two, with the help of \cref{prop:lin_appr}, and $C$ independent of $h$ and $t$: 

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \norm{\theta_h(t)}_{H^1(\Omega_h)}^2 \leq  \frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2} \norm{\theta_h(0)}_{H^1(\Omega_h)}^2\\
+ Ch\int_0^t \norm{\partial_t u}_{H^2(\Omega)}\norm{\partial_t \theta_h}_{L^2(\Omega_h)}\\
+ Ch\int_0^t(\norm{\partial_t u}_{H^2(\Omega)}+	\norm{\partial_t g_D}_{H^2(\Gamma_D)})\norm{\partial_t \theta_h}_{L^2(\Omega_h)}\\
+ Ch^2\int_0^t C_f\norm{\partial_t \theta_h}_{L^2(\Omega_h)}+ Ch\int_0^t \norm{f_h}_{L^2(\Omega_h)}\norm{\partial_t \theta_h}_{L^2(\Omega_h)}\\ 
+ Ch\int_0^t \norm{\partial_t g_N}_{H^2(\Gamma_N)}\norm{ \theta_h}_{H^1(\Omega_h)}\\
+ Ch\norm{g_N(t)}_{H^2(\Gamma_N)}\norm{ \theta_h(t)}_{H^1(\Omega_h)}\\
+ Ch\norm{g_N(0)}_{H^2(\Gamma_N)}\norm{ \theta_h(0)}_{H^1(\Omega_h)}
\end{align*}

Applying Young's inequality several times, with possibly a different $C$, still independent of $h$ and $t$:

\begin{align*}
\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{2} \norm{\theta_h(t)}_{H^1(\Omega_h)}^2 \leq  \frac{1}{2} \norm{\theta_h(t)}_{L^2(\Omega_h)}^2 + \frac{1}{2} \norm{\theta_h(0)}_{H^1(\Omega_h)}^2\\
+ Ch^2\int_0^t \norm{\partial_t u}_{H^2(\Omega)}^2 + \frac{1}{6}\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)}\\
+ Ch^2\int_0^t(\norm{\partial_t u}_{H^2(\Omega)}+	\norm{\partial_t g_D}_{H^2(\Gamma_D)})^2 + \frac{1}{6} \int_0^t\norm{\partial_t \theta_h}_{L^2(\Omega_h)}^2\\
+ Ch^2\int_0^t C_f^2+ Ch^2\int_0^t \norm{f_h}_{L^2(\Omega_h)}^2  + \frac{1}{6}\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)}\\ 
+ Ch^2\int_0^t \norm{\partial_t g_N}_{H^2(\Gamma_N)}^2 + \int_0^t \norm{ \theta_h}_{H^1(\Omega_h)}^2\\
+ Ch^2\norm{g_N(t)}_{H^2(\Gamma_N)}^2 + \frac{1}{4}\norm{ \theta_h(t)}_{H^1(\Omega_h)}^2\\
+ Ch^2\norm{g_N(0)}_{H^2(\Gamma_N)}^2 + \frac{1}{2}\norm{ \theta_h(0)}_{H^1(\Omega_h)}^2
\end{align*}

We re-arrange, and apply \cref{eqn:theta_energy} to the term $\ds \norm{ \theta_h(t)}^2_{L^2(\Omega_h)} + \int_0^t \norm{ \theta_h}_{H^1(\Omega_h)}^2$. 

Calling $q=\ds \int_0^T \left [ \norm{\partial_t u}_{H^2(\Omega)}^2 +	\norm{\partial_t g_D}_{H^2(\Gamma_D)}^2 + C_f^2 +  \norm{f_h}_{L^2(\Omega_h)}^2 + Q^2+ \norm{g_N}_{H^2(\Gamma_N)}^2 + \norm{\partial_t g_N}_{H^2(\Gamma_N)}^2 \right ] $ we read:


\begin{align*}
\frac{1}{2}\int_0^t\norm{\partial_t \theta_h}^2_{L^2(\Omega_h)} + \frac{1}{4} \norm{\theta_h(t)}_{H^1(\Omega_h)}^2 \lesssim  \norm{\theta_h(0)}_{H^1(\Omega_h)}^2+ h^4q
\end{align*}

or also, upon using \cref{prop:lift}, \cref{prop:ritz} and \cref{prop:interp_curv}:

\begin{align*}
\int_0^T\norm{\partial_t \theta_h^l}^2_{L^2(\Omega)} + \norm{\theta_h(t)^l}_{H^1(\Omega)}^2 \lesssim  \norm{\theta_h(0)}_{H^1(\Omega_h)}^2+ h^4q \lesssim h^2\norm{u_0}_{H^2(\Omega)}^2+ h^4q
\end{align*}

\underline{Conclusion}

There holds 

\begin{align*}
\norm{e(t)}_{H^1(\Omega)}^2 + \int_0^T\norm{\partial_t e}^2_{L^2(\Omega)}  \leq \\
\int_0^T\norm{\partial_t \rho}^2_{L^2(\Omega)} + h^2\norm{\rho(t)}_{H^1(\Omega)}^2 + \int_0^T\norm{\partial_t  \theta_h^l}^2_{L^2(\Omega)} + \norm{ \theta_h^l(t)}_{H^1(\Omega)}^2\leq \ind{above, and \cref{prop:ritz}}\leq \\
h^2\int_0^T(\norm{\partial_t u }_{H^2(\Omega)}^2 + \norm{\partial_t g_D }_{H^2(\Gamma_D)}^2) + h^2\norm{u(t)}_{H^2(\Omega)}^2 +  h^2\norm{u_0}_{H^2(\Omega)}^2+ h^4q
\end{align*}

\end{mproof}

If however we content ourselves with estimating the convergence of the derivatives in a weaker norm, we can actually obtain $O(h^2)$ convergence, in every case. To do so, it will be crucial to establish the $H^1$ stability of the $L^2$ projection in our context. This fact is known for polyhedral domains with some assumptions on the meshes, see e.g. \cite{yserentant}.

\begin{cor}[Order two convergence of derivatives in dual norm]
\label{cor:deriv_est_semid}
Under \cref{ass:smoothness_par_discr}, \cref{ass:discr_reg} and \cref{ass:basic_par_mix} we have, for all $w \in L^2(I,H^1_{0,D}(\Omega))$:

\begin{align*}
\left | \int_I (\partial_t(u-u_h^l), w)_{L^2(\Omega)}\right |\lesssim h^2 A \norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

\end{cor}

\begin{mproof}

We introduce the $L^2$ projection $\pi_h: L^2(\Omega) \rightarrow S^1_{h,0,D_h}$, given by:

$$(\pi_h w, v_h)_{L^2(\Omega_h)}=(w, v_h^l)_{L^2(\Omega)},\quad \forall  v_h \in S^1_{h,0,D_h}$$

The definition is remimniscent of that of the Ritz projection. We will prove well-posedness and $H^k$ stability of such projection, i.e. $\norm{\pi_h w}_{H^k(\Omega_h)}\lesssim\norm{w}_{H^k(\Omega)}$, for $k=0,1$.

First, let us show how this projection helps in the estimate.

\underline{Conclusion}

For $w \in H^1_{0,D}(\Omega)$ we estimate $(\partial_t(\theta_h^l), w)_{L^2(\Omega)} = (w, (\partial_t\theta_h^l))_{L^2(\Omega)} =  (\pi_h w,\partial_t\theta_h)_{L^2(\Omega_h)}$. We have also used that lifting and differentiating with respect to time commute, by \cref{prop:lift} and \cref{lemma:bochner_Hk_map}. We can now apply \cref{eqn:theta}:

\begin{align*}
	(\partial_t(\theta_h^l), w)_{L^2(\Omega)} = a_h(\theta_h, \pi_h w) - E_h(\pi_h w ) \lesssim \ind{\cref{eqn:theta_residual}}\lesssim\\
	\norm{\theta_h}_{H^1(\Omega_h)} \norm{\pi_h w}_{H^1(\Omega_h)} + h^2 (\norm{\pi_h w }_{H^1(\Omega_h)} C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} ) \lesssim\\
	\norm{\theta_h}_{H^1(\Omega_h)} \norm{ w}_{H^1(\Omega)} + h^2 \norm{w }_{H^1(\Omega)} (C_f + \norm{f_h}_{H^1(\Omega_h)} + \norm{g_N}_{H^2(\Gamma_N)} + \norm{\partial_t u}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)} )
\end{align*}

where in the last step we used the supposed stability of $\pi_h$. Integrating in time and using the Cauchy-Schwarz inequality:

\begin{align*}
	\left | \int_I(\partial_t(\theta_h^l), w)_{L^2(\Omega)} \right |^2 \lesssim\\
	\left (\int_I \norm{\theta_h}_{H^1(\Omega_h)}^2+ h^4 \int_I (C_f^2 + \norm{f_h}_{H^1(\Omega_h)}^2 + \norm{g_N}^2_{H^2(\Gamma_N)} + \norm{\partial_t u}^2_{H^2(\Omega)} + \norm{\partial_t g_D}^2_{H^2(\Gamma_D)} )\right) \int_I\norm{ w}_{H^1(\Omega)}^2 \lesssim \ind{\cref{eqn:theta_energy}} \lesssim\\
	h^4 \left (  \int_I Q^2 + \norm{u_0}_{H^2(\Omega)}^2 + \int_I (C_f^2 +\norm{f_h}_{H^1(\Omega_h)}^2 + \norm{g_N}^2_{H^2(\Gamma_N)} + \norm{\partial_t u}^2_{H^2(\Omega)} + \norm{\partial_t g_D}^2_{H^2(\Gamma_D)} )\right) \norm{w}_{L^2(I,H^1(\Omega))}^2
\end{align*}

We can also estimate:
\begin{align*}
\left | \int_I (\rho_t, w)_{L^2(\Omega)}\right |\lesssim \ind{as in the proof of \cref{thm:semidiscrete_error_bound}}\lesssim\\\int_I
h^2 (\norm{\partial_t w}_{H^2(\Omega)} + \norm{\partial_t g_D}_{H^2(\Gamma_D)})\norm{w}_{H^1(\Omega_h)} \lesssim \ind{Cauchy-Schwarz}\lesssim\\
h^2 \sqrt{\norm{\partial_t u}_{H^2(\Omega)}^2 + \norm{\partial_t g_D}_{H^2(\Gamma_D)}^2}\norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

and by the usual splitting $e=\rho + \theta_h^l$ we can conclude.

\underline{$L^2$ projection: well-posedness}

From the definition of $\pi_h$ we obtain:

$$(\pi_h w, v_h)_{L^2(\Omega_h)}=(w, v_h^l)_{L^2(\Omega)}  = (w^{-l} \xi, v_h)_{L^2(\Omega_h)}$$

where $\xi \in L^\infty(\Omega_h)$ is a term originating from the change of variables. We therefore recognize that $\pi_h w$ is the usual $L^2$ projection of $w^{-l} \xi\in L^2(\Omega_h)$ onto the closed subspace $S^1_{h,0,D_h}$, for which we know existence and uniqueness.

\textcolor{red}{To be precise we don't know whether $G_h$ takes measurable functions into measurable functions. But for $L^2$ arguments, we can reason as follows: $w^{-l}$ we know to be piecewise in $L^2$, so we can glue it to an $L^2$ fcn by in case modifying it on a null set. Also $\xi$ is piecewise measurable (it is peicewise $C^1$). So $w^{-l}\xi$ is measurable and $L^2$. Well actually now we know it...}

\underline{$L^2$ projection: stability}

$L^2$ stability of $\pi_h$ follows by testing with $\pi_h w$ itself and using \cref{prop:lift}.

Also, denote by $\pi_h^*$ the usual $L^2$ projector:

$$(\pi_h^* v - v, v_h)_{L^2(\Omega_h)}=0,\quad \forall  v_h \in S^1_{h,0,D_h}$$

We have, for $w \in L^2(\Omega)$, that $(\pi_h w - \pi_h^* w^{-l}, v_h)_{L^2(\Omega_h)} = (w, v_h^l)_{L^2(\Omega)} - (w^{-l}, v_h)_{L^2(\Omega_h)}$. An application of \cref{prop:lin_appr} and of \cref{prop:lift} (\textcolor{red}{4.6 still applies here, do the reasonings elementwise and use lemma 8.16 of \cite{ranner}}) yields:

\begin{align*}
	\norm{\pi_h w - \pi_h^* w^{-l}}^2_{L^2(\Omega_h)}\lesssim h \norm{w}_{L^2(\Omega)}\norm{\pi_h w - \pi_h^* w^{-l}}_{L^2(\Omega_h)}
\end{align*}

Now, we can adapt the original proof of \cite{bank} to our case, see in particular (A.1).

In fact: $|\pi_h w|_{H^1(\Omega_h)}\leq |\pi_h w -\pi^* w^{-l}|_{H^1(\Omega_h)} + |\pi_h^* w^{-l}|_{H^1(\Omega_h)}$.

We can apply an inverse inequality to the first member: $|\pi_h w -\pi^* w^{-l}|_{H^1(\Omega_h)}\lesssim h^{-1}\norm{\pi_h w -\pi^* w^{-l}}_{L^2(\Omega_h)}\lesssim \norm{w}_{L^2(\Omega)}$.

For the second term, consider a suitable $w_h \in S^{1}_{h,0,D_h}$. We have: $|\pi_h^* w^{-l}|_{H^1(\Omega_h)}\leq |\pi_h^* (w^{-l}-w_h)|_{H^1(\Omega_h)} +|\pi_h^* w_h|_{H^1(\Omega_h)}\lesssim h^{-1}\norm{\pi_h^*(w^{-l}-w_h)}_{L^2(\Omega_h)} +\norm{w_h}_{H^1(\Omega_h)}$, where we again applied inverse inequalities, together with the fact that $\pi_h^* w_h = w_h$ for $w_h \in S^1_{h,0,D_h}$ (i.e $\pi_h^*$ is really a projection, unlike $\pi_h$). Moreover, $\norm{\pi_h^* v}_{L^2(\Omega_h)}\leq \norm{v}_{L^2(\Omega_h)}$, so that $|\pi_h^* w^{-l}|_{H^1(\Omega_h)} \lesssim h^{-1}\norm{w^{-l}-w_h}_{L^2(\Omega_h)} +\norm{w_h}_{H^1(\Omega_h)}$

So, if there holds $\norm{w^{-l}-w_h}_{L^2(\Omega_h)}\lesssim h \norm{w}_{H^1(\Omega)}$ and $\norm{w_h}_{H^1(\Omega_h)}\lesssim \norm{w}_{H^1(\Omega)}$, then we are done.

\textcolor{red}{what is h??? Also throughout the rest of the thesis... I checked this, it is the maximum $h_K$ in the linear triangulation for Ranner, and a parameter that I can choose to be $h$ of Ranner, in Bernardi}

\underline{Finding $w_h$}

Such $w_h$ will be the optimal order interpolator with boundary conditions described in (5.9) at page 1230, \cite{bernardi}. We need to check that our framework matches that of \cite{bernardi} to apply such a result.

But this is ensured by the construction outlined in \cite{ranner}, sections 8.5 and 8.6. The assumptions of theorem 5.1, in particular, are all satisfied: that the triangulations satisfy the so called $1$-regularity is proved in lemma 8.13 or \cite{ranner}, whereas all the other properties are already discussed in \cite{bernardi} following example 2 (see pages 1216, 1221, 1228, and remark 5.2 at page 1230).

Applying corollary 5.1 of \cite{bernardi} to $\Gamma_0=\Gamma_D$ ($\Gamma_0$ is in the notation of \cite{bernardi}) we find $w_h \in S^{1}_{h,0,D_h}$ (true by proposition and corollary 5.1, \cite{bernardi}), with:

\begin{itemize}
	\item $\norm{w-w_h^l}_{L^2(\Omega)}\lesssim h \norm{w}_{H^1(\Omega)}$
	\item $|w-w_h^l|_{H^1(\Omega)}\lesssim \norm{w}_{H^1(\Omega)}$
\end{itemize}

Therefore we also get $\norm{w_h^l}_{H^1(\Omega)} \lesssim(C(1+h)+1)\norm{w}_{H^1(\Omega)}$.

Applying \cref{prop:lift} we see that $w_h$ satisfies all the requirements. Note, is is essential here that $w=0$ on $\Gamma_D$.

%\textcolor{red}{One could be extra careful here, or maybe just assume the existence of $u_h$}

\end{mproof}

\subsection{Fully discrete estimates}

Here, we attempt at deriving fully discrete estimates given the semidiscrete results just above. We found difficulties in adapting the arguments of \cite{thomee}, and this is the main reason for passing through the semidiscrete world at first. In particular, one would have to compare at some point quantities similar to $(\partial_t u, e_h^l)_{L^2(\Omega)}$ and $(\partial_t u_h, e_h)_{L^2(\Omega_h)}$, for $e_h$ the discretization error we want to bound. This difference is $O(h^2)$, but then $H^1$ norms of $e_h$ appear, which makes it difficult to apply some algebraic manipulations to bound the weaker $L^2$ norm. To keep only $L^2$ norms, one has to content himself with an $O(h)$ discrepancy in the aforementioned term, which would yield suboptimal results.

\begin{ass}[Assumptions for full discretization]
\label{ass:full_discr_smoothness}
\textcolor{white}{ }

We discuss the implicit Euler method ($\theta=1$) and the Crank-Nicolson method ($\theta=1/2$).

We ask \cref{ass:discr_reg}.

We further assume:

\begin{itemize}
	\item $g_N \in H^{1/\theta}(I, H^2(\Gamma_N))$
	\item $g_D \in H^{1/\theta+1}(I, H^{3/2}(\Gamma_D))$
	\item $f_h\in H^{1/\theta}(I, S^1_{h})$
	\item $\norm{\delta_{h}(0)^{(1/\theta)}}_{L^2(\Omega_h)}$ is bounded uniformly for small $h$
\end{itemize}

\end{ass}

We consider $f_h^k$ to be a suitable approximation of $f_h(t^k)$, i.e. $f_h^k \simeq f_h(t^k)$.

\begin{pb}[Numerical scheme]
\label{pb:num_scheme}
Under \cref{ass:full_discr_smoothness}, it is:

\begin{align*}
\left ( \frac{u_{h}^{k+1}-u_h^k}{\delta t}, v_h\right)_{L^2(\Omega_h)} + a_h(\theta u_h^{k+1}+(1-\theta)u^k_h, v_h) =\\ (\theta f_h^{k+1}+(1-\theta)f_h^k, v_h)_{L^2(\Omega_h)} + (\theta g_{N,h}^{k+1} + (1 - \theta)g_{N,h}^{k} , v_h)_{L^2(\Gamma_{N_h})},\quad v_h \in S^1_{h,0,D_h}, 1\leq k \leq K\\
u_h^{k+1}=g_{D,h}^{k+1},\quad 1\leq k \leq K \text{,  on } \Gamma_{D_h}\\
u_h^0=u_{0h}
\end{align*}

\end{pb}

\begin{prop}[Discrete versus semidiscrete]
\label{prop:d_vd_sd}
We are working under \cref{{ass:full_discr_smoothness}}.

Call $e_h^k:=u_h^k-u_h(t^k)$ and $\delta f_h^k:=f_h^k-f_h(t^k)$. Then, for $\theta=1, 1/2$, we have $u_h \in H^{1/\theta+1}(I, S^1_h)$ and, for $1\leq n \leq K$:

\begin{align*}
\delta t \sum_{k=0}^{n-1} \norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{(H^1_{0,D_h}(\Omega_h))^*}^2 + \norm{e_{h}^{n}}_{L^2(\Omega_h)}^2 + \delta t \sum_{k=0}^{n-1}\norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 \lesssim \\
D^2 + (\delta t)^{2/\theta} C^2
\end{align*}

where $C^2:=\ds \int_I \norm{f^{(1/\theta)}_h}_{-1,h}^2+\int_I\norm{ g_{N}^{(1/\theta)}}_{H^{2}(\Gamma_{N})}^2 + \int_I\norm{g_D^{(1/\theta+1)}}_{H^{3/2}(\Gamma_D)}^2 + \norm{\delta_{h}(0)^{(1/\theta)}}_{L^2(\Omega_h)}^2$.

Moreover, $\ds D_n^2:= \ds {\delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2}$.

We refer to the proof of \cref{prop:wp_discr_par} for the definition and properties of $\delta_h$.

\end{prop}

Note, the difference quotient is estimated in the dual norm of $H^1_{0,D_h}=\{u \in H^1, u(\Gamma_{D_h})=0\}$.

\begin{mproof}

Recall the semidiscrete problem, \cref{pb:inh_parabolic_discr}, for  $u_h \in H^1(I, S^1_h)$:
 
\begin{align*}
(\partial_t u_h, v_h)_{L^2(\Omega_h)} + a_h(u_h, v_h) = (f_h, v_h)_{L^2(\Omega_h)} + (g_{N,h}, v_h)_{L^2(\Gamma_{N_h})}, v_h \in S^1_{h,0,D_h}, a.e. t\\
u_h=g_{D,h}\text{ for a.e. }t \text{,  on } \Gamma_{D_h}\\
u_h(0)=u_{0h}
\end{align*}

For the $L^2$ estimate we closely follow \cite{quarteroni} here, page 385 and following, in particular, theorem 11.3.1 and 11.3.2.

\underline{Error equation}

We note that the sole smoothness assumptions allow us to conclude that $u_h \in H^2(I, S^1_h)$, so that $\partial_t u_h$ admits pointwise values. Then we have: \textcolor{red}{A $\theta$ is probably missing from $\partial_t$}

\begin{align*}
\left ( \frac{u_{h}(t^{k+1})-u_h(t^k)}{\delta t}, v_h\right)_{L^2(\Omega_h)} + a_h(\theta u_h(t^{k+1}) + (1-\theta) u_h(t^{k}), v_h) =\\ \left ( \frac{u_{h}(t^{k+1})-u_h(t^k)}{\delta t} - \partial_t u_h(t^{k+1}) - (1-\theta)\partial_t u_h(t^k), v_h\right)_{L^2(\Omega_h)} +\\ (\theta f_h(t^{k+1})+(1-\theta)f_h(t^{k}), v_h)_{L^2(\Omega_h)} + (\theta g_{N,h}(t^{k+1})+(1-\theta)g_{N,h}(t^{k}), v_h)_{L^2(\Gamma_{N_h})}
\end{align*}

By the equations for the fully discrete problem, and calling $e_h^k:=u_h^k-u_h(t^k)$, and $\delta f_h^k:=f_h^k-f_h(t^k)$:

\begin{align}
\label{eqn:discr_err}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, v_h\right)_{L^2(\Omega_h)} + a_h(\theta e_h^{k+1}+(1-\theta)e^k_h, v_h) = (\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k, v_h)_{L^2(\Omega_h)} \\
e_h^{k+1}=0  \text{,  on } \Gamma_{D_h}\\
e_h^0=0
\end{align}

where we defined $Q_h^k:\ds =\frac{u_{h}(t^{k+1})-u_h(t^k)}{\delta t} - \partial_t u_h(t^{k+1}) - (1-\theta)\partial_tu_h(t^k)$.

\underline{Stability}

We test the above error equation with $\theta e_h^{k+1}+(1-\theta)e_h^k \in S^1_{h,0,D_h}$ to obtain, also thanks to the $h$ uniform coercivity of $a_h$ we have shown in \cref{thm:H1_est_ell}:

\begin{align*}
\norm{e_{h}^{k+1}}_{L^2(\Omega_h)}^2-\norm{e_h^k}^2_{L^2(\Omega_h)}+ (2\theta -1)\norm{e_h^{k+1}-e_h^{k}}_{L^2(\Omega_h)}^2 + 2C\delta t \norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 \leq \\ 2\delta t \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}\norm{\theta e_h^{k+1}+(1-\theta)e_h^k}_{L^2(\Omega_h)} +\\ 2\delta t \norm{ Q_h^k}_{-1,h}\norm{\theta e_h^{k+1}+(1-\theta)e_h^k}_{H^1(\Omega_h)}
\end{align*}

where $C$ is independent of $h,k$. Here $\norm{w}_{-1,h}:=\ds \sup_{0 \neq v_h \in S^1_{h,0,D_h} }\frac{(w,v_h)_{L^2(\Omega_h)}}{\norm{v_h}_{H^1(\Omega_h)}}$. We now apply Young's inequality and leave out a non-negative term on the left to obtain:

\begin{align*}
\norm{e_{h}^{k+1}}_{L^2(\Omega_h)}^2-\norm{e_h^k}^2_{L^2(\Omega_h)}+ 2(C - 2\epsilon) \delta t \norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 \leq \\
2\delta t\epsilon^{-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + 2\delta t \epsilon^{-1}\norm{ Q_h^k}_{-1,h}^2
\end{align*}

$\epsilon$ must be of course chosen small enough. We then sum from $k=0$ to $n-1$ to obtain:

\begin{align*}
\norm{e_{h}^{n}}_{L^2(\Omega_h)}^2 + \delta t \sum_{k=0}^{n-1}\norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 \lesssim \\
\delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + \delta t \sum_{k=0}^{n-1}\norm{ Q_h^k}_{-1,h}^2
\end{align*}

\underline{Conclusion: $L^2$ estimate}

It remains to qualify $ Q_h^k$.

In the case $\theta = 1/2$, from the smoothness assumptions on the data we obtain $u_h \in H^3(I,S^1_h)$, together with:

\begin{align*}
( u_h''', v_h)_{L^2(\Omega_h)} + a_h(u_h'', v_h) = (f_h'', v_h)_{L^2(\Omega_h)} + (g_{N,h}'', v_h)_{L^2(\Gamma_{N_h})}
\end{align*}

By the smoothness of $u_h$ we obtain $(Q_h^k,v_h)=	\ds \frac{1}{2\delta t}\left(\int_{t^k}^{t^{k+1}}(t^{k+1}-s)(t^k-s)u_h'''(s)ds, v_h\right)_{L^2(\Omega_h)}$, which means that:

$$|(Q_h^k,v_h)|\leq \frac{1}{2\delta t} \sqrt{\int_{t^k}^{t^{k+1}}(t^{k+1}-s)^2(t^k-s)^2ds}\sqrt{\int_{t^k}^{t^{k+1}}(u_h'''(s), v_h)_{L^2(\Omega_h)}^2ds}\leq C \delta t^{3/2}	\sqrt{\int_{t^k}^{t^{k+1}} \norm{u_h'''(s)}_{-1,h}^2 ds} \norm{v_h}_{H^1(\Omega_h)} $$ 

This means that:  $$\delta t \sum_{k=0}^{n-1}\norm{ Q_h^k}_{-1,h}^2\lesssim \delta t^4 \int_I \norm{u_h'''}_{-1,h}^2$$

Differentiating \cref{pb:inh_parabolic_discr} twice we obtain:

$$\norm{u_h'''(t)}_{-1,h}\leq \norm{f''_h}_{-1,h}+\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})} + \norm{u_h''}_{H^1(\Omega_h)}$$

We therefore only need to estimate the very last piece. This is done by energy estimates, as in \cref{prop:wp_discr_par}. 
We consider the splitting $u_h = \delta_h + G_{D,h}$, see \cref{ass:discr_reg}, and estimate $\norm{\delta_h''}_{H^1(\Omega_h)}$. We find out in particular that:

\begin{align*}
	\norm{\delta_h''}_{C([0,T],L^2(\Omega_h))} + \norm{\delta_h''}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h''}_{L^2(I,(S^{1}_{h,0,D_h})^*)} + \norm{g_{N,h}''}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}'''}_{L^2(I,H^1(\Omega_h)))} + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}
\end{align*}

and by definition of $u_h$:

\begin{align}
\label{eqn:dd_est}
\norm{u_h''}_{L^2(I,H^1(\Omega_h))}\lesssim \\\norm{f_h''}_{L^2(I,(S^{1}_{h,0,D_h})^*)} + \norm{g_{N,h}''}_{L^2(I,L^2(\Gamma_{N_h}))} + \norm{G_{D,h}'''}_{L^2(I,H^1(\Omega_h)))} + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}
\end{align}

We only need to estimate the term on the right. Using \cref{eqn:ode} we find out that:

\begin{align*}
	d_h'(0)=-M_h^{-1}(A_h d_h(0)+F_h(0))\\
	d_h''(0)=-M_h^{-1}(A_h d_h'(0)+F_h'(0))
\end{align*}

Under our hypothesis \cref{ass:full_discr_smoothness}, we have that $\norm{\delta_h''(0)}_{L^2(\Omega_h)}^2 = |M^{1/2}_hd_h(0)''|\lesssim C$. This, and \cref{ass:discr_reg}, yield a bound, uniform on $h$, on $\ds \int_I \norm{u_h'''}_{-1,h}^2$.

This bound is:

\begin{align*}
	\int_I \norm{u_h'''(t)}_{-1,h}^2\lesssim \int_I \norm{f''_h}_{-1,h}^2+\int_I\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}^2 + \int_I\norm{G_{D,h}'''}_{H^1(\Omega_h)}^2 + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}^2
\end{align*}

But $\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}=\norm{\Pi_h g_{N}''}_{L^2(\Gamma_{N_h})}$, where $\Pi_h$ is the nodal interpolator (see \cref{ass:discr_reg}). By \cref{prop:lin_appr}, $\norm{g_{N,h}''}_{L^2(\Gamma_{N_h})}\lesssim \norm{\Pi_c g_{N}''}_{L^2(\Gamma_{N})}\leq (1+h^2)\norm{ g_{N}''}_{H^2(\Gamma_{N})}$, where we also used \cref{prop:interp_curv}.

Moreover $\norm{G_{D,h}'''}_{H^1(\Omega_h)} = \norm{\Pi_h G_D'''}_{H^1(\Omega_h)}\lesssim  \norm{\Pi_c G_D'''}_{H^1(\Omega)}\lesssim (1+h)\norm{G_D'''}_{H^2(\Omega)}\lesssim \norm{g_D'''}_{H^{3/2}(\Gamma_D)}$.

Therefore:

\begin{align*}
	\int_I \norm{u_h'''(t)}_{-1,h}^2\lesssim \int_I \norm{f''_h}_{-1,h}^2+\int_I\norm{ g_{N}''}_{H^{2}(\Gamma_{N})}^2 + \int_I\norm{g_D'''}_{H^{3/2}(\Gamma_D)}^2 + \norm{\delta_{h}(0)''}_{L^2(\Omega_h)}^2
\end{align*}


The proof for $\theta=1$ is very similar.

%\underline{Conclusion: estimates in energy norm}
%
%We go back to \cref{eqn:discr_err}. Starting with the case $\theta = 1/2$, we test with $e_h^{k+1}-e_h^{k}$ instead. We obtain:
%
%\begin{align*}
%	a_h((e_h^{k+1}+e^k_h)/2, e_h^{k+1}-e_h^{k}) \leq \frac{1}{2}( \delta f_h^{k+1} + \delta f_h^k + Q_h^k, e_h^{k+1}-e_h^{k})_{L^2(\Omega_h)}
%\end{align*}
%
%This means:
%
%\begin{align*}
%	(\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} - \norm{\nabla e^k_h}_{L^2(I,\Omega_h)})(\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} + \norm{\nabla e^k_h}_{L^2(I,\Omega_h)})\leq\norm{ \delta f_h^{k+1} + \delta f_h^k + Q_h^k}_{-1,h}\norm{ e_h^{k+1}-e_h^{k}}_{H^1(\Omega_h)}
%\end{align*}
%
%Taking again advantage of the $h$ uniform coercivity $\norm{ v_h}_{H^1(\Omega_h)}\lesssim \norm{v_h}_{\nabla (\Omega_h)}$, for any $v_h \in S^1_{h,0,D_h}$, we find:
%
%\begin{align*}
%	\norm{\nabla e_h^{k+1}}_{L^2(I,\Omega_h)} - \norm{\nabla e^k_h}_{L^2(I,\Omega_h)}\lesssim \norm{ \delta f_h^{k+1} + \delta f_h^k + Q_h^k}_{-1,h}
%\end{align*}
%
%\textcolor{red}{what if we are dividing by $0$? Np}

\underline{Conclusion: estimates for the difference quotient}

We go back to \cref{eqn:discr_err}.  We employ the $L^2$ projection $\pi_h^*$ as in the proof of \cref{cor:deriv_est_semid}, where we proved its stabilities properties. Consider then any $v \in H^1_{0,D}(\Omega)$, so that $v^{-l} \in H^1_{0,D_h}(\Omega_h)$ (i.e. $v^{-l}=0$ on $\Gamma_{D_h}$) \textcolor{red}{are you sure :D?}.

Then:

\begin{align}
\label{eqn:der_err_eqn}
\left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, v^{-l}\right)_{L^2(\Omega_h)} = \left ( \frac{e_{h}^{k+1}-e_h^k}{\delta t}, \pi_h^* v^{-l}\right)_{L^2(\Omega_h)} =  \\- a_h(\theta e_h^{k+1}+(1-\theta)e^k_h, \pi_h^* v^{-l}) + (\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k, \pi_h^* v^{-l})_{L^2(\Omega_h)}
\end{align}

which leads us to:

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{(H^1_{0,D_h}(\Omega_h))^*} \lesssim  \\\norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)} + \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k}_{-1,h}
\end{align*}

We thus have:

\begin{align*}
\delta t \sum_{k=0}^{n-1} \norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{(H^1_{0,D_h}(\Omega_h))^*}^2 \lesssim  \\\delta t \sum_{k=0}^{n-1}\norm{\theta e_h^{k+1}+(1-\theta)e^k_h}_{H^1(\Omega_h)}^2 + \delta t \sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2+ \delta t \sum_{k=0}^{n-1} \norm{Q_h^k}_{-1,h}^2\lesssim\\
\delta t \sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 +\\
(\delta t)^{2/\theta} \left( \int_I \norm{f^{(1/\theta)}_h}_{-1,h}^2+\int_I\norm{ g_{N}^{(1/\theta)}}_{H^{2}(\Gamma_{N})}^2 + \int_I\norm{g_D^{(1/\theta+1)}}_{H^{3/2}(\Gamma_D)}^2 + \norm{\delta_{h}(0)^{(1/\theta)}}_{L^2(\Omega_h)}^2\right)
\end{align*}

\end{mproof}

\begin{thm}[Fully discrete estimates]
\label{thm:fully_discr_est_par}
With the hypothesis and notation of \cref{thm:semidiscrete_error_bound}, \cref{prop:d_vd_sd}, \cref{cor:L2_deriv_est}, \cref{cor:deriv_est_semid}, there holds:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim  h^2 A  + D +  (\delta t)^{1/\theta}C\\
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - (u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - (u_h^{k})^l)}_{H^1(\Omega)}^2} \lesssim hB + D + (\delta t)^{1/\theta} C\\
	\left | \int_I (\partial_t u , w_K)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(\Omega)} \right |\lesssim \left ( h^2A + D + (\delta t)^{1/\theta} C\right ) \norm{w_K}_{L^2(I,H^1_{0,D}(\Omega))}
\end{align*}

where $D^2:= \ds {\delta t\sum_{k=0}^{K-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2}$. Here $w_K$ is assumed to be piecewise constant on the time discretization, and with values $w_{K,k}$, on $[t^k,t^{k+1}]$, that belong to $H^1_{0,D}(\Omega)$. \textcolor{red}{If we put $w \in H^(I,H^1_{0,D)}$ this probably still works, by choosing to evaluate the sum on the right on the local averages of $w$, and employing dual estimates for such projection}.
\end{thm}

\begin{mproof}

\underline{$L^2$ norm}

By \cref{thm:semidiscrete_error_bound}, $\norm{u(t)-u_h^l(t)}_{L^2(\Omega)}^2 \lesssim	 h^4A^2$. Combining this with the $L^2$ estimates proved in \cref{prop:d_vd_sd} we see, thanks to \cref{prop:lift}:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim \\ \norm{u(t^k)-u_h^l(t^k)}_{L^2(\Omega)}+ \norm{u_h(t^k)-u_h^k}_{L^2(\Omega)}\lesssim \\A h^2 + \sqrt{\delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} + C (\delta t)^{1/\theta} 
\end{align*}

\underline{$H^1$ norm}

%If we employed \cref{cor:L2_deriv_est}, which yields $\norm{u(t)-u_h^l(t)}_{H^1(\Omega)} \lesssim Bh$, we would obtain a suboptimal estimate in space. We do otherwise: c

Using \cref{prop:d_vd_sd} and \cref{prop:lift}:

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(\Omega)}^2 \lesssim \\
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h(t^{k+1})^l) + (1-\theta)(u(t^{k}) -u_h(t^{k})^l)}_{H^1(\Omega)}^2 + \delta t \sum_{k=0}^{K-1} \norm{\theta e_h^{k+1} + (1-\theta)e_h^k}_{H^1(\Omega)}^2 
\end{align*}

For the case $\theta = 1/2$ one could argue by noticing that $ \ds \frac{e_h(t^k)+e_h(t^{k+1})}{2} = \frac{1}{\delta t}\int_{t^k}^{t^{k+1}}\Pi e_h(s) ds$, bounding the first sum by $\norm{\Pi u - u}_{L^2(I,H^1(\Omega))}^2 + \norm{\Pi u_h^l - u_h^l}_{L^2(I,H^1(\Omega))}^2 + \norm{e_h}_{L^2(I,H^1(\Omega))}^2$,  $\Pi e_h$ being the Lagrangian linear interpolator of $e_h:=u-u_h^l$, and then using the $O(\delta t^2)$ approximation power of $\Pi$, thus obtaining s bound that is  $O(\delta t^4 + h^2)$.

But by employing \cref{cor:L2_deriv_est} the proof simplifies and is fine for both values of $\theta$. In fact: 

\begin{align*}
	\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h(t^{k+1})^l) + (1-\theta)(u(t^{k}) -u_h(t^{k})^l)}_{H^1(\Omega)}^2 \leq \\
	2\delta t \sum_{k=0}^{K} \norm{u(t^{k}) -u_h(t^{k})^l}_{H^1(\Omega)}^2 \lesssim \\
	2 \delta t K h^2 B^2
\end{align*}

%\lesssim\\
%	\delta t \sum_{k=0}^{K-1} B^2 h^2 + \delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + (\delta t)^{2/\theta} C^2 \lesssim\\
%	B^2h^2 + \delta t\sum_{k=0}^{n-1} \norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2 + C^2(\delta t)^{2/\theta}

\underline{Estimate for the derivative}

Let $w \in L^2(I,H^1_{0,D}(\Omega))$ be piecewise constant in time, with values $w_k$ on $[t^k,t^{k+1}]$. We can then write:

\begin{align*}
	\int_I (\partial_t u , w)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)} = \\
	\int_I (\partial_t (u-u_h^l) , w)_{L^2(\Omega)} + \sum_{k=0}^{K-1} \left (\int_{[t^k,t^{k+1}]} \partial_t u_h^l , w_k\right )_{L^2(\Omega)} -\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)} = \\
	\int_I (\partial_t (u-u_h^l) , w)_{L^2(\Omega)} + \delta t \sum_{k=0}^{K-1}\left ( \frac{(e^{k+1}_h)^l - (e_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)}
\end{align*}

For the first term we can use \cref{cor:deriv_est_semid}. For the second one we can write, thanks to \cref{prop:lift} \textcolor{red}{(one is not a FEM function, are we sure this holds? Also, is $w^{-l}$ of zero value???????????)}:

\begin{align*}
	\left | \delta t \sum_{k=0}^{K-1}\left ( \frac{(e^{k+1}_h)^l - (e_h^k)^l}{\delta t} , w_k\right )_{L^2(\Omega)}\right | \lesssim \\
	\delta t h \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)} \norm{w_k}_{H^1(\Omega)} + \delta t \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{-1,h} \norm{w_k}_{H^1(\Omega)} \leq \\
	\left ( h\sqrt{\delta t \sum_{k=0}^{K-1}  \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)}^2}  + \sqrt{ \sum_{k=0}^{K-1}\norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{-1,h}^2}\right ) \norm{w}_{L^2(I,H^1(\Omega))}
\end{align*}

If we can control $\ds \delta t \sum_{k=0}^{K-1} \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)}^2$ we are done, also by the estimates in \cref{prop:d_vd_sd}. 

%On this matter, we can adopt inverse inequalities to get, for $h$ small enough:
%
%\begin{align*}
%	\delta t \sum_{k=0}^{K-1} h^2 \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{H^1(\Omega_h)}^2 \lesssim \delta t \sum_{k=0}^{K-1} \norm{ \frac{e^{k+1}_h - e_h^k}{\delta t}}_{L^2(\Omega_h)}^2
%\end{align*}

We now test \cref{eqn:discr_err} by $\ds \frac{e^{k+1}_h - e_h^k}{\delta t}$. Then:

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 + a_h\left (\theta e_h^{k+1}+(1-\theta)e^k_h, \frac{e^{k+1}_h - e_h^k}{\delta t}\right ) = \left (\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k + Q_h^k, \frac{e^{k+1}_h - e_h^k}{\delta t} \right )_{L^2(\Omega_h)}
\end{align*}

Applying an additional Young's inequality in the case $\theta =  1$ this reads: 

\begin{align*}
\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 + \frac{\norm{\nabla e_h^{k+1}}_{L^2(\Omega_h)}^2}{2\delta t}-  \frac{\norm{\nabla e_h^{k}}_{L^2(\Omega_h)}^2}{2\delta t}\leq  \left (\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)} + \norm{Q_h^k}_{-1,h} \right )\norm{\frac{e^{k+1}_h - e_h^k}{\delta t}}_{H^1(\Omega_h)}
\end{align*}

or also, as $e^0_h=0$:

\begin{align*}
\delta t \sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 \leq  \left (\sqrt{\delta t \sum_{k=0}^{K-1}\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} +\sqrt{\delta t \sum_{k=0}^{K-1}\norm{Q_h^k}_{-1,h}^2} \right )\sqrt{\delta t \sum_{k=0}^{K-1}\norm{\frac{e^{k+1}_h - e_h^k}{\delta t}}_{H^1(\Omega_h)}^2}
\end{align*}


Applying inverse inequalities and by the proof of \cref{prop:d_vd_sd}, for $h$ small:

\begin{align*}
h\sqrt{\delta t\sum_{k=0}^{K-1}\norm{ \frac{e_{h}^{k+1}-e_h^k}{\delta t}}_{L^2(\Omega_h)}^2 }\leq  \sqrt{\delta t \sum_{k=0}^{K-1}\norm{\theta \delta f_h^{k+1}+(1-\theta)\delta f_h^k}_{L^2(\Omega_h)}^2} + (\delta t)^{1/\theta} C
\end{align*}

\end{mproof}


\begin{cor}[Further estimates for $A,B,C,D$]
\label{cor:actual_par_est}
Assume that $f_h^k$ and $f_h$ are the, respectively, fully discrete and semidiscrete solutions (see \cref{pb:num_scheme} and  \cref{pb:inh_parabolic_discr}) of \cref{pb:inh_parabolic}, for which all the assumptions of \cref{thm:fully_discr_est_par} hold (in particular, all the continuous and discrete compatibility conditions).

We assume for simplicity, for the right hand side of the equation of $f$, call it $F$, that $F \in H^{1/\theta}(I,H^2(\Omega))$ and we take $F_h = \Pi_h F$ and $F_h^k=F_h(t^k)$.

We can therefore say that:

\begin{align*}
	\norm{u(t^k)-(u_h^k)^l}_{L^2(\Omega)}\lesssim  h^2 + (\delta t)^{1/\theta}\\
	\sqrt{\delta t \sum_{k=0}^{K-1} \norm{\theta(u(t^{k+1}) - u_h^{k+1})^l) + (1-\theta)(u(t^{k}) - u_h^{k})^l)}_{H^1(\Omega)}^2} \lesssim h + (\delta t)^{1/\theta}\\
	\left | \int_I (\partial_t u , w_K)_{L^2(\Omega)}-\delta t \sum_{k=0}^{K-1}\left ( \frac{(u^{k+1}_h)^l - (u_h^k)^l}{\delta t} , w_{K,k}\right )_{L^2(\Omega)} \right |\lesssim \left ( h^2 + (\delta t)^{1/\theta} \right ) \norm{w_K}_{L^2(I,H^1_{0,D}(\Omega))}
\end{align*}

and $w_K$ is as in \cref{thm:fully_discr_est_par}.

Note, the Dirichlet and Neumann boundaries need not to be the same for $f$, $u$.

\end{cor}


\begin{mproof}

We start to establish semidiscrete and fully discrete estimates for $f$.

We assume the following notation for its problem, see \cref{pb:inh_parabolic}:

$$
\left\{\begin{matrix}
\partial_t f-\Delta f = F & \text{ on } \Omega \times I \\ 
f = \gamma_D & \text{ on } \Gamma_D' \times I\\ 
\partial_\nu f = \gamma_N & \text{ on } \Gamma_N' \times I \\
f(0) =  f_0
\end{matrix}\right.
$$

By our hypothesis, we can apply \cref{thm:fully_discr_est_par} to $f$ and obtain error bounds with constants $A(f), B(f), C(f), D(f)$ which we now show to be bounded, uniformly with respect to $h, \delta t$.

In particular, by the choice of $F_h^k$, we see that $D(f)=0$.

For $C(f)$, the requirement of compatibilty leaves only one last bound to be made, that on $\ds \int_I\norm{F_h^{(1/\theta)}}_{-1,h}^2$. This one is surely bounded with $h$, by the choice of $F_h=\Pi_h F$, the time smoothness of $F$, and \cref{prop:interp_curv}.

For $A(f), B(f)$ we only need to estimate $\ds \int_I C_F^2$ and $\ds \int_I \norm{F_h}_{H^1(\Omega_h)}^2$. The latter term is done as above. Morevoer, by \cref{prop:interp_curv}, $C_F$ is just $\norm{F}_{H^2(\Omega)}$, whose integral in time is bounded by assumption.

Therefore, \cref{prop:d_vd_sd} yields the estimate:

\begin{align*}
	D^2 = \delta t \sum_{k=0}^{K-1} \norm{\theta(f_h(t^{k+1}) - f_h^{k+1}) + (1-\theta)(f_h(t^{k}) - f_h^{k})}_{H^1(\Omega)}^2 \lesssim (\delta t)^{2/\theta}
\end{align*}

and $C_f = A_f$ by \cref{thm:semidiscrete_error_bound}.

There remains to check that $A, B, C$ are also bounded with $h, \delta t$.

For $C$, the assumed compatibility requirements leave us only the estimation of $\ds\int_I\norm{f_h^{(1/\theta)}}_{-1,h}^2$. To avoid complications with the fact that  this dual norm $\{-1,h\}$ might not actually be the same dual norm of the problem of $f$ (in fact, the Dirichlet and Neumann boundaries may not be the same between $f$ and $u$), we proceed to estimate the stronger $L^2(\Omega_h)$ norm. This can be done as above \cref{eqn:dd_est}. The bound uniform on $h$ is again a consequence of the assumed compatibility conditions, and the fact that $\norm{F_h^{(2/\theta)}}_{L^2(I,L^2(\Omega_h))} $ is bounded, by the requirements on $F$.

There remains to bound $A, B$. Our smoothness assumptions allow us to only check $A$, where we see that we need to bound $\ds \int C_f^2$ (already done, by above $C_f=A_f$) and $\ds \int_I \norm{F_h}_{H^1(\Omega_h)}^2$. This term is bounded by basic energy estimates on $f_h$.

This concludes the proof of $7$, that of $9$ follows just like $6$ implied $8$, see above.

\end{mproof}

\textcolor{red}{Make a comment on why imposing BCs with interpolation of nodal values exactly on the boundary, is the right thing to do, in shape optimization... for instance, when the boundary moves, a projected bc would also move and we would need to know the exact transformation etc}

\textcolor{red}{One could be extraprecise and track the dependence on $\Omega$ too, this is very difficult though}
\end{appendices}

\printbibliography[title={Bibliography}]

\addcontentsline{toc}{chapter}{Bibliography}

\end{document}
